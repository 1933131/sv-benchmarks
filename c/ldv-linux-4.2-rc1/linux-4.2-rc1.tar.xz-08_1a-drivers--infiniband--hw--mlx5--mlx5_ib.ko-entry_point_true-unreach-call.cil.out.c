extern void __VERIFIER_error() __attribute__ ((__noreturn__));
/* Generated by CIL v. 1.5.1 */
/* print_CIL_Input is false */

#line 20 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned char __u8;
#line 23 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned short __u16;
#line 25 "include/uapi/asm-generic/int-ll64.h"
typedef int __s32;
#line 26 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned int __u32;
#line 30 "include/uapi/asm-generic/int-ll64.h"
typedef unsigned long long __u64;
#line 15 "include/asm-generic/int-ll64.h"
typedef signed char s8;
#line 16 "include/asm-generic/int-ll64.h"
typedef unsigned char u8;
#line 19 "include/asm-generic/int-ll64.h"
typedef unsigned short u16;
#line 21 "include/asm-generic/int-ll64.h"
typedef int s32;
#line 22 "include/asm-generic/int-ll64.h"
typedef unsigned int u32;
#line 24 "include/asm-generic/int-ll64.h"
typedef long long s64;
#line 25 "include/asm-generic/int-ll64.h"
typedef unsigned long long u64;
#line 14 "./include/uapi/asm-generic/posix_types.h"
typedef long __kernel_long_t;
#line 15 "./include/uapi/asm-generic/posix_types.h"
typedef unsigned long __kernel_ulong_t;
#line 27 "./include/uapi/asm-generic/posix_types.h"
typedef int __kernel_pid_t;
#line 48 "./include/uapi/asm-generic/posix_types.h"
typedef unsigned int __kernel_uid32_t;
#line 49 "./include/uapi/asm-generic/posix_types.h"
typedef unsigned int __kernel_gid32_t;
#line 71 "./include/uapi/asm-generic/posix_types.h"
typedef __kernel_ulong_t __kernel_size_t;
#line 72 "./include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_ssize_t;
#line 87 "./include/uapi/asm-generic/posix_types.h"
typedef long long __kernel_loff_t;
#line 88 "./include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_time_t;
#line 89 "./include/uapi/asm-generic/posix_types.h"
typedef __kernel_long_t __kernel_clock_t;
#line 90 "./include/uapi/asm-generic/posix_types.h"
typedef int __kernel_timer_t;
#line 91 "./include/uapi/asm-generic/posix_types.h"
typedef int __kernel_clockid_t;
#line 33 "include/uapi/linux/types.h"
typedef __u16 __be16;
#line 35 "include/uapi/linux/types.h"
typedef __u32 __be32;
#line 37 "include/uapi/linux/types.h"
typedef __u64 __be64;
#line 229 "include/linux/compiler.h"
struct kernel_symbol {
   unsigned long value ;
   char const   *name ;
};
#line 33 "include/linux/export.h"
struct module;
#line 12 "include/linux/types.h"
typedef __u32 __kernel_dev_t;
#line 15 "include/linux/types.h"
typedef __kernel_dev_t dev_t;
#line 18 "include/linux/types.h"
typedef unsigned short umode_t;
#line 21 "include/linux/types.h"
typedef __kernel_pid_t pid_t;
#line 26 "include/linux/types.h"
typedef __kernel_clockid_t clockid_t;
#line 29 "include/linux/types.h"
typedef _Bool bool;
#line 31 "include/linux/types.h"
typedef __kernel_uid32_t uid_t;
#line 32 "include/linux/types.h"
typedef __kernel_gid32_t gid_t;
#line 45 "include/linux/types.h"
typedef __kernel_loff_t loff_t;
#line 54 "include/linux/types.h"
typedef __kernel_size_t size_t;
#line 59 "include/linux/types.h"
typedef __kernel_ssize_t ssize_t;
#line 69 "include/linux/types.h"
typedef __kernel_time_t time_t;
#line 102 "include/linux/types.h"
typedef __s32 int32_t;
#line 108 "include/linux/types.h"
typedef __u32 uint32_t;
#line 111 "include/linux/types.h"
typedef __u64 uint64_t;
#line 152 "include/linux/types.h"
typedef u64 dma_addr_t;
#line 157 "include/linux/types.h"
typedef unsigned int gfp_t;
#line 159 "include/linux/types.h"
typedef unsigned int oom_flags_t;
#line 162 "include/linux/types.h"
typedef u64 phys_addr_t;
#line 167 "include/linux/types.h"
typedef phys_addr_t resource_size_t;
#line 177 "include/linux/types.h"
struct __anonstruct_atomic_t_6 {
   int counter ;
};
#line 177 "include/linux/types.h"
typedef struct __anonstruct_atomic_t_6 atomic_t;
#line 182 "include/linux/types.h"
struct __anonstruct_atomic64_t_7 {
   long counter ;
};
#line 182 "include/linux/types.h"
typedef struct __anonstruct_atomic64_t_7 atomic64_t;
#line 183 "include/linux/types.h"
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
#line 188
struct hlist_node;
#line 188 "include/linux/types.h"
struct hlist_head {
   struct hlist_node *first ;
};
#line 192 "include/linux/types.h"
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
#line 203 "include/linux/types.h"
struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head * ) ;
};
#line 67 "./arch/x86/include/asm/page_types.h"
struct pt_regs {
   unsigned long r15 ;
   unsigned long r14 ;
   unsigned long r13 ;
   unsigned long r12 ;
   unsigned long bp ;
   unsigned long bx ;
   unsigned long r11 ;
   unsigned long r10 ;
   unsigned long r9 ;
   unsigned long r8 ;
   unsigned long ax ;
   unsigned long cx ;
   unsigned long dx ;
   unsigned long si ;
   unsigned long di ;
   unsigned long orig_ax ;
   unsigned long ip ;
   unsigned long cs ;
   unsigned long flags ;
   unsigned long sp ;
   unsigned long ss ;
};
#line 66 "./arch/x86/include/asm/ptrace.h"
struct __anonstruct____missing_field_name_9 {
   unsigned int a ;
   unsigned int b ;
};
#line 66 "./arch/x86/include/asm/ptrace.h"
struct __anonstruct____missing_field_name_10 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
};
#line 66 "./arch/x86/include/asm/ptrace.h"
union __anonunion____missing_field_name_8 {
   struct __anonstruct____missing_field_name_9 __annonCompField4 ;
   struct __anonstruct____missing_field_name_10 __annonCompField5 ;
};
#line 66 "./arch/x86/include/asm/ptrace.h"
struct desc_struct {
   union __anonunion____missing_field_name_8 __annonCompField6 ;
};
#line 12 "./arch/x86/include/asm/pgtable_64_types.h"
typedef unsigned long pteval_t;
#line 15 "./arch/x86/include/asm/pgtable_64_types.h"
typedef unsigned long pgdval_t;
#line 16 "./arch/x86/include/asm/pgtable_64_types.h"
typedef unsigned long pgprotval_t;
#line 18 "./arch/x86/include/asm/pgtable_64_types.h"
struct __anonstruct_pte_t_11 {
   pteval_t pte ;
};
#line 18 "./arch/x86/include/asm/pgtable_64_types.h"
typedef struct __anonstruct_pte_t_11 pte_t;
#line 20 "./arch/x86/include/asm/pgtable_64_types.h"
struct pgprot {
   pgprotval_t pgprot ;
};
#line 218 "./arch/x86/include/asm/pgtable_types.h"
typedef struct pgprot pgprot_t;
#line 220 "./arch/x86/include/asm/pgtable_types.h"
struct __anonstruct_pgd_t_12 {
   pgdval_t pgd ;
};
#line 220 "./arch/x86/include/asm/pgtable_types.h"
typedef struct __anonstruct_pgd_t_12 pgd_t;
#line 361
struct page;
#line 361 "./arch/x86/include/asm/pgtable_types.h"
typedef struct page *pgtable_t;
#line 372
struct file;
#line 385
struct seq_file;
#line 423
struct thread_struct;
#line 425
struct mm_struct;
#line 426
struct task_struct;
#line 427
struct cpumask;
#line 20 "./arch/x86/include/asm/spinlock_types.h"
struct qspinlock {
   atomic_t val ;
};
#line 33 "include/asm-generic/qspinlock_types.h"
typedef struct qspinlock arch_spinlock_t;
#line 34 "include/asm-generic/qspinlock_types.h"
struct qrwlock {
   atomic_t cnts ;
   arch_spinlock_t lock ;
};
#line 14 "include/asm-generic/qrwlock_types.h"
typedef struct qrwlock arch_rwlock_t;
#line 131 "include/linux/init.h"
typedef void (*ctor_fn_t)(void);
#line 234 "include/linux/printk.h"
struct _ddebug {
   char const   *modname ;
   char const   *function ;
   char const   *filename ;
   char const   *format ;
   unsigned int lineno : 18 ;
   unsigned char flags ;
};
#line 48 "include/linux/dynamic_debug.h"
struct device;
#line 432 "include/linux/printk.h"
struct completion;
#line 555 "./arch/x86/include/asm/percpu.h"
struct bug_entry {
   int bug_addr_disp ;
   int file_disp ;
   unsigned short line ;
   unsigned short flags ;
};
#line 102 "include/linux/bug.h"
struct timespec;
#line 103
struct compat_timespec;
#line 104 "include/linux/bug.h"
struct __anonstruct_futex_16 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};
#line 104 "include/linux/bug.h"
struct __anonstruct_nanosleep_17 {
   clockid_t clockid ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
#line 104
struct pollfd;
#line 104 "include/linux/bug.h"
struct __anonstruct_poll_18 {
   struct pollfd *ufds ;
   int nfds ;
   int has_timeout ;
   unsigned long tv_sec ;
   unsigned long tv_nsec ;
};
#line 104 "include/linux/bug.h"
union __anonunion____missing_field_name_15 {
   struct __anonstruct_futex_16 futex ;
   struct __anonstruct_nanosleep_17 nanosleep ;
   struct __anonstruct_poll_18 poll ;
};
#line 104 "include/linux/bug.h"
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion____missing_field_name_15 __annonCompField7 ;
};
#line 127 "./arch/x86/include/uapi/asm/vm86.h"
struct kernel_vm86_regs {
   struct pt_regs pt ;
   unsigned short es ;
   unsigned short __esh ;
   unsigned short ds ;
   unsigned short __dsh ;
   unsigned short fs ;
   unsigned short __fsh ;
   unsigned short gs ;
   unsigned short __gsh ;
};
#line 79 "./arch/x86/include/asm/vm86.h"
union __anonunion____missing_field_name_19 {
   struct pt_regs *regs ;
   struct kernel_vm86_regs *vm86 ;
};
#line 79 "./arch/x86/include/asm/vm86.h"
struct math_emu_info {
   long ___orig_eip ;
   union __anonunion____missing_field_name_19 __annonCompField8 ;
};
#line 328 "include/linux/bitmap.h"
struct cpumask {
   unsigned long bits[128U] ;
};
#line 15 "include/linux/cpumask.h"
typedef struct cpumask cpumask_t;
#line 652 "include/linux/cpumask.h"
typedef struct cpumask *cpumask_var_t;
#line 260 "./arch/x86/include/asm/special_insns.h"
struct fregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
#line 26 "./arch/x86/include/asm/fpu/types.h"
struct __anonstruct____missing_field_name_29 {
   u64 rip ;
   u64 rdp ;
};
#line 26 "./arch/x86/include/asm/fpu/types.h"
struct __anonstruct____missing_field_name_30 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
#line 26 "./arch/x86/include/asm/fpu/types.h"
union __anonunion____missing_field_name_28 {
   struct __anonstruct____missing_field_name_29 __annonCompField12 ;
   struct __anonstruct____missing_field_name_30 __annonCompField13 ;
};
#line 26 "./arch/x86/include/asm/fpu/types.h"
union __anonunion____missing_field_name_31 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
#line 26 "./arch/x86/include/asm/fpu/types.h"
struct fxregs_state {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion____missing_field_name_28 __annonCompField14 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion____missing_field_name_31 __annonCompField15 ;
};
#line 66 "./arch/x86/include/asm/fpu/types.h"
struct swregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};
#line 155 "./arch/x86/include/asm/fpu/types.h"
struct xstate_header {
   u64 xfeatures ;
   u64 xcomp_bv ;
   u64 reserved[6U] ;
};
#line 161 "./arch/x86/include/asm/fpu/types.h"
struct xregs_state {
   struct fxregs_state i387 ;
   struct xstate_header header ;
   u8 __reserved[464U] ;
};
#line 179 "./arch/x86/include/asm/fpu/types.h"
union fpregs_state {
   struct fregs_state fsave ;
   struct fxregs_state fxsave ;
   struct swregs_state soft ;
   struct xregs_state xsave ;
};
#line 193 "./arch/x86/include/asm/fpu/types.h"
struct fpu {
   union fpregs_state state ;
   unsigned int last_cpu ;
   unsigned char fpstate_active ;
   unsigned char fpregs_active ;
   unsigned char counter ;
};
#line 170 "./arch/x86/include/asm/processor.h"
struct seq_operations;
#line 369
struct perf_event;
#line 370 "./arch/x86/include/asm/processor.h"
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
   unsigned long sp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
   unsigned short gsindex ;
   unsigned long fs ;
   unsigned long gs ;
   struct fpu fpu ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
   unsigned long ptrace_dr7 ;
   unsigned long cr2 ;
   unsigned long trap_nr ;
   unsigned long error_code ;
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
   unsigned int io_bitmap_max ;
};
#line 23 "include/asm-generic/atomic-long.h"
typedef atomic64_t atomic_long_t;
#line 33 "include/linux/bottom_half.h"
struct lockdep_map;
#line 55 "include/linux/debug_locks.h"
struct stack_trace {
   unsigned int nr_entries ;
   unsigned int max_entries ;
   unsigned long *entries ;
   int skip ;
};
#line 28 "include/linux/stacktrace.h"
struct lockdep_subclass_key {
   char __one_byte ;
};
#line 53 "include/linux/lockdep.h"
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
#line 59 "include/linux/lockdep.h"
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
   unsigned int dep_gen_id ;
   unsigned long usage_mask ;
   struct stack_trace usage_traces[13U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
   unsigned long ops ;
   char const   *name ;
   int name_version ;
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};
#line 144 "include/linux/lockdep.h"
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const   *name ;
   int cpu ;
   unsigned long ip ;
};
#line 205 "include/linux/lockdep.h"
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 1 ;
   unsigned char hardirqs_off : 1 ;
   unsigned short references : 12 ;
   unsigned int pin_count ;
};
#line 546 "include/linux/lockdep.h"
struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
#line 32 "include/linux/spinlock_types.h"
typedef struct raw_spinlock raw_spinlock_t;
#line 33 "include/linux/spinlock_types.h"
struct __anonstruct____missing_field_name_35 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};
#line 33 "include/linux/spinlock_types.h"
union __anonunion____missing_field_name_34 {
   struct raw_spinlock rlock ;
   struct __anonstruct____missing_field_name_35 __annonCompField17 ;
};
#line 33 "include/linux/spinlock_types.h"
struct spinlock {
   union __anonunion____missing_field_name_34 __annonCompField18 ;
};
#line 76 "include/linux/spinlock_types.h"
typedef struct spinlock spinlock_t;
#line 23 "include/linux/rwlock_types.h"
struct __anonstruct_rwlock_t_36 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
#line 23 "include/linux/rwlock_types.h"
typedef struct __anonstruct_rwlock_t_36 rwlock_t;
#line 426 "include/linux/spinlock.h"
struct seqcount {
   unsigned int sequence ;
   struct lockdep_map dep_map ;
};
#line 52 "include/linux/seqlock.h"
typedef struct seqcount seqcount_t;
#line 404 "include/linux/seqlock.h"
struct __anonstruct_seqlock_t_45 {
   struct seqcount seqcount ;
   spinlock_t lock ;
};
#line 404 "include/linux/seqlock.h"
typedef struct __anonstruct_seqlock_t_45 seqlock_t;
#line 598 "include/linux/seqlock.h"
struct timespec {
   __kernel_time_t tv_sec ;
   long tv_nsec ;
};
#line 83 "include/linux/highuid.h"
struct user_namespace;
#line 22 "include/linux/uidgid.h"
struct __anonstruct_kuid_t_46 {
   uid_t val ;
};
#line 22 "include/linux/uidgid.h"
typedef struct __anonstruct_kuid_t_46 kuid_t;
#line 27 "include/linux/uidgid.h"
struct __anonstruct_kgid_t_47 {
   gid_t val ;
};
#line 27 "include/linux/uidgid.h"
typedef struct __anonstruct_kgid_t_47 kgid_t;
#line 36 "include/linux/stat.h"
struct vm_area_struct;
#line 38 "include/linux/wait.h"
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
#line 43 "include/linux/wait.h"
typedef struct __wait_queue_head wait_queue_head_t;
#line 95 "include/linux/nodemask.h"
struct __anonstruct_nodemask_t_48 {
   unsigned long bits[16U] ;
};
#line 95 "include/linux/nodemask.h"
typedef struct __anonstruct_nodemask_t_48 nodemask_t;
#line 13 "include/linux/osq_lock.h"
struct optimistic_spin_queue {
   atomic_t tail ;
};
#line 39 "include/linux/osq_lock.h"
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct task_struct *owner ;
   void *magic ;
   struct lockdep_map dep_map ;
};
#line 67 "include/linux/mutex.h"
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   void *magic ;
};
#line 177
struct rw_semaphore;
#line 178 "include/linux/mutex.h"
struct rw_semaphore {
   long count ;
   struct list_head wait_list ;
   raw_spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct task_struct *owner ;
   struct lockdep_map dep_map ;
};
#line 172 "include/linux/rwsem.h"
struct completion {
   unsigned int done ;
   wait_queue_head_t wait ;
};
#line 437 "include/linux/jiffies.h"
union ktime {
   s64 tv64 ;
};
#line 41 "include/linux/ktime.h"
typedef union ktime ktime_t;
#line 361 "include/linux/rcupdate.h"
struct srcu_struct;
#line 1121 "include/linux/rcupdate.h"
struct timer_list {
   struct hlist_node entry ;
   unsigned long expires ;
   void (*function)(unsigned long  ) ;
   unsigned long data ;
   u32 flags ;
   int slack ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
   struct lockdep_map lockdep_map ;
};
#line 238 "include/linux/timer.h"
struct hrtimer;
#line 239
enum hrtimer_restart;
#line 240 "include/linux/timer.h"
struct rb_node {
   unsigned long __rb_parent_color ;
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
#line 41 "include/linux/rbtree.h"
struct rb_root {
   struct rb_node *rb_node ;
};
#line 838 "include/uapi/linux/sysctl.h"
struct nsproxy;
#line 259 "include/linux/timer.h"
struct workqueue_struct;
#line 260
struct work_struct;
#line 54 "include/linux/workqueue.h"
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
#line 107 "include/linux/workqueue.h"
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   struct workqueue_struct *wq ;
   int cpu ;
};
#line 616 "include/linux/workqueue.h"
struct srcu_struct_array {
   unsigned long c[2U] ;
   unsigned long seq[2U] ;
};
#line 40 "include/linux/srcu.h"
struct rcu_batch {
   struct callback_head *head ;
   struct callback_head **tail ;
};
#line 44 "include/linux/srcu.h"
struct srcu_struct {
   unsigned long completed ;
   struct srcu_struct_array *per_cpu_ref ;
   spinlock_t queue_lock ;
   bool running ;
   struct rcu_batch batch_queue ;
   struct rcu_batch batch_check0 ;
   struct rcu_batch batch_check1 ;
   struct rcu_batch batch_done ;
   struct delayed_work work ;
   struct lockdep_map dep_map ;
};
#line 64 "./arch/x86/include/asm/e820.h"
struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const   *name ;
   unsigned long flags ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};
#line 172 "./arch/x86/include/asm/x86_init.h"
struct pci_dev;
#line 58 "include/linux/pm.h"
struct pm_message {
   int event ;
};
#line 64 "include/linux/pm.h"
typedef struct pm_message pm_message_t;
#line 65 "include/linux/pm.h"
struct dev_pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
   int (*suspend_late)(struct device * ) ;
   int (*resume_early)(struct device * ) ;
   int (*freeze_late)(struct device * ) ;
   int (*thaw_early)(struct device * ) ;
   int (*poweroff_late)(struct device * ) ;
   int (*restore_early)(struct device * ) ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
   int (*runtime_suspend)(struct device * ) ;
   int (*runtime_resume)(struct device * ) ;
   int (*runtime_idle)(struct device * ) ;
};
#line 320
enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
} ;
#line 327
enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
} ;
#line 335
struct wakeup_source;
#line 336
struct wake_irq;
#line 338 "include/linux/pm.h"
struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
   struct list_head clock_list ;
};
#line 553
struct dev_pm_qos;
#line 553 "include/linux/pm.h"
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char async_suspend : 1 ;
   bool is_prepared ;
   bool is_suspended ;
   bool is_noirq_suspended ;
   bool is_late_suspended ;
   bool ignore_children ;
   bool early_init ;
   bool direct_complete ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path ;
   bool syscore ;
   struct timer_list suspend_timer ;
   unsigned long timer_expires ;
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   struct wake_irq *wakeirq ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned char disable_depth : 3 ;
   unsigned char idle_notification : 1 ;
   unsigned char request_pending : 1 ;
   unsigned char deferred_resume : 1 ;
   unsigned char run_wake : 1 ;
   unsigned char runtime_auto : 1 ;
   unsigned char no_callbacks : 1 ;
   unsigned char irq_safe : 1 ;
   unsigned char use_autosuspend : 1 ;
   unsigned char timer_autosuspends : 1 ;
   unsigned char memalloc_noio : 1 ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
   int autosuspend_delay ;
   unsigned long last_busy ;
   unsigned long active_jiffies ;
   unsigned long suspended_jiffies ;
   unsigned long accounting_timestamp ;
   struct pm_subsys_data *subsys_data ;
   void (*set_latency_tolerance)(struct device * , s32  ) ;
   struct dev_pm_qos *qos ;
};
#line 615 "include/linux/pm.h"
struct dev_pm_domain {
   struct dev_pm_ops ops ;
   void (*detach)(struct device * , bool  ) ;
   int (*activate)(struct device * ) ;
   void (*sync)(struct device * ) ;
   void (*dismiss)(struct device * ) ;
};
#line 133 "./arch/x86/include/asm/topology.h"
struct pci_bus;
#line 24 "./arch/x86/include/asm/mmu.h"
struct __anonstruct_mm_context_t_115 {
   void *ldt ;
   int size ;
   unsigned short ia32_compat ;
   struct mutex lock ;
   void *vdso ;
   atomic_t perf_rdpmc_allowed ;
};
#line 24 "./arch/x86/include/asm/mmu.h"
typedef struct __anonstruct_mm_context_t_115 mm_context_t;
#line 1281 "include/linux/mmzone.h"
struct llist_node;
#line 64 "include/linux/llist.h"
struct llist_node {
   struct llist_node *next ;
};
#line 37 "include/linux/kmod.h"
struct cred;
#line 19 "./arch/x86/include/asm/elf.h"
struct inode;
#line 58 "./arch/x86/include/asm/uprobes.h"
struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
   unsigned int saved_trap_nr ;
   unsigned int saved_tf ;
};
#line 66
enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
} ;
#line 73 "./arch/x86/include/asm/uprobes.h"
struct __anonstruct____missing_field_name_148 {
   struct arch_uprobe_task autask ;
   unsigned long vaddr ;
};
#line 73 "./arch/x86/include/asm/uprobes.h"
struct __anonstruct____missing_field_name_149 {
   struct callback_head dup_xol_work ;
   unsigned long dup_xol_addr ;
};
#line 73 "./arch/x86/include/asm/uprobes.h"
union __anonunion____missing_field_name_147 {
   struct __anonstruct____missing_field_name_148 __annonCompField33 ;
   struct __anonstruct____missing_field_name_149 __annonCompField34 ;
};
#line 73
struct uprobe;
#line 73
struct return_instance;
#line 73 "./arch/x86/include/asm/uprobes.h"
struct uprobe_task {
   enum uprobe_task_state state ;
   union __anonunion____missing_field_name_147 __annonCompField35 ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
   struct return_instance *return_instances ;
   unsigned int depth ;
};
#line 94 "include/linux/uprobes.h"
struct xol_area;
#line 95 "include/linux/uprobes.h"
struct uprobes_state {
   struct xol_area *xol_area ;
};
#line 133
struct address_space;
#line 134
struct mem_cgroup;
#line 31 "include/linux/mm_types.h"
typedef void compound_page_dtor(struct page * );
#line 32 "include/linux/mm_types.h"
union __anonunion____missing_field_name_150 {
   struct address_space *mapping ;
   void *s_mem ;
};
#line 32 "include/linux/mm_types.h"
union __anonunion____missing_field_name_152 {
   unsigned long index ;
   void *freelist ;
   bool pfmemalloc ;
};
#line 32 "include/linux/mm_types.h"
struct __anonstruct____missing_field_name_156 {
   unsigned short inuse ;
   unsigned short objects : 15 ;
   unsigned char frozen : 1 ;
};
#line 32 "include/linux/mm_types.h"
union __anonunion____missing_field_name_155 {
   atomic_t _mapcount ;
   struct __anonstruct____missing_field_name_156 __annonCompField38 ;
   int units ;
};
#line 32 "include/linux/mm_types.h"
struct __anonstruct____missing_field_name_154 {
   union __anonunion____missing_field_name_155 __annonCompField39 ;
   atomic_t _count ;
};
#line 32 "include/linux/mm_types.h"
union __anonunion____missing_field_name_153 {
   unsigned long counters ;
   struct __anonstruct____missing_field_name_154 __annonCompField40 ;
   unsigned int active ;
};
#line 32 "include/linux/mm_types.h"
struct __anonstruct____missing_field_name_151 {
   union __anonunion____missing_field_name_152 __annonCompField37 ;
   union __anonunion____missing_field_name_153 __annonCompField41 ;
};
#line 32 "include/linux/mm_types.h"
struct __anonstruct____missing_field_name_158 {
   struct page *next ;
   int pages ;
   int pobjects ;
};
#line 32
struct slab;
#line 32 "include/linux/mm_types.h"
struct __anonstruct____missing_field_name_159 {
   compound_page_dtor *compound_dtor ;
   unsigned long compound_order ;
};
#line 32 "include/linux/mm_types.h"
union __anonunion____missing_field_name_157 {
   struct list_head lru ;
   struct __anonstruct____missing_field_name_158 __annonCompField43 ;
   struct slab *slab_page ;
   struct callback_head callback_head ;
   struct __anonstruct____missing_field_name_159 __annonCompField44 ;
   pgtable_t pmd_huge_pte ;
};
#line 32
struct kmem_cache;
#line 32 "include/linux/mm_types.h"
union __anonunion____missing_field_name_160 {
   unsigned long private ;
   spinlock_t *ptl ;
   struct kmem_cache *slab_cache ;
   struct page *first_page ;
};
#line 32 "include/linux/mm_types.h"
struct page {
   unsigned long flags ;
   union __anonunion____missing_field_name_150 __annonCompField36 ;
   struct __anonstruct____missing_field_name_151 __annonCompField42 ;
   union __anonunion____missing_field_name_157 __annonCompField45 ;
   union __anonunion____missing_field_name_160 __annonCompField46 ;
   struct mem_cgroup *mem_cgroup ;
};
#line 181 "include/linux/mm_types.h"
struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};
#line 266 "include/linux/mm_types.h"
struct __anonstruct_shared_161 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
};
#line 266
struct anon_vma;
#line 266
struct vm_operations_struct;
#line 266
struct mempolicy;
#line 266 "include/linux/mm_types.h"
struct vm_area_struct {
   unsigned long vm_start ;
   unsigned long vm_end ;
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   struct rb_node vm_rb ;
   unsigned long rb_subtree_gap ;
   struct mm_struct *vm_mm ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
   struct __anonstruct_shared_161 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct  const  *vm_ops ;
   unsigned long vm_pgoff ;
   struct file *vm_file ;
   void *vm_private_data ;
   struct mempolicy *vm_policy ;
};
#line 334 "include/linux/mm_types.h"
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
#line 340 "include/linux/mm_types.h"
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
#line 353 "include/linux/mm_types.h"
struct task_rss_stat {
   int events ;
   int count[3U] ;
};
#line 361 "include/linux/mm_types.h"
struct mm_rss_stat {
   atomic_long_t count[3U] ;
};
#line 366
struct kioctx_table;
#line 367
struct linux_binfmt;
#line 367
struct mmu_notifier_mm;
#line 367 "include/linux/mm_types.h"
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   u32 vmacache_seqnum ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   unsigned long mmap_base ;
   unsigned long mmap_legacy_base ;
   unsigned long task_size ;
   unsigned long highest_vm_end ;
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   atomic_long_t nr_ptes ;
   atomic_long_t nr_pmds ;
   int map_count ;
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
   unsigned long hiwater_vm ;
   unsigned long total_vm ;
   unsigned long locked_vm ;
   unsigned long pinned_vm ;
   unsigned long shared_vm ;
   unsigned long exec_vm ;
   unsigned long stack_vm ;
   unsigned long def_flags ;
   unsigned long start_code ;
   unsigned long end_code ;
   unsigned long start_data ;
   unsigned long end_data ;
   unsigned long start_brk ;
   unsigned long brk ;
   unsigned long start_stack ;
   unsigned long arg_start ;
   unsigned long arg_end ;
   unsigned long env_start ;
   unsigned long env_end ;
   unsigned long saved_auxv[46U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   cpumask_var_t cpu_vm_mask_var ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   spinlock_t ioctx_lock ;
   struct kioctx_table *ioctx_table ;
   struct task_struct *owner ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   struct cpumask cpumask_allocation ;
   unsigned long numa_next_scan ;
   unsigned long numa_scan_offset ;
   int numa_scan_seq ;
   bool tlb_flush_pending ;
   struct uprobes_state uprobes_state ;
   void *bd_addr ;
};
#line 15 "include/uapi/linux/elf.h"
typedef __u64 Elf64_Addr;
#line 16 "include/uapi/linux/elf.h"
typedef __u16 Elf64_Half;
#line 20 "include/uapi/linux/elf.h"
typedef __u32 Elf64_Word;
#line 21 "include/uapi/linux/elf.h"
typedef __u64 Elf64_Xword;
#line 190 "include/uapi/linux/elf.h"
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
   unsigned char st_other ;
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
#line 198 "include/uapi/linux/elf.h"
typedef struct elf64_sym Elf64_Sym;
#line 53 "include/linux/elf.h"
union __anonunion____missing_field_name_166 {
   unsigned long bitmap[4U] ;
   struct callback_head callback_head ;
};
#line 53 "include/linux/elf.h"
struct idr_layer {
   int prefix ;
   int layer ;
   struct idr_layer *ary[256U] ;
   int count ;
   union __anonunion____missing_field_name_166 __annonCompField47 ;
};
#line 41 "include/linux/idr.h"
struct idr {
   struct idr_layer *hint ;
   struct idr_layer *top ;
   int layers ;
   int cur ;
   spinlock_t lock ;
   int id_free_cnt ;
   struct idr_layer *id_free ;
};
#line 124 "include/linux/idr.h"
struct ida_bitmap {
   long nr_busy ;
   unsigned long bitmap[15U] ;
};
#line 153 "include/linux/idr.h"
struct ida {
   struct idr idr ;
   struct ida_bitmap *free_bitmap ;
};
#line 185
struct dentry;
#line 189
struct kernfs_open_node;
#line 190
struct kernfs_iattrs;
#line 213
struct kernfs_root;
#line 213 "include/linux/idr.h"
struct kernfs_elem_dir {
   unsigned long subdirs ;
   struct rb_root children ;
   struct kernfs_root *root ;
};
#line 85 "include/linux/kernfs.h"
struct kernfs_node;
#line 85 "include/linux/kernfs.h"
struct kernfs_elem_symlink {
   struct kernfs_node *target_kn ;
};
#line 89
struct kernfs_ops;
#line 89 "include/linux/kernfs.h"
struct kernfs_elem_attr {
   struct kernfs_ops  const  *ops ;
   struct kernfs_open_node *open ;
   loff_t size ;
   struct kernfs_node *notify_next ;
};
#line 96 "include/linux/kernfs.h"
union __anonunion____missing_field_name_171 {
   struct kernfs_elem_dir dir ;
   struct kernfs_elem_symlink symlink ;
   struct kernfs_elem_attr attr ;
};
#line 96 "include/linux/kernfs.h"
struct kernfs_node {
   atomic_t count ;
   atomic_t active ;
   struct lockdep_map dep_map ;
   struct kernfs_node *parent ;
   char const   *name ;
   struct rb_node rb ;
   void const   *ns ;
   unsigned int hash ;
   union __anonunion____missing_field_name_171 __annonCompField48 ;
   void *priv ;
   unsigned short flags ;
   umode_t mode ;
   unsigned int ino ;
   struct kernfs_iattrs *iattr ;
};
#line 138 "include/linux/kernfs.h"
struct kernfs_syscall_ops {
   int (*remount_fs)(struct kernfs_root * , int * , char * ) ;
   int (*show_options)(struct seq_file * , struct kernfs_root * ) ;
   int (*mkdir)(struct kernfs_node * , char const   * , umode_t  ) ;
   int (*rmdir)(struct kernfs_node * ) ;
   int (*rename)(struct kernfs_node * , struct kernfs_node * , char const   * ) ;
};
#line 155 "include/linux/kernfs.h"
struct kernfs_root {
   struct kernfs_node *kn ;
   unsigned int flags ;
   struct ida ino_ida ;
   struct kernfs_syscall_ops *syscall_ops ;
   struct list_head supers ;
   wait_queue_head_t deactivate_waitq ;
};
#line 171 "include/linux/kernfs.h"
struct kernfs_open_file {
   struct kernfs_node *kn ;
   struct file *file ;
   void *priv ;
   struct mutex mutex ;
   int event ;
   struct list_head list ;
   char *prealloc_buf ;
   size_t atomic_write_len ;
   bool mmapped ;
   struct vm_operations_struct  const  *vm_ops ;
};
#line 188 "include/linux/kernfs.h"
struct kernfs_ops {
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   ssize_t (*read)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   size_t atomic_write_len ;
   bool prealloc ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   int (*mmap)(struct kernfs_open_file * , struct vm_area_struct * ) ;
   struct lock_class_key lockdep_key ;
};
#line 477
struct sock;
#line 478
struct kobject;
#line 479
enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
} ;
#line 485 "include/linux/kernfs.h"
struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   bool (*current_may_mount)(void) ;
   void *(*grab_current_ns)(void) ;
   void const   *(*netlink_ns)(struct sock * ) ;
   void const   *(*initial_ns)(void) ;
   void (*drop_ns)(void * ) ;
};
#line 59 "include/linux/kobject_ns.h"
struct bin_attribute;
#line 60 "include/linux/kobject_ns.h"
struct attribute {
   char const   *name ;
   umode_t mode ;
   bool ignore_lockdep ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};
#line 37 "include/linux/sysfs.h"
struct attribute_group {
   char const   *name ;
   umode_t (*is_visible)(struct kobject * , struct attribute * , int  ) ;
   struct attribute **attrs ;
   struct bin_attribute **bin_attrs ;
};
#line 82 "include/linux/sysfs.h"
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                   loff_t  , size_t  ) ;
   ssize_t (*write)(struct file * , struct kobject * , struct bin_attribute * , char * ,
                    loff_t  , size_t  ) ;
   int (*mmap)(struct file * , struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
#line 155 "include/linux/sysfs.h"
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const   * , size_t  ) ;
};
#line 509 "include/linux/sysfs.h"
struct kref {
   atomic_t refcount ;
};
#line 52 "include/linux/kobject.h"
struct kset;
#line 52
struct kobj_type;
#line 52 "include/linux/kobject.h"
struct kobject {
   char const   *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct kernfs_node *sd ;
   struct kref kref ;
   struct delayed_work release ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
   unsigned char uevent_suppress : 1 ;
};
#line 114 "include/linux/kobject.h"
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops  const  *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations  const  *(*child_ns_type)(struct kobject * ) ;
   void const   *(*namespace)(struct kobject * ) ;
};
#line 122 "include/linux/kobject.h"
struct kobj_uevent_env {
   char *argv[3U] ;
   char *envp[32U] ;
   int envp_idx ;
   char buf[2048U] ;
   int buflen ;
};
#line 130 "include/linux/kobject.h"
struct kset_uevent_ops {
   int (* const  filter)(struct kset * , struct kobject * ) ;
   char const   *(* const  name)(struct kset * , struct kobject * ) ;
   int (* const  uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
#line 147 "include/linux/kobject.h"
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops  const  *uevent_ops ;
};
#line 222
struct kernel_param;
#line 227 "include/linux/kobject.h"
struct kernel_param_ops {
   unsigned int flags ;
   int (*set)(char const   * , struct kernel_param  const  * ) ;
   int (*get)(char * , struct kernel_param  const  * ) ;
   void (*free)(void * ) ;
};
#line 62 "include/linux/moduleparam.h"
struct kparam_string;
#line 62
struct kparam_array;
#line 62 "include/linux/moduleparam.h"
union __anonunion____missing_field_name_172 {
   void *arg ;
   struct kparam_string  const  *str ;
   struct kparam_array  const  *arr ;
};
#line 62 "include/linux/moduleparam.h"
struct kernel_param {
   char const   *name ;
   struct module *mod ;
   struct kernel_param_ops  const  *ops ;
   u16 const   perm ;
   s8 level ;
   u8 flags ;
   union __anonunion____missing_field_name_172 __annonCompField49 ;
};
#line 83 "include/linux/moduleparam.h"
struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};
#line 89 "include/linux/moduleparam.h"
struct kparam_array {
   unsigned int max ;
   unsigned int elemsize ;
   unsigned int *num ;
   struct kernel_param_ops  const  *ops ;
   void *elem ;
};
#line 469 "include/linux/moduleparam.h"
struct latch_tree_node {
   struct rb_node node[2U] ;
};
#line 211 "include/linux/rbtree_latch.h"
struct mod_arch_specific {

};
#line 37 "include/linux/module.h"
struct module_param_attrs;
#line 37 "include/linux/module.h"
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
   struct completion *kobj_completion ;
};
#line 47 "include/linux/module.h"
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module_kobject * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module_kobject * , char const   * ,
                    size_t  ) ;
   void (*setup)(struct module * , char const   * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
#line 73
struct exception_table_entry;
#line 206
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2,
    MODULE_STATE_UNFORMED = 3
} ;
#line 213 "include/linux/module.h"
struct mod_tree_node {
   struct module *mod ;
   struct latch_tree_node node ;
};
#line 220
struct module_sect_attrs;
#line 220
struct module_notes_attrs;
#line 220
struct tracepoint;
#line 220
struct trace_event_call;
#line 220
struct trace_enum_map;
#line 220 "include/linux/module.h"
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const   *version ;
   char const   *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol  const  *syms ;
   unsigned long const   *crcs ;
   unsigned int num_syms ;
   struct mutex param_lock ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
   unsigned int num_gpl_syms ;
   struct kernel_symbol  const  *gpl_syms ;
   unsigned long const   *gpl_crcs ;
   struct kernel_symbol  const  *unused_syms ;
   unsigned long const   *unused_crcs ;
   unsigned int num_unused_syms ;
   unsigned int num_unused_gpl_syms ;
   struct kernel_symbol  const  *unused_gpl_syms ;
   unsigned long const   *unused_gpl_crcs ;
   bool sig_ok ;
   bool async_probe_requested ;
   struct kernel_symbol  const  *gpl_future_syms ;
   unsigned long const   *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
   unsigned int num_exentries ;
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
   unsigned int core_size ;
   unsigned int init_text_size ;
   unsigned int core_text_size ;
   struct mod_tree_node mtn_core ;
   struct mod_tree_node mtn_init ;
   unsigned int init_ro_size ;
   unsigned int core_ro_size ;
   struct mod_arch_specific arch ;
   unsigned int taints ;
   unsigned int num_bugs ;
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   Elf64_Sym *core_symtab ;
   unsigned int num_symtab ;
   unsigned int core_num_syms ;
   char *strtab ;
   char *core_strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
   unsigned int num_tracepoints ;
   struct tracepoint * const  *tracepoints_ptrs ;
   unsigned int num_trace_bprintk_fmt ;
   char const   **trace_bprintk_fmt_start ;
   struct trace_event_call **trace_events ;
   unsigned int num_trace_events ;
   struct trace_enum_map **trace_enums ;
   unsigned int num_trace_enums ;
   unsigned int num_ftrace_callsites ;
   unsigned long *ftrace_callsites ;
   bool klp_alive ;
   struct list_head source_list ;
   struct list_head target_list ;
   void (*exit)(void) ;
   atomic_t refcnt ;
   ctor_fn_t (**ctors)(void) ;
   unsigned int num_ctors ;
};
#line 22 "include/linux/capability.h"
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
#line 25 "include/linux/capability.h"
typedef struct kernel_cap_struct kernel_cap_t;
#line 84 "include/linux/plist.h"
struct plist_node {
   int prio ;
   struct list_head prio_list ;
   struct list_head node_list ;
};
#line 4 "include/asm-generic/cputime_jiffies.h"
typedef unsigned long cputime_t;
#line 25 "include/linux/sem.h"
struct sem_undo_list;
#line 25 "include/linux/sem.h"
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
#line 78 "include/uapi/linux/shm.h"
struct user_struct;
#line 26 "include/linux/shm.h"
struct sysv_shm {
   struct list_head shm_clist ;
};
#line 24 "./arch/x86/include/asm/signal.h"
struct __anonstruct_sigset_t_180 {
   unsigned long sig[1U] ;
};
#line 24 "./arch/x86/include/asm/signal.h"
typedef struct __anonstruct_sigset_t_180 sigset_t;
#line 25
struct siginfo;
#line 17 "./include/uapi/asm-generic/signal-defs.h"
typedef void __signalfn_t(int  );
#line 18 "./include/uapi/asm-generic/signal-defs.h"
typedef __signalfn_t *__sighandler_t;
#line 20 "./include/uapi/asm-generic/signal-defs.h"
typedef void __restorefn_t(void);
#line 21 "./include/uapi/asm-generic/signal-defs.h"
typedef __restorefn_t *__sigrestore_t;
#line 34 "./arch/x86/include/asm/signal.h"
union sigval {
   int sival_int ;
   void *sival_ptr ;
};
#line 10 "include/uapi/asm-generic/siginfo.h"
typedef union sigval sigval_t;
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__kill_182 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__timer_183 {
   __kernel_timer_t _tid ;
   int _overrun ;
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__rt_184 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigchld_185 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__addr_bnd_187 {
   void *_lower ;
   void *_upper ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigfault_186 {
   void *_addr ;
   short _addr_lsb ;
   struct __anonstruct__addr_bnd_187 _addr_bnd ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigpoll_188 {
   long _band ;
   int _fd ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct __anonstruct__sigsys_189 {
   void *_call_addr ;
   int _syscall ;
   unsigned int _arch ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
union __anonunion__sifields_181 {
   int _pad[28U] ;
   struct __anonstruct__kill_182 _kill ;
   struct __anonstruct__timer_183 _timer ;
   struct __anonstruct__rt_184 _rt ;
   struct __anonstruct__sigchld_185 _sigchld ;
   struct __anonstruct__sigfault_186 _sigfault ;
   struct __anonstruct__sigpoll_188 _sigpoll ;
   struct __anonstruct__sigsys_189 _sigsys ;
};
#line 11 "include/uapi/asm-generic/siginfo.h"
struct siginfo {
   int si_signo ;
   int si_errno ;
   int si_code ;
   union __anonunion__sifields_181 _sifields ;
};
#line 113 "include/uapi/asm-generic/siginfo.h"
typedef struct siginfo siginfo_t;
#line 22 "include/linux/signal.h"
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
#line 243 "include/linux/signal.h"
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
#line 257 "include/linux/signal.h"
struct k_sigaction {
   struct sigaction sa ;
};
#line 450
struct pid_namespace;
#line 450 "include/linux/signal.h"
struct upid {
   int nr ;
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
#line 56 "include/linux/pid.h"
struct pid {
   atomic_t count ;
   unsigned int level ;
   struct hlist_head tasks[3U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};
#line 68 "include/linux/pid.h"
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
#line 53 "include/uapi/linux/seccomp.h"
struct seccomp_filter;
#line 54 "include/uapi/linux/seccomp.h"
struct seccomp {
   int mode ;
   struct seccomp_filter *filter ;
};
#line 40 "include/linux/rtmutex.h"
struct rt_mutex_waiter;
#line 41 "include/uapi/linux/resource.h"
struct rlimit {
   __kernel_ulong_t rlim_cur ;
   __kernel_ulong_t rlim_max ;
};
#line 11 "include/linux/resource.h"
struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};
#line 12 "include/linux/timerqueue.h"
struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};
#line 50
struct hrtimer_clock_base;
#line 51
struct hrtimer_cpu_base;
#line 60
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
#line 65 "include/linux/timerqueue.h"
struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
#line 123 "include/linux/hrtimer.h"
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   int index ;
   clockid_t clockid ;
   struct timerqueue_head active ;
   ktime_t (*get_time)(void) ;
   ktime_t offset ;
};
#line 156 "include/linux/hrtimer.h"
struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   seqcount_t seq ;
   struct hrtimer *running ;
   unsigned int cpu ;
   unsigned int active_bases ;
   unsigned int clock_was_set_seq ;
   bool migration_enabled ;
   bool nohz_active ;
   unsigned char in_hrtirq : 1 ;
   unsigned char hres_active : 1 ;
   unsigned char hang_detected : 1 ;
   ktime_t expires_next ;
   struct hrtimer *next_timer ;
   unsigned int nr_events ;
   unsigned int nr_retries ;
   unsigned int nr_hangs ;
   unsigned int max_hang_time ;
   struct hrtimer_clock_base clock_base[4U] ;
};
#line 466 "include/linux/hrtimer.h"
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
#line 45 "include/linux/task_io_accounting.h"
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
   unsigned long max ;
};
#line 39 "include/linux/latencytop.h"
struct assoc_array_ptr;
#line 39 "include/linux/latencytop.h"
struct assoc_array {
   struct assoc_array_ptr *root ;
   unsigned long nr_leaves_on_tree ;
};
#line 31 "include/linux/key.h"
typedef int32_t key_serial_t;
#line 34 "include/linux/key.h"
typedef uint32_t key_perm_t;
#line 35
struct key;
#line 36
struct signal_struct;
#line 37
struct key_type;
#line 41 "include/linux/key.h"
struct keyring_index_key {
   struct key_type *type ;
   char const   *description ;
   size_t desc_len ;
};
#line 123 "include/linux/key.h"
union __anonunion____missing_field_name_196 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};
#line 123
struct key_user;
#line 123 "include/linux/key.h"
union __anonunion____missing_field_name_197 {
   time_t expiry ;
   time_t revoked_at ;
};
#line 123 "include/linux/key.h"
struct __anonstruct____missing_field_name_199 {
   struct key_type *type ;
   char *description ;
};
#line 123 "include/linux/key.h"
union __anonunion____missing_field_name_198 {
   struct keyring_index_key index_key ;
   struct __anonstruct____missing_field_name_199 __annonCompField52 ;
};
#line 123 "include/linux/key.h"
union __anonunion_type_data_200 {
   struct list_head link ;
   unsigned long x[2U] ;
   void *p[2U] ;
   int reject_error ;
};
#line 123 "include/linux/key.h"
union __anonunion_payload_202 {
   unsigned long value ;
   void *rcudata ;
   void *data ;
   void *data2[2U] ;
};
#line 123 "include/linux/key.h"
union __anonunion____missing_field_name_201 {
   union __anonunion_payload_202 payload ;
   struct assoc_array keys ;
};
#line 123 "include/linux/key.h"
struct key {
   atomic_t usage ;
   key_serial_t serial ;
   union __anonunion____missing_field_name_196 __annonCompField50 ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion____missing_field_name_197 __annonCompField51 ;
   time_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
   unsigned short datalen ;
   unsigned long flags ;
   union __anonunion____missing_field_name_198 __annonCompField53 ;
   union __anonunion_type_data_200 type_data ;
   union __anonunion____missing_field_name_201 __annonCompField54 ;
};
#line 358
struct audit_context;
#line 27 "include/linux/selinux.h"
struct group_info {
   atomic_t usage ;
   int ngroups ;
   int nblocks ;
   kgid_t small_block[32U] ;
   kgid_t *blocks[0U] ;
};
#line 90 "include/linux/cred.h"
struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   unsigned char jit_keyring ;
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};
#line 369
struct percpu_ref;
#line 55 "include/linux/percpu-refcount.h"
typedef void percpu_ref_func_t(struct percpu_ref * );
#line 68 "include/linux/percpu-refcount.h"
struct percpu_ref {
   atomic_long_t count ;
   unsigned long percpu_count_ptr ;
   percpu_ref_func_t *release ;
   percpu_ref_func_t *confirm_switch ;
   bool force_atomic ;
   struct callback_head rcu ;
};
#line 27 "include/linux/percpu-rwsem.h"
struct cgroup;
#line 28
struct cgroup_root;
#line 29
struct cgroup_subsys;
#line 30
struct cgroup_taskset;
#line 72 "include/linux/percpu-rwsem.h"
struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   struct cgroup_subsys *ss ;
   struct percpu_ref refcnt ;
   struct cgroup_subsys_state *parent ;
   struct list_head sibling ;
   struct list_head children ;
   int id ;
   unsigned int flags ;
   u64 serial_nr ;
   struct callback_head callback_head ;
   struct work_struct destroy_work ;
};
#line 124 "include/linux/cgroup-defs.h"
struct css_set {
   atomic_t refcount ;
   struct hlist_node hlist ;
   struct list_head tasks ;
   struct list_head mg_tasks ;
   struct list_head cgrp_links ;
   struct cgroup *dfl_cgrp ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct list_head mg_preload_node ;
   struct list_head mg_node ;
   struct cgroup *mg_src_cgrp ;
   struct css_set *mg_dst_cset ;
   struct list_head e_cset_node[12U] ;
   struct callback_head callback_head ;
};
#line 197 "include/linux/cgroup-defs.h"
struct cgroup {
   struct cgroup_subsys_state self ;
   unsigned long flags ;
   int id ;
   int populated_cnt ;
   struct kernfs_node *kn ;
   struct kernfs_node *procs_kn ;
   struct kernfs_node *populated_kn ;
   unsigned int subtree_control ;
   unsigned int child_subsys_mask ;
   struct cgroup_subsys_state *subsys[12U] ;
   struct cgroup_root *root ;
   struct list_head cset_links ;
   struct list_head e_csets[12U] ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   wait_queue_head_t offline_waitq ;
   struct work_struct release_agent_work ;
};
#line 270 "include/linux/cgroup-defs.h"
struct cgroup_root {
   struct kernfs_root *kf_root ;
   unsigned int subsys_mask ;
   int hierarchy_id ;
   struct cgroup cgrp ;
   atomic_t nr_cgrps ;
   struct list_head root_list ;
   unsigned int flags ;
   struct idr cgroup_idr ;
   char release_agent_path[4096U] ;
   char name[64U] ;
};
#line 306 "include/linux/cgroup-defs.h"
struct cftype {
   char name[64U] ;
   int private ;
   umode_t mode ;
   size_t max_write_len ;
   unsigned int flags ;
   struct cgroup_subsys *ss ;
   struct list_head node ;
   struct kernfs_ops *kf_ops ;
   u64 (*read_u64)(struct cgroup_subsys_state * , struct cftype * ) ;
   s64 (*read_s64)(struct cgroup_subsys_state * , struct cftype * ) ;
   int (*seq_show)(struct seq_file * , void * ) ;
   void *(*seq_start)(struct seq_file * , loff_t * ) ;
   void *(*seq_next)(struct seq_file * , void * , loff_t * ) ;
   void (*seq_stop)(struct seq_file * , void * ) ;
   int (*write_u64)(struct cgroup_subsys_state * , struct cftype * , u64  ) ;
   int (*write_s64)(struct cgroup_subsys_state * , struct cftype * , s64  ) ;
   ssize_t (*write)(struct kernfs_open_file * , char * , size_t  , loff_t  ) ;
   struct lock_class_key lockdep_key ;
};
#line 388 "include/linux/cgroup-defs.h"
struct cgroup_subsys {
   struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state * ) ;
   int (*css_online)(struct cgroup_subsys_state * ) ;
   void (*css_offline)(struct cgroup_subsys_state * ) ;
   void (*css_released)(struct cgroup_subsys_state * ) ;
   void (*css_free)(struct cgroup_subsys_state * ) ;
   void (*css_reset)(struct cgroup_subsys_state * ) ;
   void (*css_e_css_changed)(struct cgroup_subsys_state * ) ;
   int (*can_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*cancel_attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*attach)(struct cgroup_subsys_state * , struct cgroup_taskset * ) ;
   void (*fork)(struct task_struct * ) ;
   void (*exit)(struct cgroup_subsys_state * , struct cgroup_subsys_state * , struct task_struct * ) ;
   void (*bind)(struct cgroup_subsys_state * ) ;
   int disabled ;
   int early_init ;
   bool broken_hierarchy ;
   bool warned_broken_hierarchy ;
   int id ;
   char const   *name ;
   struct cgroup_root *root ;
   struct idr css_idr ;
   struct list_head cfts ;
   struct cftype *dfl_cftypes ;
   struct cftype *legacy_cftypes ;
   unsigned int depends_on ;
};
#line 128 "include/linux/sched.h"
struct futex_pi_state;
#line 129
struct robust_list_head;
#line 130
struct bio_list;
#line 131
struct fs_struct;
#line 132
struct perf_event_context;
#line 133
struct blk_plug;
#line 135
struct nameidata;
#line 188
struct cfs_rq;
#line 189
struct task_group;
#line 477 "include/linux/sched.h"
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
#line 516 "include/linux/sched.h"
struct pacct_struct {
   int ac_flag ;
   long ac_exitcode ;
   unsigned long ac_mem ;
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
   unsigned long ac_majflt ;
};
#line 524 "include/linux/sched.h"
struct cpu_itimer {
   cputime_t expires ;
   cputime_t incr ;
   u32 error ;
   u32 incr_error ;
};
#line 531 "include/linux/sched.h"
struct cputime {
   cputime_t utime ;
   cputime_t stime ;
};
#line 543 "include/linux/sched.h"
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
};
#line 563 "include/linux/sched.h"
struct task_cputime_atomic {
   atomic64_t utime ;
   atomic64_t stime ;
   atomic64_t sum_exec_runtime ;
};
#line 584 "include/linux/sched.h"
struct thread_group_cputimer {
   struct task_cputime_atomic cputime_atomic ;
   int running ;
};
#line 620
struct autogroup;
#line 621
struct tty_struct;
#line 621
struct taskstats;
#line 621
struct tty_audit_buf;
#line 621 "include/linux/sched.h"
struct signal_struct {
   atomic_t sigcnt ;
   atomic_t live ;
   int nr_threads ;
   struct list_head thread_head ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
   int notify_count ;
   struct task_struct *group_exit_task ;
   int group_stop_count ;
   unsigned int flags ;
   unsigned char is_child_subreaper : 1 ;
   unsigned char has_child_subreaper : 1 ;
   int posix_timer_id ;
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   struct cpu_itimer it[2U] ;
   struct thread_group_cputimer cputimer ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct pid *tty_old_pgrp ;
   int leader ;
   struct tty_struct *tty ;
   struct autogroup *autogroup ;
   seqlock_t stats_lock ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   unsigned long cnvcsw ;
   unsigned long cnivcsw ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   unsigned long cmin_flt ;
   unsigned long cmaj_flt ;
   unsigned long inblock ;
   unsigned long oublock ;
   unsigned long cinblock ;
   unsigned long coublock ;
   unsigned long maxrss ;
   unsigned long cmaxrss ;
   struct task_io_accounting ioac ;
   unsigned long long sum_sched_runtime ;
   struct rlimit rlim[16U] ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
   unsigned int audit_tty_log_passwd ;
   struct tty_audit_buf *tty_audit_buf ;
   oom_flags_t oom_flags ;
   short oom_score_adj ;
   short oom_score_adj_min ;
   struct mutex cred_guard_mutex ;
};
#line 790 "include/linux/sched.h"
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
   unsigned long locked_shm ;
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
};
#line 833
struct backing_dev_info;
#line 834
struct reclaim_state;
#line 835 "include/linux/sched.h"
struct sched_info {
   unsigned long pcount ;
   unsigned long long run_delay ;
   unsigned long long last_arrival ;
   unsigned long long last_queued ;
};
#line 849 "include/linux/sched.h"
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   u64 blkio_start ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   u64 freepages_start ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
#line 897 "include/linux/sched.h"
struct wake_q_node {
   struct wake_q_node *next ;
};
#line 1126
struct io_context;
#line 1160
struct pipe_inode_info;
#line 1162 "include/linux/sched.h"
struct load_weight {
   unsigned long weight ;
   u32 inv_weight ;
};
#line 1169 "include/linux/sched.h"
struct sched_avg {
   u64 last_runnable_update ;
   s64 decay_count ;
   unsigned long load_avg_contrib ;
   unsigned long utilization_avg_contrib ;
   u32 runnable_avg_sum ;
   u32 avg_period ;
   u32 running_avg_sum ;
};
#line 1194 "include/linux/sched.h"
struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};
#line 1229 "include/linux/sched.h"
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   int depth ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
   struct sched_avg avg ;
};
#line 1261
struct rt_rq;
#line 1261 "include/linux/sched.h"
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
   unsigned long watchdog_stamp ;
   unsigned int time_slice ;
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
#line 1277 "include/linux/sched.h"
struct sched_dl_entity {
   struct rb_node rb_node ;
   u64 dl_runtime ;
   u64 dl_deadline ;
   u64 dl_period ;
   u64 dl_bw ;
   s64 runtime ;
   u64 deadline ;
   unsigned int flags ;
   int dl_throttled ;
   int dl_new ;
   int dl_boosted ;
   int dl_yielded ;
   struct hrtimer dl_timer ;
};
#line 1343 "include/linux/sched.h"
struct memcg_oom_info {
   struct mem_cgroup *memcg ;
   gfp_t gfp_mask ;
   int order ;
   unsigned char may_oom : 1 ;
};
#line 1769
struct sched_class;
#line 1769
struct files_struct;
#line 1769
struct compat_robust_list_head;
#line 1769
struct numa_group;
#line 1769
struct ftrace_ret_stack;
#line 1769 "include/linux/sched.h"
struct task_struct {
   long volatile   state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
   struct llist_node wake_entry ;
   int on_cpu ;
   struct task_struct *last_wakee ;
   unsigned long wakee_flips ;
   unsigned long wakee_flip_decay_ts ;
   int wake_cpu ;
   int on_rq ;
   int prio ;
   int static_prio ;
   int normal_prio ;
   unsigned int rt_priority ;
   struct sched_class  const  *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct sched_dl_entity dl ;
   struct hlist_head preempt_notifiers ;
   unsigned int btrace_seq ;
   unsigned int policy ;
   int nr_cpus_allowed ;
   cpumask_t cpus_allowed ;
   unsigned long rcu_tasks_nvcsw ;
   bool rcu_tasks_holdout ;
   struct list_head rcu_tasks_holdout_list ;
   int rcu_tasks_idle_cpu ;
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct rb_node pushable_dl_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   u32 vmacache_seqnum ;
   struct vm_area_struct *vmacache[4U] ;
   struct task_rss_stat rss_stat ;
   int exit_state ;
   int exit_code ;
   int exit_signal ;
   int pdeath_signal ;
   unsigned long jobctl ;
   unsigned int personality ;
   unsigned char in_execve : 1 ;
   unsigned char in_iowait : 1 ;
   unsigned char sched_reset_on_fork : 1 ;
   unsigned char sched_contributes_to_load : 1 ;
   unsigned char sched_migrated : 1 ;
   unsigned char memcg_kmem_skip_account : 1 ;
   unsigned char brk_randomized : 1 ;
   unsigned long atomic_flags ;
   struct restart_block restart_block ;
   pid_t pid ;
   pid_t tgid ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct list_head thread_node ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   struct cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   u64 start_time ;
   u64 real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred  const  *real_cred ;
   struct cred  const  *cred ;
   char comm[16U] ;
   struct nameidata *nameidata ;
   struct sysv_sem sysvsem ;
   struct sysv_shm sysvshm ;
   unsigned long last_switch_count ;
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct wake_q_node wake_q ;
   struct rb_root pi_waiters ;
   struct rb_node *pi_waiters_leftmost ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
   unsigned long hardirq_enable_ip ;
   unsigned long hardirq_disable_ip ;
   unsigned int hardirq_enable_event ;
   unsigned int hardirq_disable_event ;
   int hardirqs_enabled ;
   int hardirq_context ;
   unsigned long softirq_disable_ip ;
   unsigned long softirq_enable_ip ;
   unsigned int softirq_disable_event ;
   unsigned int softirq_enable_event ;
   int softirqs_enabled ;
   int softirq_context ;
   u64 curr_chain_key ;
   int lockdep_depth ;
   unsigned int lockdep_recursion ;
   struct held_lock held_locks[48U] ;
   gfp_t lockdep_reclaim_gfp ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
   int cpuset_slab_spread_rotor ;
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_next ;
   short pref_node_fork ;
   int numa_scan_seq ;
   unsigned int numa_scan_period ;
   unsigned int numa_scan_period_max ;
   int numa_preferred_nid ;
   unsigned long numa_migrate_retry ;
   u64 node_stamp ;
   u64 last_task_numa_placement ;
   u64 last_sum_exec_runtime ;
   struct callback_head numa_work ;
   struct list_head numa_entry ;
   struct numa_group *numa_group ;
   unsigned long *numa_faults ;
   unsigned long total_numa_faults ;
   unsigned long numa_faults_locality[3U] ;
   unsigned long numa_pages_migrated ;
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
   int nr_dirtied ;
   int nr_dirtied_pause ;
   unsigned long dirty_paused_when ;
   int latency_record_count ;
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
   unsigned long default_timer_slack_ns ;
   unsigned int kasan_depth ;
   int curr_ret_stack ;
   struct ftrace_ret_stack *ret_stack ;
   unsigned long long ftrace_timestamp ;
   atomic_t trace_overrun ;
   atomic_t tracing_graph_pause ;
   unsigned long trace ;
   unsigned long trace_recursion ;
   struct memcg_oom_info memcg_oom ;
   struct uprobe_task *utask ;
   unsigned int sequential_io ;
   unsigned int sequential_io_avg ;
   unsigned long task_state_change ;
   int pagefault_disabled ;
};
#line 55 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct mlx5_core_dev;
#line 13 "include/linux/mod_devicetable.h"
typedef unsigned long kernel_ulong_t;
#line 14 "include/linux/mod_devicetable.h"
struct pci_device_id {
   __u32 vendor ;
   __u32 device ;
   __u32 subvendor ;
   __u32 subdevice ;
   __u32 class ;
   __u32 class_mask ;
   kernel_ulong_t driver_data ;
};
#line 186 "include/linux/mod_devicetable.h"
struct acpi_device_id {
   __u8 id[9U] ;
   kernel_ulong_t driver_data ;
};
#line 219 "include/linux/mod_devicetable.h"
struct of_device_id {
   char name[32U] ;
   char type[32U] ;
   char compatible[128U] ;
   void const   *data ;
};
#line 650
struct klist_node;
#line 37 "include/linux/klist.h"
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
};
#line 68 "include/linux/klist.h"
struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   size_t pad_until ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations  const  *op ;
   int poll_event ;
   struct user_namespace *user_ns ;
   void *private ;
};
#line 35 "include/linux/seq_file.h"
struct seq_operations {
   void *(*start)(struct seq_file * , loff_t * ) ;
   void (*stop)(struct seq_file * , void * ) ;
   void *(*next)(struct seq_file * , void * , loff_t * ) ;
   int (*show)(struct seq_file * , void * ) ;
};
#line 187
struct pinctrl;
#line 188
struct pinctrl_state;
#line 194 "include/linux/pinctrl/consumer.h"
struct dev_pin_info {
   struct pinctrl *p ;
   struct pinctrl_state *default_state ;
   struct pinctrl_state *sleep_state ;
   struct pinctrl_state *idle_state ;
};
#line 48 "include/linux/ratelimit.h"
struct dma_map_ops;
#line 48 "include/linux/ratelimit.h"
struct dev_archdata {
   struct dma_map_ops *dma_ops ;
   void *iommu ;
};
#line 14 "./arch/x86/include/asm/device.h"
struct device_private;
#line 15
struct device_driver;
#line 16
struct driver_private;
#line 17
struct class;
#line 18
struct subsys_private;
#line 19
struct bus_type;
#line 20
struct device_node;
#line 21
struct fwnode_handle;
#line 22
struct iommu_ops;
#line 23
struct iommu_group;
#line 61 "include/linux/device.h"
struct device_attribute;
#line 61 "include/linux/device.h"
struct bus_type {
   char const   *name ;
   char const   *dev_name ;
   struct device *dev_root ;
   struct device_attribute *dev_attrs ;
   struct attribute_group  const  **bus_groups ;
   struct attribute_group  const  **dev_groups ;
   struct attribute_group  const  **drv_groups ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*online)(struct device * ) ;
   int (*offline)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct iommu_ops  const  *iommu_ops ;
   struct subsys_private *p ;
   struct lock_class_key lock_key ;
};
#line 139
struct device_type;
#line 197
enum probe_type {
    PROBE_DEFAULT_STRATEGY = 0,
    PROBE_PREFER_ASYNCHRONOUS = 1,
    PROBE_FORCE_SYNCHRONOUS = 2
} ;
#line 203 "include/linux/device.h"
struct device_driver {
   char const   *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const   *mod_name ;
   bool suppress_bind_attrs ;
   enum probe_type probe_type ;
   struct of_device_id  const  *of_match_table ;
   struct acpi_device_id  const  *acpi_match_table ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group  const  **groups ;
   struct dev_pm_ops  const  *pm ;
   struct driver_private *p ;
};
#line 353
struct class_attribute;
#line 353 "include/linux/device.h"
struct class {
   char const   *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct attribute_group  const  **dev_groups ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct kobj_ns_type_operations  const  *ns_type ;
   void const   *(*namespace)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
   struct subsys_private *p ;
};
#line 446 "include/linux/device.h"
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , struct class_attribute * , char * ) ;
   ssize_t (*store)(struct class * , struct class_attribute * , char const   * , size_t  ) ;
};
#line 514 "include/linux/device.h"
struct device_type {
   char const   *name ;
   struct attribute_group  const  **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   char *(*devnode)(struct device * , umode_t * , kuid_t * , kgid_t * ) ;
   void (*release)(struct device * ) ;
   struct dev_pm_ops  const  *pm ;
};
#line 542 "include/linux/device.h"
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const   * ,
                    size_t  ) ;
};
#line 674 "include/linux/device.h"
struct device_dma_parameters {
   unsigned int max_segment_size ;
   unsigned long segment_boundary_mask ;
};
#line 683
struct dma_coherent_mem;
#line 683
struct cma;
#line 683 "include/linux/device.h"
struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const   *init_name ;
   struct device_type  const  *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   void *driver_data ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   struct dev_pin_info *pins ;
   int numa_node ;
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   unsigned long dma_pfn_offset ;
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct cma *cma_area ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   struct attribute_group  const  **groups ;
   void (*release)(struct device * ) ;
   struct iommu_group *iommu_group ;
   bool offline_disabled ;
   bool offline ;
};
#line 829 "include/linux/device.h"
struct wakeup_source {
   char const   *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct wake_irq *wakeirq ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
   unsigned long active_count ;
   unsigned long relax_count ;
   unsigned long expire_count ;
   unsigned long wakeup_count ;
   bool active ;
   bool autosleep_enabled ;
};
#line 70 "include/linux/resource_ext.h"
struct hotplug_slot;
#line 70 "include/linux/resource_ext.h"
struct pci_slot {
   struct pci_bus *bus ;
   struct list_head list ;
   struct hotplug_slot *hotplug ;
   unsigned char number ;
   struct kobject kobj ;
};
#line 110 "include/linux/pci.h"
typedef int pci_power_t;
#line 137 "include/linux/pci.h"
typedef unsigned int pci_channel_state_t;
#line 138
enum pci_channel_state {
    pci_channel_io_normal = 1,
    pci_channel_io_frozen = 2,
    pci_channel_io_perm_failure = 3
} ;
#line 163 "include/linux/pci.h"
typedef unsigned short pci_dev_flags_t;
#line 190 "include/linux/pci.h"
typedef unsigned short pci_bus_flags_t;
#line 247
struct pcie_link_state;
#line 248
struct pci_vpd;
#line 249
struct pci_sriov;
#line 250
struct pci_ats;
#line 251
struct proc_dir_entry;
#line 251
struct pci_driver;
#line 251 "include/linux/pci.h"
union __anonunion____missing_field_name_220 {
   struct pci_sriov *sriov ;
   struct pci_dev *physfn ;
};
#line 251 "include/linux/pci.h"
struct pci_dev {
   struct list_head bus_list ;
   struct pci_bus *bus ;
   struct pci_bus *subordinate ;
   void *sysdata ;
   struct proc_dir_entry *procent ;
   struct pci_slot *slot ;
   unsigned int devfn ;
   unsigned short vendor ;
   unsigned short device ;
   unsigned short subsystem_vendor ;
   unsigned short subsystem_device ;
   unsigned int class ;
   u8 revision ;
   u8 hdr_type ;
   u8 pcie_cap ;
   u8 msi_cap ;
   u8 msix_cap ;
   unsigned char pcie_mpss : 3 ;
   u8 rom_base_reg ;
   u8 pin ;
   u16 pcie_flags_reg ;
   u8 dma_alias_devfn ;
   struct pci_driver *driver ;
   u64 dma_mask ;
   struct device_dma_parameters dma_parms ;
   pci_power_t current_state ;
   u8 pm_cap ;
   unsigned char pme_support : 5 ;
   unsigned char pme_interrupt : 1 ;
   unsigned char pme_poll : 1 ;
   unsigned char d1_support : 1 ;
   unsigned char d2_support : 1 ;
   unsigned char no_d1d2 : 1 ;
   unsigned char no_d3cold : 1 ;
   unsigned char d3cold_allowed : 1 ;
   unsigned char mmio_always_on : 1 ;
   unsigned char wakeup_prepared : 1 ;
   unsigned char runtime_d3cold : 1 ;
   unsigned char ignore_hotplug : 1 ;
   unsigned int d3_delay ;
   unsigned int d3cold_delay ;
   struct pcie_link_state *link_state ;
   pci_channel_state_t error_state ;
   struct device dev ;
   int cfg_size ;
   unsigned int irq ;
   struct resource resource[17U] ;
   bool match_driver ;
   unsigned char transparent : 1 ;
   unsigned char multifunction : 1 ;
   unsigned char is_added : 1 ;
   unsigned char is_busmaster : 1 ;
   unsigned char no_msi : 1 ;
   unsigned char no_64bit_msi : 1 ;
   unsigned char block_cfg_access : 1 ;
   unsigned char broken_parity_status : 1 ;
   unsigned char irq_reroute_variant : 2 ;
   unsigned char msi_enabled : 1 ;
   unsigned char msix_enabled : 1 ;
   unsigned char ari_enabled : 1 ;
   unsigned char is_managed : 1 ;
   unsigned char needs_freset : 1 ;
   unsigned char state_saved : 1 ;
   unsigned char is_physfn : 1 ;
   unsigned char is_virtfn : 1 ;
   unsigned char reset_fn : 1 ;
   unsigned char is_hotplug_bridge : 1 ;
   unsigned char __aer_firmware_first_valid : 1 ;
   unsigned char __aer_firmware_first : 1 ;
   unsigned char broken_intx_masking : 1 ;
   unsigned char io_window_1k : 1 ;
   unsigned char irq_managed : 1 ;
   unsigned char has_secondary_link : 1 ;
   pci_dev_flags_t dev_flags ;
   atomic_t enable_cnt ;
   u32 saved_config_space[16U] ;
   struct hlist_head saved_cap_space ;
   struct bin_attribute *rom_attr ;
   int rom_attr_enabled ;
   struct bin_attribute *res_attr[17U] ;
   struct bin_attribute *res_attr_wc[17U] ;
   struct list_head msi_list ;
   struct attribute_group  const  **msi_irq_groups ;
   struct pci_vpd *vpd ;
   union __anonunion____missing_field_name_220 __annonCompField58 ;
   struct pci_ats *ats ;
   phys_addr_t rom ;
   size_t romlen ;
   char *driver_override ;
};
#line 440
struct pci_ops;
#line 440
struct msi_controller;
#line 440 "include/linux/pci.h"
struct pci_bus {
   struct list_head node ;
   struct pci_bus *parent ;
   struct list_head children ;
   struct list_head devices ;
   struct pci_dev *self ;
   struct list_head slots ;
   struct resource *resource[4U] ;
   struct list_head resources ;
   struct resource busn_res ;
   struct pci_ops *ops ;
   struct msi_controller *msi ;
   void *sysdata ;
   struct proc_dir_entry *procdir ;
   unsigned char number ;
   unsigned char primary ;
   unsigned char max_bus_speed ;
   unsigned char cur_bus_speed ;
   char name[48U] ;
   unsigned short bridge_ctl ;
   pci_bus_flags_t bus_flags ;
   struct device *bridge ;
   struct device dev ;
   struct bin_attribute *legacy_io ;
   struct bin_attribute *legacy_mem ;
   unsigned char is_added : 1 ;
};
#line 563 "include/linux/pci.h"
struct pci_ops {
   void *(*map_bus)(struct pci_bus * , unsigned int  , int  ) ;
   int (*read)(struct pci_bus * , unsigned int  , int  , int  , u32 * ) ;
   int (*write)(struct pci_bus * , unsigned int  , int  , int  , u32  ) ;
};
#line 591 "include/linux/pci.h"
struct pci_dynids {
   spinlock_t lock ;
   struct list_head list ;
};
#line 605 "include/linux/pci.h"
typedef unsigned int pci_ers_result_t;
#line 615 "include/linux/pci.h"
struct pci_error_handlers {
   pci_ers_result_t (*error_detected)(struct pci_dev * , enum pci_channel_state  ) ;
   pci_ers_result_t (*mmio_enabled)(struct pci_dev * ) ;
   pci_ers_result_t (*link_reset)(struct pci_dev * ) ;
   pci_ers_result_t (*slot_reset)(struct pci_dev * ) ;
   void (*reset_notify)(struct pci_dev * , bool  ) ;
   void (*resume)(struct pci_dev * ) ;
};
#line 648 "include/linux/pci.h"
struct pci_driver {
   struct list_head node ;
   char const   *name ;
   struct pci_device_id  const  *id_table ;
   int (*probe)(struct pci_dev * , struct pci_device_id  const  * ) ;
   void (*remove)(struct pci_dev * ) ;
   int (*suspend)(struct pci_dev * , pm_message_t  ) ;
   int (*suspend_late)(struct pci_dev * , pm_message_t  ) ;
   int (*resume_early)(struct pci_dev * ) ;
   int (*resume)(struct pci_dev * ) ;
   void (*shutdown)(struct pci_dev * ) ;
   int (*sriov_configure)(struct pci_dev * , int  ) ;
   struct pci_error_handlers  const  *err_handler ;
   struct device_driver driver ;
   struct pci_dynids dynids ;
};
#line 207 "include/linux/mm.h"
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
   void *virtual_address ;
   struct page *cow_page ;
   struct page *page ;
   unsigned long max_pgoff ;
   pte_t *pte ;
};
#line 239 "include/linux/mm.h"
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   void (*map_pages)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*pfn_mkwrite)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*access)(struct vm_area_struct * , unsigned long  , void * , int  , int  ) ;
   char const   *(*name)(struct vm_area_struct * ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long  ) ;
   struct page *(*find_special_page)(struct vm_area_struct * , unsigned long  ) ;
};
#line 2242 "include/linux/mm.h"
struct scatterlist {
   unsigned long sg_magic ;
   unsigned long page_link ;
   unsigned int offset ;
   unsigned int length ;
   dma_addr_t dma_address ;
   unsigned int dma_length ;
};
#line 21 "include/linux/scatterlist.h"
struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
   unsigned int orig_nents ;
};
#line 19 "include/linux/dmapool.h"
struct dma_pool;
#line 35 "include/linux/dmapool.h"
struct msix_entry {
   u32 vector ;
   u16 entry ;
};
#line 34 "./arch/x86/include/asm/pci_64.h"
struct dma_attrs {
   unsigned long flags[1U] ;
};
#line 70 "include/linux/dma-attrs.h"
enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
} ;
#line 77 "include/linux/dma-attrs.h"
struct dma_map_ops {
   void *(*alloc)(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
   void (*free)(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
   int (*mmap)(struct device * , struct vm_area_struct * , void * , dma_addr_t  ,
               size_t  , struct dma_attrs * ) ;
   int (*get_sgtable)(struct device * , struct sg_table * , void * , dma_addr_t  ,
                      size_t  , struct dma_attrs * ) ;
   dma_addr_t (*map_page)(struct device * , struct page * , unsigned long  , size_t  ,
                          enum dma_data_direction  , struct dma_attrs * ) ;
   void (*unmap_page)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ,
                      struct dma_attrs * ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                 struct dma_attrs * ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ,
                    struct dma_attrs * ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t  , size_t  , enum dma_data_direction  ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   int (*mapping_error)(struct device * , dma_addr_t  ) ;
   int (*dma_supported)(struct device * , u64  ) ;
   int (*set_dma_mask)(struct device * , u64  ) ;
   int is_phys ;
};
#line 62 "./arch/x86/include/asm/uaccess.h"
struct exception_table_entry {
   int insn ;
   int fixup ;
};
#line 921 "./include/uapi/rdma/ib_user_verbs.h"
struct semaphore {
   raw_spinlock_t lock ;
   unsigned int count ;
   struct list_head wait_list ;
};
#line 58 "include/linux/radix-tree.h"
struct __anonstruct____missing_field_name_235 {
   struct radix_tree_node *parent ;
   void *private_data ;
};
#line 58 "include/linux/radix-tree.h"
union __anonunion____missing_field_name_234 {
   struct __anonstruct____missing_field_name_235 __annonCompField65 ;
   struct callback_head callback_head ;
};
#line 58 "include/linux/radix-tree.h"
struct radix_tree_node {
   unsigned int path ;
   unsigned int count ;
   union __anonunion____missing_field_name_234 __annonCompField66 ;
   struct list_head private_list ;
   void *slots[64U] ;
   unsigned long tags[3U][1U] ;
};
#line 105 "include/linux/radix-tree.h"
struct radix_tree_root {
   unsigned int height ;
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
#line 142 "include/uapi/linux/if_ether.h"
struct mmu_notifier;
#line 143
struct mmu_notifier_ops;
#line 144 "include/uapi/linux/if_ether.h"
struct mmu_notifier_mm {
   struct hlist_head list ;
   spinlock_t lock ;
};
#line 26 "include/linux/mmu_notifier.h"
struct mmu_notifier_ops {
   void (*release)(struct mmu_notifier * , struct mm_struct * ) ;
   int (*clear_flush_young)(struct mmu_notifier * , struct mm_struct * , unsigned long  ,
                            unsigned long  ) ;
   int (*test_young)(struct mmu_notifier * , struct mm_struct * , unsigned long  ) ;
   void (*change_pte)(struct mmu_notifier * , struct mm_struct * , unsigned long  ,
                      pte_t  ) ;
   void (*invalidate_page)(struct mmu_notifier * , struct mm_struct * , unsigned long  ) ;
   void (*invalidate_range_start)(struct mmu_notifier * , struct mm_struct * , unsigned long  ,
                                  unsigned long  ) ;
   void (*invalidate_range_end)(struct mmu_notifier * , struct mm_struct * , unsigned long  ,
                                unsigned long  ) ;
   void (*invalidate_range)(struct mmu_notifier * , struct mm_struct * , unsigned long  ,
                            unsigned long  ) ;
};
#line 170 "include/linux/mmu_notifier.h"
struct mmu_notifier {
   struct hlist_node hlist ;
   struct mmu_notifier_ops  const  *ops ;
};
#line 58 "include/rdma/ib_verbs.h"
struct __anonstruct_global_238 {
   __be64 subnet_prefix ;
   __be64 interface_id ;
};
#line 58 "include/rdma/ib_verbs.h"
union ib_gid {
   u8 raw[16U] ;
   struct __anonstruct_global_238 global ;
};
#line 93
enum rdma_link_layer {
    IB_LINK_LAYER_UNSPECIFIED = 0,
    IB_LINK_LAYER_INFINIBAND = 1,
    IB_LINK_LAYER_ETHERNET = 2
} ;
#line 141
enum ib_atomic_cap {
    IB_ATOMIC_NONE = 0,
    IB_ATOMIC_HCA = 1,
    IB_ATOMIC_GLOB = 2
} ;
#line 159 "include/rdma/ib_verbs.h"
struct __anonstruct_per_transport_caps_239 {
   uint32_t rc_odp_caps ;
   uint32_t uc_odp_caps ;
   uint32_t ud_odp_caps ;
};
#line 159 "include/rdma/ib_verbs.h"
struct ib_odp_caps {
   uint64_t general_caps ;
   struct __anonstruct_per_transport_caps_239 per_transport_caps ;
};
#line 179 "include/rdma/ib_verbs.h"
struct ib_cq_init_attr {
   unsigned int cqe ;
   int comp_vector ;
   u32 flags ;
};
#line 185 "include/rdma/ib_verbs.h"
struct ib_device_attr {
   u64 fw_ver ;
   __be64 sys_image_guid ;
   u64 max_mr_size ;
   u64 page_size_cap ;
   u32 vendor_id ;
   u32 vendor_part_id ;
   u32 hw_ver ;
   int max_qp ;
   int max_qp_wr ;
   int device_cap_flags ;
   int max_sge ;
   int max_sge_rd ;
   int max_cq ;
   int max_cqe ;
   int max_mr ;
   int max_pd ;
   int max_qp_rd_atom ;
   int max_ee_rd_atom ;
   int max_res_rd_atom ;
   int max_qp_init_rd_atom ;
   int max_ee_init_rd_atom ;
   enum ib_atomic_cap atomic_cap ;
   enum ib_atomic_cap masked_atomic_cap ;
   int max_ee ;
   int max_rdd ;
   int max_mw ;
   int max_raw_ipv6_qp ;
   int max_raw_ethy_qp ;
   int max_mcast_grp ;
   int max_mcast_qp_attach ;
   int max_total_mcast_qp_attach ;
   int max_ah ;
   int max_fmr ;
   int max_map_per_fmr ;
   int max_srq ;
   int max_srq_wr ;
   int max_srq_sge ;
   unsigned int max_fast_reg_page_list_len ;
   u16 max_pkeys ;
   u8 local_ca_ack_delay ;
   int sig_prot_cap ;
   int sig_guard_cap ;
   struct ib_odp_caps odp_caps ;
   uint64_t timestamp_mask ;
   uint64_t hca_core_clock ;
};
#line 233
enum ib_mtu {
    IB_MTU_256 = 1,
    IB_MTU_512 = 2,
    IB_MTU_1024 = 3,
    IB_MTU_2048 = 4,
    IB_MTU_4096 = 5
} ;
#line 253
enum ib_port_state {
    IB_PORT_NOP = 0,
    IB_PORT_DOWN = 1,
    IB_PORT_INIT = 2,
    IB_PORT_ARMED = 3,
    IB_PORT_ACTIVE = 4,
    IB_PORT_ACTIVE_DEFER = 5
} ;
#line 316 "include/rdma/ib_verbs.h"
struct ib_protocol_stats {

};
#line 319 "include/rdma/ib_verbs.h"
struct iw_protocol_stats {
   u64 ipInReceives ;
   u64 ipInHdrErrors ;
   u64 ipInTooBigErrors ;
   u64 ipInNoRoutes ;
   u64 ipInAddrErrors ;
   u64 ipInUnknownProtos ;
   u64 ipInTruncatedPkts ;
   u64 ipInDiscards ;
   u64 ipInDelivers ;
   u64 ipOutForwDatagrams ;
   u64 ipOutRequests ;
   u64 ipOutDiscards ;
   u64 ipOutNoRoutes ;
   u64 ipReasmTimeout ;
   u64 ipReasmReqds ;
   u64 ipReasmOKs ;
   u64 ipReasmFails ;
   u64 ipFragOKs ;
   u64 ipFragFails ;
   u64 ipFragCreates ;
   u64 ipInMcastPkts ;
   u64 ipOutMcastPkts ;
   u64 ipInBcastPkts ;
   u64 ipOutBcastPkts ;
   u64 tcpRtoAlgorithm ;
   u64 tcpRtoMin ;
   u64 tcpRtoMax ;
   u64 tcpMaxConn ;
   u64 tcpActiveOpens ;
   u64 tcpPassiveOpens ;
   u64 tcpAttemptFails ;
   u64 tcpEstabResets ;
   u64 tcpCurrEstab ;
   u64 tcpInSegs ;
   u64 tcpOutSegs ;
   u64 tcpRetransSegs ;
   u64 tcpInErrs ;
   u64 tcpOutRsts ;
};
#line 362 "include/rdma/ib_verbs.h"
union rdma_protocol_stats {
   struct ib_protocol_stats ib ;
   struct iw_protocol_stats iw ;
};
#line 367 "include/rdma/ib_verbs.h"
struct ib_port_attr {
   enum ib_port_state state ;
   enum ib_mtu max_mtu ;
   enum ib_mtu active_mtu ;
   int gid_tbl_len ;
   u32 port_cap_flags ;
   u32 max_msg_sz ;
   u32 bad_pkey_cntr ;
   u32 qkey_viol_cntr ;
   u16 pkey_tbl_len ;
   u16 lid ;
   u16 sm_lid ;
   u8 lmc ;
   u8 max_vl_num ;
   u8 sm_sl ;
   u8 subnet_timeout ;
   u8 init_type_reply ;
   u8 active_width ;
   u8 active_speed ;
   u8 phys_state ;
};
#line 430 "include/rdma/ib_verbs.h"
struct ib_device_modify {
   u64 sys_image_guid ;
   char node_desc[64U] ;
};
#line 441 "include/rdma/ib_verbs.h"
struct ib_port_modify {
   u32 set_port_cap_mask ;
   u32 clr_port_cap_mask ;
   u8 init_type ;
};
#line 447
enum ib_event_type {
    IB_EVENT_CQ_ERR = 0,
    IB_EVENT_QP_FATAL = 1,
    IB_EVENT_QP_REQ_ERR = 2,
    IB_EVENT_QP_ACCESS_ERR = 3,
    IB_EVENT_COMM_EST = 4,
    IB_EVENT_SQ_DRAINED = 5,
    IB_EVENT_PATH_MIG = 6,
    IB_EVENT_PATH_MIG_ERR = 7,
    IB_EVENT_DEVICE_FATAL = 8,
    IB_EVENT_PORT_ACTIVE = 9,
    IB_EVENT_PORT_ERR = 10,
    IB_EVENT_LID_CHANGE = 11,
    IB_EVENT_PKEY_CHANGE = 12,
    IB_EVENT_SM_CHANGE = 13,
    IB_EVENT_SRQ_ERR = 14,
    IB_EVENT_SRQ_LIMIT_REACHED = 15,
    IB_EVENT_QP_LAST_WQE_REACHED = 16,
    IB_EVENT_CLIENT_REREGISTER = 17,
    IB_EVENT_GID_CHANGE = 18
} ;
#line 471
struct ib_device;
#line 471
struct ib_cq;
#line 471
struct ib_qp;
#line 471
struct ib_srq;
#line 471 "include/rdma/ib_verbs.h"
union __anonunion_element_240 {
   struct ib_cq *cq ;
   struct ib_qp *qp ;
   struct ib_srq *srq ;
   u8 port_num ;
};
#line 471 "include/rdma/ib_verbs.h"
struct ib_event {
   struct ib_device *device ;
   union __anonunion_element_240 element ;
   enum ib_event_type event ;
};
#line 482 "include/rdma/ib_verbs.h"
struct ib_event_handler {
   struct ib_device *device ;
   void (*handler)(struct ib_event_handler * , struct ib_event * ) ;
   struct list_head list ;
};
#line 488 "include/rdma/ib_verbs.h"
struct ib_global_route {
   union ib_gid dgid ;
   u32 flow_label ;
   u8 sgid_index ;
   u8 hop_limit ;
   u8 traffic_class ;
};
#line 503 "include/rdma/ib_verbs.h"
struct ib_grh {
   __be32 version_tclass_flow ;
   __be16 paylen ;
   u8 next_hdr ;
   u8 hop_limit ;
   union ib_gid sgid ;
   union ib_gid dgid ;
};
#line 562 "include/rdma/ib_verbs.h"
struct ib_mr_init_attr {
   int max_reg_descriptors ;
   u32 flags ;
};
#line 574
enum ib_signature_type {
    IB_SIG_TYPE_NONE = 0,
    IB_SIG_TYPE_T10_DIF = 1
} ;
#line 579
enum ib_t10_dif_bg_type {
    IB_T10DIF_CRC = 0,
    IB_T10DIF_CSUM = 1
} ;
#line 584 "include/rdma/ib_verbs.h"
struct ib_t10_dif_domain {
   enum ib_t10_dif_bg_type bg_type ;
   u16 pi_interval ;
   u16 bg ;
   u16 app_tag ;
   u32 ref_tag ;
   bool ref_remap ;
   bool app_escape ;
   bool ref_escape ;
   u16 apptag_check_mask ;
};
#line 619 "include/rdma/ib_verbs.h"
union __anonunion_sig_241 {
   struct ib_t10_dif_domain dif ;
};
#line 619 "include/rdma/ib_verbs.h"
struct ib_sig_domain {
   enum ib_signature_type sig_type ;
   union __anonunion_sig_241 sig ;
};
#line 632 "include/rdma/ib_verbs.h"
struct ib_sig_attrs {
   u8 check_mask ;
   struct ib_sig_domain mem ;
   struct ib_sig_domain wire ;
};
#line 644
enum ib_sig_err_type {
    IB_SIG_BAD_GUARD = 0,
    IB_SIG_BAD_REFTAG = 1,
    IB_SIG_BAD_APPTAG = 2
} ;
#line 650 "include/rdma/ib_verbs.h"
struct ib_sig_err {
   enum ib_sig_err_type err_type ;
   u32 expected ;
   u32 actual ;
   u64 sig_err_offset ;
   u32 key ;
};
#line 665 "include/rdma/ib_verbs.h"
struct ib_mr_status {
   u32 fail_status ;
   struct ib_sig_err sig_err ;
};
#line 685 "include/rdma/ib_verbs.h"
struct ib_ah_attr {
   struct ib_global_route grh ;
   u16 dlid ;
   u8 sl ;
   u8 src_path_bits ;
   u8 static_rate ;
   u8 ah_flags ;
   u8 port_num ;
   u8 dmac[6U] ;
   u16 vlan_id ;
};
#line 697
enum ib_wc_status {
    IB_WC_SUCCESS = 0,
    IB_WC_LOC_LEN_ERR = 1,
    IB_WC_LOC_QP_OP_ERR = 2,
    IB_WC_LOC_EEC_OP_ERR = 3,
    IB_WC_LOC_PROT_ERR = 4,
    IB_WC_WR_FLUSH_ERR = 5,
    IB_WC_MW_BIND_ERR = 6,
    IB_WC_BAD_RESP_ERR = 7,
    IB_WC_LOC_ACCESS_ERR = 8,
    IB_WC_REM_INV_REQ_ERR = 9,
    IB_WC_REM_ACCESS_ERR = 10,
    IB_WC_REM_OP_ERR = 11,
    IB_WC_RETRY_EXC_ERR = 12,
    IB_WC_RNR_RETRY_EXC_ERR = 13,
    IB_WC_LOC_RDD_VIOL_ERR = 14,
    IB_WC_REM_INV_RD_REQ_ERR = 15,
    IB_WC_REM_ABORT_ERR = 16,
    IB_WC_INV_EECN_ERR = 17,
    IB_WC_INV_EEC_STATE_ERR = 18,
    IB_WC_FATAL_ERR = 19,
    IB_WC_RESP_TIMEOUT_ERR = 20,
    IB_WC_GENERAL_ERR = 21
} ;
#line 724
enum ib_wc_opcode {
    IB_WC_SEND = 0,
    IB_WC_RDMA_WRITE = 1,
    IB_WC_RDMA_READ = 2,
    IB_WC_COMP_SWAP = 3,
    IB_WC_FETCH_ADD = 4,
    IB_WC_BIND_MW = 5,
    IB_WC_LSO = 6,
    IB_WC_LOCAL_INV = 7,
    IB_WC_FAST_REG_MR = 8,
    IB_WC_MASKED_COMP_SWAP = 9,
    IB_WC_MASKED_FETCH_ADD = 10,
    IB_WC_RECV = 128,
    IB_WC_RECV_RDMA_WITH_IMM = 129
} ;
#line 749 "include/rdma/ib_verbs.h"
union __anonunion_ex_242 {
   __be32 imm_data ;
   u32 invalidate_rkey ;
};
#line 749 "include/rdma/ib_verbs.h"
struct ib_wc {
   u64 wr_id ;
   enum ib_wc_status status ;
   enum ib_wc_opcode opcode ;
   u32 vendor_err ;
   u32 byte_len ;
   struct ib_qp *qp ;
   union __anonunion_ex_242 ex ;
   u32 src_qp ;
   int wc_flags ;
   u16 pkey_index ;
   u16 slid ;
   u8 sl ;
   u8 dlid_path_bits ;
   u8 port_num ;
   u8 smac[6U] ;
   u16 vlan_id ;
};
#line 775
enum ib_cq_notify_flags {
    IB_CQ_SOLICITED = 1,
    IB_CQ_NEXT_COMP = 2,
    IB_CQ_SOLICITED_MASK = 3,
    IB_CQ_REPORT_MISSED_EVENTS = 4
} ;
#line 782
enum ib_srq_type {
    IB_SRQT_BASIC = 0,
    IB_SRQT_XRC = 1
} ;
#line 787
enum ib_srq_attr_mask {
    IB_SRQ_MAX_WR = 1,
    IB_SRQ_LIMIT = 2
} ;
#line 792 "include/rdma/ib_verbs.h"
struct ib_srq_attr {
   u32 max_wr ;
   u32 max_sge ;
   u32 srq_limit ;
};
#line 798
struct ib_xrcd;
#line 798 "include/rdma/ib_verbs.h"
struct __anonstruct_xrc_244 {
   struct ib_xrcd *xrcd ;
   struct ib_cq *cq ;
};
#line 798 "include/rdma/ib_verbs.h"
union __anonunion_ext_243 {
   struct __anonstruct_xrc_244 xrc ;
};
#line 798 "include/rdma/ib_verbs.h"
struct ib_srq_init_attr {
   void (*event_handler)(struct ib_event * , void * ) ;
   void *srq_context ;
   struct ib_srq_attr attr ;
   enum ib_srq_type srq_type ;
   union __anonunion_ext_243 ext ;
};
#line 812 "include/rdma/ib_verbs.h"
struct ib_qp_cap {
   u32 max_send_wr ;
   u32 max_recv_wr ;
   u32 max_send_sge ;
   u32 max_recv_sge ;
   u32 max_inline_data ;
};
#line 820
enum ib_sig_type {
    IB_SIGNAL_ALL_WR = 0,
    IB_SIGNAL_REQ_WR = 1
} ;
#line 825
enum ib_qp_type {
    IB_QPT_SMI = 0,
    IB_QPT_GSI = 1,
    IB_QPT_RC = 2,
    IB_QPT_UC = 3,
    IB_QPT_UD = 4,
    IB_QPT_RAW_IPV6 = 5,
    IB_QPT_RAW_ETHERTYPE = 6,
    IB_QPT_RAW_PACKET = 8,
    IB_QPT_XRC_INI = 9,
    IB_QPT_XRC_TGT = 10,
    IB_QPT_MAX = 11,
    IB_QPT_RESERVED1 = 4096,
    IB_QPT_RESERVED2 = 4097,
    IB_QPT_RESERVED3 = 4098,
    IB_QPT_RESERVED4 = 4099,
    IB_QPT_RESERVED5 = 4100,
    IB_QPT_RESERVED6 = 4101,
    IB_QPT_RESERVED7 = 4102,
    IB_QPT_RESERVED8 = 4103,
    IB_QPT_RESERVED9 = 4104,
    IB_QPT_RESERVED10 = 4105
} ;
#line 849
enum ib_qp_create_flags {
    IB_QP_CREATE_IPOIB_UD_LSO = 1,
    IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK = 2,
    IB_QP_CREATE_NETIF_QP = 32,
    IB_QP_CREATE_SIGNATURE_EN = 64,
    IB_QP_CREATE_USE_GFP_NOIO = 128,
    IB_QP_CREATE_RESERVED_START = 67108864,
    IB_QP_CREATE_RESERVED_END = (-0x7FFFFFFF-1)
} ;
#line 859 "include/rdma/ib_verbs.h"
struct ib_qp_init_attr {
   void (*event_handler)(struct ib_event * , void * ) ;
   void *qp_context ;
   struct ib_cq *send_cq ;
   struct ib_cq *recv_cq ;
   struct ib_srq *srq ;
   struct ib_xrcd *xrcd ;
   struct ib_qp_cap cap ;
   enum ib_sig_type sq_sig_type ;
   enum ib_qp_type qp_type ;
   enum ib_qp_create_flags create_flags ;
   u8 port_num ;
};
#line 960
enum ib_qp_state {
    IB_QPS_RESET = 0,
    IB_QPS_INIT = 1,
    IB_QPS_RTR = 2,
    IB_QPS_RTS = 3,
    IB_QPS_SQD = 4,
    IB_QPS_SQE = 5,
    IB_QPS_ERR = 6
} ;
#line 970
enum ib_mig_state {
    IB_MIG_MIGRATED = 0,
    IB_MIG_REARM = 1,
    IB_MIG_ARMED = 2
} ;
#line 976
enum ib_mw_type {
    IB_MW_TYPE_1 = 1,
    IB_MW_TYPE_2 = 2
} ;
#line 981 "include/rdma/ib_verbs.h"
struct ib_qp_attr {
   enum ib_qp_state qp_state ;
   enum ib_qp_state cur_qp_state ;
   enum ib_mtu path_mtu ;
   enum ib_mig_state path_mig_state ;
   u32 qkey ;
   u32 rq_psn ;
   u32 sq_psn ;
   u32 dest_qp_num ;
   int qp_access_flags ;
   struct ib_qp_cap cap ;
   struct ib_ah_attr ah_attr ;
   struct ib_ah_attr alt_ah_attr ;
   u16 pkey_index ;
   u16 alt_pkey_index ;
   u8 en_sqd_async_notify ;
   u8 sq_draining ;
   u8 max_rd_atomic ;
   u8 max_dest_rd_atomic ;
   u8 min_rnr_timer ;
   u8 port_num ;
   u8 timeout ;
   u8 retry_cnt ;
   u8 rnr_retry ;
   u8 alt_port_num ;
   u8 alt_timeout ;
   u8 smac[6U] ;
   u8 alt_smac[6U] ;
   u16 vlan_id ;
   u16 alt_vlan_id ;
};
#line 1013
enum ib_wr_opcode {
    IB_WR_RDMA_WRITE = 0,
    IB_WR_RDMA_WRITE_WITH_IMM = 1,
    IB_WR_SEND = 2,
    IB_WR_SEND_WITH_IMM = 3,
    IB_WR_RDMA_READ = 4,
    IB_WR_ATOMIC_CMP_AND_SWP = 5,
    IB_WR_ATOMIC_FETCH_AND_ADD = 6,
    IB_WR_LSO = 7,
    IB_WR_SEND_WITH_INV = 8,
    IB_WR_RDMA_READ_WITH_INV = 9,
    IB_WR_LOCAL_INV = 10,
    IB_WR_FAST_REG_MR = 11,
    IB_WR_MASKED_ATOMIC_CMP_AND_SWP = 12,
    IB_WR_MASKED_ATOMIC_FETCH_AND_ADD = 13,
    IB_WR_BIND_MW = 14,
    IB_WR_REG_SIG_MR = 15,
    IB_WR_RESERVED1 = 240,
    IB_WR_RESERVED2 = 241,
    IB_WR_RESERVED3 = 242,
    IB_WR_RESERVED4 = 243,
    IB_WR_RESERVED5 = 244,
    IB_WR_RESERVED6 = 245,
    IB_WR_RESERVED7 = 246,
    IB_WR_RESERVED8 = 247,
    IB_WR_RESERVED9 = 248,
    IB_WR_RESERVED10 = 249
} ;
#line 1052 "include/rdma/ib_verbs.h"
struct ib_sge {
   u64 addr ;
   u32 length ;
   u32 lkey ;
};
#line 1063 "include/rdma/ib_verbs.h"
struct ib_fast_reg_page_list {
   struct ib_device *device ;
   u64 *page_list ;
   unsigned int max_page_list_len ;
};
#line 1069
struct ib_mr;
#line 1069 "include/rdma/ib_verbs.h"
struct ib_mw_bind_info {
   struct ib_mr *mr ;
   u64 addr ;
   u64 length ;
   int mw_access_flags ;
};
#line 1086 "include/rdma/ib_verbs.h"
union __anonunion_ex_245 {
   __be32 imm_data ;
   u32 invalidate_rkey ;
};
#line 1086 "include/rdma/ib_verbs.h"
struct __anonstruct_rdma_247 {
   u64 remote_addr ;
   u32 rkey ;
};
#line 1086 "include/rdma/ib_verbs.h"
struct __anonstruct_atomic_248 {
   u64 remote_addr ;
   u64 compare_add ;
   u64 swap ;
   u64 compare_add_mask ;
   u64 swap_mask ;
   u32 rkey ;
};
#line 1086
struct ib_ah;
#line 1086 "include/rdma/ib_verbs.h"
struct __anonstruct_ud_249 {
   struct ib_ah *ah ;
   void *header ;
   int hlen ;
   int mss ;
   u32 remote_qpn ;
   u32 remote_qkey ;
   u16 pkey_index ;
   u8 port_num ;
};
#line 1086 "include/rdma/ib_verbs.h"
struct __anonstruct_fast_reg_250 {
   u64 iova_start ;
   struct ib_fast_reg_page_list *page_list ;
   unsigned int page_shift ;
   unsigned int page_list_len ;
   u32 length ;
   int access_flags ;
   u32 rkey ;
};
#line 1086
struct ib_mw;
#line 1086 "include/rdma/ib_verbs.h"
struct __anonstruct_bind_mw_251 {
   struct ib_mw *mw ;
   u32 rkey ;
   struct ib_mw_bind_info bind_info ;
};
#line 1086 "include/rdma/ib_verbs.h"
struct __anonstruct_sig_handover_252 {
   struct ib_sig_attrs *sig_attrs ;
   struct ib_mr *sig_mr ;
   int access_flags ;
   struct ib_sge *prot ;
};
#line 1086 "include/rdma/ib_verbs.h"
union __anonunion_wr_246 {
   struct __anonstruct_rdma_247 rdma ;
   struct __anonstruct_atomic_248 atomic ;
   struct __anonstruct_ud_249 ud ;
   struct __anonstruct_fast_reg_250 fast_reg ;
   struct __anonstruct_bind_mw_251 bind_mw ;
   struct __anonstruct_sig_handover_252 sig_handover ;
};
#line 1086 "include/rdma/ib_verbs.h"
struct ib_send_wr {
   struct ib_send_wr *next ;
   u64 wr_id ;
   struct ib_sge *sg_list ;
   int num_sge ;
   enum ib_wr_opcode opcode ;
   int send_flags ;
   union __anonunion_ex_245 ex ;
   union __anonunion_wr_246 wr ;
   u32 xrc_remote_srq_num ;
};
#line 1145 "include/rdma/ib_verbs.h"
struct ib_recv_wr {
   struct ib_recv_wr *next ;
   u64 wr_id ;
   struct ib_sge *sg_list ;
   int num_sge ;
};
#line 1162 "include/rdma/ib_verbs.h"
struct ib_phys_buf {
   u64 addr ;
   u64 size ;
};
#line 1167
struct ib_pd;
#line 1167 "include/rdma/ib_verbs.h"
struct ib_mr_attr {
   struct ib_pd *pd ;
   u64 device_virt_addr ;
   u64 size ;
   int mr_access_flags ;
   u32 lkey ;
   u32 rkey ;
};
#line 1183 "include/rdma/ib_verbs.h"
struct ib_mw_bind {
   u64 wr_id ;
   int send_flags ;
   struct ib_mw_bind_info bind_info ;
};
#line 1195 "include/rdma/ib_verbs.h"
struct ib_fmr_attr {
   int max_pages ;
   int max_maps ;
   u8 page_shift ;
};
#line 1201
struct ib_umem;
#line 1202 "include/rdma/ib_verbs.h"
struct ib_ucontext {
   struct ib_device *device ;
   struct list_head pd_list ;
   struct list_head mr_list ;
   struct list_head mw_list ;
   struct list_head cq_list ;
   struct list_head qp_list ;
   struct list_head srq_list ;
   struct list_head ah_list ;
   struct list_head xrcd_list ;
   struct list_head rule_list ;
   int closing ;
   struct pid *tgid ;
   struct rb_root umem_tree ;
   struct rw_semaphore umem_rwsem ;
   void (*invalidate_range)(struct ib_umem * , unsigned long  , unsigned long  ) ;
   struct mmu_notifier mn ;
   atomic_t notifier_count ;
   struct list_head no_private_counters ;
   int odp_mrs_count ;
};
#line 1234 "include/rdma/ib_verbs.h"
struct ib_uobject {
   u64 user_handle ;
   struct ib_ucontext *context ;
   void *object ;
   struct list_head list ;
   int id ;
   struct kref ref ;
   struct rw_semaphore mutex ;
   int live ;
};
#line 1246 "include/rdma/ib_verbs.h"
struct ib_udata {
   void const   *inbuf ;
   void *outbuf ;
   size_t inlen ;
   size_t outlen ;
};
#line 1253 "include/rdma/ib_verbs.h"
struct ib_pd {
   struct ib_device *device ;
   struct ib_uobject *uobject ;
   atomic_t usecnt ;
};
#line 1259 "include/rdma/ib_verbs.h"
struct ib_xrcd {
   struct ib_device *device ;
   atomic_t usecnt ;
   struct inode *inode ;
   struct mutex tgt_qp_mutex ;
   struct list_head tgt_qp_list ;
};
#line 1268 "include/rdma/ib_verbs.h"
struct ib_ah {
   struct ib_device *device ;
   struct ib_pd *pd ;
   struct ib_uobject *uobject ;
};
#line 1276 "include/rdma/ib_verbs.h"
struct ib_cq {
   struct ib_device *device ;
   struct ib_uobject *uobject ;
   void (*comp_handler)(struct ib_cq * , void * ) ;
   void (*event_handler)(struct ib_event * , void * ) ;
   void *cq_context ;
   int cqe ;
   atomic_t usecnt ;
};
#line 1286 "include/rdma/ib_verbs.h"
struct __anonstruct_xrc_254 {
   struct ib_xrcd *xrcd ;
   struct ib_cq *cq ;
   u32 srq_num ;
};
#line 1286 "include/rdma/ib_verbs.h"
union __anonunion_ext_253 {
   struct __anonstruct_xrc_254 xrc ;
};
#line 1286 "include/rdma/ib_verbs.h"
struct ib_srq {
   struct ib_device *device ;
   struct ib_pd *pd ;
   struct ib_uobject *uobject ;
   void (*event_handler)(struct ib_event * , void * ) ;
   void *srq_context ;
   enum ib_srq_type srq_type ;
   atomic_t usecnt ;
   union __anonunion_ext_253 ext ;
};
#line 1304 "include/rdma/ib_verbs.h"
struct ib_qp {
   struct ib_device *device ;
   struct ib_pd *pd ;
   struct ib_cq *send_cq ;
   struct ib_cq *recv_cq ;
   struct ib_srq *srq ;
   struct ib_xrcd *xrcd ;
   struct list_head xrcd_list ;
   atomic_t usecnt ;
   struct list_head open_list ;
   struct ib_qp *real_qp ;
   struct ib_uobject *uobject ;
   void (*event_handler)(struct ib_event * , void * ) ;
   void *qp_context ;
   u32 qp_num ;
   enum ib_qp_type qp_type ;
};
#line 1323 "include/rdma/ib_verbs.h"
struct ib_mr {
   struct ib_device *device ;
   struct ib_pd *pd ;
   struct ib_uobject *uobject ;
   u32 lkey ;
   u32 rkey ;
   atomic_t usecnt ;
};
#line 1332 "include/rdma/ib_verbs.h"
struct ib_mw {
   struct ib_device *device ;
   struct ib_pd *pd ;
   struct ib_uobject *uobject ;
   u32 rkey ;
   enum ib_mw_type type ;
};
#line 1340 "include/rdma/ib_verbs.h"
struct ib_fmr {
   struct ib_device *device ;
   struct ib_pd *pd ;
   struct list_head list ;
   u32 lkey ;
   u32 rkey ;
};
#line 1348
enum ib_flow_attr_type {
    IB_FLOW_ATTR_NORMAL = 0,
    IB_FLOW_ATTR_ALL_DEFAULT = 1,
    IB_FLOW_ATTR_MC_DEFAULT = 2,
    IB_FLOW_ATTR_SNIFFER = 3
} ;
#line 1450 "include/rdma/ib_verbs.h"
struct ib_flow_attr {
   enum ib_flow_attr_type type ;
   u16 size ;
   u16 priority ;
   u32 flags ;
   u8 num_of_specs ;
   u8 port ;
};
#line 1459 "include/rdma/ib_verbs.h"
struct ib_flow {
   struct ib_qp *qp ;
   struct ib_uobject *uobject ;
};
#line 1468
struct ib_mad_hdr;
#line 1482
struct ib_pkey_cache;
#line 1482
struct ib_gid_cache;
#line 1482 "include/rdma/ib_verbs.h"
struct ib_cache {
   rwlock_t lock ;
   struct ib_event_handler event_handler ;
   struct ib_pkey_cache **pkey_cache ;
   struct ib_gid_cache **gid_cache ;
   u8 *lmc_cache ;
};
#line 1494 "include/rdma/ib_verbs.h"
struct ib_dma_mapping_ops {
   int (*mapping_error)(struct ib_device * , u64  ) ;
   u64 (*map_single)(struct ib_device * , void * , size_t  , enum dma_data_direction  ) ;
   void (*unmap_single)(struct ib_device * , u64  , size_t  , enum dma_data_direction  ) ;
   u64 (*map_page)(struct ib_device * , struct page * , unsigned long  , size_t  ,
                   enum dma_data_direction  ) ;
   void (*unmap_page)(struct ib_device * , u64  , size_t  , enum dma_data_direction  ) ;
   int (*map_sg)(struct ib_device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*unmap_sg)(struct ib_device * , struct scatterlist * , int  , enum dma_data_direction  ) ;
   void (*sync_single_for_cpu)(struct ib_device * , u64  , size_t  , enum dma_data_direction  ) ;
   void (*sync_single_for_device)(struct ib_device * , u64  , size_t  , enum dma_data_direction  ) ;
   void *(*alloc_coherent)(struct ib_device * , size_t  , u64 * , gfp_t  ) ;
   void (*free_coherent)(struct ib_device * , size_t  , void * , u64  ) ;
};
#line 1531
struct iw_cm_verbs;
#line 1532 "include/rdma/ib_verbs.h"
struct ib_port_immutable {
   int pkey_tbl_len ;
   int gid_tbl_len ;
   u32 core_cap_flags ;
   u32 max_mad_size ;
};
#line 1542
enum ldv_23370 {
    IB_DEV_UNINITIALIZED = 0,
    IB_DEV_REGISTERED = 1,
    IB_DEV_UNREGISTERED = 2
} ;
#line 1548 "include/rdma/ib_verbs.h"
struct ib_device {
   struct device *dma_device ;
   char name[64U] ;
   struct list_head event_handler_list ;
   spinlock_t event_handler_lock ;
   spinlock_t client_data_lock ;
   struct list_head core_list ;
   struct list_head client_data_list ;
   struct ib_cache cache ;
   struct ib_port_immutable *port_immutable ;
   int num_comp_vectors ;
   struct iw_cm_verbs *iwcm ;
   int (*get_protocol_stats)(struct ib_device * , union rdma_protocol_stats * ) ;
   int (*query_device)(struct ib_device * , struct ib_device_attr * , struct ib_udata * ) ;
   int (*query_port)(struct ib_device * , u8  , struct ib_port_attr * ) ;
   enum rdma_link_layer (*get_link_layer)(struct ib_device * , u8  ) ;
   int (*query_gid)(struct ib_device * , u8  , int  , union ib_gid * ) ;
   int (*query_pkey)(struct ib_device * , u8  , u16  , u16 * ) ;
   int (*modify_device)(struct ib_device * , int  , struct ib_device_modify * ) ;
   int (*modify_port)(struct ib_device * , u8  , int  , struct ib_port_modify * ) ;
   struct ib_ucontext *(*alloc_ucontext)(struct ib_device * , struct ib_udata * ) ;
   int (*dealloc_ucontext)(struct ib_ucontext * ) ;
   int (*mmap)(struct ib_ucontext * , struct vm_area_struct * ) ;
   struct ib_pd *(*alloc_pd)(struct ib_device * , struct ib_ucontext * , struct ib_udata * ) ;
   int (*dealloc_pd)(struct ib_pd * ) ;
   struct ib_ah *(*create_ah)(struct ib_pd * , struct ib_ah_attr * ) ;
   int (*modify_ah)(struct ib_ah * , struct ib_ah_attr * ) ;
   int (*query_ah)(struct ib_ah * , struct ib_ah_attr * ) ;
   int (*destroy_ah)(struct ib_ah * ) ;
   struct ib_srq *(*create_srq)(struct ib_pd * , struct ib_srq_init_attr * , struct ib_udata * ) ;
   int (*modify_srq)(struct ib_srq * , struct ib_srq_attr * , enum ib_srq_attr_mask  ,
                     struct ib_udata * ) ;
   int (*query_srq)(struct ib_srq * , struct ib_srq_attr * ) ;
   int (*destroy_srq)(struct ib_srq * ) ;
   int (*post_srq_recv)(struct ib_srq * , struct ib_recv_wr * , struct ib_recv_wr ** ) ;
   struct ib_qp *(*create_qp)(struct ib_pd * , struct ib_qp_init_attr * , struct ib_udata * ) ;
   int (*modify_qp)(struct ib_qp * , struct ib_qp_attr * , int  , struct ib_udata * ) ;
   int (*query_qp)(struct ib_qp * , struct ib_qp_attr * , int  , struct ib_qp_init_attr * ) ;
   int (*destroy_qp)(struct ib_qp * ) ;
   int (*post_send)(struct ib_qp * , struct ib_send_wr * , struct ib_send_wr ** ) ;
   int (*post_recv)(struct ib_qp * , struct ib_recv_wr * , struct ib_recv_wr ** ) ;
   struct ib_cq *(*create_cq)(struct ib_device * , struct ib_cq_init_attr  const  * ,
                              struct ib_ucontext * , struct ib_udata * ) ;
   int (*modify_cq)(struct ib_cq * , u16  , u16  ) ;
   int (*destroy_cq)(struct ib_cq * ) ;
   int (*resize_cq)(struct ib_cq * , int  , struct ib_udata * ) ;
   int (*poll_cq)(struct ib_cq * , int  , struct ib_wc * ) ;
   int (*peek_cq)(struct ib_cq * , int  ) ;
   int (*req_notify_cq)(struct ib_cq * , enum ib_cq_notify_flags  ) ;
   int (*req_ncomp_notif)(struct ib_cq * , int  ) ;
   struct ib_mr *(*get_dma_mr)(struct ib_pd * , int  ) ;
   struct ib_mr *(*reg_phys_mr)(struct ib_pd * , struct ib_phys_buf * , int  , int  ,
                                u64 * ) ;
   struct ib_mr *(*reg_user_mr)(struct ib_pd * , u64  , u64  , u64  , int  , struct ib_udata * ) ;
   int (*rereg_user_mr)(struct ib_mr * , int  , u64  , u64  , u64  , int  , struct ib_pd * ,
                        struct ib_udata * ) ;
   int (*query_mr)(struct ib_mr * , struct ib_mr_attr * ) ;
   int (*dereg_mr)(struct ib_mr * ) ;
   int (*destroy_mr)(struct ib_mr * ) ;
   struct ib_mr *(*create_mr)(struct ib_pd * , struct ib_mr_init_attr * ) ;
   struct ib_mr *(*alloc_fast_reg_mr)(struct ib_pd * , int  ) ;
   struct ib_fast_reg_page_list *(*alloc_fast_reg_page_list)(struct ib_device * ,
                                                             int  ) ;
   void (*free_fast_reg_page_list)(struct ib_fast_reg_page_list * ) ;
   int (*rereg_phys_mr)(struct ib_mr * , int  , struct ib_pd * , struct ib_phys_buf * ,
                        int  , int  , u64 * ) ;
   struct ib_mw *(*alloc_mw)(struct ib_pd * , enum ib_mw_type  ) ;
   int (*bind_mw)(struct ib_qp * , struct ib_mw * , struct ib_mw_bind * ) ;
   int (*dealloc_mw)(struct ib_mw * ) ;
   struct ib_fmr *(*alloc_fmr)(struct ib_pd * , int  , struct ib_fmr_attr * ) ;
   int (*map_phys_fmr)(struct ib_fmr * , u64 * , int  , u64  ) ;
   int (*unmap_fmr)(struct list_head * ) ;
   int (*dealloc_fmr)(struct ib_fmr * ) ;
   int (*attach_mcast)(struct ib_qp * , union ib_gid * , u16  ) ;
   int (*detach_mcast)(struct ib_qp * , union ib_gid * , u16  ) ;
   int (*process_mad)(struct ib_device * , int  , u8  , struct ib_wc  const  * , struct ib_grh  const  * ,
                      struct ib_mad_hdr  const  * , size_t  , struct ib_mad_hdr * ,
                      size_t * , u16 * ) ;
   struct ib_xrcd *(*alloc_xrcd)(struct ib_device * , struct ib_ucontext * , struct ib_udata * ) ;
   int (*dealloc_xrcd)(struct ib_xrcd * ) ;
   struct ib_flow *(*create_flow)(struct ib_qp * , struct ib_flow_attr * , int  ) ;
   int (*destroy_flow)(struct ib_flow * ) ;
   int (*check_mr_status)(struct ib_mr * , u32  , struct ib_mr_status * ) ;
   struct ib_dma_mapping_ops *dma_ops ;
   struct module *owner ;
   struct device dev ;
   struct kobject *ports_parent ;
   struct list_head port_list ;
   enum ldv_23370 reg_state ;
   int uverbs_abi_ver ;
   u64 uverbs_cmd_mask ;
   u64 uverbs_ex_cmd_mask ;
   char node_desc[64U] ;
   __be64 node_guid ;
   u32 local_dma_lkey ;
   u8 node_type ;
   u8 phys_port_cnt ;
   int (*get_port_immutable)(struct ib_device * , u8  , struct ib_port_immutable * ) ;
};
#line 6994 "include/linux/mlx5/mlx5_ifc.h"
struct mlx5_inbox_hdr {
   __be16 opcode ;
   u8 rsvd[4U] ;
   __be16 opmod ;
};
#line 342 "include/linux/mlx5/device.h"
struct mlx5_outbox_hdr {
   u8 status ;
   u8 rsvd[3U] ;
   __be32 syndrome ;
};
#line 404 "include/linux/mlx5/device.h"
struct mlx5_cmd_layout {
   u8 type ;
   u8 rsvd0[3U] ;
   __be32 inlen ;
   __be64 in_ptr ;
   __be32 in[4U] ;
   __be32 out[4U] ;
   __be64 out_ptr ;
   __be32 outlen ;
   u8 token ;
   u8 sig ;
   u8 rsvd1 ;
   u8 status_own ;
};
#line 419 "include/linux/mlx5/device.h"
struct health_buffer {
   __be32 assert_var[5U] ;
   __be32 rsvd0[3U] ;
   __be32 assert_exit_ptr ;
   __be32 assert_callra ;
   __be32 rsvd1[2U] ;
   __be32 fw_ver ;
   __be32 hw_id ;
   __be32 rsvd2 ;
   u8 irisc_index ;
   u8 synd ;
   __be16 ext_sync ;
};
#line 434 "include/linux/mlx5/device.h"
struct mlx5_init_seg {
   __be32 fw_rev ;
   __be32 cmdif_rev_fw_sub ;
   __be32 rsvd0[2U] ;
   __be32 cmdq_addr_h ;
   __be32 cmdq_addr_l_sz ;
   __be32 cmd_dbell ;
   __be32 rsvd1[121U] ;
   struct health_buffer health ;
   __be32 rsvd2[884U] ;
   __be32 health_counter ;
   __be32 rsvd3[1019U] ;
   __be64 ieee1588_clk ;
   __be32 ieee1588_clk_type ;
   __be32 clr_intx ;
};
#line 910 "include/linux/mlx5/device.h"
struct mlx5_mkey_seg {
   u8 status ;
   u8 pcie_control ;
   u8 flags ;
   u8 version ;
   __be32 qpn_mkey7_0 ;
   u8 rsvd1[4U] ;
   __be32 flags_pd ;
   __be64 start_addr ;
   __be64 len ;
   __be32 bsfs_octo_size ;
   u8 rsvd2[16U] ;
   __be32 xlt_oct_size ;
   u8 rsvd3[3U] ;
   u8 log2_page_size ;
   u8 rsvd4[4U] ;
};
#line 943 "include/linux/mlx5/device.h"
struct mlx5_create_mkey_mbox_in {
   struct mlx5_inbox_hdr hdr ;
   __be32 input_mkey_index ;
   __be32 flags ;
   struct mlx5_mkey_seg seg ;
   u8 rsvd1[16U] ;
   __be32 xlat_oct_act_size ;
   __be32 rsvd2 ;
   u8 rsvd3[168U] ;
   __be64 pas[0U] ;
};
#line 955 "include/linux/mlx5/device.h"
struct mlx5_create_mkey_mbox_out {
   struct mlx5_outbox_hdr hdr ;
   __be32 mkey ;
   u8 rsvd[4U] ;
};
#line 126 "include/linux/mlx5/doorbell.h"
enum dbg_rsc_type {
    MLX5_DBG_RSC_QP = 0,
    MLX5_DBG_RSC_EQ = 1,
    MLX5_DBG_RSC_CQ = 2
} ;
#line 132 "include/linux/mlx5/doorbell.h"
struct mlx5_field_desc {
   struct dentry *dent ;
   int i ;
};
#line 133 "include/linux/mlx5/driver.h"
struct mlx5_rsc_debug {
   struct mlx5_core_dev *dev ;
   void *object ;
   enum dbg_rsc_type type ;
   struct dentry *root ;
   struct mlx5_field_desc fields[0U] ;
};
#line 141
enum mlx5_dev_event {
    MLX5_DEV_EVENT_SYS_ERROR = 0,
    MLX5_DEV_EVENT_PORT_UP = 1,
    MLX5_DEV_EVENT_PORT_DOWN = 2,
    MLX5_DEV_EVENT_PORT_INITIALIZED = 3,
    MLX5_DEV_EVENT_LID_CHANGE = 4,
    MLX5_DEV_EVENT_PKEY_CHANGE = 5,
    MLX5_DEV_EVENT_GUID_CHANGE = 6,
    MLX5_DEV_EVENT_CLIENT_REREG = 7
} ;
#line 157
struct mlx5_uar;
#line 157
struct mlx5_bf;
#line 157 "include/linux/mlx5/driver.h"
struct mlx5_uuar_info {
   struct mlx5_uar *uars ;
   int num_uars ;
   int num_low_latency_uuars ;
   unsigned long *bitmap ;
   unsigned int *count ;
   struct mlx5_bf *bfs ;
   struct mutex lock ;
   u32 ver ;
};
#line 172 "include/linux/mlx5/driver.h"
struct mlx5_bf {
   void *reg ;
   void *regreg ;
   int buf_size ;
   struct mlx5_uar *uar ;
   unsigned long offset ;
   int need_lock ;
   spinlock_t lock ;
   spinlock_t lock32 ;
   int uuarn ;
};
#line 189 "include/linux/mlx5/driver.h"
struct mlx5_cmd_first {
   __be32 data[4U] ;
};
#line 193
struct cache_ent;
#line 193
struct mlx5_cmd_mailbox;
#line 193 "include/linux/mlx5/driver.h"
struct mlx5_cmd_msg {
   struct list_head list ;
   struct cache_ent *cache ;
   u32 len ;
   struct mlx5_cmd_first first ;
   struct mlx5_cmd_mailbox *next ;
};
#line 201 "include/linux/mlx5/driver.h"
struct mlx5_cmd_debug {
   struct dentry *dbg_root ;
   struct dentry *dbg_in ;
   struct dentry *dbg_out ;
   struct dentry *dbg_outlen ;
   struct dentry *dbg_status ;
   struct dentry *dbg_run ;
   void *in_msg ;
   void *out_msg ;
   u8 status ;
   u16 inlen ;
   u16 outlen ;
};
#line 215 "include/linux/mlx5/driver.h"
struct cache_ent {
   spinlock_t lock ;
   struct list_head head ;
};
#line 222 "include/linux/mlx5/driver.h"
struct cmd_msg_cache {
   struct cache_ent large ;
   struct cache_ent med ;
};
#line 227 "include/linux/mlx5/driver.h"
struct mlx5_cmd_stats {
   u64 sum ;
   u64 n ;
   struct dentry *root ;
   struct dentry *avg ;
   struct dentry *count ;
   spinlock_t lock ;
};
#line 238
struct mlx5_cmd_work_ent;
#line 238 "include/linux/mlx5/driver.h"
struct mlx5_cmd {
   void *cmd_alloc_buf ;
   dma_addr_t alloc_dma ;
   int alloc_size ;
   void *cmd_buf ;
   dma_addr_t dma ;
   u16 cmdif_rev ;
   u8 log_sz ;
   u8 log_stride ;
   int max_reg_cmds ;
   int events ;
   u32 *vector ;
   spinlock_t alloc_lock ;
   spinlock_t token_lock ;
   u8 token ;
   unsigned long bitmask ;
   char wq_name[32U] ;
   struct workqueue_struct *wq ;
   struct semaphore sem ;
   struct semaphore pages_sem ;
   int mode ;
   struct mlx5_cmd_work_ent *ent_arr[32U] ;
   struct dma_pool *pool ;
   struct mlx5_cmd_debug dbg ;
   struct cmd_msg_cache cache ;
   int checksum_disabled ;
   struct mlx5_cmd_stats stats[2336U] ;
};
#line 273 "include/linux/mlx5/driver.h"
struct mlx5_port_caps {
   int gid_table_len ;
   int pkey_table_len ;
   u8 ext_port_cap ;
};
#line 279 "include/linux/mlx5/driver.h"
struct mlx5_cmd_mailbox {
   void *buf ;
   dma_addr_t dma ;
   struct mlx5_cmd_mailbox *next ;
};
#line 285 "include/linux/mlx5/driver.h"
struct mlx5_buf_list {
   void *buf ;
   dma_addr_t map ;
};
#line 290 "include/linux/mlx5/driver.h"
struct mlx5_buf {
   struct mlx5_buf_list direct ;
   int npages ;
   int size ;
   u8 page_shift ;
};
#line 297 "include/linux/mlx5/driver.h"
struct mlx5_eq {
   struct mlx5_core_dev *dev ;
   __be32 *doorbell ;
   u32 cons_index ;
   struct mlx5_buf buf ;
   int size ;
   u8 irqn ;
   u8 eqn ;
   int nent ;
   u64 mask ;
   struct list_head list ;
   int index ;
   struct mlx5_rsc_debug *dbg ;
};
#line 333 "include/linux/mlx5/driver.h"
struct mlx5_core_mr {
   u64 iova ;
   u64 size ;
   u32 key ;
   u32 pd ;
};
#line 365 "include/linux/mlx5/driver.h"
struct mlx5_eq_table {
   void *update_ci ;
   void *update_arm_ci ;
   struct list_head comp_eqs_list ;
   struct mlx5_eq pages_eq ;
   struct mlx5_eq async_eq ;
   struct mlx5_eq cmd_eq ;
   int num_comp_vectors ;
   spinlock_t lock ;
};
#line 378 "include/linux/mlx5/driver.h"
struct mlx5_uar {
   u32 index ;
   struct list_head bf_list ;
   unsigned int free_bf_bmap ;
   void *wc_map ;
   void *map ;
};
#line 386 "include/linux/mlx5/driver.h"
struct mlx5_core_health {
   struct health_buffer *health ;
   __be32 *health_counter ;
   struct timer_list timer ;
   struct list_head list ;
   u32 prev ;
   int miss_counter ;
};
#line 396 "include/linux/mlx5/driver.h"
struct mlx5_cq_table {
   spinlock_t lock ;
   struct radix_tree_root tree ;
};
#line 403 "include/linux/mlx5/driver.h"
struct mlx5_qp_table {
   spinlock_t lock ;
   struct radix_tree_root tree ;
};
#line 410 "include/linux/mlx5/driver.h"
struct mlx5_srq_table {
   spinlock_t lock ;
   struct radix_tree_root tree ;
};
#line 417 "include/linux/mlx5/driver.h"
struct mlx5_mr_table {
   rwlock_t lock ;
   struct radix_tree_root tree ;
};
#line 424 "include/linux/mlx5/driver.h"
struct mlx5_irq_info {
   cpumask_var_t mask ;
   char name[32U] ;
};
#line 429 "include/linux/mlx5/driver.h"
struct mlx5_priv {
   char name[16U] ;
   struct mlx5_eq_table eq_table ;
   struct msix_entry *msix_arr ;
   struct mlx5_irq_info *irq_info ;
   struct mlx5_uuar_info uuari ;
   struct workqueue_struct *pg_wq ;
   struct rb_root page_root ;
   int fw_pages ;
   atomic_t reg_pages ;
   struct list_head free_list ;
   struct mlx5_core_health health ;
   struct mlx5_srq_table srq_table ;
   struct mlx5_qp_table qp_table ;
   struct dentry *qp_debugfs ;
   struct dentry *eq_debugfs ;
   struct dentry *cq_debugfs ;
   struct dentry *cmdif_debugfs ;
   struct mlx5_cq_table cq_table ;
   struct mlx5_mr_table mr_table ;
   struct mutex pgdir_mutex ;
   struct list_head pgdir_list ;
   struct dentry *dbg_root ;
   spinlock_t mkey_lock ;
   u8 mkey_key ;
   struct list_head dev_list ;
   struct list_head ctx_list ;
   spinlock_t ctx_lock ;
};
#line 479
struct mlx5_profile;
#line 479 "include/linux/mlx5/driver.h"
struct mlx5_core_dev {
   struct pci_dev *pdev ;
   u8 rev_id ;
   char board_id[64U] ;
   struct mlx5_cmd cmd ;
   struct mlx5_port_caps port_caps[2U] ;
   u32 hca_caps_cur[8U][1024U] ;
   u32 hca_caps_max[8U][1024U] ;
   phys_addr_t iseg_base ;
   struct mlx5_init_seg *iseg ;
   void (*event)(struct mlx5_core_dev * , enum mlx5_dev_event  , unsigned long  ) ;
   struct mlx5_priv priv ;
   struct mlx5_profile *profile ;
   atomic_t num_qps ;
   u32 issi ;
};
#line 530 "include/linux/mlx5/driver.h"
struct mlx5_cmd_work_ent {
   struct mlx5_cmd_msg *in ;
   struct mlx5_cmd_msg *out ;
   void *uout ;
   int uout_size ;
   void (*callback)(int  , void * ) ;
   void *context ;
   int idx ;
   struct completion done ;
   struct mlx5_cmd *cmd ;
   struct work_struct work ;
   struct mlx5_cmd_layout *lay ;
   int ret ;
   int page_queue ;
   u8 status ;
   u8 token ;
   u64 ts1 ;
   u64 ts2 ;
   u16 op ;
};
#line 556
enum port_state_policy {
    MLX5_AAA_000 = 0
} ;
#line 560
enum phy_port_state {
    MLX5_AAA_111 = 0
} ;
#line 564 "include/linux/mlx5/driver.h"
struct mlx5_hca_vport_context {
   u32 field_select ;
   bool sm_virt_aware ;
   bool has_smi ;
   bool has_raw ;
   enum port_state_policy policy ;
   enum phy_port_state phys_state ;
   enum ib_port_state vport_state ;
   u8 port_physical_state ;
   u64 sys_image_guid ;
   u64 port_guid ;
   u64 node_guid ;
   u32 cap_mask1 ;
   u32 cap_mask1_perm ;
   u32 cap_mask2 ;
   u32 cap_mask2_perm ;
   u16 lid ;
   u8 init_type_reply ;
   u8 lmc ;
   u8 subnet_timeout ;
   u16 sm_lid ;
   u8 sm_sl ;
   u16 qkey_violation_counter ;
   u16 pkey_violation_counter ;
   bool grh_required ;
};
#line 816 "include/linux/mlx5/driver.h"
struct mlx5_interface {
   void *(*add)(struct mlx5_core_dev * ) ;
   void (*remove)(struct mlx5_core_dev * , void * ) ;
   void (*event)(struct mlx5_core_dev * , void * , enum mlx5_dev_event  , unsigned long  ) ;
   void *(*get_dev)(void * ) ;
   int protocol ;
   struct list_head list ;
};
#line 831 "include/linux/mlx5/driver.h"
struct __anonstruct_mr_cache_261 {
   int size ;
   int limit ;
};
#line 831 "include/linux/mlx5/driver.h"
struct mlx5_profile {
   u64 mask ;
   u8 log_max_qp ;
   struct __anonstruct_mr_cache_261 mr_cache[16U] ;
};
#line 249 "include/uapi/rdma/ib_user_mad.h"
struct ib_mad_hdr {
   u8 base_version ;
   u8 mgmt_class ;
   u8 class_version ;
   u8 method ;
   __be16 status ;
   __be16 class_specific ;
   __be64 tid ;
   __be16 attr_id ;
   __be16 resv ;
   __be32 attr_mod ;
};
#line 127 "include/rdma/ib_smi.h"
struct ib_umem_odp;
#line 128 "include/rdma/ib_smi.h"
struct ib_umem {
   struct ib_ucontext *context ;
   size_t length ;
   unsigned long address ;
   int page_size ;
   int writable ;
   int hugetlb ;
   struct work_struct work ;
   struct pid *pid ;
   struct mm_struct *mm ;
   unsigned long diff ;
   struct ib_umem_odp *odp_data ;
   struct sg_table sg_head ;
   int nmap ;
   int npages ;
};
#line 64 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_alloc_ucontext_req_v2 {
   __u32 total_num_uuars ;
   __u32 num_low_latency_uuars ;
   __u32 flags ;
   __u32 reserved ;
};
#line 71 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_alloc_ucontext_resp {
   __u32 qp_tab_size ;
   __u32 bf_reg_size ;
   __u32 tot_uuars ;
   __u32 cache_line_size ;
   __u16 max_sq_desc_sz ;
   __u16 max_rq_desc_sz ;
   __u32 max_send_wqebb ;
   __u32 max_recv_wr ;
   __u32 max_srq_recv_wr ;
   __u16 num_ports ;
   __u16 reserved ;
};
#line 85 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_alloc_pd_resp {
   __u32 pdn ;
};
#line 70 "include/linux/mlx5/srq.h"
struct mlx5_ib_ucontext {
   struct ib_ucontext ibucontext ;
   struct list_head db_page_list ;
   struct mutex db_page_mutex ;
   struct mlx5_uuar_info uuari ;
};
#line 103 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_pd {
   struct ib_pd ibpd ;
   u32 pdn ;
   u32 pa_lkey ;
};
#line 313
struct mlx5_ib_dev;
#line 347 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct umr_common {
   struct ib_pd *pd ;
   struct ib_cq *cq ;
   struct ib_qp *qp ;
   struct ib_mr *mr ;
   struct semaphore sem ;
};
#line 377 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_cache_ent {
   struct list_head head ;
   spinlock_t lock ;
   struct dentry *dir ;
   char name[4U] ;
   u32 order ;
   u32 size ;
   u32 cur ;
   u32 miss ;
   u32 limit ;
   struct dentry *fsize ;
   struct dentry *fcur ;
   struct dentry *fmiss ;
   struct dentry *flimit ;
   struct mlx5_ib_dev *dev ;
   struct work_struct work ;
   struct delayed_work dwork ;
   int pending ;
};
#line 403 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_mr_cache {
   struct workqueue_struct *wq ;
   struct mlx5_cache_ent ent[16U] ;
   int stopped ;
   struct dentry *root ;
   unsigned long last_add ;
};
#line 411 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_resources {
   struct ib_cq *c0 ;
   struct ib_xrcd *x0 ;
   struct ib_xrcd *x1 ;
   struct ib_pd *p0 ;
   struct ib_srq *s0 ;
   struct ib_srq *s1 ;
};
#line 420 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_dev {
   struct ib_device ib_dev ;
   struct mlx5_core_dev *mdev ;
   int num_ports ;
   struct mutex cap_mask_mutex ;
   bool ib_active ;
   struct umr_common umrc ;
   struct mlx5_ib_resources devr ;
   struct mlx5_mr_cache cache ;
   struct timer_list delay_timer ;
   int fill_delay ;
   struct ib_odp_caps odp_caps ;
   struct srcu_struct mr_srcu ;
};
#line 187 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
struct mlx5_reg_node_desc {
   u8 desc[64U] ;
};
#line 478 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
typedef bool ldv_func_ret_type;
#line 489 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
typedef bool ldv_func_ret_type___0;
#line 500 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
typedef bool ldv_func_ret_type___1;
#line 519 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
typedef bool ldv_func_ret_type___2;
#line 106 "include/linux/types.h"
typedef __u8 uint8_t;
#line 107 "include/linux/types.h"
typedef __u16 uint16_t;
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 6894 "include/linux/mlx5/mlx5_ifc.h"
enum mlx5_event {
    MLX5_EVENT_TYPE_COMP = 0,
    MLX5_EVENT_TYPE_PATH_MIG = 1,
    MLX5_EVENT_TYPE_COMM_EST = 2,
    MLX5_EVENT_TYPE_SQ_DRAINED = 3,
    MLX5_EVENT_TYPE_SRQ_LAST_WQE = 19,
    MLX5_EVENT_TYPE_SRQ_RQ_LIMIT = 20,
    MLX5_EVENT_TYPE_CQ_ERROR = 4,
    MLX5_EVENT_TYPE_WQ_CATAS_ERROR = 5,
    MLX5_EVENT_TYPE_PATH_MIG_FAILED = 7,
    MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR = 16,
    MLX5_EVENT_TYPE_WQ_ACCESS_ERROR = 17,
    MLX5_EVENT_TYPE_SRQ_CATAS_ERROR = 18,
    MLX5_EVENT_TYPE_INTERNAL_ERROR = 8,
    MLX5_EVENT_TYPE_PORT_CHANGE = 9,
    MLX5_EVENT_TYPE_GPIO_EVENT = 21,
    MLX5_EVENT_TYPE_REMOTE_CONFIG = 25,
    MLX5_EVENT_TYPE_DB_BF_CONGESTION = 26,
    MLX5_EVENT_TYPE_STALL_EVENT = 27,
    MLX5_EVENT_TYPE_CMD = 10,
    MLX5_EVENT_TYPE_PAGE_REQUEST = 11,
    MLX5_EVENT_TYPE_PAGE_FAULT = 12
} ;
#line 562 "include/linux/mlx5/device.h"
struct mlx5_err_cqe {
   u8 rsvd0[32U] ;
   __be32 srqn ;
   u8 rsvd1[18U] ;
   u8 vendor_err_synd ;
   u8 syndrome ;
   __be32 s_wqe_opcode_qpn ;
   __be16 wqe_counter ;
   u8 signature ;
   u8 op_own ;
};
#line 574 "include/linux/mlx5/device.h"
struct mlx5_cqe64 {
   u8 rsvd0[4U] ;
   u8 lro_tcppsh_abort_dupack ;
   u8 lro_min_ttl ;
   __be16 lro_tcp_win ;
   __be32 lro_ack_seq_num ;
   __be32 rss_hash_result ;
   u8 rss_hash_type ;
   u8 ml_path ;
   u8 rsvd20[2U] ;
   __be16 check_sum ;
   __be16 slid ;
   __be32 flags_rqpn ;
   u8 hds_ip_ext ;
   u8 l4_hdr_type_etc ;
   __be16 vlan_info ;
   __be32 srqn ;
   __be32 imm_inval_pkey ;
   u8 rsvd40[4U] ;
   __be32 byte_cnt ;
   __be64 timestamp ;
   __be32 sop_drop_qpn ;
   __be16 wqe_counter ;
   u8 signature ;
   u8 op_own ;
};
#line 635 "include/linux/mlx5/device.h"
struct mlx5_sig_err_cqe {
   u8 rsvd0[16U] ;
   __be32 expected_trans_sig ;
   __be32 actual_trans_sig ;
   __be32 expected_reftag ;
   __be32 actual_reftag ;
   __be16 syndrome ;
   u8 rsvd22[2U] ;
   __be32 mkey ;
   __be64 err_offset ;
   u8 rsvd30[8U] ;
   __be32 qpn ;
   u8 rsvd38[2U] ;
   u8 signature ;
   u8 op_own ;
};
#line 736 "include/linux/mlx5/device.h"
struct mlx5_cq_context {
   u8 status ;
   u8 cqe_sz_flags ;
   u8 st ;
   u8 rsvd3 ;
   u8 rsvd4[6U] ;
   __be16 page_offset ;
   __be32 log_sz_usr_page ;
   __be16 cq_period ;
   __be16 cq_max_count ;
   __be16 rsvd20 ;
   __be16 c_eqn ;
   u8 log_pg_sz ;
   u8 rsvd25[7U] ;
   __be32 last_notified_index ;
   __be32 solicit_producer_index ;
   __be32 consumer_counter ;
   __be32 producer_counter ;
   u8 rsvd48[8U] ;
   __be64 db_record_addr ;
};
#line 758 "include/linux/mlx5/device.h"
struct mlx5_create_cq_mbox_in {
   struct mlx5_inbox_hdr hdr ;
   __be32 input_cqn ;
   u8 rsvdx[4U] ;
   struct mlx5_cq_context ctx ;
   u8 rsvd6[192U] ;
   __be64 pas[0U] ;
};
#line 798 "include/linux/mlx5/device.h"
struct mlx5_modify_cq_mbox_in {
   struct mlx5_inbox_hdr hdr ;
   __be32 cqn ;
   __be32 field_select ;
   struct mlx5_cq_context ctx ;
   u8 rsvd[192U] ;
   __be64 pas[0U] ;
};
#line 312 "include/linux/mlx5/driver.h"
struct psv_layout {
   u32 pd ;
   u16 syndrome ;
   u16 reserved ;
   u16 bg ;
   u16 app_tag ;
   u32 ref_tag ;
};
#line 323 "include/linux/mlx5/driver.h"
struct mlx5_core_psv {
   u32 psv_idx ;
   struct psv_layout psv ;
};
#line 324 "include/linux/mlx5/driver.h"
struct mlx5_core_sig_ctx {
   struct mlx5_core_psv psv_memory ;
   struct mlx5_core_psv psv_wire ;
   struct ib_sig_err err_item ;
   bool sig_status_checked ;
   bool sig_err_exists ;
   u32 sigerr_count ;
};
#line 340
enum mlx5_res_type {
    MLX5_RES_QP = 0,
    MLX5_RES_SRQ = 1,
    MLX5_RES_XSRQ = 2
} ;
#line 346 "include/linux/mlx5/driver.h"
struct mlx5_core_rsc_common {
   enum mlx5_res_type res ;
   atomic_t refcount ;
   struct completion free ;
};
#line 352 "include/linux/mlx5/driver.h"
struct mlx5_core_srq {
   struct mlx5_core_rsc_common common ;
   u32 srqn ;
   int max ;
   int max_gs ;
   int max_avail_gather ;
   int wqe_shift ;
   void (*event)(struct mlx5_core_srq * , enum mlx5_event  ) ;
   atomic_t refcount ;
   struct completion free ;
};
#line 498
struct mlx5_db_pgdir;
#line 498
struct mlx5_ib_user_db_page;
#line 498 "include/linux/mlx5/driver.h"
union __anonunion_u_261 {
   struct mlx5_db_pgdir *pgdir ;
   struct mlx5_ib_user_db_page *user_page ;
};
#line 498 "include/linux/mlx5/driver.h"
struct mlx5_db {
   __be32 *db ;
   union __anonunion_u_261 u ;
   dma_addr_t dma ;
   int index ;
};
#line 521 "include/linux/mlx5/driver.h"
struct mlx5_db_pgdir {
   struct list_head list ;
   unsigned long bitmap[1U] ;
   __be32 *db_page ;
   dma_addr_t db_dma ;
};
#line 850 "include/linux/mlx5/driver.h"
struct mlx5_core_cq {
   u32 cqn ;
   int cqe_sz ;
   __be32 *set_ci_db ;
   __be32 *arm_db ;
   atomic_t refcount ;
   struct completion free ;
   unsigned int vector ;
   int irqn ;
   void (*comp)(struct mlx5_core_cq * ) ;
   void (*event)(struct mlx5_core_cq * , enum mlx5_event  ) ;
   struct mlx5_uar *uar ;
   u32 cons_index ;
   unsigned int arm_sn ;
   struct mlx5_rsc_debug *dbg ;
   int pid ;
};
#line 273 "include/linux/mlx5/qp.h"
struct mlx5_wqe_data_seg {
   __be32 byte_count ;
   __be32 lkey ;
   __be64 addr ;
};
#line 400
enum mlx5_pagefault_flags {
    MLX5_PFAULT_REQUESTOR = 1,
    MLX5_PFAULT_WRITE = 2,
    MLX5_PFAULT_RDMA = 4
} ;
#line 406 "include/linux/mlx5/qp.h"
struct __anonstruct_wqe_272 {
   u32 packet_size ;
   u16 wqe_index ;
};
#line 406 "include/linux/mlx5/qp.h"
struct __anonstruct_rdma_273 {
   u32 r_key ;
   u32 packet_size ;
   u32 rdma_op_len ;
   u64 rdma_va ;
};
#line 406 "include/linux/mlx5/qp.h"
union __anonunion____missing_field_name_271 {
   struct __anonstruct_wqe_272 wqe ;
   struct __anonstruct_rdma_273 rdma ;
};
#line 406 "include/linux/mlx5/qp.h"
struct mlx5_pagefault {
   u32 bytes_committed ;
   u8 event_subtype ;
   enum mlx5_pagefault_flags flags ;
   union __anonunion____missing_field_name_271 __annonCompField70 ;
};
#line 436 "include/linux/mlx5/qp.h"
struct mlx5_core_qp {
   struct mlx5_core_rsc_common common ;
   void (*event)(struct mlx5_core_qp * , int  ) ;
   void (*pfault_handler)(struct mlx5_core_qp * , struct mlx5_pagefault * ) ;
   int qpn ;
   struct mlx5_rsc_debug *dbg ;
   int pid ;
};
#line 108 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct wr_list {
   u16 opcode ;
   u16 next ;
};
#line 123 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_wq {
   u64 *wrid ;
   u32 *wr_data ;
   struct wr_list *w_list ;
   unsigned int *wqe_head ;
   u16 unsig_count ;
   spinlock_t lock ;
   int wqe_cnt ;
   int max_post ;
   int max_gs ;
   int offset ;
   int wqe_shift ;
   unsigned int head ;
   unsigned int tail ;
   u16 cur_post ;
   u16 last_poll ;
   void *qend ;
};
#line 169 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_pfault {
   struct work_struct work ;
   struct mlx5_pagefault mpfault ;
};
#line 174 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_qp {
   struct ib_qp ibqp ;
   struct mlx5_core_qp mqp ;
   struct mlx5_buf buf ;
   struct mlx5_db db ;
   struct mlx5_ib_wq rq ;
   u32 doorbell_qpn ;
   u8 sq_signal_bits ;
   u8 fm_cache ;
   int sq_max_wqes_per_wr ;
   int sq_spare_wqes ;
   struct mlx5_ib_wq sq ;
   struct ib_umem *umem ;
   int buf_size ;
   struct mutex mutex ;
   u16 xrcdn ;
   u32 flags ;
   u8 port ;
   u8 alt_port ;
   u8 atomic_rd_en ;
   u8 resp_depth ;
   u8 state ;
   int mlx_type ;
   int wq_sig ;
   int scat_cqe ;
   int max_inline_data ;
   struct mlx5_bf *bf ;
   int has_rq ;
   int uuarn ;
   int create_type ;
   u32 pa_lkey ;
   bool signature_en ;
   int disable_page_faults ;
   spinlock_t disable_page_faults_lock ;
   struct mlx5_ib_pfault pagefaults[4U] ;
};
#line 235 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_cq_buf {
   struct mlx5_buf buf ;
   struct ib_umem *umem ;
   int cqe_size ;
   int nent ;
};
#line 261 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_shared_mr_info {
   int mr_id ;
   struct ib_umem *umem ;
};
#line 266 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_cq {
   struct ib_cq ibcq ;
   struct mlx5_core_cq mcq ;
   struct mlx5_ib_cq_buf buf ;
   struct mlx5_db db ;
   spinlock_t lock ;
   struct mutex resize_mutex ;
   struct mlx5_ib_cq_buf *resize_buf ;
   struct ib_umem *resize_umem ;
   int cqe_size ;
};
#line 284 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_srq {
   struct ib_srq ibsrq ;
   struct mlx5_core_srq msrq ;
   struct mlx5_buf buf ;
   struct mlx5_db db ;
   u64 *wrid ;
   spinlock_t lock ;
   int head ;
   int tail ;
   u16 wqe_ctr ;
   struct ib_umem *umem ;
   struct mutex mutex ;
   int wq_sig ;
};
#line 313 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_mr {
   struct ib_mr ibmr ;
   struct mlx5_core_mr mmr ;
   struct ib_umem *umem ;
   struct mlx5_shared_mr_info *smr_info ;
   struct list_head list ;
   int order ;
   int umred ;
   int npages ;
   struct mlx5_ib_dev *dev ;
   struct mlx5_create_mkey_mbox_out out ;
   struct mlx5_core_sig_ctx *sig ;
   int live ;
};
#line 89 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_create_cq {
   __u64 buf_addr ;
   __u64 db_addr ;
   __u32 cqe_size ;
   __u32 reserved ;
};
#line 101 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_resize_cq {
   __u64 buf_addr ;
   __u16 cqe_size ;
   __u16 reserved0 ;
   __u32 reserved1 ;
};
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 684 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_user_db_page {
   struct list_head list ;
   struct ib_umem *umem ;
   unsigned long user_virt ;
   int refcnt ;
};
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 932 "include/rdma/ib_verbs.h"
enum ib_qp_attr_mask {
    IB_QP_STATE = 1,
    IB_QP_CUR_STATE = 2,
    IB_QP_EN_SQD_ASYNC_NOTIFY = 4,
    IB_QP_ACCESS_FLAGS = 8,
    IB_QP_PKEY_INDEX = 16,
    IB_QP_PORT = 32,
    IB_QP_QKEY = 64,
    IB_QP_AV = 128,
    IB_QP_PATH_MTU = 256,
    IB_QP_TIMEOUT = 512,
    IB_QP_RETRY_CNT = 1024,
    IB_QP_RNR_RETRY = 2048,
    IB_QP_RQ_PSN = 4096,
    IB_QP_MAX_QP_RD_ATOMIC = 8192,
    IB_QP_ALT_PATH = 16384,
    IB_QP_MIN_RNR_TIMER = 32768,
    IB_QP_SQ_PSN = 65536,
    IB_QP_MAX_DEST_RD_ATOMIC = 131072,
    IB_QP_PATH_MIG_STATE = 262144,
    IB_QP_CAP = 524288,
    IB_QP_DEST_QPN = 1048576,
    IB_QP_SMAC = 2097152,
    IB_QP_ALT_SMAC = 4194304,
    IB_QP_VID = 8388608,
    IB_QP_ALT_VID = 16777216
} ;
#line 177 "include/linux/mlx5/cq.h"
enum mlx5_qp_optpar {
    MLX5_QP_OPTPAR_ALT_ADDR_PATH = 1,
    MLX5_QP_OPTPAR_RRE = 2,
    MLX5_QP_OPTPAR_RAE = 4,
    MLX5_QP_OPTPAR_RWE = 8,
    MLX5_QP_OPTPAR_PKEY_INDEX = 16,
    MLX5_QP_OPTPAR_Q_KEY = 32,
    MLX5_QP_OPTPAR_RNR_TIMEOUT = 64,
    MLX5_QP_OPTPAR_PRIMARY_ADDR_PATH = 128,
    MLX5_QP_OPTPAR_SRA_MAX = 256,
    MLX5_QP_OPTPAR_RRA_MAX = 512,
    MLX5_QP_OPTPAR_PM_STATE = 1024,
    MLX5_QP_OPTPAR_RETRY_COUNT = 4096,
    MLX5_QP_OPTPAR_RNR_RETRY = 8192,
    MLX5_QP_OPTPAR_ACK_TIMEOUT = 16384,
    MLX5_QP_OPTPAR_PRI_PORT = 65536,
    MLX5_QP_OPTPAR_SRQN = 262144,
    MLX5_QP_OPTPAR_CQN_RCV = 524288,
    MLX5_QP_OPTPAR_DC_HS = 1048576,
    MLX5_QP_OPTPAR_DC_KEY = 2097152
} ;
#line 199
enum mlx5_qp_state {
    MLX5_QP_STATE_RST = 0,
    MLX5_QP_STATE_INIT = 1,
    MLX5_QP_STATE_RTR = 2,
    MLX5_QP_STATE_RTS = 3,
    MLX5_QP_STATE_SQER = 4,
    MLX5_QP_STATE_SQD = 5,
    MLX5_QP_STATE_ERR = 6,
    MLX5_QP_STATE_SQ_DRAINING = 7,
    MLX5_QP_STATE_SUSPENDED = 9,
    MLX5_QP_NUM_STATE = 10
} ;
#line 193 "include/linux/mlx5/qp.h"
struct mlx5_wqe_ctrl_seg {
   __be32 opmod_idx_opcode ;
   __be32 qpn_ds ;
   u8 signature ;
   u8 rsvd[2U] ;
   u8 fm_ce_se ;
   __be32 imm ;
};
#line 227 "include/linux/mlx5/qp.h"
struct mlx5_wqe_xrc_seg {
   __be32 xrc_srqn ;
   u8 rsvd[12U] ;
};
#line 239 "include/linux/mlx5/qp.h"
struct __anonstruct_qkey_255 {
   __be32 qkey ;
   __be32 reserved ;
};
#line 239 "include/linux/mlx5/qp.h"
union __anonunion_key_254 {
   struct __anonstruct_qkey_255 qkey ;
   __be64 dc_key ;
};
#line 239 "include/linux/mlx5/qp.h"
struct mlx5_av {
   union __anonunion_key_254 key ;
   __be32 dqp_dct ;
   u8 stat_rate_sl ;
   u8 fl_mlid ;
   __be16 rlid ;
   u8 reserved0[10U] ;
   u8 tclass ;
   u8 hop_limit ;
   __be32 grh_gid_fl ;
   u8 rgid[16U] ;
};
#line 258 "include/linux/mlx5/qp.h"
struct mlx5_wqe_datagram_seg {
   struct mlx5_av av ;
};
#line 262 "include/linux/mlx5/qp.h"
struct mlx5_wqe_raddr_seg {
   __be64 raddr ;
   __be32 rkey ;
   u32 reserved ;
};
#line 279 "include/linux/mlx5/qp.h"
struct mlx5_wqe_umr_ctrl_seg {
   u8 flags ;
   u8 rsvd0[3U] ;
   __be16 klm_octowords ;
   __be16 bsf_octowords ;
   __be64 mkey_mask ;
   u8 rsvd1[32U] ;
};
#line 288 "include/linux/mlx5/qp.h"
struct mlx5_seg_set_psv {
   __be32 psv_num ;
   __be16 syndrome ;
   __be16 status ;
   __be32 transient_sig ;
   __be32 ref_tag ;
};
#line 318 "include/linux/mlx5/qp.h"
struct mlx5_rwqe_sig {
   u8 rsvd0[4U] ;
   u8 signature ;
   u8 rsvd1[11U] ;
};
#line 330 "include/linux/mlx5/qp.h"
struct mlx5_wqe_inline_seg {
   __be32 byte_count ;
};
#line 341 "include/linux/mlx5/qp.h"
struct mlx5_bsf_inl {
   __be16 vld_refresh ;
   __be16 dif_apptag ;
   __be32 dif_reftag ;
   u8 sig_type ;
   u8 rp_inv_seed ;
   u8 rsvd[3U] ;
   u8 dif_inc_ref_guard_check ;
   __be16 dif_app_bitmask_check ;
};
#line 352 "include/linux/mlx5/qp.h"
union __anonunion_wire_256 {
   u8 copy_byte_mask ;
   u8 bs_selector ;
   u8 rsvd_wflags ;
};
#line 352 "include/linux/mlx5/qp.h"
union __anonunion_mem_257 {
   u8 bs_selector ;
   u8 rsvd_mflags ;
};
#line 352 "include/linux/mlx5/qp.h"
struct mlx5_bsf_basic {
   u8 bsf_size_sbs ;
   u8 check_byte_mask ;
   union __anonunion_wire_256 wire ;
   union __anonunion_mem_257 mem ;
   __be32 raw_data_size ;
   __be32 w_bfs_psv ;
   __be32 m_bfs_psv ;
};
#line 370 "include/linux/mlx5/qp.h"
struct mlx5_bsf_ext {
   __be32 t_init_gen_pro_size ;
   __be32 rsvd_epi_size ;
   __be32 w_tfs_psv ;
   __be32 m_tfs_psv ;
};
#line 376 "include/linux/mlx5/qp.h"
struct mlx5_bsf {
   struct mlx5_bsf_basic basic ;
   struct mlx5_bsf_ext ext ;
   struct mlx5_bsf_inl w_inl ;
   struct mlx5_bsf_inl m_inl ;
};
#line 379 "include/linux/mlx5/qp.h"
struct mlx5_klm {
   __be32 bcount ;
   __be32 key ;
   __be64 va ;
};
#line 385 "include/linux/mlx5/qp.h"
struct mlx5_stride_block_entry {
   __be16 stride ;
   __be16 bcount ;
   __be32 key ;
   __be64 va ;
};
#line 392 "include/linux/mlx5/qp.h"
struct mlx5_stride_block_ctrl_seg {
   __be32 bcount_per_cycle ;
   __be32 op ;
   __be32 repeat_count ;
   u16 rsvd ;
   __be16 num_entries ;
};
#line 445 "include/linux/mlx5/qp.h"
struct mlx5_qp_path {
   u8 fl ;
   u8 rsvd3 ;
   u8 free_ar ;
   u8 pkey_index ;
   u8 rsvd0 ;
   u8 grh_mlid ;
   __be16 rlid ;
   u8 ackto_lt ;
   u8 mgid_index ;
   u8 static_rate ;
   u8 hop_limit ;
   __be32 tclass_flowlabel ;
   u8 rgid[16U] ;
   u8 rsvd1[4U] ;
   u8 sl ;
   u8 port ;
   u8 rsvd2[6U] ;
};
#line 465 "include/linux/mlx5/qp.h"
struct mlx5_qp_context {
   __be32 flags ;
   __be32 flags_pd ;
   u8 mtu_msgmax ;
   u8 rq_size_stride ;
   __be16 sq_crq_size ;
   __be32 qp_counter_set_usr_page ;
   __be32 wire_qpn ;
   __be32 log_pg_sz_remote_qpn ;
   struct mlx5_qp_path pri_path ;
   struct mlx5_qp_path alt_path ;
   __be32 params1 ;
   u8 reserved2[4U] ;
   __be32 next_send_psn ;
   __be32 cqn_send ;
   u8 reserved3[8U] ;
   __be32 last_acked_psn ;
   __be32 ssn ;
   __be32 params2 ;
   __be32 rnr_nextrecvpsn ;
   __be32 xrcd ;
   __be32 cqn_recv ;
   __be64 db_rec_addr ;
   __be32 qkey ;
   __be32 rq_type_srqn ;
   __be32 rmsn ;
   __be16 hw_sq_wqe_counter ;
   __be16 sw_sq_wqe_counter ;
   __be16 hw_rcyclic_byte_counter ;
   __be16 hw_rq_counter ;
   __be16 sw_rcyclic_byte_counter ;
   __be16 sw_rq_counter ;
   u8 rsvd0[5U] ;
   u8 cgs ;
   u8 cs_req ;
   u8 cs_res ;
   __be64 dc_access_key ;
   u8 rsvd1[24U] ;
};
#line 505 "include/linux/mlx5/qp.h"
struct mlx5_create_qp_mbox_in {
   struct mlx5_inbox_hdr hdr ;
   __be32 input_qpn ;
   u8 rsvd0[4U] ;
   __be32 opt_param_mask ;
   u8 rsvd1[4U] ;
   struct mlx5_qp_context ctx ;
   u8 rsvd3[16U] ;
   __be64 pas[0U] ;
};
#line 533 "include/linux/mlx5/qp.h"
struct mlx5_modify_qp_mbox_in {
   struct mlx5_inbox_hdr hdr ;
   __be32 qpn ;
   u8 rsvd1[4U] ;
   __be32 optparam ;
   u8 rsvd0[4U] ;
   struct mlx5_qp_context ctx ;
};
#line 553 "include/linux/mlx5/qp.h"
struct mlx5_query_qp_mbox_out {
   struct mlx5_outbox_hdr hdr ;
   u8 rsvd1[8U] ;
   __be32 optparam ;
   u8 rsvd0[4U] ;
   struct mlx5_qp_context ctx ;
   u8 rsvd2[16U] ;
   __be64 pas[0U] ;
};
#line 57 "include/linux/mlx5/srq.h"
enum mlx5_ib_latency_class {
    MLX5_IB_LATENCY_CLASS_LOW = 0,
    MLX5_IB_LATENCY_CLASS_MEDIUM = 1,
    MLX5_IB_LATENCY_CLASS_HIGH = 2,
    MLX5_IB_LATENCY_CLASS_FAST_PATH = 3
} ;
#line 248 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
union __anonunion_target_261 {
   u64 virt_addr ;
   u64 offset ;
};
#line 248 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_umr_wr {
   union __anonunion_target_261 target ;
   struct ib_pd *pd ;
   unsigned int page_shift ;
   unsigned int npages ;
   u32 length ;
   int access_flags ;
   u32 mkey ;
};
#line 303 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_xrcd {
   struct ib_xrcd ibxrcd ;
   u32 xrcdn ;
};
#line 330 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_fast_reg_page_list {
   struct ib_fast_reg_page_list ibfrpl ;
   __be64 *mapped_page_list ;
   dma_addr_t map ;
};
#line 512 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_ah {
   struct ib_ah ibah ;
   struct mlx5_av av ;
};
#line 120 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_create_qp {
   __u64 buf_addr ;
   __u64 db_addr ;
   __u32 sq_wqe_count ;
   __u32 rq_wqe_count ;
   __u32 rq_wqe_shift ;
   __u32 flags ;
};
#line 129 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_create_qp_resp {
   __u32 uuar_index ;
};
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 25 "include/linux/interval_tree.h"
struct umem_odp_node {
   u64 __subtree_last ;
   struct rb_node rb ;
};
#line 44 "include/rdma/ib_umem_odp.h"
struct ib_umem_odp {
   struct page **page_list ;
   dma_addr_t *dma_list ;
   struct mutex umem_mutex ;
   void *private ;
   bool mn_counters_active ;
   int notifiers_seq ;
   int notifiers_count ;
   struct list_head no_private_counters ;
   struct ib_umem *umem ;
   struct umem_odp_node interval_tree ;
   struct completion notifier_completion ;
   int dying ;
};
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 652 "include/linux/mlx5/device.h"
struct mlx5_wqe_srq_next_seg {
   u8 rsvd0[2U] ;
   __be16 next_wqe_index ;
   u8 signature ;
   u8 rsvd1[11U] ;
};
#line 669 "include/linux/mlx5/device.h"
struct mlx5_srq_ctx {
   u8 state_log_sz ;
   u8 rsvd0[3U] ;
   __be32 flags_xrcd ;
   __be32 pgoff_cqn ;
   u8 rsvd1[4U] ;
   u8 log_pg_sz ;
   u8 rsvd2[7U] ;
   __be32 pd ;
   __be16 lwm ;
   __be16 wqe_cnt ;
   u8 rsvd3[8U] ;
   __be64 db_record ;
};
#line 684 "include/linux/mlx5/device.h"
struct mlx5_create_srq_mbox_in {
   struct mlx5_inbox_hdr hdr ;
   __be32 input_srqn ;
   u8 rsvd0[4U] ;
   struct mlx5_srq_ctx ctx ;
   u8 rsvd1[208U] ;
   __be64 pas[0U] ;
};
#line 716 "include/linux/mlx5/device.h"
struct mlx5_query_srq_mbox_out {
   struct mlx5_outbox_hdr hdr ;
   u8 rsvd0[8U] ;
   struct mlx5_srq_ctx ctx ;
   u8 rsvd1[32U] ;
   __be64 pas[0U] ;
};
#line 108 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/user.h"
struct mlx5_ib_create_srq {
   __u64 buf_addr ;
   __u64 db_addr ;
   __u32 flags ;
   __u32 reserved ;
};
#line 133 "include/linux/types.h"
typedef unsigned long sector_t;
#line 134 "include/linux/types.h"
typedef unsigned long blkcnt_t;
#line 158 "include/linux/types.h"
typedef unsigned int fmode_t;
#line 420 "include/linux/printk.h"
struct file_operations;
#line 139 "include/linux/uidgid.h"
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
   kuid_t uid ;
   kgid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
   unsigned long long blocks ;
};
#line 243 "include/linux/timer.h"
enum hrtimer_restart;
#line 186 "include/linux/idr.h"
struct iattr;
#line 187
struct super_block;
#line 188
struct file_system_type;
#line 443 "include/linux/signal.h"
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
#line 174 "include/linux/pid.h"
struct percpu_counter {
   raw_spinlock_t lock ;
   s64 count ;
   struct list_head list ;
   s32 *counters ;
};
#line 93 "include/linux/bit_spinlock.h"
struct hlist_bl_node;
#line 93 "include/linux/bit_spinlock.h"
struct hlist_bl_head {
   struct hlist_bl_node *first ;
};
#line 36 "include/linux/list_bl.h"
struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};
#line 114 "include/linux/rculist_bl.h"
struct __anonstruct____missing_field_name_220 {
   spinlock_t lock ;
   int count ;
};
#line 114 "include/linux/rculist_bl.h"
union __anonunion____missing_field_name_219 {
   struct __anonstruct____missing_field_name_220 __annonCompField58 ;
};
#line 114 "include/linux/rculist_bl.h"
struct lockref {
   union __anonunion____missing_field_name_219 __annonCompField59 ;
};
#line 50 "include/linux/lockref.h"
struct path;
#line 51
struct vfsmount;
#line 52 "include/linux/lockref.h"
struct __anonstruct____missing_field_name_222 {
   u32 hash ;
   u32 len ;
};
#line 52 "include/linux/lockref.h"
union __anonunion____missing_field_name_221 {
   struct __anonstruct____missing_field_name_222 __annonCompField60 ;
   u64 hash_len ;
};
#line 52 "include/linux/lockref.h"
struct qstr {
   union __anonunion____missing_field_name_221 __annonCompField61 ;
   unsigned char const   *name ;
};
#line 90 "include/linux/dcache.h"
struct dentry_operations;
#line 90 "include/linux/dcache.h"
union __anonunion_d_u_223 {
   struct hlist_node d_alias ;
   struct callback_head d_rcu ;
};
#line 90 "include/linux/dcache.h"
struct dentry {
   unsigned int d_flags ;
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   struct lockref d_lockref ;
   struct dentry_operations  const  *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
   void *d_fsdata ;
   struct list_head d_lru ;
   struct list_head d_child ;
   struct list_head d_subdirs ;
   union __anonunion_d_u_223 d_u ;
};
#line 142 "include/linux/dcache.h"
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_weak_revalidate)(struct dentry * , unsigned int  ) ;
   int (*d_hash)(struct dentry  const  * , struct qstr * ) ;
   int (*d_compare)(struct dentry  const  * , struct dentry  const  * , unsigned int  ,
                    char const   * , struct qstr  const  * ) ;
   int (*d_delete)(struct dentry  const  * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_prune)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int  ) ;
   struct vfsmount *(*d_automount)(struct path * ) ;
   int (*d_manage)(struct dentry * , bool  ) ;
   struct inode *(*d_select_inode)(struct dentry * , unsigned int  ) ;
};
#line 585 "include/linux/dcache.h"
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
#line 19 "include/linux/path.h"
struct shrink_control {
   gfp_t gfp_mask ;
   unsigned long nr_to_scan ;
   int nid ;
   struct mem_cgroup *memcg ;
};
#line 27 "include/linux/shrinker.h"
struct shrinker {
   unsigned long (*count_objects)(struct shrinker * , struct shrink_control * ) ;
   unsigned long (*scan_objects)(struct shrinker * , struct shrink_control * ) ;
   int seeks ;
   long batch ;
   unsigned long flags ;
   struct list_head list ;
   atomic_long_t *nr_deferred ;
};
#line 80 "include/linux/shrinker.h"
struct list_lru_one {
   struct list_head list ;
   long nr_items ;
};
#line 32 "include/linux/list_lru.h"
struct list_lru_memcg {
   struct list_lru_one *lru[0U] ;
};
#line 37 "include/linux/list_lru.h"
struct list_lru_node {
   spinlock_t lock ;
   struct list_lru_one lru ;
   struct list_lru_memcg *memcg_lrus ;
};
#line 47 "include/linux/list_lru.h"
struct list_lru {
   struct list_lru_node *node ;
   struct list_head list ;
};
#line 45 "include/linux/semaphore.h"
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
#line 38 "./include/uapi/linux/fiemap.h"
enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2
} ;
#line 47
struct block_device;
#line 60 "include/uapi/linux/fs.h"
struct bdi_writeback;
#line 61
struct export_operations;
#line 64
struct kiocb;
#line 65
struct poll_table_struct;
#line 66
struct kstatfs;
#line 67
struct swap_info_struct;
#line 68
struct iov_iter;
#line 74 "include/linux/fs.h"
struct iattr {
   unsigned int ia_valid ;
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
#line 212 "./include/uapi/linux/dqblk_xfs.h"
struct dquot;
#line 19 "include/linux/projid.h"
typedef __kernel_uid32_t projid_t;
#line 23 "include/linux/projid.h"
struct __anonstruct_kprojid_t_231 {
   projid_t val ;
};
#line 23 "include/linux/projid.h"
typedef struct __anonstruct_kprojid_t_231 kprojid_t;
#line 166 "include/uapi/linux/quota.h"
enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
} ;
#line 66 "include/linux/quota.h"
typedef long long qsize_t;
#line 67 "include/linux/quota.h"
union __anonunion____missing_field_name_232 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};
#line 67 "include/linux/quota.h"
struct kqid {
   union __anonunion____missing_field_name_232 __annonCompField65 ;
   enum quota_type type ;
};
#line 184 "include/linux/quota.h"
struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
#line 206
struct quota_format_type;
#line 207 "include/linux/quota.h"
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
   unsigned int dqi_bgrace ;
   unsigned int dqi_igrace ;
   qsize_t dqi_max_spc_limit ;
   qsize_t dqi_max_ino_limit ;
   void *dqi_priv ;
};
#line 272 "include/linux/quota.h"
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
   struct mem_dqblk dq_dqb ;
};
#line 299 "include/linux/quota.h"
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int  ) ;
   int (*read_file_info)(struct super_block * , int  ) ;
   int (*write_file_info)(struct super_block * , int  ) ;
   int (*free_file_info)(struct super_block * , int  ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
#line 310 "include/linux/quota.h"
struct dquot_operations {
   int (*write_dquot)(struct dquot * ) ;
   struct dquot *(*alloc_dquot)(struct super_block * , int  ) ;
   void (*destroy_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int  ) ;
   qsize_t *(*get_reserved_space)(struct inode * ) ;
   int (*get_projid)(struct inode * , kprojid_t * ) ;
};
#line 325 "include/linux/quota.h"
struct qc_dqblk {
   int d_fieldmask ;
   u64 d_spc_hardlimit ;
   u64 d_spc_softlimit ;
   u64 d_ino_hardlimit ;
   u64 d_ino_softlimit ;
   u64 d_space ;
   u64 d_ino_count ;
   s64 d_ino_timer ;
   s64 d_spc_timer ;
   int d_ino_warns ;
   int d_spc_warns ;
   u64 d_rt_spc_hardlimit ;
   u64 d_rt_spc_softlimit ;
   u64 d_rt_space ;
   s64 d_rt_spc_timer ;
   int d_rt_spc_warns ;
};
#line 348 "include/linux/quota.h"
struct qc_type_state {
   unsigned int flags ;
   unsigned int spc_timelimit ;
   unsigned int ino_timelimit ;
   unsigned int rt_spc_timelimit ;
   unsigned int spc_warnlimit ;
   unsigned int ino_warnlimit ;
   unsigned int rt_spc_warnlimit ;
   unsigned long long ino ;
   blkcnt_t blocks ;
   blkcnt_t nextents ;
};
#line 394 "include/linux/quota.h"
struct qc_state {
   unsigned int s_incoredqs ;
   struct qc_type_state s_state[3U] ;
};
#line 405 "include/linux/quota.h"
struct qc_info {
   int i_fieldmask ;
   unsigned int i_flags ;
   unsigned int i_spc_timelimit ;
   unsigned int i_ino_timelimit ;
   unsigned int i_rt_spc_timelimit ;
   unsigned int i_spc_warnlimit ;
   unsigned int i_ino_warnlimit ;
   unsigned int i_rt_spc_warnlimit ;
};
#line 418 "include/linux/quota.h"
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int  , int  , struct path * ) ;
   int (*quota_off)(struct super_block * , int  ) ;
   int (*quota_enable)(struct super_block * , unsigned int  ) ;
   int (*quota_disable)(struct super_block * , unsigned int  ) ;
   int (*quota_sync)(struct super_block * , int  ) ;
   int (*set_info)(struct super_block * , int  , struct qc_info * ) ;
   int (*get_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*set_dqblk)(struct super_block * , struct kqid  , struct qc_dqblk * ) ;
   int (*get_state)(struct super_block * , struct qc_state * ) ;
   int (*rm_xquota)(struct super_block * , unsigned int  ) ;
};
#line 432 "include/linux/quota.h"
struct quota_format_type {
   int qf_fmt_id ;
   struct quota_format_ops  const  *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
#line 496 "include/linux/quota.h"
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct inode *files[3U] ;
   struct mem_dqinfo info[3U] ;
   struct quota_format_ops  const  *ops[3U] ;
};
#line 526
struct writeback_control;
#line 527 "include/linux/quota.h"
struct kiocb {
   struct file *ki_filp ;
   loff_t ki_pos ;
   void (*ki_complete)(struct kiocb * , long  , long  ) ;
   void *private ;
   int ki_flags ;
};
#line 365 "include/linux/fs.h"
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int  ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                      unsigned int  , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                    unsigned int  , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t  ) ;
   void (*invalidatepage)(struct page * , unsigned int  , unsigned int  ) ;
   int (*releasepage)(struct page * , gfp_t  ) ;
   void (*freepage)(struct page * ) ;
   ssize_t (*direct_IO)(struct kiocb * , struct iov_iter * , loff_t  ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * , enum migrate_mode  ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , unsigned long  , unsigned long  ) ;
   void (*is_dirty_writeback)(struct page * , bool * , bool * ) ;
   int (*error_remove_page)(struct address_space * , struct page * ) ;
   int (*swap_activate)(struct swap_info_struct * , struct file * , sector_t * ) ;
   void (*swap_deactivate)(struct file * ) ;
};
#line 422 "include/linux/fs.h"
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   atomic_t i_mmap_writable ;
   struct rb_root i_mmap ;
   struct rw_semaphore i_mmap_rwsem ;
   unsigned long nrpages ;
   unsigned long nrshadows ;
   unsigned long writeback_index ;
   struct address_space_operations  const  *a_ops ;
   unsigned long flags ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   void *private_data ;
};
#line 442
struct request_queue;
#line 443
struct hd_struct;
#line 443
struct gendisk;
#line 443 "include/linux/fs.h"
struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   struct list_head bd_inodes ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
   int bd_invalidated ;
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct list_head bd_list ;
   unsigned long bd_private ;
   int bd_fsfreeze_count ;
   struct mutex bd_fsfreeze_mutex ;
};
#line 559
struct posix_acl;
#line 560
struct inode_operations;
#line 560 "include/linux/fs.h"
union __anonunion____missing_field_name_235 {
   unsigned int const   i_nlink ;
   unsigned int __i_nlink ;
};
#line 560 "include/linux/fs.h"
union __anonunion____missing_field_name_236 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};
#line 560
struct file_lock_context;
#line 560
struct cdev;
#line 560 "include/linux/fs.h"
union __anonunion____missing_field_name_237 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
   char *i_link ;
};
#line 560 "include/linux/fs.h"
struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations  const  *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
   union __anonunion____missing_field_name_235 __annonCompField66 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
   unsigned int i_blkbits ;
   blkcnt_t i_blocks ;
   unsigned long i_state ;
   struct mutex i_mutex ;
   unsigned long dirtied_when ;
   unsigned long dirtied_time_when ;
   struct hlist_node i_hash ;
   struct list_head i_wb_list ;
   struct bdi_writeback *i_wb ;
   int i_wb_frn_winner ;
   u16 i_wb_frn_avg_time ;
   u16 i_wb_frn_history ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   union __anonunion____missing_field_name_236 __annonCompField67 ;
   u64 i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   atomic_t i_readcount ;
   struct file_operations  const  *i_fop ;
   struct file_lock_context *i_flctx ;
   struct address_space i_data ;
   struct list_head i_devices ;
   union __anonunion____missing_field_name_237 __annonCompField68 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct hlist_head i_fsnotify_marks ;
   void *i_private ;
};
#line 806 "include/linux/fs.h"
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
};
#line 814 "include/linux/fs.h"
struct file_ra_state {
   unsigned long start ;
   unsigned int size ;
   unsigned int async_size ;
   unsigned int ra_pages ;
   unsigned int mmap_miss ;
   loff_t prev_pos ;
};
#line 837 "include/linux/fs.h"
union __anonunion_f_u_238 {
   struct llist_node fu_llist ;
   struct callback_head fu_rcuhead ;
};
#line 837 "include/linux/fs.h"
struct file {
   union __anonunion_f_u_238 f_u ;
   struct path f_path ;
   struct inode *f_inode ;
   struct file_operations  const  *f_op ;
   spinlock_t f_lock ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
   fmode_t f_mode ;
   struct mutex f_pos_lock ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred  const  *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
};
#line 922 "include/linux/fs.h"
typedef void *fl_owner_t;
#line 923
struct file_lock;
#line 924 "include/linux/fs.h"
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
#line 930 "include/linux/fs.h"
struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock * , struct file_lock * ) ;
   unsigned long (*lm_owner_key)(struct file_lock * ) ;
   fl_owner_t (*lm_get_owner)(fl_owner_t  ) ;
   void (*lm_put_owner)(fl_owner_t  ) ;
   void (*lm_notify)(struct file_lock * ) ;
   int (*lm_grant)(struct file_lock * , int  ) ;
   bool (*lm_break)(struct file_lock * ) ;
   int (*lm_change)(struct file_lock * , int  , struct list_head * ) ;
   void (*lm_setup)(struct file_lock * , void ** ) ;
};
#line 951
struct nlm_lockowner;
#line 952 "include/linux/fs.h"
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
#line 14 "include/linux/nfs_fs_i.h"
struct nfs4_lock_state;
#line 15 "include/linux/nfs_fs_i.h"
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
#line 19
struct fasync_struct;
#line 19 "include/linux/nfs_fs_i.h"
struct __anonstruct_afs_240 {
   struct list_head link ;
   int state ;
};
#line 19 "include/linux/nfs_fs_i.h"
union __anonunion_fl_u_239 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_240 afs ;
};
#line 19 "include/linux/nfs_fs_i.h"
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_list ;
   struct hlist_node fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
   unsigned char fl_type ;
   unsigned int fl_pid ;
   int fl_link_cpu ;
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
   unsigned long fl_downgrade_time ;
   struct file_lock_operations  const  *fl_ops ;
   struct lock_manager_operations  const  *fl_lmops ;
   union __anonunion_fl_u_239 fl_u ;
};
#line 1004 "include/linux/fs.h"
struct file_lock_context {
   spinlock_t flc_lock ;
   struct list_head flc_flock ;
   struct list_head flc_posix ;
   struct list_head flc_lease ;
};
#line 1062 "include/linux/fs.h"
struct fasync_struct {
   spinlock_t fa_lock ;
   int magic ;
   int fa_fd ;
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};
#line 1240 "include/linux/fs.h"
struct sb_writers {
   struct percpu_counter counter[3U] ;
   wait_queue_head_t wait ;
   int frozen ;
   wait_queue_head_t wait_unfrozen ;
   struct lockdep_map lock_map[3U] ;
};
#line 1271
struct super_operations;
#line 1271
struct xattr_handler;
#line 1271
struct mtd_info;
#line 1271 "include/linux/fs.h"
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
   unsigned long s_blocksize ;
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations  const  *s_op ;
   struct dquot_operations  const  *dq_op ;
   struct quotactl_ops  const  *s_qcop ;
   struct export_operations  const  *s_export_op ;
   unsigned long s_flags ;
   unsigned long s_iflags ;
   unsigned long s_magic ;
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler  const  **s_xattr ;
   struct list_head s_inodes ;
   struct hlist_bl_head s_anon ;
   struct list_head s_mounts ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   unsigned int s_quota_types ;
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   char s_id[32U] ;
   u8 s_uuid[16U] ;
   void *s_fs_info ;
   unsigned int s_max_links ;
   fmode_t s_mode ;
   u32 s_time_gran ;
   struct mutex s_vfs_rename_mutex ;
   char *s_subtype ;
   char *s_options ;
   struct dentry_operations  const  *s_d_op ;
   int cleancache_poolid ;
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   int s_readonly_remount ;
   struct workqueue_struct *s_dio_done_wq ;
   struct hlist_head s_pins ;
   struct list_lru s_dentry_lru ;
   struct list_lru s_inode_lru ;
   struct callback_head rcu ;
   int s_stack_depth ;
};
#line 1510 "include/linux/fs.h"
struct fiemap_extent_info {
   unsigned int fi_flags ;
   unsigned int fi_extents_mapped ;
   unsigned int fi_extents_max ;
   struct fiemap_extent *fi_extents_start ;
};
#line 1524
struct dir_context;
#line 1549 "include/linux/fs.h"
struct dir_context {
   int (*actor)(struct dir_context * , char const   * , int  , loff_t  , u64  , unsigned int  ) ;
   loff_t pos ;
};
#line 1556 "include/linux/fs.h"
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t  , int  ) ;
   ssize_t (*read)(struct file * , char * , size_t  , loff_t * ) ;
   ssize_t (*write)(struct file * , char const   * , size_t  , loff_t * ) ;
   ssize_t (*read_iter)(struct kiocb * , struct iov_iter * ) ;
   ssize_t (*write_iter)(struct kiocb * , struct iov_iter * ) ;
   int (*iterate)(struct file * , struct dir_context * ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   long (*compat_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*mremap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , loff_t  , loff_t  , int  ) ;
   int (*aio_fsync)(struct kiocb * , int  ) ;
   int (*fasync)(int  , struct file * , int  ) ;
   int (*lock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int  , size_t  , loff_t * ,
                       int  ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   int (*check_flags)(int  ) ;
   int (*flock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t  ,
                           unsigned int  ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t  ,
                          unsigned int  ) ;
   int (*setlease)(struct file * , long  , struct file_lock ** , void ** ) ;
   long (*fallocate)(struct file * , int  , loff_t  , loff_t  ) ;
   void (*show_fdinfo)(struct seq_file * , struct file * ) ;
};
#line 1617 "include/linux/fs.h"
struct inode_operations {
   struct dentry *(*lookup)(struct inode * , struct dentry * , unsigned int  ) ;
   char const   *(*follow_link)(struct dentry * , void ** ) ;
   int (*permission)(struct inode * , int  ) ;
   struct posix_acl *(*get_acl)(struct inode * , int  ) ;
   int (*readlink)(struct dentry * , char * , int  ) ;
   void (*put_link)(struct inode * , void * ) ;
   int (*create)(struct inode * , struct dentry * , umode_t  , bool  ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const   * ) ;
   int (*mkdir)(struct inode * , struct dentry * , umode_t  ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , umode_t  , dev_t  ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   int (*rename2)(struct inode * , struct dentry * , struct inode * , struct dentry * ,
                  unsigned int  ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const   * , void const   * , size_t  , int  ) ;
   ssize_t (*getxattr)(struct dentry * , char const   * , void * , size_t  ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t  ) ;
   int (*removexattr)(struct dentry * , char const   * ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64  , u64  ) ;
   int (*update_time)(struct inode * , struct timespec * , int  ) ;
   int (*atomic_open)(struct inode * , struct dentry * , struct file * , unsigned int  ,
                      umode_t  , int * ) ;
   int (*tmpfile)(struct inode * , struct dentry * , umode_t  ) ;
   int (*set_acl)(struct inode * , struct posix_acl * , int  ) ;
};
#line 1671 "include/linux/fs.h"
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * , int  ) ;
   int (*write_inode)(struct inode * , struct writeback_control * ) ;
   int (*drop_inode)(struct inode * ) ;
   void (*evict_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int  ) ;
   int (*freeze_super)(struct super_block * ) ;
   int (*freeze_fs)(struct super_block * ) ;
   int (*thaw_super)(struct super_block * ) ;
   int (*unfreeze_fs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct dentry * ) ;
   int (*show_devname)(struct seq_file * , struct dentry * ) ;
   int (*show_path)(struct seq_file * , struct dentry * ) ;
   int (*show_stats)(struct seq_file * , struct dentry * ) ;
   ssize_t (*quota_read)(struct super_block * , int  , char * , size_t  , loff_t  ) ;
   ssize_t (*quota_write)(struct super_block * , int  , char const   * , size_t  ,
                          loff_t  ) ;
   struct dquot **(*get_dquots)(struct inode * ) ;
   int (*bdev_try_to_free_page)(struct super_block * , struct page * , gfp_t  ) ;
   long (*nr_cached_objects)(struct super_block * , struct shrink_control * ) ;
   long (*free_cached_objects)(struct super_block * , struct shrink_control * ) ;
};
#line 1910 "include/linux/fs.h"
struct file_system_type {
   char const   *name ;
   int fs_flags ;
   struct dentry *(*mount)(struct file_system_type * , int  , char const   * , void * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};
#line 336 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct mlx5_ib_umr_context {
   enum ib_wc_status status ;
   struct completion done ;
};
#line 757 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
typedef int ldv_func_ret_type___3;
#line 768 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
typedef int ldv_func_ret_type___4;
#line 779 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
typedef bool ldv_func_ret_type___5;
#line 806 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
typedef int ldv_func_ret_type___6;
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 239
enum hrtimer_restart;
#line 185 "include/rdma/ib_mad.h"
struct ib_mad {
   struct ib_mad_hdr mad_hdr ;
   u8 data[232U] ;
};
#line 708 "include/rdma/ib_mad.h"
struct ib_smp {
   u8 base_version ;
   u8 mgmt_class ;
   u8 class_version ;
   u8 method ;
   __be16 status ;
   u8 hop_ptr ;
   u8 hop_cnt ;
   __be64 tid ;
   __be16 attr_id ;
   __be16 resv ;
   __be32 attr_mod ;
   __be64 mkey ;
   __be16 dr_slid ;
   __be16 dr_dlid ;
   u8 reserved[28U] ;
   u8 data[64U] ;
   u8 initial_path[64U] ;
   u8 return_path[64U] ;
};
#line 239 "include/linux/timer.h"
enum hrtimer_restart;
#line 151 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
enum mlx5_ib_pagefault_context {
    MLX5_IB_PAGEFAULT_RESPONDER_READ = 0,
    MLX5_IB_PAGEFAULT_REQUESTOR_READ = 1,
    MLX5_IB_PAGEFAULT_RESPONDER_WRITE = 2,
    MLX5_IB_PAGEFAULT_REQUESTOR_WRITE = 3,
    MLX5_IB_PAGEFAULT_CONTEXTS = 4
} ;
#line 1 "<compiler builtins>"
#line 1
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 33 "include/linux/export.h"
extern struct module __this_module ;
#line 368 "./arch/x86/include/asm/pgtable_types.h"
extern pgprot_t pgprot_writecombine(pgprot_t  ) ;
#line 72 "./arch/x86/include/asm/bitops.h"
__inline static void set_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
#line 80
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; bts %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr): "memory");
#line 82
  return;
}
}
#line 7 "./arch/x86/include/uapi/asm/swab.h"
__inline static __u32 __arch_swab32(__u32 val ) 
{ 


  {
#line 9
  __asm__  ("bswapl %0": "=r" (val): "0" (val));
#line 10
  return (val);
}
}
#line 14 "./arch/x86/include/uapi/asm/swab.h"
__inline static __u64 __arch_swab64(__u64 val ) 
{ 


  {
#line 30
  __asm__  ("bswapq %0": "=r" (val): "0" (val));
#line 31
  return (val);
}
}
#line 57 "include/uapi/linux/swab.h"
__inline static __u32 __fswab32(__u32 val ) 
{ 
  __u32 tmp ;

  {
#line 62
  tmp = __arch_swab32(val);
#line 62
  return (tmp);
}
}
#line 68 "include/uapi/linux/swab.h"
__inline static __u64 __fswab64(__u64 val ) 
{ 
  __u64 tmp ;

  {
#line 73
  tmp = __arch_swab64(val);
#line 73
  return (tmp);
}
}
#line 142 "include/linux/printk.h"
extern int printk(char const   *  , ...) ;
#line 45 "include/linux/dynamic_debug.h"
extern void __dynamic_pr_debug(struct _ddebug * , char const   *  , ...) ;
#line 248 "include/linux/kernel.h"
extern void __might_fault(char const   * , int  ) ;
#line 402
extern int sprintf(char * , char const   *  , ...) ;
#line 3 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
bool ldv_is_err(void const   *ptr ) ;
#line 5
void *ldv_err_ptr(long error ) ;
#line 6
long ldv_ptr_err(void const   *ptr ) ;
#line 25 "include/linux/list.h"
__inline static void INIT_LIST_HEAD(struct list_head *list ) 
{ 


  {
#line 27
  list->next = list;
#line 28
  list->prev = list;
#line 29
  return;
}
}
#line 87 "./arch/x86/include/asm/percpu.h"
extern void __bad_percpu_size(void) ;
#line 10 "./arch/x86/include/asm/current.h"
extern struct task_struct *current_task ;
#line 12 "./arch/x86/include/asm/current.h"
__inline static struct task_struct *get_current(void) 
{ 
  struct task_struct *pfo_ret__ ;

  {
#line 14
  switch (8UL) {
  case 1UL: 
#line 14
  __asm__  ("movb %%gs:%P1,%0": "=q" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_3129;
  case 2UL: 
#line 14
  __asm__  ("movw %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_3129;
  case 4UL: 
#line 14
  __asm__  ("movl %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_3129;
  case 8UL: 
#line 14
  __asm__  ("movq %%gs:%P1,%0": "=r" (pfo_ret__): "p" (& current_task));
#line 14
  goto ldv_3129;
  default: 
#line 14
  __bad_percpu_size();
  }
  ldv_3129: ;
#line 14
  return (pfo_ret__);
}
}
#line 30 "./arch/x86/include/asm/string_64.h"
extern void *memcpy(void * , void const   * , size_t  ) ;
#line 57
extern void *memset(void * , int  , size_t  ) ;
#line 26 "include/linux/string.h"
extern size_t strlcpy(char * , char const   * , size_t  ) ;
#line 23 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) ;
#line 32
__inline static long PTR_ERR(void const   *ptr ) ;
#line 41
__inline static bool IS_ERR(void const   *ptr ) ;
#line 25 "./arch/x86/include/asm/atomic.h"
__inline static int atomic_read(atomic_t const   *v ) 
{ 
  int __var ;

  {
#line 27
  __var = 0;
#line 27
  return ((int )*((int const volatile   *)(& v->counter)));
}
}
#line 37 "./arch/x86/include/asm/atomic.h"
__inline static void atomic_set(atomic_t *v , int i ) 
{ 


  {
#line 39
  v->counter = i;
#line 40
  return;
}
}
#line 90 "./arch/x86/include/asm/atomic.h"
__inline static void atomic_inc(atomic_t *v ) 
{ 


  {
#line 92
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; incl %0": "+m" (v->counter));
#line 94
  return;
}
}
#line 280 "include/linux/lockdep.h"
extern void lockdep_init_map(struct lockdep_map * , char const   * , struct lock_class_key * ,
                             int  ) ;
#line 119 "include/linux/mutex.h"
extern void __mutex_init(struct mutex * , char const   * , struct lock_class_key * ) ;
#line 138
extern void mutex_lock_nested(struct mutex * , unsigned int  ) ;
#line 174
extern void mutex_unlock(struct mutex * ) ;
#line 429 "include/linux/workqueue.h"
extern bool queue_work_on(int  , struct workqueue_struct * , struct work_struct * ) ;
#line 433
bool ldv_queue_work_on_5(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_7(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) ;
#line 439
extern bool queue_delayed_work_on(int  , struct workqueue_struct * , struct delayed_work * ,
                                  unsigned long  ) ;
#line 443
bool ldv_queue_delayed_work_on_6(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_9(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 452
extern void flush_workqueue(struct workqueue_struct * ) ;
#line 455
void ldv_flush_workqueue_8(struct workqueue_struct *ldv_func_arg1 ) ;
#line 32 "include/asm-generic/iomap.h"
extern unsigned int ioread32be(void * ) ;
#line 143 "include/linux/slab.h"
extern void kfree(void const   * ) ;
#line 289
extern void *__kmalloc(size_t  , gfp_t  ) ;
#line 418 "include/linux/slab.h"
__inline static void *kmalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp___2 ;

  {
#line 435
  tmp___2 = __kmalloc(size, flags);
#line 435
  return (tmp___2);
}
}
#line 525 "include/linux/slab.h"
__inline static void *kmalloc_array(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
#line 527
  if (size != 0UL && 0xffffffffffffffffUL / size < n) {
#line 528
    return ((void *)0);
  } else {

  }
#line 529
  tmp = __kmalloc(n * size, flags);
#line 529
  return (tmp);
}
}
#line 538 "include/linux/slab.h"
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
#line 540
  tmp = kmalloc_array(n, size, flags | 32768U);
#line 540
  return (tmp);
}
}
#line 581 "include/linux/slab.h"
__inline static void *kzalloc(size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
#line 583
  tmp = kmalloc(size, flags | 32768U);
#line 583
  return (tmp);
}
}
#line 6 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
extern void *malloc(size_t  ) ;
#line 7
extern void *calloc(size_t  , size_t  ) ;
#line 13
extern int __VERIFIER_nondet_int(void) ;
#line 28
extern unsigned long __VERIFIER_nondet_ulong(void) ;
#line 29
extern void *__VERIFIER_nondet_pointer(void) ;
#line 30
extern void __VERIFIER_assume(int  ) ;
#line 32 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
void *ldv_malloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
#line 33
  tmp___0 = __VERIFIER_nondet_int();
#line 33
  if (tmp___0 != 0) {
#line 34
    return ((void *)0);
  } else {
#line 36
    tmp = malloc(size);
#line 36
    p = tmp;
#line 37
    __VERIFIER_assume((unsigned long )p != (unsigned long )((void *)0));
#line 38
    return (p);
  }
}
}
#line 42 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
void *ldv_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;
  int tmp___0 ;

  {
#line 43
  tmp___0 = __VERIFIER_nondet_int();
#line 43
  if (tmp___0 != 0) {
#line 44
    return ((void *)0);
  } else {
#line 46
    tmp = calloc(1UL, size);
#line 46
    p = tmp;
#line 47
    __VERIFIER_assume((unsigned long )p != (unsigned long )((void *)0));
#line 48
    return (p);
  }
}
}
#line 52 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
void *ldv_init_zalloc(size_t size ) 
{ 
  void *p ;
  void *tmp ;

  {
#line 53
  tmp = calloc(1UL, size);
#line 53
  p = tmp;
#line 54
  __VERIFIER_assume((unsigned long )p != (unsigned long )((void *)0));
#line 55
  return (p);
}
}
#line 58 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
void *ldv_memset(void *s , int c , size_t n ) 
{ 
  void *tmp ;

  {
#line 59
  tmp = memset(s, c, n);
#line 59
  return (tmp);
}
}
#line 62 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
int ldv_undef_int(void) 
{ 
  int tmp ;

  {
#line 63
  tmp = __VERIFIER_nondet_int();
#line 63
  return (tmp);
}
}
#line 66 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
void *ldv_undef_ptr(void) 
{ 
  void *tmp ;

  {
#line 67
  tmp = __VERIFIER_nondet_pointer();
#line 67
  return (tmp);
}
}
#line 70 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
unsigned long ldv_undef_ulong(void) 
{ 
  unsigned long tmp ;

  {
#line 71
  tmp = __VERIFIER_nondet_ulong();
#line 71
  return (tmp);
}
}
#line 22 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
__inline static void ldv_stop(void) 
{ 


  {
  LDV_STOP: ;
#line 23
  goto LDV_STOP;
}
}
#line 52 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
__inline static long ldv__builtin_expect(long exp , long c ) 
{ 


  {
#line 54
  return (exp);
}
}
#line 20 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_8  ;
#line 21 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_3_1  ;
#line 22 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_timer_4_0  ;
#line 23 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_1_3  ;
#line 24 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_0  ;
#line 25 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_5  ;
#line 26 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_13  ;
#line 27 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_1_1  ;
#line 28 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_12  ;
#line 29 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_3_2  ;
#line 30 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_3_0  ;
#line 31 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_2_3  ;
#line 32 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_2_0  ;
#line 33 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_timer_4_3  ;
#line 34 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_9  ;
#line 35 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_2_2  ;
#line 36 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ref_cnt  ;
#line 37 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_3_3  ;
#line 38 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_1  ;
#line 39 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_7  ;
#line 40 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct file *limit_fops_group2  ;
#line 41 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_3_3  ;
#line 42 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_1_0  ;
#line 43 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_timer_4_2  ;
#line 44 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_1_1  ;
#line 45 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_10  ;
#line 46 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct timer_list *ldv_timer_list_4_0  ;
#line 47 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_1_3  ;
#line 48 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_2_1  ;
#line 49 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_3_2  ;
#line 50 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_6  ;
#line 51 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_3_1  ;
#line 52 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct inode *size_fops_group1  ;
#line 53 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_2  ;
#line 54 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_2_0  ;
#line 55 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct mlx5_core_dev *mlx5_ib_interface_group0  ;
#line 56 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_3_0  ;
#line 57 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_11  ;
#line 58 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_1_2  ;
#line 59 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct timer_list *ldv_timer_list_4_3  ;
#line 60 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct inode *limit_fops_group1  ;
#line 61 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int LDV_IN_INTERRUPT  =    1;
#line 62 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct timer_list *ldv_timer_list_4_2  ;
#line 64 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct work_struct *ldv_work_struct_1_2  ;
#line 65 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct file *size_fops_group2  ;
#line 66 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_2_2  ;
#line 67 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_3  ;
#line 68 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_timer_4_1  ;
#line 69 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_1_0  ;
#line 70 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
struct timer_list *ldv_timer_list_4_1  ;
#line 71 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_2_3  ;
#line 72 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_state_variable_4  ;
#line 73 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_work_2_1  ;
#line 74
void work_init_3(void) ;
#line 75
void ldv_initialize_mlx5_interface_7(void) ;
#line 76
void ldv_file_operations_6(void) ;
#line 78
void work_init_2(void) ;
#line 83
void timer_init_4(void) ;
#line 84
void activate_work_3(struct work_struct *work , int state ) ;
#line 94
void work_init_1(void) ;
#line 97
void call_and_disable_all_3(int state ) ;
#line 98
void ldv_file_operations_5(void) ;
#line 591 "include/linux/device.h"
extern int device_create_file(struct device * , struct device_attribute  const  * ) ;
#line 2012 "include/linux/mm.h"
extern int remap_pfn_range(struct vm_area_struct * , unsigned long  , unsigned long  ,
                           unsigned long  , pgprot_t  ) ;
#line 650 "./arch/x86/include/asm/uaccess.h"
extern unsigned long _copy_from_user(void * , void const   * , unsigned int  ) ;
#line 652
extern unsigned long _copy_to_user(void * , void const   * , unsigned int  ) ;
#line 672
extern void __copy_from_user_overflow(void) ;
#line 677
extern void __copy_to_user_overflow(void) ;
#line 693 "./arch/x86/include/asm/uaccess.h"
__inline static unsigned long copy_from_user(void *to , void const   *from , unsigned long n ) 
{ 
  int sz ;
  unsigned long tmp ;
  long tmp___0 ;

  {
#line 695
  tmp = __builtin_object_size((void const   *)to, 0);
#line 695
  sz = (int )tmp;
#line 697
  __might_fault("./arch/x86/include/asm/uaccess.h", 697);
#line 717
  tmp___0 = ldv__builtin_expect((long )(sz < 0 || (unsigned long )sz >= n), 1L);
#line 717
  if (tmp___0 != 0L) {
#line 718
    n = _copy_from_user(to, from, (unsigned int )n);
  } else {
#line 722
    __copy_from_user_overflow();
  }
#line 724
  return (n);
}
}
#line 728 "./arch/x86/include/asm/uaccess.h"
__inline static unsigned long copy_to_user(void *to , void const   *from , unsigned long n ) 
{ 
  int sz ;
  unsigned long tmp ;
  long tmp___0 ;

  {
#line 730
  tmp = __builtin_object_size(from, 0);
#line 730
  sz = (int )tmp;
#line 732
  __might_fault("./arch/x86/include/asm/uaccess.h", 732);
#line 735
  tmp___0 = ldv__builtin_expect((long )(sz < 0 || (unsigned long )sz >= n), 1L);
#line 735
  if (tmp___0 != 0L) {
#line 736
    n = _copy_to_user(to, from, (unsigned int )n);
  } else {
#line 740
    __copy_to_user_overflow();
  }
#line 742
  return (n);
}
}
#line 32 "include/linux/semaphore.h"
__inline static void sema_init(struct semaphore *sem , int val ) 
{ 
  struct lock_class_key __key ;
  struct semaphore __constr_expr_0 ;

  {
#line 35
  __constr_expr_0.lock.raw_lock.val.counter = 0;
#line 35
  __constr_expr_0.lock.magic = 3735899821U;
#line 35
  __constr_expr_0.lock.owner_cpu = 4294967295U;
#line 35
  __constr_expr_0.lock.owner = (void *)-1;
#line 35
  __constr_expr_0.lock.dep_map.key = 0;
#line 35
  __constr_expr_0.lock.dep_map.class_cache[0] = 0;
#line 35
  __constr_expr_0.lock.dep_map.class_cache[1] = 0;
#line 35
  __constr_expr_0.lock.dep_map.name = "(*sem).lock";
#line 35
  __constr_expr_0.lock.dep_map.cpu = 0;
#line 35
  __constr_expr_0.lock.dep_map.ip = 0UL;
#line 35
  __constr_expr_0.count = (unsigned int )val;
#line 35
  __constr_expr_0.wait_list.next = & sem->wait_list;
#line 35
  __constr_expr_0.wait_list.prev = & sem->wait_list;
#line 35
  *sem = __constr_expr_0;
#line 36
  lockdep_init_map(& sem->lock.dep_map, "semaphore->lock", & __key, 0);
#line 37
  return;
}
}
#line 1768 "include/rdma/ib_verbs.h"
extern struct ib_device *ib_alloc_device(size_t  ) ;
#line 1769
extern void ib_dealloc_device(struct ib_device * ) ;
#line 1771
extern int ib_register_device(struct ib_device * , int (*)(struct ib_device * , u8  ,
                                                           struct kobject * ) ) ;
#line 1774
extern void ib_unregister_device(struct ib_device * ) ;
#line 1783 "include/rdma/ib_verbs.h"
__inline static int ib_copy_from_udata(void *dest , struct ib_udata *udata , size_t len ) 
{ 
  unsigned long tmp ;

  {
#line 1785
  tmp = copy_from_user(dest, udata->inbuf, len);
#line 1785
  return (tmp != 0UL ? -14 : 0);
}
}
#line 1788 "include/rdma/ib_verbs.h"
__inline static int ib_copy_to_udata(struct ib_udata *udata , void *src , size_t len ) 
{ 
  unsigned long tmp ;

  {
#line 1790
  tmp = copy_to_user(udata->outbuf, (void const   *)src, len);
#line 1790
  return (tmp != 0UL ? -14 : 0);
}
}
#line 1815
extern void ib_dispatch_event(struct ib_event * ) ;
#line 2131
extern struct ib_pd *ib_alloc_pd(struct ib_device * ) ;
#line 2137
extern int ib_dealloc_pd(struct ib_pd * ) ;
#line 2377
extern struct ib_cq *ib_create_cq(struct ib_device * , void (*)(struct ib_cq * , void * ) ,
                                  void (*)(struct ib_event * , void * ) , void * ,
                                  struct ib_cq_init_attr  const  * ) ;
#line 2405
extern int ib_destroy_cq(struct ib_cq * ) ;
#line 2464 "include/rdma/ib_verbs.h"
__inline static int ib_req_notify_cq(struct ib_cq *cq , enum ib_cq_notify_flags flags ) 
{ 
  int tmp ;

  {
#line 2467
  tmp = (*((cq->device)->req_notify_cq))(cq, flags);
#line 2467
  return (tmp);
}
}
#line 2494
extern struct ib_mr *ib_get_dma_mr(struct ib_pd * , int  ) ;
#line 2808
extern int ib_dereg_mr(struct ib_mr * ) ;
#line 1185 "include/linux/mlx5/device.h"
__inline static u16 mlx5_to_sw_pkey_sz(int pkey_sz ) 
{ 


  {
#line 1187
  if (pkey_sz > 5) {
#line 1188
    return (0U);
  } else {

  }
#line 1189
  return ((u16 )(128 << pkey_sz));
}
}
#line 617 "include/linux/mlx5/driver.h"
__inline static u16 fw_rev_maj(struct mlx5_core_dev *dev ) 
{ 
  unsigned int tmp ;

  {
#line 619
  tmp = ioread32be((void *)(& (dev->iseg)->fw_rev));
#line 619
  return ((u16 )tmp);
}
}
#line 622 "include/linux/mlx5/driver.h"
__inline static u16 fw_rev_min(struct mlx5_core_dev *dev ) 
{ 
  unsigned int tmp ;

  {
#line 624
  tmp = ioread32be((void *)(& (dev->iseg)->fw_rev));
#line 624
  return ((u16 )(tmp >> 16));
}
}
#line 627 "include/linux/mlx5/driver.h"
__inline static u16 fw_rev_sub(struct mlx5_core_dev *dev ) 
{ 
  unsigned int tmp ;

  {
#line 629
  tmp = ioread32be((void *)(& (dev->iseg)->cmdif_rev_fw_sub));
#line 629
  return ((u16 )tmp);
}
}
#line 665
extern int mlx5_cmd_alloc_uar(struct mlx5_core_dev * , u32 * ) ;
#line 666
extern int mlx5_cmd_free_uar(struct mlx5_core_dev * , u32  ) ;
#line 691
extern int mlx5_core_create_mkey(struct mlx5_core_dev * , struct mlx5_core_mr * ,
                                 struct mlx5_create_mkey_mbox_in * , int  , void (*)(int  ,
                                                                                     void * ) ,
                                 void * , struct mlx5_create_mkey_mbox_out * ) ;
#line 695
extern int mlx5_core_destroy_mkey(struct mlx5_core_dev * , struct mlx5_core_mr * ) ;
#line 700
extern int mlx5_core_alloc_pd(struct mlx5_core_dev * , u32 * ) ;
#line 701
extern int mlx5_core_dealloc_pd(struct mlx5_core_dev * , u32  ) ;
#line 732
extern int mlx5_core_attach_mcg(struct mlx5_core_dev * , union ib_gid * , u32  ) ;
#line 733
extern int mlx5_core_detach_mcg(struct mlx5_core_dev * , union ib_gid * , u32  ) ;
#line 737
extern int mlx5_core_access_reg(struct mlx5_core_dev * , void * , int  , void * ,
                                int  , u16  , int  , int  ) ;
#line 741
extern int mlx5_set_port_caps(struct mlx5_core_dev * , u8  , u32  ) ;
#line 748
extern int mlx5_query_port_link_width_oper(struct mlx5_core_dev * , u8 * , u8  ) ;
#line 750
extern int mlx5_query_port_proto_oper(struct mlx5_core_dev * , u8 * , int  , u8  ) ;
#line 760
extern void mlx5_query_port_max_mtu(struct mlx5_core_dev * , int * , u8  ) ;
#line 761
extern void mlx5_query_port_oper_mtu(struct mlx5_core_dev * , int * , u8  ) ;
#line 764
extern int mlx5_query_port_vl_hw_cap(struct mlx5_core_dev * , u8 * , u8  ) ;
#line 828
extern int mlx5_register_interface(struct mlx5_interface * ) ;
#line 829
extern void mlx5_unregister_interface(struct mlx5_interface * ) ;
#line 830
extern int mlx5_core_query_vendor_id(struct mlx5_core_dev * , u32 * ) ;
#line 841 "include/linux/mlx5/driver.h"
__inline static int mlx5_get_gid_table_len(u16 param ) 
{ 


  {
#line 843
  if ((unsigned int )param > 4U) {
#line 844
    printk("\fgid table length is zero\n");
#line 845
    return (0);
  } else {

  }
#line 848
  return (8 << (int )param);
}
}
#line 40 "include/linux/mlx5/vport.h"
extern int mlx5_query_hca_vport_gid(struct mlx5_core_dev * , u8  , u8  , u16  , u16  ,
                                    union ib_gid * ) ;
#line 43
extern int mlx5_query_hca_vport_pkey(struct mlx5_core_dev * , u8  , u8  , u16  , u16  ,
                                     u16 * ) ;
#line 46
extern int mlx5_query_hca_vport_context(struct mlx5_core_dev * , u8  , u8  , u16  ,
                                        struct mlx5_hca_vport_context * ) ;
#line 50
extern int mlx5_query_hca_vport_system_image_guid(struct mlx5_core_dev * , u64 * ) ;
#line 52
extern int mlx5_query_hca_vport_node_guid(struct mlx5_core_dev * , u64 * ) ;
#line 98 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_ucontext *to_mucontext(struct ib_ucontext *ibucontext ) 
{ 
  struct ib_ucontext  const  *__mptr ;

  {
#line 100
  __mptr = (struct ib_ucontext  const  *)ibucontext;
#line 100
  return ((struct mlx5_ib_ucontext *)__mptr);
}
}
#line 457 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_dev *to_mdev(struct ib_device *ibdev ) 
{ 
  struct ib_device  const  *__mptr ;

  {
#line 459
  __mptr = (struct ib_device  const  *)ibdev;
#line 459
  return ((struct mlx5_ib_dev *)__mptr);
}
}
#line 482 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_pd *to_mpd(struct ib_pd *ibpd ) 
{ 
  struct ib_pd  const  *__mptr ;

  {
#line 484
  __mptr = (struct ib_pd  const  *)ibpd;
#line 484
  return ((struct mlx5_ib_pd *)__mptr);
}
}
#line 533
struct ib_ah *mlx5_ib_create_ah(struct ib_pd *pd , struct ib_ah_attr *ah_attr ) ;
#line 534
int mlx5_ib_query_ah(struct ib_ah *ibah , struct ib_ah_attr *ah_attr ) ;
#line 535
int mlx5_ib_destroy_ah(struct ib_ah *ah ) ;
#line 536
struct ib_srq *mlx5_ib_create_srq(struct ib_pd *pd , struct ib_srq_init_attr *init_attr ,
                                  struct ib_udata *udata ) ;
#line 539
int mlx5_ib_modify_srq(struct ib_srq *ibsrq , struct ib_srq_attr *attr , enum ib_srq_attr_mask attr_mask ,
                       struct ib_udata *udata ) ;
#line 541
int mlx5_ib_query_srq(struct ib_srq *ibsrq , struct ib_srq_attr *srq_attr ) ;
#line 542
int mlx5_ib_destroy_srq(struct ib_srq *srq ) ;
#line 543
int mlx5_ib_post_srq_recv(struct ib_srq *ibsrq , struct ib_recv_wr *wr , struct ib_recv_wr **bad_wr ) ;
#line 545
struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd , struct ib_qp_init_attr *init_attr ,
                                struct ib_udata *udata ) ;
#line 548
int mlx5_ib_modify_qp(struct ib_qp *ibqp , struct ib_qp_attr *attr , int attr_mask ,
                      struct ib_udata *udata ) ;
#line 550
int mlx5_ib_query_qp(struct ib_qp *ibqp , struct ib_qp_attr *qp_attr , int qp_attr_mask ,
                     struct ib_qp_init_attr *qp_init_attr ) ;
#line 552
int mlx5_ib_destroy_qp(struct ib_qp *qp ) ;
#line 553
int mlx5_ib_post_send(struct ib_qp *ibqp , struct ib_send_wr *wr , struct ib_send_wr **bad_wr ) ;
#line 555
int mlx5_ib_post_recv(struct ib_qp *ibqp , struct ib_recv_wr *wr , struct ib_recv_wr **bad_wr ) ;
#line 560
struct ib_cq *mlx5_ib_create_cq(struct ib_device *ibdev , struct ib_cq_init_attr  const  *attr ,
                                struct ib_ucontext *context , struct ib_udata *udata ) ;
#line 564
int mlx5_ib_destroy_cq(struct ib_cq *cq ) ;
#line 565
int mlx5_ib_poll_cq(struct ib_cq *ibcq , int num_entries , struct ib_wc *wc ) ;
#line 566
int mlx5_ib_arm_cq(struct ib_cq *ibcq , enum ib_cq_notify_flags flags ) ;
#line 567
int mlx5_ib_modify_cq(struct ib_cq *cq , u16 cq_count , u16 cq_period ) ;
#line 568
int mlx5_ib_resize_cq(struct ib_cq *ibcq , int entries , struct ib_udata *udata ) ;
#line 569
struct ib_mr *mlx5_ib_get_dma_mr(struct ib_pd *pd , int acc ) ;
#line 570
struct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd , u64 start , u64 length , u64 virt_addr ,
                                  int access_flags , struct ib_udata *udata ) ;
#line 575
int mlx5_ib_dereg_mr(struct ib_mr *ibmr ) ;
#line 576
int mlx5_ib_destroy_mr(struct ib_mr *ibmr ) ;
#line 577
struct ib_mr *mlx5_ib_create_mr(struct ib_pd *pd , struct ib_mr_init_attr *mr_init_attr ) ;
#line 579
struct ib_mr *mlx5_ib_alloc_fast_reg_mr(struct ib_pd *pd , int max_page_list_len ) ;
#line 581
struct ib_fast_reg_page_list *mlx5_ib_alloc_fast_reg_page_list(struct ib_device *ibdev ,
                                                               int page_list_len ) ;
#line 583
void mlx5_ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list ) ;
#line 590
int mlx5_ib_process_mad(struct ib_device *ibdev , int mad_flags , u8 port_num , struct ib_wc  const  *in_wc ,
                        struct ib_grh  const  *in_grh , struct ib_mad_hdr  const  *in ,
                        size_t in_mad_size , struct ib_mad_hdr *out , size_t *out_mad_size ,
                        u16 *out_mad_pkey_index ) ;
#line 595
struct ib_xrcd *mlx5_ib_alloc_xrcd(struct ib_device *ibdev , struct ib_ucontext *context ,
                                   struct ib_udata *udata ) ;
#line 598
int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd ) ;
#line 600
int mlx5_query_ext_port_caps(struct mlx5_ib_dev *dev , u8 port ) ;
#line 603
int mlx5_query_mad_ifc_system_image_guid(struct ib_device *ibdev , __be64 *sys_image_guid ) ;
#line 605
int mlx5_query_mad_ifc_max_pkeys(struct ib_device *ibdev , u16 *max_pkeys ) ;
#line 607
int mlx5_query_mad_ifc_vendor_id(struct ib_device *ibdev , u32 *vendor_id ) ;
#line 609
int mlx5_query_mad_ifc_node_desc(struct mlx5_ib_dev *dev , char *node_desc ) ;
#line 610
int mlx5_query_mad_ifc_node_guid(struct mlx5_ib_dev *dev , __be64 *node_guid ) ;
#line 611
int mlx5_query_mad_ifc_pkey(struct ib_device *ibdev , u8 port , u16 index , u16 *pkey ) ;
#line 613
int mlx5_query_mad_ifc_gids(struct ib_device *ibdev , u8 port , int index , union ib_gid *gid ) ;
#line 615
int mlx5_query_mad_ifc_port(struct ib_device *ibdev , u8 port , struct ib_port_attr *props ) ;
#line 617
int mlx5_ib_query_port(struct ib_device *ibdev , u8 port , struct ib_port_attr *props ) ;
#line 630
int mlx5_mr_cache_init(struct mlx5_ib_dev *dev ) ;
#line 631
int mlx5_mr_cache_cleanup(struct mlx5_ib_dev *dev ) ;
#line 633
void mlx5_umr_cq_handler(struct ib_cq *cq , void *cq_context ) ;
#line 634
int mlx5_ib_check_mr_status(struct ib_mr *ibmr , u32 check_mask , struct ib_mr_status *mr_status ) ;
#line 640
void mlx5_ib_internal_fill_odp_caps(struct mlx5_ib_dev *dev ) ;
#line 644
int mlx5_ib_odp_init_one(struct mlx5_ib_dev *ibdev ) ;
#line 645
void mlx5_ib_odp_remove_one(struct mlx5_ib_dev *ibdev ) ;
#line 646
int mlx5_ib_odp_init(void) ;
#line 647
void mlx5_ib_odp_cleanup(void) ;
#line 650
void mlx5_ib_invalidate_range(struct ib_umem *umem , unsigned long start , unsigned long end ) ;
#line 58 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int deprecated_prof_sel  =    2;
#line 62 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static char mlx5_version[66U]  = 
#line 62
  {      'm',      'l',      'x',      '5', 
        '_',      'i',      'b',      ':', 
        ' ',      'M',      'e',      'l', 
        'l',      'a',      'n',      'o', 
        'x',      ' ',      'C',      'o', 
        'n',      'n',      'e',      'c', 
        't',      '-',      'I',      'B', 
        ' ',      'I',      'n',      'f', 
        'i',      'n',      'i',      'b', 
        'a',      'n',      'd',      ' ', 
        'd',      'r',      'i',      'v', 
        'e',      'r',      ' ',      'v', 
        '2',      '.',      '2',      '-', 
        '1',      ' ',      '(',      'F', 
        'e',      'b',      ' ',      '2', 
        '0',      '1',      '4',      ')', 
        '\n',      '\000'};
#line 67 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static enum rdma_link_layer mlx5_ib_port_link_layer(struct ib_device *device ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  __u32 tmp___0 ;

  {
#line 69
  tmp = to_mdev(device);
#line 69
  dev = tmp;
#line 71
  tmp___0 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 13UL));
#line 71
  switch ((tmp___0 >> 8) & 3U) {
  case 0U: ;
#line 73
  return (1);
  case 1U: ;
#line 75
  return (2);
  default: ;
#line 77
  return (0);
  }
}
}
#line 81 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_use_mad_ifc(struct mlx5_ib_dev *dev ) 
{ 


  {
#line 83
  return ((dev->mdev)->issi == 0U);
}
}
#line 92 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_get_vport_access_method(struct ib_device *ibdev ) 
{ 
  struct mlx5_ib_dev *tmp ;
  int tmp___0 ;
  enum rdma_link_layer tmp___1 ;

  {
#line 94
  tmp = to_mdev(ibdev);
#line 94
  tmp___0 = mlx5_use_mad_ifc(tmp);
#line 94
  if (tmp___0 != 0) {
#line 95
    return (0);
  } else {

  }
#line 97
  tmp___1 = mlx5_ib_port_link_layer(ibdev);
#line 97
  if ((unsigned int )tmp___1 == 2U) {
#line 99
    return (2);
  } else {

  }
#line 101
  return (1);
}
}
#line 104 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_query_system_image_guid(struct ib_device *ibdev , __be64 *sys_image_guid ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  u64 tmp___0 ;
  int err ;
  int tmp___1 ;
  int tmp___2 ;
  __u64 tmp___3 ;

  {
#line 107
  tmp = to_mdev(ibdev);
#line 107
  dev = tmp;
#line 108
  mdev = dev->mdev;
#line 112
  tmp___1 = mlx5_get_vport_access_method(ibdev);
#line 112
  switch (tmp___1) {
  case 0: 
#line 114
  tmp___2 = mlx5_query_mad_ifc_system_image_guid(ibdev, sys_image_guid);
#line 114
  return (tmp___2);
  case 1: 
#line 118
  err = mlx5_query_hca_vport_system_image_guid(mdev, & tmp___0);
#line 119
  if (err == 0) {
#line 120
    tmp___3 = __fswab64(tmp___0);
#line 120
    *sys_image_guid = tmp___3;
  } else {

  }
#line 121
  return (err);
  default: ;
#line 124
  return (-22);
  }
}
}
#line 128 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_query_max_pkeys(struct ib_device *ibdev , u16 *max_pkeys ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  int tmp___0 ;
  int tmp___1 ;
  __u32 tmp___2 ;

  {
#line 131
  tmp = to_mdev(ibdev);
#line 131
  dev = tmp;
#line 132
  mdev = dev->mdev;
#line 134
  tmp___0 = mlx5_get_vport_access_method(ibdev);
#line 134
  switch (tmp___0) {
  case 0: 
#line 136
  tmp___1 = mlx5_query_mad_ifc_max_pkeys(ibdev, max_pkeys);
#line 136
  return (tmp___1);
  case 1: ;
  case 2: 
#line 140
  tmp___2 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 12UL));
#line 140
  *max_pkeys = mlx5_to_sw_pkey_sz((int )tmp___2 & 65535);
#line 142
  return (0);
  default: ;
#line 145
  return (-22);
  }
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_query_vendor_id(struct ib_device *ibdev , u32 *vendor_id ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 152
  tmp = to_mdev(ibdev);
#line 152
  dev = tmp;
#line 154
  tmp___0 = mlx5_get_vport_access_method(ibdev);
#line 154
  switch (tmp___0) {
  case 0: 
#line 156
  tmp___1 = mlx5_query_mad_ifc_vendor_id(ibdev, vendor_id);
#line 156
  return (tmp___1);
  case 1: ;
  case 2: 
#line 160
  tmp___2 = mlx5_core_query_vendor_id(dev->mdev, vendor_id);
#line 160
  return (tmp___2);
  default: ;
#line 163
  return (-22);
  }
}
}
#line 167 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_query_node_guid(struct mlx5_ib_dev *dev , __be64 *node_guid ) 
{ 
  u64 tmp ;
  int err ;
  int tmp___0 ;
  int tmp___1 ;
  __u64 tmp___2 ;

  {
#line 173
  tmp___0 = mlx5_get_vport_access_method(& dev->ib_dev);
#line 173
  switch (tmp___0) {
  case 0: 
#line 175
  tmp___1 = mlx5_query_mad_ifc_node_guid(dev, node_guid);
#line 175
  return (tmp___1);
  case 1: 
#line 178
  err = mlx5_query_hca_vport_node_guid(dev->mdev, & tmp);
#line 179
  if (err == 0) {
#line 180
    tmp___2 = __fswab64(tmp);
#line 180
    *node_guid = tmp___2;
  } else {

  }
#line 181
  return (err);
  default: ;
#line 184
  return (-22);
  }
}
}
#line 192 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_query_node_desc(struct mlx5_ib_dev *dev , char *node_desc ) 
{ 
  struct mlx5_reg_node_desc in ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 196
  tmp___0 = mlx5_use_mad_ifc(dev);
#line 196
  if (tmp___0 != 0) {
#line 197
    tmp = mlx5_query_mad_ifc_node_desc(dev, node_desc);
#line 197
    return (tmp);
  } else {

  }
#line 199
  memset((void *)(& in), 0, 64UL);
#line 201
  tmp___1 = mlx5_core_access_reg(dev->mdev, (void *)(& in), 64, (void *)node_desc,
                                 64, 24577, 0, 0);
#line 201
  return (tmp___1);
}
}
#line 206 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_query_device(struct ib_device *ibdev , struct ib_device_attr *props ,
                                struct ib_udata *uhw ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  int err ;
  int max_rq_sg ;
  int max_sq_sg ;
  u16 tmp___0 ;
  u16 tmp___1 ;
  u16 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  __u32 tmp___12 ;
  __u32 tmp___13 ;
  int _min1 ;
  int _min2 ;
  __u32 tmp___14 ;
  __u32 tmp___15 ;
  __u32 tmp___16 ;
  __u32 tmp___17 ;
  __u32 tmp___18 ;
  __u32 tmp___19 ;
  __u32 tmp___20 ;
  __u32 tmp___21 ;
  __u32 tmp___22 ;
  __u32 tmp___23 ;
  __u32 tmp___24 ;
  __u32 tmp___25 ;

  {
#line 210
  tmp = to_mdev(ibdev);
#line 210
  dev = tmp;
#line 211
  mdev = dev->mdev;
#line 212
  err = -12;
#line 216
  if (uhw->inlen != 0UL || uhw->outlen != 0UL) {
#line 217
    return (-22);
  } else {

  }
#line 219
  memset((void *)props, 0, 224UL);
#line 220
  err = mlx5_query_system_image_guid(ibdev, & props->sys_image_guid);
#line 222
  if (err != 0) {
#line 223
    return (err);
  } else {

  }
#line 225
  err = mlx5_query_max_pkeys(ibdev, & props->max_pkeys);
#line 226
  if (err != 0) {
#line 227
    return (err);
  } else {

  }
#line 229
  err = mlx5_query_vendor_id(ibdev, & props->vendor_id);
#line 230
  if (err != 0) {
#line 231
    return (err);
  } else {

  }
#line 233
  tmp___0 = fw_rev_maj(dev->mdev);
#line 233
  tmp___1 = fw_rev_min(dev->mdev);
#line 233
  tmp___2 = fw_rev_sub(dev->mdev);
#line 233
  props->fw_ver = (((unsigned long long )tmp___0 << 32) | (unsigned long long )((int )tmp___1 << 16)) | (unsigned long long )tmp___2;
#line 236
  props->device_cap_flags = 7200;
#line 241
  tmp___3 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 241
  if ((tmp___3 & 256U) != 0U) {
#line 242
    props->device_cap_flags = props->device_cap_flags | 2;
  } else {

  }
#line 243
  tmp___4 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 243
  if ((tmp___4 & 512U) != 0U) {
#line 244
    props->device_cap_flags = props->device_cap_flags | 4;
  } else {

  }
#line 245
  tmp___5 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 245
  if ((tmp___5 & 131072U) != 0U) {
#line 246
    props->device_cap_flags = props->device_cap_flags | 16;
  } else {

  }
#line 247
  props->device_cap_flags = props->device_cap_flags | 32768;
#line 248
  tmp___6 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 248
  if ((tmp___6 & 8U) != 0U) {
#line 249
    props->device_cap_flags = props->device_cap_flags | 1048576;
  } else {

  }
#line 250
  props->device_cap_flags = props->device_cap_flags | 2097152;
#line 251
  tmp___7 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 16UL));
#line 251
  if ((tmp___7 & 256U) != 0U) {
#line 252
    props->device_cap_flags = props->device_cap_flags | 1073741824;
#line 254
    props->sig_prot_cap = 7;
#line 257
    props->sig_guard_cap = 3;
  } else {

  }
#line 260
  tmp___8 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 260
  if ((tmp___8 & 8388608U) != 0U) {
#line 261
    props->device_cap_flags = props->device_cap_flags | 4194304;
  } else {

  }
#line 263
  props->vendor_part_id = (u32 )(mdev->pdev)->device;
#line 264
  props->hw_ver = (u32 )(mdev->pdev)->revision;
#line 266
  props->max_mr_size = 0xffffffffffffffffULL;
#line 267
  tmp___9 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 18UL));
#line 267
  props->page_size_cap = 1ULL << ((int )tmp___9 & 255);
#line 268
  tmp___10 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 4UL));
#line 268
  props->max_qp = 1 << ((int )tmp___10 & 31);
#line 269
  tmp___11 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 4UL));
#line 269
  props->max_qp_wr = 1 << ((int )(tmp___11 >> 16) & 255);
#line 270
  tmp___12 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 21UL));
#line 270
  max_rq_sg = (int )(((unsigned long )tmp___12 & 65535UL) / 16UL);
#line 272
  tmp___13 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 20UL));
#line 272
  max_sq_sg = (int )((((unsigned long )tmp___13 & 65535UL) - 16UL) / 16UL);
#line 275
  _min1 = max_rq_sg;
#line 275
  _min2 = max_sq_sg;
#line 275
  props->max_sge = _min1 < _min2 ? _min1 : _min2;
#line 276
  tmp___14 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 6UL));
#line 276
  props->max_cq = 1 << ((int )tmp___14 & 31);
#line 277
  tmp___15 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 7UL));
#line 277
  props->max_cqe = (1 << (int )(tmp___15 >> 24)) + -1;
#line 278
  tmp___16 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 7UL));
#line 278
  props->max_mr = 1 << ((int )(tmp___16 >> 16) & 63);
#line 279
  tmp___17 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 25UL));
#line 279
  props->max_pd = 1 << ((int )(tmp___17 >> 16) & 31);
#line 280
  tmp___18 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 10UL));
#line 280
  props->max_qp_rd_atom = 1 << ((int )(tmp___18 >> 16) & 63);
#line 281
  tmp___19 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 10UL));
#line 281
  props->max_qp_init_rd_atom = 1 << ((int )tmp___19 & 63);
#line 282
  tmp___20 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 5UL));
#line 282
  props->max_srq = 1 << ((int )(tmp___20 >> 16) & 31);
#line 283
  tmp___21 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 4UL));
#line 283
  props->max_srq_wr = (1 << (int )(tmp___21 >> 24)) + -1;
#line 284
  tmp___22 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 13UL));
#line 284
  props->local_ca_ack_delay = (unsigned int )((u8 )(tmp___22 >> 16)) & 31U;
#line 285
  props->max_res_rd_atom = props->max_qp_rd_atom * props->max_qp;
#line 286
  props->max_srq_sge = max_rq_sg + -1;
#line 287
  props->max_fast_reg_page_list_len = 4294967295U;
#line 288
  props->atomic_cap = 0;
#line 289
  props->masked_atomic_cap = 0;
#line 290
  tmp___23 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 24UL));
#line 290
  props->max_mcast_grp = 1 << ((int )tmp___23 & 255);
#line 291
  tmp___24 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 23UL));
#line 291
  props->max_mcast_qp_attach = (int )tmp___24 & 33554431;
#line 292
  props->max_total_mcast_qp_attach = props->max_mcast_qp_attach * props->max_mcast_grp;
#line 294
  props->max_map_per_fmr = 2147483647;
#line 297
  tmp___25 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 297
  if ((tmp___25 & 16777216U) != 0U) {
#line 298
    props->device_cap_flags = (long )props->device_cap_flags | (-0x7FFFFFFF-1);
  } else {

  }
#line 299
  props->odp_caps = dev->odp_caps;
#line 302
  return (0);
}
}
#line 313 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int translate_active_width(struct ib_device *ibdev , u8 active_width , u8 *ib_width ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int err ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___2 ;
  long tmp___3 ;

  {
#line 316
  tmp = to_mdev(ibdev);
#line 316
  dev = tmp;
#line 317
  err = 0;
#line 319
  if ((int )active_width & 1) {
#line 320
    *ib_width = 1U;
  } else
#line 321
  if (((int )active_width & 2) != 0) {
#line 322
    descriptor.modname = "mlx5_ib";
#line 322
    descriptor.function = "translate_active_width";
#line 322
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 322
    descriptor.format = "%s:%s:%d:(pid %d): active_width %d is not supported by IB spec\n";
#line 322
    descriptor.lineno = 323U;
#line 322
    descriptor.flags = 0U;
#line 322
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 322
    if (tmp___1 != 0L) {
#line 322
      tmp___0 = get_current();
#line 322
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): active_width %d is not supported by IB spec\n",
                         (char *)(& dev->ib_dev.name), "translate_active_width", 323,
                         tmp___0->pid, (int )active_width);
    } else {

    }
#line 324
    err = -22;
  } else
#line 325
  if (((int )active_width & 4) != 0) {
#line 326
    *ib_width = 2U;
  } else
#line 327
  if (((int )active_width & 8) != 0) {
#line 328
    *ib_width = 4U;
  } else
#line 329
  if (((int )active_width & 16) != 0) {
#line 330
    *ib_width = 8U;
  } else {
#line 332
    descriptor___0.modname = "mlx5_ib";
#line 332
    descriptor___0.function = "translate_active_width";
#line 332
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 332
    descriptor___0.format = "%s:%s:%d:(pid %d): Invalid active_width %d\n";
#line 332
    descriptor___0.lineno = 333U;
#line 332
    descriptor___0.flags = 0U;
#line 332
    tmp___3 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 332
    if (tmp___3 != 0L) {
#line 332
      tmp___2 = get_current();
#line 332
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): Invalid active_width %d\n",
                         (char *)(& dev->ib_dev.name), "translate_active_width", 333,
                         tmp___2->pid, (int )active_width);
    } else {

    }
#line 334
    err = -22;
  }
#line 337
  return (err);
}
}
#line 340 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_mtu_to_ib_mtu(int mtu ) 
{ 


  {
#line 342
  switch (mtu) {
  case 256: ;
#line 343
  return (1);
  case 512: ;
#line 344
  return (2);
  case 1024: ;
#line 345
  return (3);
  case 2048: ;
#line 346
  return (4);
  case 4096: ;
#line 347
  return (5);
  default: 
#line 349
  printk("\finvalid mtu\n");
#line 350
  return (-1);
  }
}
}
#line 374 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int translate_max_vl_num(struct ib_device *ibdev , u8 vl_hw_cap , u8 *max_vl_num ) 
{ 


  {
#line 377
  switch ((int )vl_hw_cap) {
  case 1: 
#line 379
  *max_vl_num = 1U;
#line 380
  goto ldv_37867;
  case 2: 
#line 382
  *max_vl_num = 2U;
#line 383
  goto ldv_37867;
  case 4: 
#line 385
  *max_vl_num = 3U;
#line 386
  goto ldv_37867;
  case 8: 
#line 388
  *max_vl_num = 4U;
#line 389
  goto ldv_37867;
  case 15: 
#line 391
  *max_vl_num = 5U;
#line 392
  goto ldv_37867;
  default: ;
#line 395
  return (-22);
  }
  ldv_37867: ;
#line 398
  return (0);
}
}
#line 401 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_query_hca_port(struct ib_device *ibdev , u8 port , struct ib_port_attr *props ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  struct mlx5_hca_vport_context *rep ;
  int max_mtu ;
  int oper_mtu ;
  int err ;
  u8 ib_link_width_oper ;
  u8 vl_hw_cap ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
#line 404
  tmp = to_mdev(ibdev);
#line 404
  dev = tmp;
#line 405
  mdev = dev->mdev;
#line 413
  tmp___0 = kzalloc(80UL, 208U);
#line 413
  rep = (struct mlx5_hca_vport_context *)tmp___0;
#line 414
  if ((unsigned long )rep == (unsigned long )((struct mlx5_hca_vport_context *)0)) {
#line 415
    err = -12;
#line 416
    goto out;
  } else {

  }
#line 419
  memset((void *)props, 0, 48UL);
#line 421
  err = mlx5_query_hca_vport_context(mdev, 0, (int )port, 0, rep);
#line 422
  if (err != 0) {
#line 423
    goto out;
  } else {

  }
#line 425
  props->lid = rep->lid;
#line 426
  props->lmc = rep->lmc;
#line 427
  props->sm_lid = rep->sm_lid;
#line 428
  props->sm_sl = rep->sm_sl;
#line 429
  props->state = rep->vport_state;
#line 430
  props->phys_state = rep->port_physical_state;
#line 431
  props->port_cap_flags = rep->cap_mask1;
#line 432
  tmp___1 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 11UL));
#line 432
  props->gid_tbl_len = mlx5_get_gid_table_len((int )((u16 )tmp___1));
#line 433
  tmp___2 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 14UL));
#line 433
  props->max_msg_sz = (u32 )(1 << ((int )(tmp___2 >> 24) & 31));
#line 434
  tmp___3 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 12UL));
#line 434
  props->pkey_tbl_len = mlx5_to_sw_pkey_sz((int )tmp___3 & 65535);
#line 435
  props->bad_pkey_cntr = (u32 )rep->pkey_violation_counter;
#line 436
  props->qkey_viol_cntr = (u32 )rep->qkey_violation_counter;
#line 437
  props->subnet_timeout = rep->subnet_timeout;
#line 438
  props->init_type_reply = rep->init_type_reply;
#line 440
  err = mlx5_query_port_link_width_oper(mdev, & ib_link_width_oper, (int )port);
#line 441
  if (err != 0) {
#line 442
    goto out;
  } else {

  }
#line 444
  err = translate_active_width(ibdev, (int )ib_link_width_oper, & props->active_width);
#line 446
  if (err != 0) {
#line 447
    goto out;
  } else {

  }
#line 448
  err = mlx5_query_port_proto_oper(mdev, & props->active_speed, 1, (int )port);
#line 450
  if (err != 0) {
#line 451
    goto out;
  } else {

  }
#line 453
  mlx5_query_port_max_mtu(mdev, & max_mtu, (int )port);
#line 455
  tmp___4 = mlx5_mtu_to_ib_mtu(max_mtu);
#line 455
  props->max_mtu = (enum ib_mtu )tmp___4;
#line 457
  mlx5_query_port_oper_mtu(mdev, & oper_mtu, (int )port);
#line 459
  tmp___5 = mlx5_mtu_to_ib_mtu(oper_mtu);
#line 459
  props->active_mtu = (enum ib_mtu )tmp___5;
#line 461
  err = mlx5_query_port_vl_hw_cap(mdev, & vl_hw_cap, (int )port);
#line 462
  if (err != 0) {
#line 463
    goto out;
  } else {

  }
#line 465
  err = translate_max_vl_num(ibdev, (int )vl_hw_cap, & props->max_vl_num);
  out: 
#line 468
  kfree((void const   *)rep);
#line 469
  return (err);
}
}
#line 472 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
int mlx5_ib_query_port(struct ib_device *ibdev , u8 port , struct ib_port_attr *props ) 
{ 
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 475
  tmp = mlx5_get_vport_access_method(ibdev);
#line 475
  switch (tmp) {
  case 0: 
#line 477
  tmp___0 = mlx5_query_mad_ifc_port(ibdev, (int )port, props);
#line 477
  return (tmp___0);
  case 1: 
#line 480
  tmp___1 = mlx5_query_hca_port(ibdev, (int )port, props);
#line 480
  return (tmp___1);
  default: ;
#line 483
  return (-22);
  }
}
}
#line 487 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_query_gid(struct ib_device *ibdev , u8 port , int index , union ib_gid *gid ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 490
  tmp = to_mdev(ibdev);
#line 490
  dev = tmp;
#line 491
  mdev = dev->mdev;
#line 493
  tmp___0 = mlx5_get_vport_access_method(ibdev);
#line 493
  switch (tmp___0) {
  case 0: 
#line 495
  tmp___1 = mlx5_query_mad_ifc_gids(ibdev, (int )port, index, gid);
#line 495
  return (tmp___1);
  case 1: 
#line 498
  tmp___2 = mlx5_query_hca_vport_gid(mdev, 0, (int )port, 0, (int )((u16 )index),
                                     gid);
#line 498
  return (tmp___2);
  default: ;
#line 501
  return (-22);
  }
}
}
#line 506 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_query_pkey(struct ib_device *ibdev , u8 port , u16 index , u16 *pkey ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;

  {
#line 509
  tmp = to_mdev(ibdev);
#line 509
  dev = tmp;
#line 510
  mdev = dev->mdev;
#line 512
  tmp___0 = mlx5_get_vport_access_method(ibdev);
#line 512
  switch (tmp___0) {
  case 0: 
#line 514
  tmp___1 = mlx5_query_mad_ifc_pkey(ibdev, (int )port, (int )index, pkey);
#line 514
  return (tmp___1);
  case 1: ;
  case 2: 
#line 518
  tmp___2 = mlx5_query_hca_vport_pkey(mdev, 0, (int )port, 0, (int )index, pkey);
#line 518
  return (tmp___2);
  default: ;
#line 521
  return (-22);
  }
}
}
#line 525 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_modify_device(struct ib_device *ibdev , int mask , struct ib_device_modify *props ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_reg_node_desc in ;
  struct mlx5_reg_node_desc out ;
  int err ;

  {
#line 528
  tmp = to_mdev(ibdev);
#line 528
  dev = tmp;
#line 533
  if ((mask & -3) != 0) {
#line 534
    return (-95);
  } else {

  }
#line 536
  if ((mask & 2) == 0) {
#line 537
    return (0);
  } else {

  }
#line 543
  memcpy((void *)(& in), (void const   *)(& props->node_desc), 64UL);
#line 544
  err = mlx5_core_access_reg(dev->mdev, (void *)(& in), 64, (void *)(& out), 64, 24577,
                             0, 1);
#line 546
  if (err != 0) {
#line 547
    return (err);
  } else {

  }
#line 549
  memcpy((void *)(& ibdev->node_desc), (void const   *)(& props->node_desc), 64UL);
#line 551
  return (err);
}
}
#line 554 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_modify_port(struct ib_device *ibdev , u8 port , int mask , struct ib_port_modify *props ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct ib_port_attr attr ;
  u32 tmp___0 ;
  int err ;

  {
#line 557
  tmp = to_mdev(ibdev);
#line 557
  dev = tmp;
#line 562
  mutex_lock_nested(& dev->cap_mask_mutex, 0U);
#line 564
  err = mlx5_ib_query_port(ibdev, (int )port, & attr);
#line 565
  if (err != 0) {
#line 566
    goto out;
  } else {

  }
#line 568
  tmp___0 = (attr.port_cap_flags | props->set_port_cap_mask) & ~ props->clr_port_cap_mask;
#line 571
  err = mlx5_set_port_caps(dev->mdev, (int )port, tmp___0);
  out: 
#line 574
  mutex_unlock(& dev->cap_mask_mutex);
#line 575
  return (err);
}
}
#line 578 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct ib_ucontext *mlx5_ib_alloc_ucontext(struct ib_device *ibdev , struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_alloc_ucontext_req_v2 req ;
  struct mlx5_ib_alloc_ucontext_resp resp ;
  struct mlx5_ib_ucontext *context ;
  struct mlx5_uuar_info *uuari ;
  struct mlx5_uar *uars ;
  int gross_uuars ;
  int num_uars ;
  int ver ;
  int uuarn ;
  int err ;
  int i ;
  size_t reqlen ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;
  void *tmp___5 ;
  void *tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  __u32 tmp___12 ;
  __u32 tmp___13 ;
  void *tmp___14 ;
  void *tmp___15 ;
  struct lock_class_key __key ;
  void *tmp___16 ;
  void *tmp___17 ;
  void *tmp___18 ;
  struct lock_class_key __key___0 ;
  __u32 tmp___19 ;
  void *tmp___20 ;

  {
#line 581
  tmp = to_mdev(ibdev);
#line 581
  dev = tmp;
#line 595
  if (! dev->ib_active) {
#line 596
    tmp___0 = ERR_PTR(-11L);
#line 596
    return ((struct ib_ucontext *)tmp___0);
  } else {

  }
#line 598
  memset((void *)(& req), 0, 16UL);
#line 599
  reqlen = udata->inlen - 8UL;
#line 600
  if (reqlen == 8UL) {
#line 601
    ver = 0;
  } else
#line 602
  if (reqlen == 16UL) {
#line 603
    ver = 2;
  } else {
#line 605
    tmp___1 = ERR_PTR(-22L);
#line 605
    return ((struct ib_ucontext *)tmp___1);
  }
#line 607
  err = ib_copy_from_udata((void *)(& req), udata, reqlen);
#line 608
  if (err != 0) {
#line 609
    tmp___2 = ERR_PTR((long )err);
#line 609
    return ((struct ib_ucontext *)tmp___2);
  } else {

  }
#line 611
  if (req.flags != 0U || req.reserved != 0U) {
#line 612
    tmp___3 = ERR_PTR(-22L);
#line 612
    return ((struct ib_ucontext *)tmp___3);
  } else {

  }
#line 614
  if (req.total_num_uuars > 512U) {
#line 615
    tmp___4 = ERR_PTR(-12L);
#line 615
    return ((struct ib_ucontext *)tmp___4);
  } else {

  }
#line 617
  if (req.total_num_uuars == 0U) {
#line 618
    tmp___5 = ERR_PTR(-22L);
#line 618
    return ((struct ib_ucontext *)tmp___5);
  } else {

  }
#line 620
  req.total_num_uuars = (req.total_num_uuars + 1U) & 4294967294U;
#line 622
  if (req.num_low_latency_uuars > req.total_num_uuars - 1U) {
#line 623
    tmp___6 = ERR_PTR(-22L);
#line 623
    return ((struct ib_ucontext *)tmp___6);
  } else {

  }
#line 625
  num_uars = (int )(req.total_num_uuars / 2U);
#line 626
  gross_uuars = num_uars * 4;
#line 627
  tmp___7 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 627
  resp.qp_tab_size = (__u32 )(1 << ((int )tmp___7 & 31));
#line 628
  tmp___8 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 19UL));
#line 628
  resp.bf_reg_size = (__u32 )(1 << ((int )(tmp___8 >> 16) & 31));
#line 629
  resp.cache_line_size = 64U;
#line 630
  tmp___9 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 20UL));
#line 630
  resp.max_sq_desc_sz = (__u16 )tmp___9;
#line 631
  tmp___10 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 21UL));
#line 631
  resp.max_rq_desc_sz = (__u16 )tmp___10;
#line 632
  tmp___11 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 632
  resp.max_send_wqebb = (__u32 )(1 << ((int )(tmp___11 >> 16) & 255));
#line 633
  tmp___12 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 633
  resp.max_recv_wr = (__u32 )(1 << ((int )(tmp___12 >> 16) & 255));
#line 634
  tmp___13 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 634
  resp.max_srq_recv_wr = (__u32 )(1 << (int )(tmp___13 >> 24));
#line 636
  tmp___14 = kzalloc(784UL, 208U);
#line 636
  context = (struct mlx5_ib_ucontext *)tmp___14;
#line 637
  if ((unsigned long )context == (unsigned long )((struct mlx5_ib_ucontext *)0)) {
#line 638
    tmp___15 = ERR_PTR(-12L);
#line 638
    return ((struct ib_ucontext *)tmp___15);
  } else {

  }
#line 640
  uuari = & context->uuari;
#line 641
  __mutex_init(& uuari->lock, "&uuari->lock", & __key);
#line 642
  tmp___16 = kcalloc((size_t )num_uars, 48UL, 208U);
#line 642
  uars = (struct mlx5_uar *)tmp___16;
#line 643
  if ((unsigned long )uars == (unsigned long )((struct mlx5_uar *)0)) {
#line 644
    err = -12;
#line 645
    goto out_ctx;
  } else {

  }
#line 648
  tmp___17 = kcalloc(((unsigned long )gross_uuars + 63UL) / 64UL, 8UL, 208U);
#line 648
  uuari->bitmap = (unsigned long *)tmp___17;
#line 651
  if ((unsigned long )uuari->bitmap == (unsigned long )((unsigned long *)0UL)) {
#line 652
    err = -12;
#line 653
    goto out_uar_ctx;
  } else {

  }
#line 658
  i = 0;
#line 658
  goto ldv_37959;
  ldv_37958: 
#line 659
  uuarn = i & 3;
#line 660
  if (uuarn == 2 || uuarn == 3) {
#line 661
    set_bit((long )i, (unsigned long volatile   *)uuari->bitmap);
  } else {

  }
#line 658
  i = i + 1;
  ldv_37959: ;
#line 658
  if (i < gross_uuars) {
#line 660
    goto ldv_37958;
  } else {

  }
#line 664
  tmp___18 = kcalloc((size_t )gross_uuars, 4UL, 208U);
#line 664
  uuari->count = (unsigned int *)tmp___18;
#line 665
  if ((unsigned long )uuari->count == (unsigned long )((unsigned int *)0U)) {
#line 666
    err = -12;
#line 667
    goto out_bitmap;
  } else {

  }
#line 670
  i = 0;
#line 670
  goto ldv_37964;
  ldv_37963: 
#line 671
  err = mlx5_cmd_alloc_uar(dev->mdev, & (uars + (unsigned long )i)->index);
#line 672
  if (err != 0) {
#line 673
    goto out_count;
  } else {

  }
#line 670
  i = i + 1;
  ldv_37964: ;
#line 670
  if (i < num_uars) {
#line 672
    goto ldv_37963;
  } else {

  }
#line 677
  context->ibucontext.invalidate_range = & mlx5_ib_invalidate_range;
#line 680
  INIT_LIST_HEAD(& context->db_page_list);
#line 681
  __mutex_init(& context->db_page_mutex, "&context->db_page_mutex", & __key___0);
#line 683
  resp.tot_uuars = req.total_num_uuars;
#line 684
  tmp___19 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 13UL));
#line 684
  resp.num_ports = (unsigned int )((__u16 )tmp___19) & 255U;
#line 685
  err = ib_copy_to_udata(udata, (void *)(& resp), 34UL);
#line 687
  if (err != 0) {
#line 688
    goto out_uars;
  } else {

  }
#line 690
  uuari->ver = (u32 )ver;
#line 691
  uuari->num_low_latency_uuars = (int )req.num_low_latency_uuars;
#line 692
  uuari->uars = uars;
#line 693
  uuari->num_uars = num_uars;
#line 694
  return (& context->ibucontext);
  out_uars: 
#line 697
  i = i - 1;
#line 697
  goto ldv_37969;
  ldv_37968: 
#line 698
  mlx5_cmd_free_uar(dev->mdev, (uars + (unsigned long )i)->index);
#line 697
  i = i - 1;
  ldv_37969: ;
#line 697
  if (i >= 0) {
#line 699
    goto ldv_37968;
  } else {

  }

  out_count: 
#line 700
  kfree((void const   *)uuari->count);
  out_bitmap: 
#line 703
  kfree((void const   *)uuari->bitmap);
  out_uar_ctx: 
#line 706
  kfree((void const   *)uars);
  out_ctx: 
#line 709
  kfree((void const   *)context);
#line 710
  tmp___20 = ERR_PTR((long )err);
#line 710
  return ((struct ib_ucontext *)tmp___20);
}
}
#line 713 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_dealloc_ucontext(struct ib_ucontext *ibcontext ) 
{ 
  struct mlx5_ib_ucontext *context ;
  struct mlx5_ib_ucontext *tmp ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp___0 ;
  struct mlx5_uuar_info *uuari ;
  int i ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;

  {
#line 715
  tmp = to_mucontext(ibcontext);
#line 715
  context = tmp;
#line 716
  tmp___0 = to_mdev(ibcontext->device);
#line 716
  dev = tmp___0;
#line 717
  uuari = & context->uuari;
#line 720
  i = 0;
#line 720
  goto ldv_37980;
  ldv_37979: 
#line 721
  tmp___2 = mlx5_cmd_free_uar(dev->mdev, (uuari->uars + (unsigned long )i)->index);
#line 721
  if (tmp___2 != 0) {
#line 722
    tmp___1 = get_current();
#line 722
    printk("\f%s:%s:%d:(pid %d): failed to free UAR 0x%x\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_dealloc_ucontext", 722, tmp___1->pid, (uuari->uars + (unsigned long )i)->index);
  } else {

  }
#line 720
  i = i + 1;
  ldv_37980: ;
#line 720
  if (uuari->num_uars > i) {
#line 722
    goto ldv_37979;
  } else {

  }
#line 725
  kfree((void const   *)uuari->count);
#line 726
  kfree((void const   *)uuari->bitmap);
#line 727
  kfree((void const   *)uuari->uars);
#line 728
  kfree((void const   *)context);
#line 730
  return (0);
}
}
#line 733 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static phys_addr_t uar_index2pfn(struct mlx5_ib_dev *dev , int index ) 
{ 


  {
#line 735
  return ((((dev->mdev)->pdev)->resource[0].start >> 12) + (resource_size_t )index);
}
}
#line 738 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int get_command(unsigned long offset ) 
{ 


  {
#line 740
  return ((int )(offset >> 8) & 255);
}
}
#line 743 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int get_arg(unsigned long offset ) 
{ 


  {
#line 745
  return ((int )offset & 255);
}
}
#line 748 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int get_index(unsigned long offset ) 
{ 
  int tmp ;

  {
#line 750
  tmp = get_arg(offset);
#line 750
  return (tmp);
}
}
#line 753 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_mmap(struct ib_ucontext *ibcontext , struct vm_area_struct *vma ) 
{ 
  struct mlx5_ib_ucontext *context ;
  struct mlx5_ib_ucontext *tmp ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp___0 ;
  struct mlx5_uuar_info *uuari ;
  unsigned long command ;
  unsigned long idx ;
  phys_addr_t pfn ;
  int tmp___1 ;
  int tmp___2 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  int tmp___5 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___6 ;
  long tmp___7 ;

  {
#line 755
  tmp = to_mucontext(ibcontext);
#line 755
  context = tmp;
#line 756
  tmp___0 = to_mdev(ibcontext->device);
#line 756
  dev = tmp___0;
#line 757
  uuari = & context->uuari;
#line 762
  tmp___1 = get_command(vma->vm_pgoff);
#line 762
  command = (unsigned long )tmp___1;
#line 763
  switch (command) {
  case 0UL: ;
#line 765
  if (vma->vm_end - vma->vm_start != 4096UL) {
#line 766
    return (-22);
  } else {

  }
#line 768
  tmp___2 = get_index(vma->vm_pgoff);
#line 768
  idx = (unsigned long )tmp___2;
#line 769
  if ((unsigned long )uuari->num_uars <= idx) {
#line 770
    return (-22);
  } else {

  }
#line 772
  pfn = uar_index2pfn(dev, (int )(uuari->uars + idx)->index);
#line 773
  descriptor.modname = "mlx5_ib";
#line 773
  descriptor.function = "mlx5_ib_mmap";
#line 773
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 773
  descriptor.format = "%s:%s:%d:(pid %d): uar idx 0x%lx, pfn 0x%llx\n";
#line 773
  descriptor.lineno = 774U;
#line 773
  descriptor.flags = 0U;
#line 773
  tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 773
  if (tmp___4 != 0L) {
#line 773
    tmp___3 = get_current();
#line 773
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): uar idx 0x%lx, pfn 0x%llx\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_mmap", 774, tmp___3->pid,
                       idx, pfn);
  } else {

  }
#line 776
  vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
#line 777
  tmp___5 = remap_pfn_range(vma, vma->vm_start, (unsigned long )pfn, 4096UL, vma->vm_page_prot);
#line 777
  if (tmp___5 != 0) {
#line 779
    return (-11);
  } else {

  }
#line 781
  descriptor___0.modname = "mlx5_ib";
#line 781
  descriptor___0.function = "mlx5_ib_mmap";
#line 781
  descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 781
  descriptor___0.format = "%s:%s:%d:(pid %d): mapped WC at 0x%lx, PA 0x%llx\n";
#line 781
  descriptor___0.lineno = 783U;
#line 781
  descriptor___0.flags = 0U;
#line 781
  tmp___7 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 781
  if (tmp___7 != 0L) {
#line 781
    tmp___6 = get_current();
#line 781
    __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): mapped WC at 0x%lx, PA 0x%llx\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_mmap", 783, tmp___6->pid,
                       vma->vm_start, pfn << 12);
  } else {

  }
#line 784
  goto ldv_38009;
  case 1UL: ;
#line 787
  return (-38);
  default: ;
#line 790
  return (-22);
  }
  ldv_38009: ;
#line 793
  return (0);
}
}
#line 796 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int alloc_pa_mkey(struct mlx5_ib_dev *dev , u32 *key , u32 pdn ) 
{ 
  struct mlx5_create_mkey_mbox_in *in ;
  struct mlx5_mkey_seg *seg ;
  struct mlx5_core_mr mr ;
  int err ;
  void *tmp ;
  __u32 tmp___0 ;
  struct task_struct *tmp___1 ;

  {
#line 803
  tmp = kzalloc(272UL, 208U);
#line 803
  in = (struct mlx5_create_mkey_mbox_in *)tmp;
#line 804
  if ((unsigned long )in == (unsigned long )((struct mlx5_create_mkey_mbox_in *)0)) {
#line 805
    return (-12);
  } else {

  }
#line 807
  seg = & in->seg;
#line 808
  seg->flags = 4U;
#line 809
  tmp___0 = __fswab32(pdn | 2147483648U);
#line 809
  seg->flags_pd = tmp___0;
#line 810
  seg->qpn_mkey7_0 = 16777215U;
#line 811
  seg->start_addr = 0ULL;
#line 813
  err = mlx5_core_create_mkey(dev->mdev, & mr, in, 272, (void (*)(int  , void * ))0,
                              (void *)0, (struct mlx5_create_mkey_mbox_out *)0);
#line 815
  if (err != 0) {
#line 816
    tmp___1 = get_current();
#line 816
    printk("\f%s:%s:%d:(pid %d): failed to create mkey, %d\n", (char *)(& dev->ib_dev.name),
           "alloc_pa_mkey", 816, tmp___1->pid, err);
#line 817
    goto err_in;
  } else {

  }
#line 820
  kfree((void const   *)in);
#line 821
  *key = mr.key;
#line 823
  return (0);
  err_in: 
#line 826
  kfree((void const   *)in);
#line 828
  return (err);
}
}
#line 831 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void free_pa_mkey(struct mlx5_ib_dev *dev , u32 key ) 
{ 
  struct mlx5_core_mr mr ;
  int err ;
  struct task_struct *tmp ;

  {
#line 836
  memset((void *)(& mr), 0, 24UL);
#line 837
  mr.key = key;
#line 838
  err = mlx5_core_destroy_mkey(dev->mdev, & mr);
#line 839
  if (err != 0) {
#line 840
    tmp = get_current();
#line 840
    printk("\f%s:%s:%d:(pid %d): failed to destroy mkey 0x%x\n", (char *)(& dev->ib_dev.name),
           "free_pa_mkey", 840, tmp->pid, key);
  } else {

  }
#line 841
  return;
}
}
#line 843 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct ib_pd *mlx5_ib_alloc_pd(struct ib_device *ibdev , struct ib_ucontext *context ,
                                      struct ib_udata *udata ) 
{ 
  struct mlx5_ib_alloc_pd_resp resp ;
  struct mlx5_ib_pd *pd ;
  int err ;
  void *tmp ;
  void *tmp___0 ;
  struct mlx5_ib_dev *tmp___1 ;
  void *tmp___2 ;
  struct mlx5_ib_dev *tmp___3 ;
  void *tmp___4 ;
  int tmp___5 ;
  struct mlx5_ib_dev *tmp___6 ;
  struct mlx5_ib_dev *tmp___7 ;
  void *tmp___8 ;

  {
#line 851
  tmp = kmalloc(32UL, 208U);
#line 851
  pd = (struct mlx5_ib_pd *)tmp;
#line 852
  if ((unsigned long )pd == (unsigned long )((struct mlx5_ib_pd *)0)) {
#line 853
    tmp___0 = ERR_PTR(-12L);
#line 853
    return ((struct ib_pd *)tmp___0);
  } else {

  }
#line 855
  tmp___1 = to_mdev(ibdev);
#line 855
  err = mlx5_core_alloc_pd(tmp___1->mdev, & pd->pdn);
#line 856
  if (err != 0) {
#line 857
    kfree((void const   *)pd);
#line 858
    tmp___2 = ERR_PTR((long )err);
#line 858
    return ((struct ib_pd *)tmp___2);
  } else {

  }
#line 861
  if ((unsigned long )context != (unsigned long )((struct ib_ucontext *)0)) {
#line 862
    resp.pdn = pd->pdn;
#line 863
    tmp___5 = ib_copy_to_udata(udata, (void *)(& resp), 4UL);
#line 863
    if (tmp___5 != 0) {
#line 864
      tmp___3 = to_mdev(ibdev);
#line 864
      mlx5_core_dealloc_pd(tmp___3->mdev, pd->pdn);
#line 865
      kfree((void const   *)pd);
#line 866
      tmp___4 = ERR_PTR(-14L);
#line 866
      return ((struct ib_pd *)tmp___4);
    } else {

    }
  } else {
#line 869
    tmp___6 = to_mdev(ibdev);
#line 869
    err = alloc_pa_mkey(tmp___6, & pd->pa_lkey, pd->pdn);
#line 870
    if (err != 0) {
#line 871
      tmp___7 = to_mdev(ibdev);
#line 871
      mlx5_core_dealloc_pd(tmp___7->mdev, pd->pdn);
#line 872
      kfree((void const   *)pd);
#line 873
      tmp___8 = ERR_PTR((long )err);
#line 873
      return ((struct ib_pd *)tmp___8);
    } else {

    }
  }
#line 877
  return (& pd->ibpd);
}
}
#line 880 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_dealloc_pd(struct ib_pd *pd ) 
{ 
  struct mlx5_ib_dev *mdev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_pd *mpd ;
  struct mlx5_ib_pd *tmp___0 ;

  {
#line 882
  tmp = to_mdev(pd->device);
#line 882
  mdev = tmp;
#line 883
  tmp___0 = to_mpd(pd);
#line 883
  mpd = tmp___0;
#line 885
  if ((unsigned long )pd->uobject == (unsigned long )((struct ib_uobject *)0)) {
#line 886
    free_pa_mkey(mdev, mpd->pa_lkey);
  } else {

  }
#line 888
  mlx5_core_dealloc_pd(mdev->mdev, mpd->pdn);
#line 889
  kfree((void const   *)mpd);
#line 891
  return (0);
}
}
#line 894 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_mcg_attach(struct ib_qp *ibqp , union ib_gid *gid , u16 lid ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int err ;
  struct task_struct *tmp___0 ;

  {
#line 896
  tmp = to_mdev(ibqp->device);
#line 896
  dev = tmp;
#line 899
  err = mlx5_core_attach_mcg(dev->mdev, gid, ibqp->qp_num);
#line 900
  if (err != 0) {
#line 901
    tmp___0 = get_current();
#line 901
    printk("\f%s:%s:%d:(pid %d): failed attaching QPN 0x%x, MGID %pI6\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_mcg_attach", 902, tmp___0->pid, ibqp->qp_num, (u8 *)(& gid->raw));
  } else {

  }
#line 904
  return (err);
}
}
#line 907 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_mcg_detach(struct ib_qp *ibqp , union ib_gid *gid , u16 lid ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int err ;
  struct task_struct *tmp___0 ;

  {
#line 909
  tmp = to_mdev(ibqp->device);
#line 909
  dev = tmp;
#line 912
  err = mlx5_core_detach_mcg(dev->mdev, gid, ibqp->qp_num);
#line 913
  if (err != 0) {
#line 914
    tmp___0 = get_current();
#line 914
    printk("\f%s:%s:%d:(pid %d): failed detaching QPN 0x%x, MGID %pI6\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_mcg_detach", 915, tmp___0->pid, ibqp->qp_num, (u8 *)(& gid->raw));
  } else {

  }
#line 917
  return (err);
}
}
#line 920 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int init_node_data(struct mlx5_ib_dev *dev ) 
{ 
  int err ;
  int tmp ;

  {
#line 924
  err = mlx5_query_node_desc(dev, (char *)(& dev->ib_dev.node_desc));
#line 925
  if (err != 0) {
#line 926
    return (err);
  } else {

  }
#line 928
  (dev->mdev)->rev_id = ((dev->mdev)->pdev)->revision;
#line 930
  tmp = mlx5_query_node_guid(dev, & dev->ib_dev.node_guid);
#line 930
  return (tmp);
}
}
#line 933 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static ssize_t show_fw_pages(struct device *device , struct device_attribute *attr ,
                             char *buf ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device  const  *__mptr ;
  int tmp ;

  {
#line 937
  __mptr = (struct device  const  *)device;
#line 937
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffffc58UL;
#line 939
  tmp = sprintf(buf, "%d\n", (dev->mdev)->priv.fw_pages);
#line 939
  return ((ssize_t )tmp);
}
}
#line 942 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static ssize_t show_reg_pages(struct device *device , struct device_attribute *attr ,
                              char *buf ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device  const  *__mptr ;
  int tmp ;
  int tmp___0 ;

  {
#line 946
  __mptr = (struct device  const  *)device;
#line 946
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffffc58UL;
#line 948
  tmp = atomic_read((atomic_t const   *)(& (dev->mdev)->priv.reg_pages));
#line 948
  tmp___0 = sprintf(buf, "%d\n", tmp);
#line 948
  return ((ssize_t )tmp___0);
}
}
#line 951 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static ssize_t show_hca(struct device *device , struct device_attribute *attr , char *buf ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device  const  *__mptr ;
  int tmp ;

  {
#line 955
  __mptr = (struct device  const  *)device;
#line 955
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffffc58UL;
#line 956
  tmp = sprintf(buf, "MT%d\n", (int )((dev->mdev)->pdev)->device);
#line 956
  return ((ssize_t )tmp);
}
}
#line 959 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static ssize_t show_fw_ver(struct device *device , struct device_attribute *attr ,
                           char *buf ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device  const  *__mptr ;
  u16 tmp ;
  u16 tmp___0 ;
  u16 tmp___1 ;
  int tmp___2 ;

  {
#line 963
  __mptr = (struct device  const  *)device;
#line 963
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffffc58UL;
#line 964
  tmp = fw_rev_sub(dev->mdev);
#line 964
  tmp___0 = fw_rev_min(dev->mdev);
#line 964
  tmp___1 = fw_rev_maj(dev->mdev);
#line 964
  tmp___2 = sprintf(buf, "%d.%d.%d\n", (int )tmp___1, (int )tmp___0, (int )tmp);
#line 964
  return ((ssize_t )tmp___2);
}
}
#line 968 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static ssize_t show_rev(struct device *device , struct device_attribute *attr , char *buf ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device  const  *__mptr ;
  int tmp ;

  {
#line 972
  __mptr = (struct device  const  *)device;
#line 972
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffffc58UL;
#line 973
  tmp = sprintf(buf, "%x\n", (int )(dev->mdev)->rev_id);
#line 973
  return ((ssize_t )tmp);
}
}
#line 976 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static ssize_t show_board(struct device *device , struct device_attribute *attr ,
                          char *buf ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device  const  *__mptr ;
  int tmp ;

  {
#line 980
  __mptr = (struct device  const  *)device;
#line 980
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffffc58UL;
#line 981
  tmp = sprintf(buf, "%.*s\n", 64, (char *)(& (dev->mdev)->board_id));
#line 981
  return ((ssize_t )tmp);
}
}
#line 985 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute dev_attr_hw_rev  =    {{"hw_rev", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0}, {(char)0},
                                    {(char)0}, {(char)0}, {(char)0}}}}, & show_rev,
    (ssize_t (*)(struct device * , struct device_attribute * , char const   * , size_t  ))0};
#line 986 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute dev_attr_fw_ver  =    {{"fw_ver", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0}, {(char)0},
                                    {(char)0}, {(char)0}, {(char)0}}}}, & show_fw_ver,
    (ssize_t (*)(struct device * , struct device_attribute * , char const   * , size_t  ))0};
#line 987 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute dev_attr_hca_type  =    {{"hca_type", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                      {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_hca, (ssize_t (*)(struct device * , struct device_attribute * , char const   * ,
                             size_t  ))0};
#line 988 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute dev_attr_board_id  =    {{"board_id", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                      {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_board, (ssize_t (*)(struct device * , struct device_attribute * , char const   * ,
                               size_t  ))0};
#line 989 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute dev_attr_fw_pages  =    {{"fw_pages", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                      {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_fw_pages, (ssize_t (*)(struct device * , struct device_attribute * , char const   * ,
                                  size_t  ))0};
#line 990 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute dev_attr_reg_pages  =    {{"reg_pages", 292U, (_Bool)0, 0, {{{(char)0}, {(char)0}, {(char)0}, {(char)0},
                                       {(char)0}, {(char)0}, {(char)0}, {(char)0}}}},
    & show_reg_pages, (ssize_t (*)(struct device * , struct device_attribute * , char const   * ,
                                   size_t  ))0};
#line 992 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct device_attribute *mlx5_class_attributes[6U]  = {      & dev_attr_hw_rev,      & dev_attr_fw_ver,      & dev_attr_hca_type,      & dev_attr_board_id, 
        & dev_attr_fw_pages,      & dev_attr_reg_pages};
#line 1001 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void mlx5_ib_event(struct mlx5_core_dev *dev , void *context , enum mlx5_dev_event event ,
                          unsigned long param ) 
{ 
  struct mlx5_ib_dev *ibdev ;
  struct ib_event ibev ;
  u8 port ;
  struct task_struct *tmp ;

  {
#line 1004
  ibdev = (struct mlx5_ib_dev *)context;
#line 1007
  port = 0U;
#line 1009
  switch ((unsigned int )event) {
  case 0U: 
#line 1011
  ibdev->ib_active = 0;
#line 1012
  ibev.event = 8;
#line 1013
  goto ldv_38200;
  case 1U: 
#line 1016
  ibev.event = 9;
#line 1017
  port = (unsigned char )param;
#line 1018
  goto ldv_38200;
  case 2U: 
#line 1021
  ibev.event = 10;
#line 1022
  port = (unsigned char )param;
#line 1023
  goto ldv_38200;
  case 3U: ;
#line 1027
  return;
  case 4U: 
#line 1030
  ibev.event = 11;
#line 1031
  port = (unsigned char )param;
#line 1032
  goto ldv_38200;
  case 5U: 
#line 1035
  ibev.event = 12;
#line 1036
  port = (unsigned char )param;
#line 1037
  goto ldv_38200;
  case 6U: 
#line 1040
  ibev.event = 18;
#line 1041
  port = (unsigned char )param;
#line 1042
  goto ldv_38200;
  case 7U: 
#line 1045
  ibev.event = 17;
#line 1046
  port = (unsigned char )param;
#line 1047
  goto ldv_38200;
  }
  ldv_38200: 
#line 1050
  ibev.device = & ibdev->ib_dev;
#line 1051
  ibev.element.port_num = port;
#line 1053
  if ((unsigned int )port == 0U || (int )port > ibdev->num_ports) {
#line 1054
    tmp = get_current();
#line 1054
    printk("\f%s:%s:%d:(pid %d): warning: event on port %d\n", (char *)(& ibdev->ib_dev.name),
           "mlx5_ib_event", 1054, tmp->pid, (int )port);
#line 1055
    return;
  } else {

  }
#line 1058
  if ((int )ibdev->ib_active) {
#line 1059
    ib_dispatch_event(& ibev);
  } else {

  }
#line 1060
  return;
}
}
#line 1062 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void get_ext_port_caps(struct mlx5_ib_dev *dev ) 
{ 
  int port ;
  __u32 tmp ;

  {
#line 1066
  port = 1;
#line 1066
  goto ldv_38214;
  ldv_38213: 
#line 1067
  mlx5_query_ext_port_caps(dev, (int )((u8 )port));
#line 1066
  port = port + 1;
  ldv_38214: 
#line 1066
  tmp = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 13UL));
#line 1066
  if ((unsigned int )port <= (tmp & 255U)) {
#line 1068
    goto ldv_38213;
  } else {

  }

#line 1073
  return;
}
}
#line 1070 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int get_port_caps(struct mlx5_ib_dev *dev ) 
{ 
  struct ib_device_attr *dprops ;
  struct ib_port_attr *pprops ;
  int err ;
  int port ;
  struct ib_udata uhw ;
  void *tmp ;
  void *tmp___0 ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  __u32 tmp___5 ;

  {
#line 1072
  dprops = (struct ib_device_attr *)0;
#line 1073
  pprops = (struct ib_port_attr *)0;
#line 1074
  err = -12;
#line 1076
  uhw.inbuf = 0;
#line 1076
  uhw.outbuf = 0;
#line 1076
  uhw.inlen = 0UL;
#line 1076
  uhw.outlen = 0UL;
#line 1078
  tmp = kmalloc(48UL, 208U);
#line 1078
  pprops = (struct ib_port_attr *)tmp;
#line 1079
  if ((unsigned long )pprops == (unsigned long )((struct ib_port_attr *)0)) {
#line 1080
    goto out;
  } else {

  }
#line 1082
  tmp___0 = kmalloc(224UL, 208U);
#line 1082
  dprops = (struct ib_device_attr *)tmp___0;
#line 1083
  if ((unsigned long )dprops == (unsigned long )((struct ib_device_attr *)0)) {
#line 1084
    goto out;
  } else {

  }
#line 1086
  err = mlx5_ib_query_device(& dev->ib_dev, dprops, & uhw);
#line 1087
  if (err != 0) {
#line 1088
    tmp___1 = get_current();
#line 1088
    printk("\f%s:%s:%d:(pid %d): query_device failed %d\n", (char *)(& dev->ib_dev.name),
           "get_port_caps", 1088, tmp___1->pid, err);
#line 1089
    goto out;
  } else {

  }
#line 1092
  port = 1;
#line 1092
  goto ldv_38229;
  ldv_38228: 
#line 1093
  err = mlx5_ib_query_port(& dev->ib_dev, (int )((u8 )port), pprops);
#line 1094
  if (err != 0) {
#line 1095
    tmp___2 = get_current();
#line 1095
    printk("\f%s:%s:%d:(pid %d): query_port %d failed %d\n", (char *)(& dev->ib_dev.name),
           "get_port_caps", 1096, tmp___2->pid, port, err);
#line 1097
    goto ldv_38226;
  } else {

  }
#line 1099
  (dev->mdev)->port_caps[port + -1].pkey_table_len = (int )dprops->max_pkeys;
#line 1101
  (dev->mdev)->port_caps[port + -1].gid_table_len = pprops->gid_tbl_len;
#line 1103
  descriptor.modname = "mlx5_ib";
#line 1103
  descriptor.function = "get_port_caps";
#line 1103
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1103
  descriptor.format = "%s:%s:%d:(pid %d): pkey_table_len %d, gid_table_len %d\n";
#line 1103
  descriptor.lineno = 1104U;
#line 1103
  descriptor.flags = 0U;
#line 1103
  tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1103
  if (tmp___4 != 0L) {
#line 1103
    tmp___3 = get_current();
#line 1103
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): pkey_table_len %d, gid_table_len %d\n",
                       (char *)(& dev->ib_dev.name), "get_port_caps", 1104, tmp___3->pid,
                       (int )dprops->max_pkeys, pprops->gid_tbl_len);
  } else {

  }
#line 1092
  port = port + 1;
  ldv_38229: 
#line 1092
  tmp___5 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 13UL));
#line 1092
  if ((unsigned int )port <= (tmp___5 & 255U)) {
#line 1094
    goto ldv_38228;
  } else {

  }
  ldv_38226: ;
  out: 
#line 1108
  kfree((void const   *)pprops);
#line 1109
  kfree((void const   *)dprops);
#line 1111
  return (err);
}
}
#line 1114 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void destroy_umrc_res(struct mlx5_ib_dev *dev ) 
{ 
  int err ;
  struct task_struct *tmp ;

  {
#line 1118
  err = mlx5_mr_cache_cleanup(dev);
#line 1119
  if (err != 0) {
#line 1120
    tmp = get_current();
#line 1120
    printk("\f%s:%s:%d:(pid %d): mr cache cleanup failed\n", (char *)(& dev->ib_dev.name),
           "destroy_umrc_res", 1120, tmp->pid);
  } else {

  }
#line 1122
  mlx5_ib_destroy_qp(dev->umrc.qp);
#line 1123
  ib_destroy_cq(dev->umrc.cq);
#line 1124
  ib_dereg_mr(dev->umrc.mr);
#line 1125
  ib_dealloc_pd(dev->umrc.pd);
#line 1126
  return;
}
}
#line 1132 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int create_umr_res(struct mlx5_ib_dev *dev ) 
{ 
  struct ib_qp_init_attr *init_attr ;
  struct ib_qp_attr *attr ;
  struct ib_pd *pd ;
  struct ib_cq *cq ;
  struct ib_qp *qp ;
  struct ib_mr *mr ;
  struct ib_cq_init_attr cq_attr ;
  int ret ;
  void *tmp ;
  void *tmp___0 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___1 ;
  long tmp___2 ;
  long tmp___3 ;
  bool tmp___4 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___5 ;
  long tmp___6 ;
  long tmp___7 ;
  bool tmp___8 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___9 ;
  long tmp___10 ;
  long tmp___11 ;
  bool tmp___12 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___13 ;
  long tmp___14 ;
  long tmp___15 ;
  bool tmp___16 ;
  struct _ddebug descriptor___3 ;
  struct task_struct *tmp___17 ;
  long tmp___18 ;
  struct _ddebug descriptor___4 ;
  struct task_struct *tmp___19 ;
  long tmp___20 ;
  struct _ddebug descriptor___5 ;
  struct task_struct *tmp___21 ;
  long tmp___22 ;
  struct task_struct *tmp___23 ;

  {
#line 1134
  init_attr = (struct ib_qp_init_attr *)0;
#line 1135
  attr = (struct ib_qp_attr *)0;
#line 1140
  cq_attr.cqe = 0U;
#line 1140
  cq_attr.comp_vector = 0;
#line 1140
  cq_attr.flags = 0U;
#line 1143
  tmp = kzalloc(168UL, 208U);
#line 1143
  attr = (struct ib_qp_attr *)tmp;
#line 1144
  tmp___0 = kzalloc(88UL, 208U);
#line 1144
  init_attr = (struct ib_qp_init_attr *)tmp___0;
#line 1145
  if ((unsigned long )attr == (unsigned long )((struct ib_qp_attr *)0) || (unsigned long )init_attr == (unsigned long )((struct ib_qp_init_attr *)0)) {
#line 1146
    ret = -12;
#line 1147
    goto error_0;
  } else {

  }
#line 1150
  pd = ib_alloc_pd(& dev->ib_dev);
#line 1151
  tmp___4 = IS_ERR((void const   *)pd);
#line 1151
  if ((int )tmp___4) {
#line 1152
    descriptor.modname = "mlx5_ib";
#line 1152
    descriptor.function = "create_umr_res";
#line 1152
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1152
    descriptor.format = "%s:%s:%d:(pid %d): Couldn\'t create PD for sync UMR QP\n";
#line 1152
    descriptor.lineno = 1152U;
#line 1152
    descriptor.flags = 0U;
#line 1152
    tmp___2 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1152
    if (tmp___2 != 0L) {
#line 1152
      tmp___1 = get_current();
#line 1152
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): Couldn\'t create PD for sync UMR QP\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1152, tmp___1->pid);
    } else {

    }
#line 1153
    tmp___3 = PTR_ERR((void const   *)pd);
#line 1153
    ret = (int )tmp___3;
#line 1154
    goto error_0;
  } else {

  }
#line 1157
  mr = ib_get_dma_mr(pd, 1);
#line 1158
  tmp___8 = IS_ERR((void const   *)mr);
#line 1158
  if ((int )tmp___8) {
#line 1159
    descriptor___0.modname = "mlx5_ib";
#line 1159
    descriptor___0.function = "create_umr_res";
#line 1159
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1159
    descriptor___0.format = "%s:%s:%d:(pid %d): Couldn\'t create DMA MR for sync UMR QP\n";
#line 1159
    descriptor___0.lineno = 1159U;
#line 1159
    descriptor___0.flags = 0U;
#line 1159
    tmp___6 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 1159
    if (tmp___6 != 0L) {
#line 1159
      tmp___5 = get_current();
#line 1159
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): Couldn\'t create DMA MR for sync UMR QP\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1159, tmp___5->pid);
    } else {

    }
#line 1160
    tmp___7 = PTR_ERR((void const   *)mr);
#line 1160
    ret = (int )tmp___7;
#line 1161
    goto error_1;
  } else {

  }
#line 1164
  cq_attr.cqe = 128U;
#line 1165
  cq = ib_create_cq(& dev->ib_dev, & mlx5_umr_cq_handler, (void (*)(struct ib_event * ,
                                                                    void * ))0, (void *)0,
                    (struct ib_cq_init_attr  const  *)(& cq_attr));
#line 1167
  tmp___12 = IS_ERR((void const   *)cq);
#line 1167
  if ((int )tmp___12) {
#line 1168
    descriptor___1.modname = "mlx5_ib";
#line 1168
    descriptor___1.function = "create_umr_res";
#line 1168
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1168
    descriptor___1.format = "%s:%s:%d:(pid %d): Couldn\'t create CQ for sync UMR QP\n";
#line 1168
    descriptor___1.lineno = 1168U;
#line 1168
    descriptor___1.flags = 0U;
#line 1168
    tmp___10 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 1168
    if (tmp___10 != 0L) {
#line 1168
      tmp___9 = get_current();
#line 1168
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): Couldn\'t create CQ for sync UMR QP\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1168, tmp___9->pid);
    } else {

    }
#line 1169
    tmp___11 = PTR_ERR((void const   *)cq);
#line 1169
    ret = (int )tmp___11;
#line 1170
    goto error_2;
  } else {

  }
#line 1172
  ib_req_notify_cq(cq, 2);
#line 1174
  init_attr->send_cq = cq;
#line 1175
  init_attr->recv_cq = cq;
#line 1176
  init_attr->sq_sig_type = 0;
#line 1177
  init_attr->cap.max_send_wr = 128U;
#line 1178
  init_attr->cap.max_send_sge = 1U;
#line 1179
  init_attr->qp_type = 4096;
#line 1180
  init_attr->port_num = 1U;
#line 1181
  qp = mlx5_ib_create_qp(pd, init_attr, (struct ib_udata *)0);
#line 1182
  tmp___16 = IS_ERR((void const   *)qp);
#line 1182
  if ((int )tmp___16) {
#line 1183
    descriptor___2.modname = "mlx5_ib";
#line 1183
    descriptor___2.function = "create_umr_res";
#line 1183
    descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1183
    descriptor___2.format = "%s:%s:%d:(pid %d): Couldn\'t create sync UMR QP\n";
#line 1183
    descriptor___2.lineno = 1183U;
#line 1183
    descriptor___2.flags = 0U;
#line 1183
    tmp___14 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 1183
    if (tmp___14 != 0L) {
#line 1183
      tmp___13 = get_current();
#line 1183
      __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): Couldn\'t create sync UMR QP\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1183, tmp___13->pid);
    } else {

    }
#line 1184
    tmp___15 = PTR_ERR((void const   *)qp);
#line 1184
    ret = (int )tmp___15;
#line 1185
    goto error_3;
  } else {

  }
#line 1187
  qp->device = & dev->ib_dev;
#line 1188
  qp->real_qp = qp;
#line 1189
  qp->uobject = (struct ib_uobject *)0;
#line 1190
  qp->qp_type = 4096;
#line 1192
  attr->qp_state = 1;
#line 1193
  attr->port_num = 1U;
#line 1194
  ret = mlx5_ib_modify_qp(qp, attr, 49, (struct ib_udata *)0);
#line 1196
  if (ret != 0) {
#line 1197
    descriptor___3.modname = "mlx5_ib";
#line 1197
    descriptor___3.function = "create_umr_res";
#line 1197
    descriptor___3.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1197
    descriptor___3.format = "%s:%s:%d:(pid %d): Couldn\'t modify UMR QP\n";
#line 1197
    descriptor___3.lineno = 1197U;
#line 1197
    descriptor___3.flags = 0U;
#line 1197
    tmp___18 = ldv__builtin_expect((long )descriptor___3.flags & 1L, 0L);
#line 1197
    if (tmp___18 != 0L) {
#line 1197
      tmp___17 = get_current();
#line 1197
      __dynamic_pr_debug(& descriptor___3, "%s:%s:%d:(pid %d): Couldn\'t modify UMR QP\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1197, tmp___17->pid);
    } else {

    }
#line 1198
    goto error_4;
  } else {

  }
#line 1201
  memset((void *)attr, 0, 168UL);
#line 1202
  attr->qp_state = 2;
#line 1203
  attr->path_mtu = 1;
#line 1205
  ret = mlx5_ib_modify_qp(qp, attr, 1, (struct ib_udata *)0);
#line 1206
  if (ret != 0) {
#line 1207
    descriptor___4.modname = "mlx5_ib";
#line 1207
    descriptor___4.function = "create_umr_res";
#line 1207
    descriptor___4.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1207
    descriptor___4.format = "%s:%s:%d:(pid %d): Couldn\'t modify umr QP to rtr\n";
#line 1207
    descriptor___4.lineno = 1207U;
#line 1207
    descriptor___4.flags = 0U;
#line 1207
    tmp___20 = ldv__builtin_expect((long )descriptor___4.flags & 1L, 0L);
#line 1207
    if (tmp___20 != 0L) {
#line 1207
      tmp___19 = get_current();
#line 1207
      __dynamic_pr_debug(& descriptor___4, "%s:%s:%d:(pid %d): Couldn\'t modify umr QP to rtr\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1207, tmp___19->pid);
    } else {

    }
#line 1208
    goto error_4;
  } else {

  }
#line 1211
  memset((void *)attr, 0, 168UL);
#line 1212
  attr->qp_state = 3;
#line 1213
  ret = mlx5_ib_modify_qp(qp, attr, 1, (struct ib_udata *)0);
#line 1214
  if (ret != 0) {
#line 1215
    descriptor___5.modname = "mlx5_ib";
#line 1215
    descriptor___5.function = "create_umr_res";
#line 1215
    descriptor___5.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c";
#line 1215
    descriptor___5.format = "%s:%s:%d:(pid %d): Couldn\'t modify umr QP to rts\n";
#line 1215
    descriptor___5.lineno = 1215U;
#line 1215
    descriptor___5.flags = 0U;
#line 1215
    tmp___22 = ldv__builtin_expect((long )descriptor___5.flags & 1L, 0L);
#line 1215
    if (tmp___22 != 0L) {
#line 1215
      tmp___21 = get_current();
#line 1215
      __dynamic_pr_debug(& descriptor___5, "%s:%s:%d:(pid %d): Couldn\'t modify umr QP to rts\n",
                         (char *)(& dev->ib_dev.name), "create_umr_res", 1215, tmp___21->pid);
    } else {

    }
#line 1216
    goto error_4;
  } else {

  }
#line 1219
  dev->umrc.qp = qp;
#line 1220
  dev->umrc.cq = cq;
#line 1221
  dev->umrc.mr = mr;
#line 1222
  dev->umrc.pd = pd;
#line 1224
  sema_init(& dev->umrc.sem, 128);
#line 1225
  ret = mlx5_mr_cache_init(dev);
#line 1226
  if (ret != 0) {
#line 1227
    tmp___23 = get_current();
#line 1227
    printk("\f%s:%s:%d:(pid %d): mr cache init failed %d\n", (char *)(& dev->ib_dev.name),
           "create_umr_res", 1227, tmp___23->pid, ret);
#line 1228
    goto error_4;
  } else {

  }
#line 1231
  kfree((void const   *)attr);
#line 1232
  kfree((void const   *)init_attr);
#line 1234
  return (0);
  error_4: 
#line 1237
  mlx5_ib_destroy_qp(qp);
  error_3: 
#line 1240
  ib_destroy_cq(cq);
  error_2: 
#line 1243
  ib_dereg_mr(mr);
  error_1: 
#line 1246
  ib_dealloc_pd(pd);
  error_0: 
#line 1249
  kfree((void const   *)attr);
#line 1250
  kfree((void const   *)init_attr);
#line 1251
  return (ret);
}
}
#line 1254 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int create_dev_resources(struct mlx5_ib_resources *devr ) 
{ 
  struct ib_srq_init_attr attr ;
  struct mlx5_ib_dev *dev ;
  struct ib_cq_init_attr cq_attr ;
  int ret ;
  struct mlx5_ib_resources  const  *__mptr ;
  long tmp ;
  bool tmp___0 ;
  long tmp___1 ;
  bool tmp___2 ;
  long tmp___3 ;
  bool tmp___4 ;
  struct lock_class_key __key ;
  long tmp___5 ;
  bool tmp___6 ;
  struct lock_class_key __key___0 ;
  long tmp___7 ;
  bool tmp___8 ;
  long tmp___9 ;
  bool tmp___10 ;

  {
#line 1258
  cq_attr.cqe = 1U;
#line 1258
  cq_attr.comp_vector = 0;
#line 1258
  cq_attr.flags = 0U;
#line 1259
  ret = 0;
#line 1261
  __mptr = (struct mlx5_ib_resources  const  *)devr;
#line 1261
  dev = (struct mlx5_ib_dev *)__mptr + 0xfffffffffffff510UL;
#line 1263
  devr->p0 = mlx5_ib_alloc_pd(& dev->ib_dev, (struct ib_ucontext *)0, (struct ib_udata *)0);
#line 1264
  tmp___0 = IS_ERR((void const   *)devr->p0);
#line 1264
  if ((int )tmp___0) {
#line 1265
    tmp = PTR_ERR((void const   *)devr->p0);
#line 1265
    ret = (int )tmp;
#line 1266
    goto error0;
  } else {

  }
#line 1268
  (devr->p0)->device = & dev->ib_dev;
#line 1269
  (devr->p0)->uobject = (struct ib_uobject *)0;
#line 1270
  atomic_set(& (devr->p0)->usecnt, 0);
#line 1272
  devr->c0 = mlx5_ib_create_cq(& dev->ib_dev, (struct ib_cq_init_attr  const  *)(& cq_attr),
                               (struct ib_ucontext *)0, (struct ib_udata *)0);
#line 1273
  tmp___2 = IS_ERR((void const   *)devr->c0);
#line 1273
  if ((int )tmp___2) {
#line 1274
    tmp___1 = PTR_ERR((void const   *)devr->c0);
#line 1274
    ret = (int )tmp___1;
#line 1275
    goto error1;
  } else {

  }
#line 1277
  (devr->c0)->device = & dev->ib_dev;
#line 1278
  (devr->c0)->uobject = (struct ib_uobject *)0;
#line 1279
  (devr->c0)->comp_handler = (void (*)(struct ib_cq * , void * ))0;
#line 1280
  (devr->c0)->event_handler = (void (*)(struct ib_event * , void * ))0;
#line 1281
  (devr->c0)->cq_context = (void *)0;
#line 1282
  atomic_set(& (devr->c0)->usecnt, 0);
#line 1284
  devr->x0 = mlx5_ib_alloc_xrcd(& dev->ib_dev, (struct ib_ucontext *)0, (struct ib_udata *)0);
#line 1285
  tmp___4 = IS_ERR((void const   *)devr->x0);
#line 1285
  if ((int )tmp___4) {
#line 1286
    tmp___3 = PTR_ERR((void const   *)devr->x0);
#line 1286
    ret = (int )tmp___3;
#line 1287
    goto error2;
  } else {

  }
#line 1289
  (devr->x0)->device = & dev->ib_dev;
#line 1290
  (devr->x0)->inode = (struct inode *)0;
#line 1291
  atomic_set(& (devr->x0)->usecnt, 0);
#line 1292
  __mutex_init(& (devr->x0)->tgt_qp_mutex, "&devr->x0->tgt_qp_mutex", & __key);
#line 1293
  INIT_LIST_HEAD(& (devr->x0)->tgt_qp_list);
#line 1295
  devr->x1 = mlx5_ib_alloc_xrcd(& dev->ib_dev, (struct ib_ucontext *)0, (struct ib_udata *)0);
#line 1296
  tmp___6 = IS_ERR((void const   *)devr->x1);
#line 1296
  if ((int )tmp___6) {
#line 1297
    tmp___5 = PTR_ERR((void const   *)devr->x1);
#line 1297
    ret = (int )tmp___5;
#line 1298
    goto error3;
  } else {

  }
#line 1300
  (devr->x1)->device = & dev->ib_dev;
#line 1301
  (devr->x1)->inode = (struct inode *)0;
#line 1302
  atomic_set(& (devr->x1)->usecnt, 0);
#line 1303
  __mutex_init(& (devr->x1)->tgt_qp_mutex, "&devr->x1->tgt_qp_mutex", & __key___0);
#line 1304
  INIT_LIST_HEAD(& (devr->x1)->tgt_qp_list);
#line 1306
  memset((void *)(& attr), 0, 48UL);
#line 1307
  attr.attr.max_sge = 1U;
#line 1308
  attr.attr.max_wr = 1U;
#line 1309
  attr.srq_type = 1;
#line 1310
  attr.ext.xrc.cq = devr->c0;
#line 1311
  attr.ext.xrc.xrcd = devr->x0;
#line 1313
  devr->s0 = mlx5_ib_create_srq(devr->p0, & attr, (struct ib_udata *)0);
#line 1314
  tmp___8 = IS_ERR((void const   *)devr->s0);
#line 1314
  if ((int )tmp___8) {
#line 1315
    tmp___7 = PTR_ERR((void const   *)devr->s0);
#line 1315
    ret = (int )tmp___7;
#line 1316
    goto error4;
  } else {

  }
#line 1318
  (devr->s0)->device = & dev->ib_dev;
#line 1319
  (devr->s0)->pd = devr->p0;
#line 1320
  (devr->s0)->uobject = (struct ib_uobject *)0;
#line 1321
  (devr->s0)->event_handler = (void (*)(struct ib_event * , void * ))0;
#line 1322
  (devr->s0)->srq_context = (void *)0;
#line 1323
  (devr->s0)->srq_type = 1;
#line 1324
  (devr->s0)->ext.xrc.xrcd = devr->x0;
#line 1325
  (devr->s0)->ext.xrc.cq = devr->c0;
#line 1326
  atomic_inc(& ((devr->s0)->ext.xrc.xrcd)->usecnt);
#line 1327
  atomic_inc(& ((devr->s0)->ext.xrc.cq)->usecnt);
#line 1328
  atomic_inc(& (devr->p0)->usecnt);
#line 1329
  atomic_set(& (devr->s0)->usecnt, 0);
#line 1331
  memset((void *)(& attr), 0, 48UL);
#line 1332
  attr.attr.max_sge = 1U;
#line 1333
  attr.attr.max_wr = 1U;
#line 1334
  attr.srq_type = 0;
#line 1335
  devr->s1 = mlx5_ib_create_srq(devr->p0, & attr, (struct ib_udata *)0);
#line 1336
  tmp___10 = IS_ERR((void const   *)devr->s1);
#line 1336
  if ((int )tmp___10) {
#line 1337
    tmp___9 = PTR_ERR((void const   *)devr->s1);
#line 1337
    ret = (int )tmp___9;
#line 1338
    goto error5;
  } else {

  }
#line 1340
  (devr->s1)->device = & dev->ib_dev;
#line 1341
  (devr->s1)->pd = devr->p0;
#line 1342
  (devr->s1)->uobject = (struct ib_uobject *)0;
#line 1343
  (devr->s1)->event_handler = (void (*)(struct ib_event * , void * ))0;
#line 1344
  (devr->s1)->srq_context = (void *)0;
#line 1345
  (devr->s1)->srq_type = 0;
#line 1346
  (devr->s1)->ext.xrc.cq = devr->c0;
#line 1347
  atomic_inc(& (devr->p0)->usecnt);
#line 1348
  atomic_set(& (devr->s0)->usecnt, 0);
#line 1350
  return (0);
  error5: 
#line 1353
  mlx5_ib_destroy_srq(devr->s0);
  error4: 
#line 1355
  mlx5_ib_dealloc_xrcd(devr->x1);
  error3: 
#line 1357
  mlx5_ib_dealloc_xrcd(devr->x0);
  error2: 
#line 1359
  mlx5_ib_destroy_cq(devr->c0);
  error1: 
#line 1361
  mlx5_ib_dealloc_pd(devr->p0);
  error0: ;
#line 1363
  return (ret);
}
}
#line 1366 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void destroy_dev_resources(struct mlx5_ib_resources *devr ) 
{ 


  {
#line 1368
  mlx5_ib_destroy_srq(devr->s1);
#line 1369
  mlx5_ib_destroy_srq(devr->s0);
#line 1370
  mlx5_ib_dealloc_xrcd(devr->x0);
#line 1371
  mlx5_ib_dealloc_xrcd(devr->x1);
#line 1372
  mlx5_ib_destroy_cq(devr->c0);
#line 1373
  mlx5_ib_dealloc_pd(devr->p0);
#line 1374
  return;
}
}
#line 1376 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_port_immutable(struct ib_device *ibdev , u8 port_num , struct ib_port_immutable *immutable ) 
{ 
  struct ib_port_attr attr ;
  int err ;

  {
#line 1382
  err = mlx5_ib_query_port(ibdev, (int )port_num, & attr);
#line 1383
  if (err != 0) {
#line 1384
    return (err);
  } else {

  }
#line 1386
  immutable->pkey_tbl_len = (int )attr.pkey_tbl_len;
#line 1387
  immutable->gid_tbl_len = attr.gid_tbl_len;
#line 1388
  immutable->core_cap_flags = 1052695U;
#line 1389
  immutable->max_mad_size = 256U;
#line 1391
  return (0);
}
}
#line 1394 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void *mlx5_ib_add(struct mlx5_core_dev *mdev ) 
{ 
  struct mlx5_ib_dev *dev ;
  int err ;
  int i ;
  __u32 tmp ;
  bool __print_once ;
  struct ib_device *tmp___0 ;
  int tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  struct lock_class_key __key ;

  {
#line 1401
  tmp = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 13UL));
#line 1401
  if (((tmp >> 8) & 3U) == 1U) {
#line 1402
    return ((void *)0);
  } else {

  }
#line 1404
  if (! __print_once) {
#line 1404
    __print_once = 1;
#line 1404
    printk("\016%s", (char *)(& mlx5_version));
  } else {

  }
#line 1406
  tmp___0 = ib_alloc_device(11024UL);
#line 1406
  dev = (struct mlx5_ib_dev *)tmp___0;
#line 1407
  if ((unsigned long )dev == (unsigned long )((struct mlx5_ib_dev *)0)) {
#line 1408
    return ((void *)0);
  } else {

  }
#line 1410
  dev->mdev = mdev;
#line 1412
  err = get_port_caps(dev);
#line 1413
  if (err != 0) {
#line 1414
    goto err_dealloc;
  } else {

  }
#line 1416
  tmp___1 = mlx5_use_mad_ifc(dev);
#line 1416
  if (tmp___1 != 0) {
#line 1417
    get_ext_port_caps(dev);
  } else {

  }
#line 1421
  strlcpy((char *)(& dev->ib_dev.name), "mlx5_%d", 64UL);
#line 1422
  dev->ib_dev.owner = & __this_module;
#line 1423
  dev->ib_dev.node_type = 1U;
#line 1424
  dev->ib_dev.local_dma_lkey = 0U;
#line 1425
  tmp___2 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 13UL));
#line 1425
  dev->num_ports = (int )tmp___2 & 255;
#line 1426
  dev->ib_dev.phys_port_cnt = (u8 )dev->num_ports;
#line 1427
  dev->ib_dev.num_comp_vectors = (dev->mdev)->priv.eq_table.num_comp_vectors;
#line 1429
  dev->ib_dev.dma_device = & (mdev->pdev)->dev;
#line 1431
  dev->ib_dev.uverbs_abi_ver = 1;
#line 1432
  dev->ib_dev.uverbs_cmd_mask = 1717166809631ULL;
#line 1456
  dev->ib_dev.uverbs_ex_cmd_mask = 2ULL;
#line 1459
  dev->ib_dev.query_device = & mlx5_ib_query_device;
#line 1460
  dev->ib_dev.query_port = & mlx5_ib_query_port;
#line 1461
  dev->ib_dev.query_gid = & mlx5_ib_query_gid;
#line 1462
  dev->ib_dev.query_pkey = & mlx5_ib_query_pkey;
#line 1463
  dev->ib_dev.modify_device = & mlx5_ib_modify_device;
#line 1464
  dev->ib_dev.modify_port = & mlx5_ib_modify_port;
#line 1465
  dev->ib_dev.alloc_ucontext = & mlx5_ib_alloc_ucontext;
#line 1466
  dev->ib_dev.dealloc_ucontext = & mlx5_ib_dealloc_ucontext;
#line 1467
  dev->ib_dev.mmap = & mlx5_ib_mmap;
#line 1468
  dev->ib_dev.alloc_pd = & mlx5_ib_alloc_pd;
#line 1469
  dev->ib_dev.dealloc_pd = & mlx5_ib_dealloc_pd;
#line 1470
  dev->ib_dev.create_ah = & mlx5_ib_create_ah;
#line 1471
  dev->ib_dev.query_ah = & mlx5_ib_query_ah;
#line 1472
  dev->ib_dev.destroy_ah = & mlx5_ib_destroy_ah;
#line 1473
  dev->ib_dev.create_srq = & mlx5_ib_create_srq;
#line 1474
  dev->ib_dev.modify_srq = & mlx5_ib_modify_srq;
#line 1475
  dev->ib_dev.query_srq = & mlx5_ib_query_srq;
#line 1476
  dev->ib_dev.destroy_srq = & mlx5_ib_destroy_srq;
#line 1477
  dev->ib_dev.post_srq_recv = & mlx5_ib_post_srq_recv;
#line 1478
  dev->ib_dev.create_qp = & mlx5_ib_create_qp;
#line 1479
  dev->ib_dev.modify_qp = & mlx5_ib_modify_qp;
#line 1480
  dev->ib_dev.query_qp = & mlx5_ib_query_qp;
#line 1481
  dev->ib_dev.destroy_qp = & mlx5_ib_destroy_qp;
#line 1482
  dev->ib_dev.post_send = & mlx5_ib_post_send;
#line 1483
  dev->ib_dev.post_recv = & mlx5_ib_post_recv;
#line 1484
  dev->ib_dev.create_cq = & mlx5_ib_create_cq;
#line 1485
  dev->ib_dev.modify_cq = & mlx5_ib_modify_cq;
#line 1486
  dev->ib_dev.resize_cq = & mlx5_ib_resize_cq;
#line 1487
  dev->ib_dev.destroy_cq = & mlx5_ib_destroy_cq;
#line 1488
  dev->ib_dev.poll_cq = & mlx5_ib_poll_cq;
#line 1489
  dev->ib_dev.req_notify_cq = & mlx5_ib_arm_cq;
#line 1490
  dev->ib_dev.get_dma_mr = & mlx5_ib_get_dma_mr;
#line 1491
  dev->ib_dev.reg_user_mr = & mlx5_ib_reg_user_mr;
#line 1492
  dev->ib_dev.dereg_mr = & mlx5_ib_dereg_mr;
#line 1493
  dev->ib_dev.destroy_mr = & mlx5_ib_destroy_mr;
#line 1494
  dev->ib_dev.attach_mcast = & mlx5_ib_mcg_attach;
#line 1495
  dev->ib_dev.detach_mcast = & mlx5_ib_mcg_detach;
#line 1496
  dev->ib_dev.process_mad = & mlx5_ib_process_mad;
#line 1497
  dev->ib_dev.create_mr = & mlx5_ib_create_mr;
#line 1498
  dev->ib_dev.alloc_fast_reg_mr = & mlx5_ib_alloc_fast_reg_mr;
#line 1499
  dev->ib_dev.alloc_fast_reg_page_list = & mlx5_ib_alloc_fast_reg_page_list;
#line 1500
  dev->ib_dev.free_fast_reg_page_list = & mlx5_ib_free_fast_reg_page_list;
#line 1501
  dev->ib_dev.check_mr_status = & mlx5_ib_check_mr_status;
#line 1502
  dev->ib_dev.get_port_immutable = & mlx5_port_immutable;
#line 1504
  mlx5_ib_internal_fill_odp_caps(dev);
#line 1506
  tmp___3 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 1506
  if ((tmp___3 & 8U) != 0U) {
#line 1507
    dev->ib_dev.alloc_xrcd = & mlx5_ib_alloc_xrcd;
#line 1508
    dev->ib_dev.dealloc_xrcd = & mlx5_ib_dealloc_xrcd;
#line 1509
    dev->ib_dev.uverbs_cmd_mask = dev->ib_dev.uverbs_cmd_mask | 412316860416ULL;
  } else {

  }
#line 1514
  err = init_node_data(dev);
#line 1515
  if (err != 0) {
#line 1516
    goto err_dealloc;
  } else {

  }
#line 1518
  __mutex_init(& dev->cap_mask_mutex, "&dev->cap_mask_mutex", & __key);
#line 1520
  err = create_dev_resources(& dev->devr);
#line 1521
  if (err != 0) {
#line 1522
    goto err_dealloc;
  } else {

  }
#line 1524
  err = mlx5_ib_odp_init_one(dev);
#line 1525
  if (err != 0) {
#line 1526
    goto err_rsrc;
  } else {

  }
#line 1528
  err = ib_register_device(& dev->ib_dev, (int (*)(struct ib_device * , u8  , struct kobject * ))0);
#line 1529
  if (err != 0) {
#line 1530
    goto err_odp;
  } else {

  }
#line 1532
  err = create_umr_res(dev);
#line 1533
  if (err != 0) {
#line 1534
    goto err_dev;
  } else {

  }
#line 1536
  i = 0;
#line 1536
  goto ldv_38304;
  ldv_38303: 
#line 1537
  err = device_create_file(& dev->ib_dev.dev, (struct device_attribute  const  *)mlx5_class_attributes[i]);
#line 1539
  if (err != 0) {
#line 1540
    goto err_umrc;
  } else {

  }
#line 1536
  i = i + 1;
  ldv_38304: ;
#line 1536
  if ((unsigned int )i <= 5U) {
#line 1538
    goto ldv_38303;
  } else {

  }
#line 1543
  dev->ib_active = 1;
#line 1545
  return ((void *)dev);
  err_umrc: 
#line 1548
  destroy_umrc_res(dev);
  err_dev: 
#line 1551
  ib_unregister_device(& dev->ib_dev);
  err_odp: 
#line 1554
  mlx5_ib_odp_remove_one(dev);
  err_rsrc: 
#line 1557
  destroy_dev_resources(& dev->devr);
  err_dealloc: 
#line 1560
  ib_dealloc_device((struct ib_device *)dev);
#line 1562
  return ((void *)0);
}
}
#line 1565 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void mlx5_ib_remove(struct mlx5_core_dev *mdev , void *context ) 
{ 
  struct mlx5_ib_dev *dev ;

  {
#line 1567
  dev = (struct mlx5_ib_dev *)context;
#line 1569
  ib_unregister_device(& dev->ib_dev);
#line 1570
  destroy_umrc_res(dev);
#line 1571
  mlx5_ib_odp_remove_one(dev);
#line 1572
  destroy_dev_resources(& dev->devr);
#line 1573
  ib_dealloc_device(& dev->ib_dev);
#line 1574
  return;
}
}
#line 1576 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static struct mlx5_interface mlx5_ib_interface  =    {& mlx5_ib_add, & mlx5_ib_remove, & mlx5_ib_event, 0, 0, {0, 0}};
#line 1583 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static int mlx5_ib_init(void) 
{ 
  int err ;

  {
#line 1587
  if (deprecated_prof_sel != 2) {
#line 1588
    printk("\fprof_sel is deprecated for mlx5_ib, set it for mlx5_core\n");
  } else {

  }
#line 1590
  err = mlx5_ib_odp_init();
#line 1591
  if (err != 0) {
#line 1592
    return (err);
  } else {

  }
#line 1594
  err = mlx5_register_interface(& mlx5_ib_interface);
#line 1595
  if (err != 0) {
#line 1596
    goto clean_odp;
  } else {

  }
#line 1598
  return (err);
  clean_odp: 
#line 1601
  mlx5_ib_odp_cleanup();
#line 1602
  return (err);
}
}
#line 1605 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.c"
static void mlx5_ib_cleanup(void) 
{ 


  {
#line 1607
  mlx5_unregister_interface(& mlx5_ib_interface);
#line 1608
  mlx5_ib_odp_cleanup();
#line 1609
  return;
}
}
#line 104 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
int ldv_retval_1  ;
#line 105
extern void ldv_initialize(void) ;
#line 106
void ldv_check_final_state(void) ;
#line 109 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
void ldv_initialize_mlx5_interface_7(void) 
{ 
  void *tmp ;

  {
#line 110
  tmp = ldv_init_zalloc(329944UL);
#line 110
  mlx5_ib_interface_group0 = (struct mlx5_core_dev *)tmp;
#line 111
  return;
}
}
#line 123
void ldv_main_exported_6(void) ;
#line 124
void ldv_main_exported_5(void) ;
#line 128 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
void main(void) 
{ 
  struct device_attribute *ldvarg8 ;
  void *tmp ;
  char *ldvarg7 ;
  void *tmp___0 ;
  struct device *ldvarg6 ;
  void *tmp___1 ;
  enum mlx5_dev_event ldvarg11 ;
  unsigned long ldvarg10 ;
  void *ldvarg12 ;
  void *tmp___2 ;
  void *ldvarg9 ;
  void *tmp___3 ;
  char *ldvarg14 ;
  void *tmp___4 ;
  struct device *ldvarg13 ;
  void *tmp___5 ;
  struct device_attribute *ldvarg15 ;
  void *tmp___6 ;
  struct device_attribute *ldvarg18 ;
  void *tmp___7 ;
  char *ldvarg17 ;
  void *tmp___8 ;
  struct device *ldvarg16 ;
  void *tmp___9 ;
  struct device_attribute *ldvarg21 ;
  void *tmp___10 ;
  char *ldvarg20 ;
  void *tmp___11 ;
  struct device *ldvarg19 ;
  void *tmp___12 ;
  struct device_attribute *ldvarg24 ;
  void *tmp___13 ;
  char *ldvarg23 ;
  void *tmp___14 ;
  struct device *ldvarg22 ;
  void *tmp___15 ;
  struct device_attribute *ldvarg27 ;
  void *tmp___16 ;
  char *ldvarg26 ;
  void *tmp___17 ;
  struct device *ldvarg25 ;
  void *tmp___18 ;
  int tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  int tmp___22 ;
  int tmp___23 ;
  int tmp___24 ;
  int tmp___25 ;
  int tmp___26 ;
  int tmp___27 ;

  {
#line 131
  tmp = ldv_init_zalloc(48UL);
#line 131
  ldvarg8 = (struct device_attribute *)tmp;
#line 132
  tmp___0 = ldv_init_zalloc(1UL);
#line 132
  ldvarg7 = (char *)tmp___0;
#line 133
  tmp___1 = ldv_init_zalloc(1416UL);
#line 133
  ldvarg6 = (struct device *)tmp___1;
#line 136
  tmp___2 = ldv_init_zalloc(1UL);
#line 136
  ldvarg12 = tmp___2;
#line 137
  tmp___3 = ldv_init_zalloc(1UL);
#line 137
  ldvarg9 = tmp___3;
#line 138
  tmp___4 = ldv_init_zalloc(1UL);
#line 138
  ldvarg14 = (char *)tmp___4;
#line 139
  tmp___5 = ldv_init_zalloc(1416UL);
#line 139
  ldvarg13 = (struct device *)tmp___5;
#line 140
  tmp___6 = ldv_init_zalloc(48UL);
#line 140
  ldvarg15 = (struct device_attribute *)tmp___6;
#line 141
  tmp___7 = ldv_init_zalloc(48UL);
#line 141
  ldvarg18 = (struct device_attribute *)tmp___7;
#line 142
  tmp___8 = ldv_init_zalloc(1UL);
#line 142
  ldvarg17 = (char *)tmp___8;
#line 143
  tmp___9 = ldv_init_zalloc(1416UL);
#line 143
  ldvarg16 = (struct device *)tmp___9;
#line 144
  tmp___10 = ldv_init_zalloc(48UL);
#line 144
  ldvarg21 = (struct device_attribute *)tmp___10;
#line 145
  tmp___11 = ldv_init_zalloc(1UL);
#line 145
  ldvarg20 = (char *)tmp___11;
#line 146
  tmp___12 = ldv_init_zalloc(1416UL);
#line 146
  ldvarg19 = (struct device *)tmp___12;
#line 147
  tmp___13 = ldv_init_zalloc(48UL);
#line 147
  ldvarg24 = (struct device_attribute *)tmp___13;
#line 148
  tmp___14 = ldv_init_zalloc(1UL);
#line 148
  ldvarg23 = (char *)tmp___14;
#line 149
  tmp___15 = ldv_init_zalloc(1416UL);
#line 149
  ldvarg22 = (struct device *)tmp___15;
#line 150
  tmp___16 = ldv_init_zalloc(48UL);
#line 150
  ldvarg27 = (struct device_attribute *)tmp___16;
#line 151
  tmp___17 = ldv_init_zalloc(1UL);
#line 151
  ldvarg26 = (char *)tmp___17;
#line 152
  tmp___18 = ldv_init_zalloc(1416UL);
#line 152
  ldvarg25 = (struct device *)tmp___18;
#line 129
  ldv_initialize();
#line 134
  ldv_memset((void *)(& ldvarg11), 0, 4UL);
#line 135
  ldv_memset((void *)(& ldvarg10), 0, 8UL);
#line 154
  ldv_state_variable_6 = 0;
#line 155
  ldv_state_variable_11 = 0;
#line 157
  work_init_3();
#line 159
  ldv_state_variable_3 = 1;
#line 160
  ldv_state_variable_7 = 0;
#line 161
  ldv_state_variable_9 = 0;
#line 162
  ldv_state_variable_12 = 0;
#line 164
  work_init_2();
#line 166
  ldv_state_variable_2 = 1;
#line 167
  ldv_state_variable_8 = 0;
#line 169
  work_init_1();
#line 171
  ldv_state_variable_1 = 1;
#line 173
  timer_init_4();
#line 175
  ldv_state_variable_4 = 1;
#line 176
  ref_cnt = 0;
#line 177
  ldv_state_variable_0 = 1;
#line 178
  ldv_state_variable_13 = 0;
#line 179
  ldv_state_variable_10 = 0;
#line 180
  ldv_state_variable_5 = 0;
  ldv_38429: 
#line 182
  tmp___19 = __VERIFIER_nondet_int();
#line 182
  switch (tmp___19) {
  case 0: ;
#line 186
  if (ldv_state_variable_6 != 0) {
#line 187
    ldv_main_exported_6();
  } else {

  }
#line 190
  goto ldv_38386;
  case 1: ;
#line 194
  if (ldv_state_variable_11 != 0) {
#line 195
    tmp___20 = __VERIFIER_nondet_int();
#line 195
    switch (tmp___20) {
    case 0: ;
#line 198
    if (ldv_state_variable_11 == 1) {
#line 200
      show_hca(ldvarg6, ldvarg8, ldvarg7);
#line 202
      ldv_state_variable_11 = 1;
    } else {

    }
#line 205
    goto ldv_38389;
    default: 
#line 206
    ldv_stop();
    }
    ldv_38389: ;
  } else {

  }
#line 210
  goto ldv_38386;
  case 2: ;
#line 217
  goto ldv_38386;
  case 3: ;
#line 221
  if (ldv_state_variable_7 != 0) {
#line 222
    tmp___21 = __VERIFIER_nondet_int();
#line 222
    switch (tmp___21) {
    case 0: ;
#line 225
    if (ldv_state_variable_7 == 1) {
#line 227
      mlx5_ib_event(mlx5_ib_interface_group0, ldvarg12, ldvarg11, ldvarg10);
#line 229
      ldv_state_variable_7 = 1;
    } else {

    }
#line 232
    if (ldv_state_variable_7 == 2) {
#line 234
      mlx5_ib_event(mlx5_ib_interface_group0, ldvarg12, ldvarg11, ldvarg10);
#line 236
      ldv_state_variable_7 = 2;
    } else {

    }
#line 239
    goto ldv_38394;
    case 1: ;
#line 242
    if (ldv_state_variable_7 == 1) {
#line 244
      mlx5_ib_add(mlx5_ib_interface_group0);
#line 246
      ldv_state_variable_7 = 2;
#line 247
      ref_cnt = ref_cnt + 1;
    } else {

    }
#line 250
    goto ldv_38394;
    case 2: ;
#line 253
    if (ldv_state_variable_7 == 2) {
#line 255
      mlx5_ib_remove(mlx5_ib_interface_group0, ldvarg9);
#line 257
      ldv_state_variable_7 = 1;
#line 258
      ref_cnt = ref_cnt - 1;
    } else {

    }
#line 261
    goto ldv_38394;
    default: 
#line 262
    ldv_stop();
    }
    ldv_38394: ;
  } else {

  }
#line 266
  goto ldv_38386;
  case 4: ;
#line 270
  if (ldv_state_variable_9 != 0) {
#line 271
    tmp___22 = __VERIFIER_nondet_int();
#line 271
    switch (tmp___22) {
    case 0: ;
#line 274
    if (ldv_state_variable_9 == 1) {
#line 276
      show_fw_pages(ldvarg13, ldvarg15, ldvarg14);
#line 278
      ldv_state_variable_9 = 1;
    } else {

    }
#line 281
    goto ldv_38400;
    default: 
#line 282
    ldv_stop();
    }
    ldv_38400: ;
  } else {

  }
#line 286
  goto ldv_38386;
  case 5: ;
#line 290
  if (ldv_state_variable_12 != 0) {
#line 291
    tmp___23 = __VERIFIER_nondet_int();
#line 291
    switch (tmp___23) {
    case 0: ;
#line 294
    if (ldv_state_variable_12 == 1) {
#line 296
      show_fw_ver(ldvarg16, ldvarg18, ldvarg17);
#line 298
      ldv_state_variable_12 = 1;
    } else {

    }
#line 301
    goto ldv_38404;
    default: 
#line 302
    ldv_stop();
    }
    ldv_38404: ;
  } else {

  }
#line 306
  goto ldv_38386;
  case 6: ;
#line 313
  goto ldv_38386;
  case 7: ;
#line 317
  if (ldv_state_variable_8 != 0) {
#line 318
    tmp___24 = __VERIFIER_nondet_int();
#line 318
    switch (tmp___24) {
    case 0: ;
#line 321
    if (ldv_state_variable_8 == 1) {
#line 323
      show_reg_pages(ldvarg19, ldvarg21, ldvarg20);
#line 325
      ldv_state_variable_8 = 1;
    } else {

    }
#line 328
    goto ldv_38409;
    default: 
#line 329
    ldv_stop();
    }
    ldv_38409: ;
  } else {

  }
#line 333
  goto ldv_38386;
  case 8: ;
#line 340
  goto ldv_38386;
  case 9: ;
#line 347
  goto ldv_38386;
  case 10: ;
#line 351
  if (ldv_state_variable_0 != 0) {
#line 352
    tmp___25 = __VERIFIER_nondet_int();
#line 352
    switch (tmp___25) {
    case 0: ;
#line 355
    if (ldv_state_variable_0 == 3 && ref_cnt == 0) {
#line 357
      mlx5_ib_cleanup();
#line 358
      ldv_state_variable_0 = 2;
#line 359
      goto ldv_final;
    } else {

    }
#line 362
    goto ldv_38416;
    case 1: ;
#line 365
    if (ldv_state_variable_0 == 1) {
#line 367
      ldv_retval_1 = mlx5_ib_init();
#line 369
      if (ldv_retval_1 == 0) {
#line 370
        ldv_state_variable_0 = 3;
#line 371
        ldv_state_variable_5 = 1;
#line 372
        ldv_file_operations_5();
#line 373
        ldv_state_variable_10 = 1;
#line 374
        ldv_state_variable_13 = 1;
#line 375
        ldv_state_variable_8 = 1;
#line 376
        ldv_state_variable_12 = 1;
#line 377
        ldv_state_variable_9 = 1;
#line 378
        ldv_state_variable_7 = 1;
#line 379
        ldv_initialize_mlx5_interface_7();
#line 380
        ldv_state_variable_11 = 1;
#line 381
        ldv_state_variable_6 = 1;
#line 382
        ldv_file_operations_6();
      } else {

      }
#line 384
      if (ldv_retval_1 != 0) {
#line 385
        ldv_state_variable_0 = 2;
#line 386
        goto ldv_final;
      } else {

      }
    } else {

    }
#line 390
    goto ldv_38416;
    default: 
#line 391
    ldv_stop();
    }
    ldv_38416: ;
  } else {

  }
#line 395
  goto ldv_38386;
  case 11: ;
#line 399
  if (ldv_state_variable_13 != 0) {
#line 400
    tmp___26 = __VERIFIER_nondet_int();
#line 400
    switch (tmp___26) {
    case 0: ;
#line 403
    if (ldv_state_variable_13 == 1) {
#line 405
      show_rev(ldvarg22, ldvarg24, ldvarg23);
#line 407
      ldv_state_variable_13 = 1;
    } else {

    }
#line 410
    goto ldv_38421;
    default: 
#line 411
    ldv_stop();
    }
    ldv_38421: ;
  } else {

  }
#line 415
  goto ldv_38386;
  case 12: ;
#line 419
  if (ldv_state_variable_10 != 0) {
#line 420
    tmp___27 = __VERIFIER_nondet_int();
#line 420
    switch (tmp___27) {
    case 0: ;
#line 423
    if (ldv_state_variable_10 == 1) {
#line 425
      show_board(ldvarg25, ldvarg27, ldvarg26);
#line 427
      ldv_state_variable_10 = 1;
    } else {

    }
#line 430
    goto ldv_38425;
    default: 
#line 431
    ldv_stop();
    }
    ldv_38425: ;
  } else {

  }
#line 435
  goto ldv_38386;
  case 13: ;
#line 439
  if (ldv_state_variable_5 != 0) {
#line 440
    ldv_main_exported_5();
  } else {

  }
#line 443
  goto ldv_38386;
  default: 
#line 444
  ldv_stop();
  }
  ldv_38386: ;
#line 446
  goto ldv_38429;
  ldv_final: 
#line 448
  ldv_check_final_state();
#line 449
  return;
}
}
#line 452 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
__inline static void *ERR_PTR(long error ) 
{ 
  void *tmp ;

  {
#line 455
  tmp = ldv_err_ptr(error);
#line 455
  return (tmp);
}
}
#line 458 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
__inline static long PTR_ERR(void const   *ptr ) 
{ 
  long tmp ;

  {
#line 461
  tmp = ldv_ptr_err(ptr);
#line 461
  return (tmp);
}
}
#line 464 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
__inline static bool IS_ERR(void const   *ptr ) 
{ 
  bool tmp ;

  {
#line 467
  tmp = ldv_is_err(ptr);
#line 467
  return (tmp);
}
}
#line 476 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
bool ldv_queue_work_on_5(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 480
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 480
  ldv_func_res = tmp;
#line 482
  activate_work_3(ldv_func_arg3, 2);
#line 484
  return (ldv_func_res);
}
}
#line 487 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
bool ldv_queue_delayed_work_on_6(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 491
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 491
  ldv_func_res = tmp;
#line 493
  activate_work_3(& ldv_func_arg3->work, 2);
#line 495
  return (ldv_func_res);
}
}
#line 498 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
bool ldv_queue_work_on_7(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                         struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 502
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 502
  ldv_func_res = tmp;
#line 504
  activate_work_3(ldv_func_arg3, 2);
#line 506
  return (ldv_func_res);
}
}
#line 509 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
void ldv_flush_workqueue_8(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 512
  flush_workqueue(ldv_func_arg1);
#line 514
  call_and_disable_all_3(2);
#line 515
  return;
}
}
#line 517 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/main.o.c.prepared"
bool ldv_queue_delayed_work_on_9(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                 struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 521
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 521
  ldv_func_res = tmp;
#line 523
  activate_work_3(& ldv_func_arg3->work, 2);
#line 525
  return (ldv_func_res);
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 437 "./arch/x86/include/asm/bitops.h"
__inline static int fls(int x ) 
{ 
  int r ;

  {
#line 451
  __asm__  ("bsrl %1,%0": "=r" (r): "rm" (x), "0" (-1));
#line 464
  return (r + 1);
}
}
#line 479 "./arch/x86/include/asm/bitops.h"
__inline static int fls64(__u64 x ) 
{ 
  int bitpos ;

  {
#line 481
  bitpos = -1;
#line 487
  __asm__  ("bsrq %1,%q0": "+r" (bitpos): "rm" (x));
#line 490
  return (bitpos + 1);
}
}
#line 46 "include/uapi/linux/swab.h"
__inline static __u16 __fswab16(__u16 val ) 
{ 


  {
#line 53
  return ((__u16 )((int )((short )((int )val << 8)) | (int )((short )((int )val >> 8))));
}
}
#line 174 "include/linux/bitops.h"
__inline static unsigned int fls_long(unsigned long l ) 
{ 
  int tmp___0 ;

  {
#line 178
  tmp___0 = fls64((__u64 )l);
#line 178
  return ((unsigned int )tmp___0);
}
}
#line 32 "include/linux/log2.h"
__inline static int __ilog2_u32(u32 n ) 
{ 
  int tmp ;

  {
#line 34
  tmp = fls((int )n);
#line 34
  return (tmp + -1);
}
}
#line 61 "include/linux/log2.h"
__inline static unsigned long __roundup_pow_of_two(unsigned long n ) 
{ 
  unsigned int tmp ;

  {
#line 63
  tmp = fls_long(n - 1UL);
#line 63
  return (1UL << (int )tmp);
}
}
#line 23 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) ;
#line 32
__inline static long PTR_ERR(void const   *ptr ) ;
#line 41
__inline static bool IS_ERR(void const   *ptr ) ;
#line 116 "./arch/x86/include/asm/atomic.h"
__inline static int atomic_dec_and_test(atomic_t *v ) 
{ 
  char c ;

  {
#line 118
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; decl %0; sete %1": "+m" (v->counter),
                       "=qm" (c): : "memory");
#line 118
  return ((int )((signed char )c) != 0);
}
}
#line 93 "include/linux/spinlock.h"
extern void __raw_spin_lock_init(raw_spinlock_t * , char const   * , struct lock_class_key * ) ;
#line 31 "include/linux/spinlock_api_smp.h"
extern void _raw_spin_lock_irq(raw_spinlock_t * ) ;
#line 34
extern unsigned long _raw_spin_lock_irqsave(raw_spinlock_t * ) ;
#line 43
extern void _raw_spin_unlock_irq(raw_spinlock_t * ) ;
#line 45
extern void _raw_spin_unlock_irqrestore(raw_spinlock_t * , unsigned long  ) ;
#line 18 "include/linux/rwlock_api_smp.h"
extern void _raw_read_lock(rwlock_t * ) ;
#line 30
extern void _raw_read_unlock(rwlock_t * ) ;
#line 299 "include/linux/spinlock.h"
__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock ) 
{ 


  {
#line 301
  return (& lock->__annonCompField18.rlock);
}
}
#line 340 "include/linux/spinlock.h"
__inline static void spin_lock_irq(spinlock_t *lock ) 
{ 


  {
#line 342
  _raw_spin_lock_irq(& lock->__annonCompField18.rlock);
#line 343
  return;
}
}
#line 365 "include/linux/spinlock.h"
__inline static void spin_unlock_irq(spinlock_t *lock ) 
{ 


  {
#line 367
  _raw_spin_unlock_irq(& lock->__annonCompField18.rlock);
#line 368
  return;
}
}
#line 370 "include/linux/spinlock.h"
__inline static void spin_unlock_irqrestore(spinlock_t *lock , unsigned long flags ) 
{ 


  {
#line 372
  _raw_spin_unlock_irqrestore(& lock->__annonCompField18.rlock, flags);
#line 373
  return;
}
}
#line 106 "include/linux/completion.h"
extern void complete(struct completion * ) ;
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_19(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_21(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_20(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_23(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_22(struct workqueue_struct *ldv_func_arg1 ) ;
#line 91 "./arch/x86/include/asm/io.h"
__inline static void writeq(unsigned long val , void volatile   *addr ) 
{ 


  {
#line 91
  __asm__  volatile   ("movq %0,%1": : "r" (val), "m" (*((unsigned long volatile   *)addr)): "memory");
#line 92
  return;
}
}
#line 403 "include/linux/mm.h"
extern void kvfree(void const   * ) ;
#line 85 "include/rdma/ib_umem.h"
extern struct ib_umem *ib_umem_get(struct ib_ucontext * , unsigned long  , size_t  ,
                                   int  , int  ) ;
#line 87
extern void ib_umem_release(struct ib_umem * ) ;
#line 70 "include/linux/vmalloc.h"
extern void *vzalloc(unsigned long  ) ;
#line 268 "include/linux/radix-tree.h"
extern void *radix_tree_lookup(struct radix_tree_root * , unsigned long  ) ;
#line 49 "include/linux/mlx5/doorbell.h"
__inline static void mlx5_write64(__be32 *val , void *dest , spinlock_t *doorbell_lock ) 
{ 


  {
#line 52
  writeq((unsigned long )*((u64 *)val), (void volatile   *)dest);
#line 53
  return;
}
}
#line 592 "include/linux/mlx5/driver.h"
__inline static void *mlx5_buf_offset(struct mlx5_buf *buf , int offset ) 
{ 


  {
#line 594
  return (buf->direct.buf + (unsigned long )offset);
}
}
#line 637 "include/linux/mlx5/driver.h"
__inline static void *mlx5_vzalloc(unsigned long size ) 
{ 
  void *rtn ;

  {
#line 641
  rtn = kzalloc(size, 720U);
#line 642
  if ((unsigned long )rtn == (unsigned long )((void *)0)) {
#line 643
    rtn = vzalloc(size);
  } else {

  }
#line 644
  return (rtn);
}
}
#line 647 "include/linux/mlx5/driver.h"
__inline static u32 mlx5_base_mkey(u32 const   key ) 
{ 


  {
#line 649
  return ((u32 )key & 4294967040U);
}
}
#line 675
extern int mlx5_buf_alloc(struct mlx5_core_dev * , int  , struct mlx5_buf * ) ;
#line 676
extern void mlx5_buf_free(struct mlx5_core_dev * , struct mlx5_buf * ) ;
#line 716
extern void mlx5_fill_page_array(struct mlx5_buf * , __be64 * ) ;
#line 723
extern struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev * , u32  ) ;
#line 731
extern int mlx5_vector2eqn(struct mlx5_core_dev * , int  , int * , int * ) ;
#line 775
extern int mlx5_db_alloc(struct mlx5_core_dev * , struct mlx5_db * ) ;
#line 776
extern void mlx5_db_free(struct mlx5_core_dev * , struct mlx5_db * ) ;
#line 123 "include/linux/mlx5/cq.h"
__inline static int cqe_sz_to_mlx_sz(u8 size ) 
{ 


  {
#line 125
  return ((unsigned int )size != 64U);
}
}
#line 128 "include/linux/mlx5/cq.h"
__inline static void mlx5_cq_set_ci(struct mlx5_core_cq *cq ) 
{ 
  __u32 tmp ;

  {
#line 130
  tmp = __fswab32(cq->cons_index & 16777215U);
#line 130
  *(cq->set_ci_db) = tmp;
#line 131
  return;
}
}
#line 138 "include/linux/mlx5/cq.h"
__inline static void mlx5_cq_arm(struct mlx5_core_cq *cq , u32 cmd , void *uar_page ,
                                 spinlock_t *doorbell_lock , u32 cons_index ) 
{ 
  __be32 doorbell[2U] ;
  u32 sn ;
  u32 ci ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;

  {
#line 147
  sn = cq->arm_sn & 3U;
#line 148
  ci = cons_index & 16777215U;
#line 150
  tmp = __fswab32(((sn << 28) | cmd) | ci);
#line 150
  *(cq->arm_db) = tmp;
#line 155
  __asm__  volatile   ("sfence": : : "memory");
#line 157
  tmp___0 = __fswab32(((sn << 28) | cmd) | ci);
#line 157
  doorbell[0] = tmp___0;
#line 158
  tmp___1 = __fswab32(cq->cqn);
#line 158
  doorbell[1] = tmp___1;
#line 160
  mlx5_write64((__be32 *)(& doorbell), uar_page + 32UL, doorbell_lock);
#line 161
  return;
}
}
#line 165
extern int mlx5_core_create_cq(struct mlx5_core_dev * , struct mlx5_core_cq * , struct mlx5_create_cq_mbox_in * ,
                               int  ) ;
#line 167
extern int mlx5_core_destroy_cq(struct mlx5_core_dev * , struct mlx5_core_cq * ) ;
#line 170
extern int mlx5_core_modify_cq(struct mlx5_core_dev * , struct mlx5_core_cq * , struct mlx5_modify_cq_mbox_in * ,
                               int  ) ;
#line 598 "include/linux/mlx5/qp.h"
__inline static struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev ,
                                                      u32 qpn ) 
{ 
  void *tmp ;

  {
#line 600
  tmp = radix_tree_lookup(& dev->priv.qp_table.tree, (unsigned long )qpn);
#line 600
  return ((struct mlx5_core_qp *)tmp);
}
}
#line 603 "include/linux/mlx5/qp.h"
__inline static struct mlx5_core_mr *__mlx5_mr_lookup(struct mlx5_core_dev *dev ,
                                                      u32 key ) 
{ 
  void *tmp ;

  {
#line 605
  tmp = radix_tree_lookup(& dev->priv.mr_table.tree, (unsigned long )key);
#line 605
  return ((struct mlx5_core_mr *)tmp);
}
}
#line 447 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_cq *to_mibcq(struct mlx5_core_cq *mcq ) 
{ 
  struct mlx5_core_cq  const  *__mptr ;

  {
#line 449
  __mptr = (struct mlx5_core_cq  const  *)mcq;
#line 449
  return ((struct mlx5_ib_cq *)__mptr + 0xffffffffffffffd0UL);
}
}
#line 467 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_cq *to_mcq(struct ib_cq *ibcq ) 
{ 
  struct ib_cq  const  *__mptr ;

  {
#line 469
  __mptr = (struct ib_cq  const  *)ibcq;
#line 469
  return ((struct mlx5_ib_cq *)__mptr);
}
}
#line 472 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_qp *to_mibqp(struct mlx5_core_qp *mqp ) 
{ 
  struct mlx5_core_qp  const  *__mptr ;

  {
#line 474
  __mptr = (struct mlx5_core_qp  const  *)mqp;
#line 474
  return ((struct mlx5_ib_qp *)__mptr + 0xffffffffffffff80UL);
}
}
#line 477 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_mr *to_mibmr(struct mlx5_core_mr *mmr ) 
{ 
  struct mlx5_core_mr  const  *__mptr ;

  {
#line 479
  __mptr = (struct mlx5_core_mr  const  *)mmr;
#line 479
  return ((struct mlx5_ib_mr *)__mptr + 0xffffffffffffffd8UL);
}
}
#line 487 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_srq *to_msrq(struct ib_srq *ibsrq ) 
{ 
  struct ib_srq  const  *__mptr ;

  {
#line 489
  __mptr = (struct ib_srq  const  *)ibsrq;
#line 489
  return ((struct mlx5_ib_srq *)__mptr);
}
}
#line 497 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_srq *to_mibsrq(struct mlx5_core_srq *msrq ) 
{ 
  struct mlx5_core_srq  const  *__mptr ;

  {
#line 499
  __mptr = (struct mlx5_core_srq  const  *)msrq;
#line 499
  return ((struct mlx5_ib_srq *)__mptr + 0xffffffffffffffb8UL);
}
}
#line 522
int mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context , unsigned long virt , struct mlx5_db *db ) ;
#line 524
void mlx5_ib_db_unmap_user(struct mlx5_ib_ucontext *context , struct mlx5_db *db ) ;
#line 525
void __mlx5_ib_cq_clean(struct mlx5_ib_cq *cq , u32 rsn , struct mlx5_ib_srq *srq ) ;
#line 526
void mlx5_ib_cq_clean(struct mlx5_ib_cq *cq , u32 qpn , struct mlx5_ib_srq *srq ) ;
#line 527
void mlx5_ib_free_srq_wqe(struct mlx5_ib_srq *srq , int wqe_index ) ;
#line 557
void *mlx5_get_send_wqe(struct mlx5_ib_qp *qp , int n ) ;
#line 621
void mlx5_ib_cont_pages(struct ib_umem *umem , u64 addr , int *count , int *shift ,
                        int *ncont , int *order ) ;
#line 626
void mlx5_ib_populate_pas(struct mlx5_ib_dev *dev , struct ib_umem *umem , int page_shift ,
                          __be64 *pas , int access_flags ) ;
#line 629
int mlx5_ib_get_cqe_size(struct mlx5_ib_dev *dev , struct ib_cq *ibcq ) ;
#line 39 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void mlx5_ib_cq_comp(struct mlx5_core_cq *cq ) 
{ 
  struct ib_cq *ibcq ;
  struct mlx5_ib_cq *tmp ;

  {
#line 41
  tmp = to_mibcq(cq);
#line 41
  ibcq = & tmp->ibcq;
#line 43
  (*(ibcq->comp_handler))(ibcq, ibcq->cq_context);
#line 44
  return;
}
}
#line 46 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void mlx5_ib_cq_event(struct mlx5_core_cq *mcq , enum mlx5_event type ) 
{ 
  struct mlx5_ib_cq *cq ;
  struct mlx5_core_cq  const  *__mptr ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct ib_cq *ibcq ;
  struct ib_event event ;
  struct task_struct *tmp___0 ;

  {
#line 48
  __mptr = (struct mlx5_core_cq  const  *)mcq;
#line 48
  cq = (struct mlx5_ib_cq *)__mptr + 0xffffffffffffffd0UL;
#line 49
  tmp = to_mdev(cq->ibcq.device);
#line 49
  dev = tmp;
#line 50
  ibcq = & cq->ibcq;
#line 53
  if ((unsigned int )type != 4U) {
#line 54
    tmp___0 = get_current();
#line 54
    printk("\f%s:%s:%d:(pid %d): Unexpected event type %d on CQ %06x\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_cq_event", 55, tmp___0->pid, (unsigned int )type, mcq->cqn);
#line 56
    return;
  } else {

  }
#line 59
  if ((unsigned long )ibcq->event_handler != (unsigned long )((void (*)(struct ib_event * ,
                                                                        void * ))0)) {
#line 60
    event.device = & dev->ib_dev;
#line 61
    event.event = 0;
#line 62
    event.element.cq = ibcq;
#line 63
    (*(ibcq->event_handler))(& event, ibcq->cq_context);
  } else {

  }
#line 65
  return;
}
}
#line 67 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void *get_cqe_from_buf(struct mlx5_ib_cq_buf *buf , int n , int size ) 
{ 
  void *tmp ;

  {
#line 69
  tmp = mlx5_buf_offset(& buf->buf, n * size);
#line 69
  return (tmp);
}
}
#line 72 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void *get_cqe(struct mlx5_ib_cq *cq , int n ) 
{ 
  void *tmp ;

  {
#line 74
  tmp = get_cqe_from_buf(& cq->buf, n, cq->mcq.cqe_sz);
#line 74
  return (tmp);
}
}
#line 77 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static u8 sw_ownership_bit(int n , int nent ) 
{ 


  {
#line 79
  return ((n & nent) != 0);
}
}
#line 82 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void *get_sw_cqe(struct mlx5_ib_cq *cq , int n ) 
{ 
  void *cqe ;
  void *tmp ;
  struct mlx5_cqe64 *cqe64 ;
  long tmp___0 ;

  {
#line 84
  tmp = get_cqe(cq, cq->ibcq.cqe & n);
#line 84
  cqe = tmp;
#line 87
  cqe64 = cq->mcq.cqe_sz != 64 ? (struct mlx5_cqe64 *)cqe + 64U : (struct mlx5_cqe64 *)cqe;
#line 89
  tmp___0 = ldv__builtin_expect((unsigned int )((int )cqe64->op_own >> 4) != 15U, 1L);
#line 89
  if (tmp___0 != 0L && ! ((_Bool )((int )cqe64->op_own & 1)) ^ (((cq->ibcq.cqe + 1) & n) != 0)) {
#line 91
    return (cqe);
  } else {
#line 93
    return ((void *)0);
  }
}
}
#line 97 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void *next_cqe_sw(struct mlx5_ib_cq *cq ) 
{ 
  void *tmp ;

  {
#line 99
  tmp = get_sw_cqe(cq, (int )cq->mcq.cons_index);
#line 99
  return (tmp);
}
}
#line 102 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static enum ib_wc_opcode get_umr_comp(struct mlx5_ib_wq *wq , int idx ) 
{ 


  {
#line 104
  switch (*(wq->wr_data + (unsigned long )idx)) {
  case 240U: ;
#line 106
  return (0);
  case 10U: ;
#line 109
  return (7);
  case 11U: ;
#line 112
  return (8);
  default: 
#line 115
  printk("\funknown completion status\n");
#line 116
  return (0);
  }
}
}
#line 120 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void handle_good_req(struct ib_wc *wc , struct mlx5_cqe64 *cqe , struct mlx5_ib_wq *wq ,
                            int idx ) 
{ 
  __u32 tmp ;
  __u32 tmp___0 ;

  {
#line 123
  wc->wc_flags = 0;
#line 124
  tmp = __fswab32(cqe->sop_drop_qpn);
#line 124
  switch (tmp >> 24) {
  case 9U: 
#line 126
  wc->wc_flags = wc->wc_flags | 2;
  case 8U: 
#line 128
  wc->opcode = 1;
#line 129
  goto ldv_37686;
  case 11U: 
#line 131
  wc->wc_flags = wc->wc_flags | 2;
  case 10U: ;
  case 1U: 
#line 134
  wc->opcode = 0;
#line 135
  goto ldv_37686;
  case 16U: 
#line 137
  wc->opcode = 2;
#line 138
  tmp___0 = __fswab32(cqe->byte_cnt);
#line 138
  wc->byte_len = tmp___0;
#line 139
  goto ldv_37686;
  case 17U: 
#line 141
  wc->opcode = 3;
#line 142
  wc->byte_len = 8U;
#line 143
  goto ldv_37686;
  case 18U: 
#line 145
  wc->opcode = 4;
#line 146
  wc->byte_len = 8U;
#line 147
  goto ldv_37686;
  case 20U: 
#line 149
  wc->opcode = 9;
#line 150
  wc->byte_len = 8U;
#line 151
  goto ldv_37686;
  case 21U: 
#line 153
  wc->opcode = 10;
#line 154
  wc->byte_len = 8U;
#line 155
  goto ldv_37686;
  case 24U: 
#line 157
  wc->opcode = 5;
#line 158
  goto ldv_37686;
  case 37U: 
#line 160
  wc->opcode = get_umr_comp(wq, idx);
#line 161
  goto ldv_37686;
  }
  ldv_37686: ;
#line 164
  return;
}
}
#line 170 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void handle_responder(struct ib_wc *wc , struct mlx5_cqe64 *cqe , struct mlx5_ib_qp *qp ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_srq *srq ;
  struct mlx5_ib_wq *wq ;
  u16 wqe_ctr ;
  u8 g ;
  struct mlx5_core_srq *msrq ;
  __u32 tmp___0 ;
  __u16 tmp___1 ;
  int tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u16 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;

  {
#line 173
  tmp = to_mdev(qp->ibqp.device);
#line 173
  dev = tmp;
#line 179
  if ((unsigned long )qp->ibqp.srq != (unsigned long )((struct ib_srq *)0) || (unsigned long )qp->ibqp.xrcd != (unsigned long )((struct ib_xrcd *)0)) {
#line 180
    msrq = (struct mlx5_core_srq *)0;
#line 182
    if ((unsigned long )qp->ibqp.xrcd != (unsigned long )((struct ib_xrcd *)0)) {
#line 183
      tmp___0 = __fswab32(cqe->srqn);
#line 183
      msrq = mlx5_core_get_srq(dev->mdev, tmp___0);
#line 185
      srq = to_mibsrq(msrq);
    } else {
#line 187
      srq = to_msrq(qp->ibqp.srq);
    }
#line 189
    if ((unsigned long )srq != (unsigned long )((struct mlx5_ib_srq *)0)) {
#line 190
      tmp___1 = __fswab16((int )cqe->wqe_counter);
#line 190
      wqe_ctr = tmp___1;
#line 191
      wc->wr_id = *(srq->wrid + (unsigned long )wqe_ctr);
#line 192
      mlx5_ib_free_srq_wqe(srq, (int )wqe_ctr);
#line 193
      if ((unsigned long )msrq != (unsigned long )((struct mlx5_core_srq *)0)) {
#line 193
        tmp___2 = atomic_dec_and_test(& msrq->refcount);
#line 193
        if (tmp___2 != 0) {
#line 194
          complete(& msrq->free);
        } else {

        }
      } else {

      }
    } else {

    }
  } else {
#line 197
    wq = & qp->rq;
#line 198
    wc->wr_id = *(wq->wrid + (unsigned long )(wq->tail & (unsigned int )(wq->wqe_cnt + -1)));
#line 199
    wq->tail = wq->tail + 1U;
  }
#line 201
  tmp___3 = __fswab32(cqe->byte_cnt);
#line 201
  wc->byte_len = tmp___3;
#line 203
  switch ((int )cqe->op_own >> 4) {
  case 1: 
#line 205
  wc->opcode = 129;
#line 206
  wc->wc_flags = 2;
#line 207
  wc->ex.imm_data = cqe->imm_inval_pkey;
#line 208
  goto ldv_37712;
  case 2: 
#line 210
  wc->opcode = 128;
#line 211
  wc->wc_flags = 0;
#line 212
  goto ldv_37712;
  case 3: 
#line 214
  wc->opcode = 128;
#line 215
  wc->wc_flags = 2;
#line 216
  wc->ex.imm_data = cqe->imm_inval_pkey;
#line 217
  goto ldv_37712;
  case 4: 
#line 219
  wc->opcode = 128;
#line 220
  wc->wc_flags = 4;
#line 221
  tmp___4 = __fswab32(cqe->imm_inval_pkey);
#line 221
  wc->ex.invalidate_rkey = tmp___4;
#line 222
  goto ldv_37712;
  }
  ldv_37712: 
#line 224
  tmp___5 = __fswab16((int )cqe->slid);
#line 224
  wc->slid = tmp___5;
#line 225
  tmp___6 = __fswab32(cqe->flags_rqpn);
#line 225
  wc->sl = (unsigned int )((u8 )(tmp___6 >> 24)) & 15U;
#line 226
  tmp___7 = __fswab32(cqe->flags_rqpn);
#line 226
  wc->src_qp = tmp___7 & 16777215U;
#line 227
  wc->dlid_path_bits = cqe->ml_path;
#line 228
  tmp___8 = __fswab32(cqe->flags_rqpn);
#line 228
  g = (unsigned int )((u8 )(tmp___8 >> 28)) & 3U;
#line 229
  wc->wc_flags = wc->wc_flags | ((unsigned int )g != 0U);
#line 230
  tmp___9 = __fswab32(cqe->imm_inval_pkey);
#line 230
  wc->pkey_index = (u16 )tmp___9;
#line 231
  return;
}
}
#line 233 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void dump_cqe(struct mlx5_ib_dev *dev , struct mlx5_err_cqe *cqe ) 
{ 
  __be32 *p ;
  int i ;
  struct task_struct *tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;

  {
#line 235
  p = (__be32 *)cqe;
#line 238
  tmp = get_current();
#line 238
  printk("\f%s:%s:%d:(pid %d): dump error cqe\n", (char *)(& dev->ib_dev.name), "dump_cqe",
         238, tmp->pid);
#line 239
  i = 0;
#line 239
  goto ldv_37724;
  ldv_37723: 
#line 240
  tmp___0 = __fswab32(*(p + 3UL));
#line 240
  tmp___1 = __fswab32(*(p + 2UL));
#line 240
  tmp___2 = __fswab32(*(p + 1UL));
#line 240
  tmp___3 = __fswab32(*p);
#line 240
  printk("\016%08x %08x %08x %08x\n", tmp___3, tmp___2, tmp___1, tmp___0);
#line 239
  i = i + 1;
#line 239
  p = p + 4UL;
  ldv_37724: ;
#line 239
  if ((unsigned int )i <= 3U) {
#line 241
    goto ldv_37723;
  } else {

  }

#line 246
  return;
}
}
#line 245 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void mlx5_handle_error_cqe(struct mlx5_ib_dev *dev , struct mlx5_err_cqe *cqe ,
                                  struct ib_wc *wc ) 
{ 
  int dump ;

  {
#line 249
  dump = 1;
#line 251
  switch ((int )cqe->syndrome) {
  case 1: 
#line 253
  wc->status = 1;
#line 254
  goto ldv_37733;
  case 2: 
#line 256
  wc->status = 2;
#line 257
  goto ldv_37733;
  case 4: 
#line 259
  wc->status = 4;
#line 260
  goto ldv_37733;
  case 5: 
#line 262
  dump = 0;
#line 263
  wc->status = 5;
#line 264
  goto ldv_37733;
  case 6: 
#line 266
  wc->status = 6;
#line 267
  goto ldv_37733;
  case 16: 
#line 269
  wc->status = 7;
#line 270
  goto ldv_37733;
  case 17: 
#line 272
  wc->status = 8;
#line 273
  goto ldv_37733;
  case 18: 
#line 275
  wc->status = 9;
#line 276
  goto ldv_37733;
  case 19: 
#line 278
  wc->status = 10;
#line 279
  goto ldv_37733;
  case 20: 
#line 281
  wc->status = 11;
#line 282
  goto ldv_37733;
  case 21: 
#line 284
  wc->status = 12;
#line 285
  dump = 0;
#line 286
  goto ldv_37733;
  case 22: 
#line 288
  wc->status = 13;
#line 289
  dump = 0;
#line 290
  goto ldv_37733;
  case 34: 
#line 292
  wc->status = 16;
#line 293
  goto ldv_37733;
  default: 
#line 295
  wc->status = 21;
#line 296
  goto ldv_37733;
  }
  ldv_37733: 
#line 299
  wc->vendor_err = (u32 )cqe->vendor_err_synd;
#line 300
  if (dump != 0) {
#line 301
    dump_cqe(dev, cqe);
  } else {

  }
#line 302
  return;
}
}
#line 304 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int is_atomic_response(struct mlx5_ib_qp *qp , uint16_t idx ) 
{ 


  {
#line 308
  return (0);
}
}
#line 311 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void *mlx5_get_atomic_laddr(struct mlx5_ib_qp *qp , uint16_t idx ) 
{ 
  struct mlx5_wqe_data_seg *dpseg ;
  void *addr ;
  void *tmp ;
  __u64 tmp___0 ;

  {
#line 316
  tmp = mlx5_get_send_wqe(qp, (int )idx);
#line 316
  dpseg = (struct mlx5_wqe_data_seg *)tmp + 48U;
#line 319
  tmp___0 = __fswab64(dpseg->addr);
#line 319
  addr = (void *)tmp___0;
#line 320
  return (addr);
}
}
#line 323 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void handle_atomic(struct mlx5_ib_qp *qp , struct mlx5_cqe64 *cqe64 , uint16_t idx ) 
{ 
  void *addr ;
  int byte_count ;
  int i ;
  int tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u64 tmp___2 ;

  {
#line 330
  tmp = is_atomic_response(qp, (int )idx);
#line 330
  if (tmp == 0) {
#line 331
    return;
  } else {

  }
#line 333
  tmp___0 = __fswab32(cqe64->byte_cnt);
#line 333
  byte_count = (int )tmp___0;
#line 334
  addr = mlx5_get_atomic_laddr(qp, (int )idx);
#line 336
  if (byte_count == 4) {
#line 337
    tmp___1 = __fswab32(*((__be32 *)addr));
#line 337
    *((uint32_t *)addr) = tmp___1;
  } else {
#line 339
    i = 0;
#line 339
    goto ldv_37766;
    ldv_37765: 
#line 340
    tmp___2 = __fswab64(*((__be64 *)addr));
#line 340
    *((uint64_t *)addr) = tmp___2;
#line 341
    addr = addr + 8UL;
#line 339
    i = i + 8;
    ldv_37766: ;
#line 339
    if (i < byte_count) {
#line 341
      goto ldv_37765;
    } else {

    }

  }
#line 345
  return;
}
}
#line 348 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void handle_atomics(struct mlx5_ib_qp *qp , struct mlx5_cqe64 *cqe64 , u16 tail ,
                           u16 head ) 
{ 
  u16 idx ;

  {
  ldv_37776: 
#line 354
  idx = (u16 )((int )((short )((unsigned int )((unsigned short )qp->sq.wqe_cnt) + 65535U)) & (int )((short )tail));
#line 355
  handle_atomic(qp, cqe64, (int )idx);
#line 356
  if ((int )idx == (int )head) {
#line 357
    goto ldv_37775;
  } else {

  }
#line 359
  tail = (qp->sq.w_list + (unsigned long )idx)->next;
#line 360
  goto ldv_37776;
  ldv_37775: 
#line 361
  tail = (qp->sq.w_list + (unsigned long )idx)->next;
#line 362
  qp->sq.last_poll = tail;
#line 363
  return;
}
}
#line 365 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void free_cq_buf(struct mlx5_ib_dev *dev , struct mlx5_ib_cq_buf *buf ) 
{ 


  {
#line 367
  mlx5_buf_free(dev->mdev, & buf->buf);
#line 368
  return;
}
}
#line 370 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void get_sig_err_item(struct mlx5_sig_err_cqe *cqe , struct ib_sig_err *item ) 
{ 
  u16 syndrome ;
  __u16 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u64 tmp___6 ;
  __u32 tmp___7 ;

  {
#line 373
  tmp = __fswab16((int )cqe->syndrome);
#line 373
  syndrome = tmp;
#line 379
  if (((int )syndrome & 8192) != 0) {
#line 380
    item->err_type = 0;
#line 381
    tmp___0 = __fswab32(cqe->expected_trans_sig);
#line 381
    item->expected = tmp___0 >> 16;
#line 382
    tmp___1 = __fswab32(cqe->actual_trans_sig);
#line 382
    item->actual = tmp___1 >> 16;
  } else
#line 384
  if (((int )syndrome & 2048) != 0) {
#line 385
    item->err_type = 1;
#line 386
    tmp___2 = __fswab32(cqe->expected_reftag);
#line 386
    item->expected = tmp___2;
#line 387
    tmp___3 = __fswab32(cqe->actual_reftag);
#line 387
    item->actual = tmp___3;
  } else
#line 389
  if (((int )syndrome & 4096) != 0) {
#line 390
    item->err_type = 2;
#line 391
    tmp___4 = __fswab32(cqe->expected_trans_sig);
#line 391
    item->expected = tmp___4 & 65535U;
#line 392
    tmp___5 = __fswab32(cqe->actual_trans_sig);
#line 392
    item->actual = tmp___5 & 65535U;
  } else {
#line 394
    printk("\vGot signature completion error with bad syndrome %04x\n", (int )syndrome);
  }
#line 398
  tmp___6 = __fswab64(cqe->err_offset);
#line 398
  item->sig_err_offset = tmp___6;
#line 399
  tmp___7 = __fswab32(cqe->mkey);
#line 399
  item->key = tmp___7;
#line 400
  return;
}
}
#line 402 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int mlx5_poll_one(struct mlx5_ib_cq *cq , struct mlx5_ib_qp **cur_qp , struct ib_wc *wc ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_err_cqe *err_cqe ;
  struct mlx5_cqe64 *cqe64 ;
  struct mlx5_core_qp *mqp ;
  struct mlx5_ib_wq *wq ;
  struct mlx5_sig_err_cqe *sig_err_cqe ;
  struct mlx5_core_mr *mmr ;
  struct mlx5_ib_mr *mr ;
  uint8_t opcode ;
  uint32_t qpn ;
  u16 wqe_ctr ;
  void *cqe ;
  int idx ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  __u32 tmp___3 ;
  struct task_struct *tmp___4 ;
  long tmp___5 ;
  __u16 tmp___6 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___7 ;
  long tmp___8 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___9 ;
  long tmp___10 ;
  __u16 tmp___11 ;
  struct mlx5_ib_srq *srq ;
  __u16 tmp___12 ;
  __u32 tmp___13 ;
  u32 tmp___14 ;
  __u32 tmp___15 ;
  struct task_struct *tmp___16 ;
  long tmp___17 ;
  struct task_struct *tmp___18 ;

  {
#line 406
  tmp = to_mdev(cq->ibcq.device);
#line 406
  dev = tmp;
  repoll: 
#line 421
  cqe = next_cqe_sw(cq);
#line 422
  if ((unsigned long )cqe == (unsigned long )((void *)0)) {
#line 423
    return (-11);
  } else {

  }
#line 425
  cqe64 = cq->mcq.cqe_sz != 64 ? (struct mlx5_cqe64 *)cqe + 64U : (struct mlx5_cqe64 *)cqe;
#line 427
  cq->mcq.cons_index = cq->mcq.cons_index + 1U;
#line 432
  __asm__  volatile   ("lfence": : : "memory");
#line 434
  opcode = (uint8_t )((int )cqe64->op_own >> 4);
#line 435
  tmp___2 = ldv__builtin_expect((unsigned int )opcode == 5U, 0L);
#line 435
  if (tmp___2 != 0L) {
#line 436
    tmp___1 = ldv__builtin_expect((unsigned long )cq->resize_buf != (unsigned long )((struct mlx5_ib_cq_buf *)0),
                               1L);
#line 436
    if (tmp___1 != 0L) {
#line 437
      free_cq_buf(dev, & cq->buf);
#line 438
      cq->buf = *(cq->resize_buf);
#line 439
      kfree((void const   *)cq->resize_buf);
#line 440
      cq->resize_buf = (struct mlx5_ib_cq_buf *)0;
#line 441
      goto repoll;
    } else {
#line 443
      tmp___0 = get_current();
#line 443
      printk("\f%s:%s:%d:(pid %d): unexpected resize cqe\n", (char *)(& dev->ib_dev.name),
             "mlx5_poll_one", 443, tmp___0->pid);
    }
  } else {

  }
#line 447
  tmp___3 = __fswab32(cqe64->sop_drop_qpn);
#line 447
  qpn = tmp___3 & 16777215U;
#line 448
  if ((unsigned long )*cur_qp == (unsigned long )((struct mlx5_ib_qp *)0) || (*cur_qp)->ibqp.qp_num != qpn) {
#line 453
    mqp = __mlx5_qp_lookup(dev->mdev, qpn);
#line 454
    tmp___5 = ldv__builtin_expect((unsigned long )mqp == (unsigned long )((struct mlx5_core_qp *)0),
                               0L);
#line 454
    if (tmp___5 != 0L) {
#line 455
      tmp___4 = get_current();
#line 455
      printk("\f%s:%s:%d:(pid %d): CQE@CQ %06x for unknown QPN %6x\n", (char *)(& dev->ib_dev.name),
             "mlx5_poll_one", 456, tmp___4->pid, cq->mcq.cqn, qpn);
#line 457
      return (-22);
    } else {

    }
#line 460
    *cur_qp = to_mibqp(mqp);
  } else {

  }
#line 463
  wc->qp = & (*cur_qp)->ibqp;
#line 464
  switch ((int )opcode) {
  case 0: 
#line 466
  wq = & (*cur_qp)->sq;
#line 467
  tmp___6 = __fswab16((int )cqe64->wqe_counter);
#line 467
  wqe_ctr = tmp___6;
#line 468
  idx = (int )wqe_ctr & (wq->wqe_cnt + -1);
#line 469
  handle_good_req(wc, cqe64, wq, idx);
#line 470
  handle_atomics(*cur_qp, cqe64, (int )wq->last_poll, (int )((u16 )idx));
#line 471
  wc->wr_id = *(wq->wrid + (unsigned long )idx);
#line 472
  wq->tail = *(wq->wqe_head + (unsigned long )idx) + 1U;
#line 473
  wc->status = 0;
#line 474
  goto ldv_37807;
  case 1: ;
  case 2: ;
  case 3: ;
  case 4: 
#line 479
  handle_responder(wc, cqe64, *cur_qp);
#line 480
  wc->status = 0;
#line 481
  goto ldv_37807;
  case 5: ;
#line 483
  goto ldv_37807;
  case 13: ;
  case 14: 
#line 486
  err_cqe = (struct mlx5_err_cqe *)cqe64;
#line 487
  mlx5_handle_error_cqe(dev, err_cqe, wc);
#line 488
  descriptor.modname = "mlx5_ib";
#line 488
  descriptor.function = "mlx5_poll_one";
#line 488
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c";
#line 488
  descriptor.format = "%s:%s:%d:(pid %d): %s error cqe on cqn 0x%x:\n";
#line 488
  descriptor.lineno = 490U;
#line 488
  descriptor.flags = 0U;
#line 488
  tmp___8 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 488
  if (tmp___8 != 0L) {
#line 488
    tmp___7 = get_current();
#line 488
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): %s error cqe on cqn 0x%x:\n",
                       (char *)(& dev->ib_dev.name), "mlx5_poll_one", 490, tmp___7->pid,
                       (unsigned int )opcode == 13U ? (char *)"Requestor" : (char *)"Responder",
                       cq->mcq.cqn);
  } else {

  }
#line 491
  descriptor___0.modname = "mlx5_ib";
#line 491
  descriptor___0.function = "mlx5_poll_one";
#line 491
  descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c";
#line 491
  descriptor___0.format = "%s:%s:%d:(pid %d): syndrome 0x%x, vendor syndrome 0x%x\n";
#line 491
  descriptor___0.lineno = 492U;
#line 491
  descriptor___0.flags = 0U;
#line 491
  tmp___10 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 491
  if (tmp___10 != 0L) {
#line 491
    tmp___9 = get_current();
#line 491
    __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): syndrome 0x%x, vendor syndrome 0x%x\n",
                       (char *)(& dev->ib_dev.name), "mlx5_poll_one", 492, tmp___9->pid,
                       (int )err_cqe->syndrome, (int )err_cqe->vendor_err_synd);
  } else {

  }
#line 493
  if ((unsigned int )opcode == 13U) {
#line 494
    wq = & (*cur_qp)->sq;
#line 495
    tmp___11 = __fswab16((int )cqe64->wqe_counter);
#line 495
    wqe_ctr = tmp___11;
#line 496
    idx = (int )wqe_ctr & (wq->wqe_cnt + -1);
#line 497
    wc->wr_id = *(wq->wrid + (unsigned long )idx);
#line 498
    wq->tail = *(wq->wqe_head + (unsigned long )idx) + 1U;
  } else
#line 502
  if ((unsigned long )(*cur_qp)->ibqp.srq != (unsigned long )((struct ib_srq *)0)) {
#line 503
    srq = to_msrq((*cur_qp)->ibqp.srq);
#line 504
    tmp___12 = __fswab16((int )cqe64->wqe_counter);
#line 504
    wqe_ctr = tmp___12;
#line 505
    wc->wr_id = *(srq->wrid + (unsigned long )wqe_ctr);
#line 506
    mlx5_ib_free_srq_wqe(srq, (int )wqe_ctr);
  } else {
#line 508
    wq = & (*cur_qp)->rq;
#line 509
    wc->wr_id = *(wq->wrid + (unsigned long )(wq->tail & (unsigned int )(wq->wqe_cnt + -1)));
#line 510
    wq->tail = wq->tail + 1U;
  }
#line 513
  goto ldv_37807;
  case 12: 
#line 515
  sig_err_cqe = (struct mlx5_sig_err_cqe *)cqe64;
#line 517
  _raw_read_lock(& (dev->mdev)->priv.mr_table.lock);
#line 518
  tmp___13 = __fswab32(sig_err_cqe->mkey);
#line 518
  tmp___14 = mlx5_base_mkey(tmp___13);
#line 518
  mmr = __mlx5_mr_lookup(dev->mdev, tmp___14);
#line 520
  tmp___17 = ldv__builtin_expect((unsigned long )mmr == (unsigned long )((struct mlx5_core_mr *)0),
                              0L);
#line 520
  if (tmp___17 != 0L) {
#line 521
    _raw_read_unlock(& (dev->mdev)->priv.mr_table.lock);
#line 522
    tmp___15 = __fswab32(sig_err_cqe->mkey);
#line 522
    tmp___16 = get_current();
#line 522
    printk("\f%s:%s:%d:(pid %d): CQE@CQ %06x for unknown MR %6x\n", (char *)(& dev->ib_dev.name),
           "mlx5_poll_one", 523, tmp___16->pid, cq->mcq.cqn, tmp___15);
#line 524
    return (-22);
  } else {

  }
#line 527
  mr = to_mibmr(mmr);
#line 528
  get_sig_err_item(sig_err_cqe, & (mr->sig)->err_item);
#line 529
  (mr->sig)->sig_err_exists = 1;
#line 530
  (mr->sig)->sigerr_count = (mr->sig)->sigerr_count + 1U;
#line 532
  tmp___18 = get_current();
#line 532
  printk("\f%s:%s:%d:(pid %d): CQN: 0x%x Got SIGERR on key: 0x%x err_type %x err_offset %llx expected %x actual %x\n",
         (char *)(& dev->ib_dev.name), "mlx5_poll_one", 537, tmp___18->pid, cq->mcq.cqn,
         (mr->sig)->err_item.key, (unsigned int )(mr->sig)->err_item.err_type, (mr->sig)->err_item.sig_err_offset,
         (mr->sig)->err_item.expected, (mr->sig)->err_item.actual);
#line 539
  _raw_read_unlock(& (dev->mdev)->priv.mr_table.lock);
#line 540
  goto repoll;
  }
  ldv_37807: ;
#line 543
  return (0);
}
}
#line 546 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
int mlx5_ib_poll_cq(struct ib_cq *ibcq , int num_entries , struct ib_wc *wc ) 
{ 
  struct mlx5_ib_cq *cq ;
  struct mlx5_ib_cq *tmp ;
  struct mlx5_ib_qp *cur_qp ;
  unsigned long flags ;
  int npolled ;
  int err ;
  raw_spinlock_t *tmp___0 ;

  {
#line 548
  tmp = to_mcq(ibcq);
#line 548
  cq = tmp;
#line 549
  cur_qp = (struct mlx5_ib_qp *)0;
#line 552
  err = 0;
#line 554
  tmp___0 = spinlock_check(& cq->lock);
#line 554
  flags = _raw_spin_lock_irqsave(tmp___0);
#line 556
  npolled = 0;
#line 556
  goto ldv_37834;
  ldv_37833: 
#line 557
  err = mlx5_poll_one(cq, & cur_qp, wc + (unsigned long )npolled);
#line 558
  if (err != 0) {
#line 559
    goto ldv_37832;
  } else {

  }
#line 556
  npolled = npolled + 1;
  ldv_37834: ;
#line 556
  if (npolled < num_entries) {
#line 558
    goto ldv_37833;
  } else {

  }
  ldv_37832: ;
#line 562
  if (npolled != 0) {
#line 563
    mlx5_cq_set_ci(& cq->mcq);
  } else {

  }
#line 565
  spin_unlock_irqrestore(& cq->lock, flags);
#line 567
  if (err == 0 || err == -11) {
#line 568
    return (npolled);
  } else {
#line 570
    return (err);
  }
}
}
#line 573 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
int mlx5_ib_arm_cq(struct ib_cq *ibcq , enum ib_cq_notify_flags flags ) 
{ 
  struct mlx5_core_dev *mdev ;
  struct mlx5_ib_dev *tmp ;
  void *uar_page ;
  struct mlx5_ib_cq *tmp___0 ;
  struct mlx5_ib_cq *tmp___1 ;

  {
#line 575
  tmp = to_mdev(ibcq->device);
#line 575
  mdev = tmp->mdev;
#line 576
  uar_page = (mdev->priv.uuari.uars)->map;
#line 578
  tmp___0 = to_mcq(ibcq);
#line 578
  tmp___1 = to_mcq(ibcq);
#line 578
  mlx5_cq_arm(& tmp___1->mcq, ((unsigned int )flags & 3U) == 1U ? 16777216U : 0U,
              uar_page, (spinlock_t *)0, tmp___0->mcq.cons_index);
#line 585
  return (0);
}
}
#line 588 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int alloc_cq_buf(struct mlx5_ib_dev *dev , struct mlx5_ib_cq_buf *buf , int nent ,
                        int cqe_size ) 
{ 
  int err ;

  {
#line 593
  err = mlx5_buf_alloc(dev->mdev, nent * cqe_size, & buf->buf);
#line 594
  if (err != 0) {
#line 595
    return (err);
  } else {

  }
#line 597
  buf->cqe_size = cqe_size;
#line 598
  buf->nent = nent;
#line 600
  return (0);
}
}
#line 603 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int create_cq_user(struct mlx5_ib_dev *dev , struct ib_udata *udata , struct ib_ucontext *context ,
                          struct mlx5_ib_cq *cq , int entries , struct mlx5_create_cq_mbox_in **cqb ,
                          int *cqe_size , int *index , int *inlen ) 
{ 
  struct mlx5_ib_create_cq ucmd ;
  size_t ucmdlen ;
  int page_shift ;
  int npages ;
  int ncont ;
  int err ;
  int tmp ;
  long tmp___0 ;
  bool tmp___1 ;
  struct mlx5_ib_ucontext *tmp___2 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  void *tmp___5 ;
  struct mlx5_ib_ucontext *tmp___6 ;
  struct mlx5_ib_ucontext *tmp___7 ;

  {
#line 615
  ucmdlen = udata->inlen - 8UL <= 23UL ? 20UL : 24UL;
#line 620
  tmp = ib_copy_from_udata((void *)(& ucmd), udata, ucmdlen);
#line 620
  if (tmp != 0) {
#line 621
    return (-14);
  } else {

  }
#line 623
  if (ucmdlen == 24UL && ucmd.reserved != 0U) {
#line 625
    return (-22);
  } else {

  }
#line 627
  if (ucmd.cqe_size != 64U && ucmd.cqe_size != 128U) {
#line 628
    return (-22);
  } else {

  }
#line 630
  *cqe_size = (int )ucmd.cqe_size;
#line 632
  cq->buf.umem = ib_umem_get(context, (unsigned long )ucmd.buf_addr, (size_t )(ucmd.cqe_size * (__u32 )entries),
                             1, 1);
#line 635
  tmp___1 = IS_ERR((void const   *)cq->buf.umem);
#line 635
  if ((int )tmp___1) {
#line 636
    tmp___0 = PTR_ERR((void const   *)cq->buf.umem);
#line 636
    err = (int )tmp___0;
#line 637
    return (err);
  } else {

  }
#line 640
  tmp___2 = to_mucontext(context);
#line 640
  err = mlx5_ib_db_map_user(tmp___2, (unsigned long )ucmd.db_addr, & cq->db);
#line 642
  if (err != 0) {
#line 643
    goto err_umem;
  } else {

  }
#line 645
  mlx5_ib_cont_pages(cq->buf.umem, ucmd.buf_addr, & npages, & page_shift, & ncont,
                     (int *)0);
#line 647
  descriptor.modname = "mlx5_ib";
#line 647
  descriptor.function = "create_cq_user";
#line 647
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c";
#line 647
  descriptor.format = "%s:%s:%d:(pid %d): addr 0x%llx, size %u, npages %d, page_shift %d, ncont %d\n";
#line 647
  descriptor.lineno = 648U;
#line 647
  descriptor.flags = 0U;
#line 647
  tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 647
  if (tmp___4 != 0L) {
#line 647
    tmp___3 = get_current();
#line 647
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): addr 0x%llx, size %u, npages %d, page_shift %d, ncont %d\n",
                       (char *)(& dev->ib_dev.name), "create_cq_user", 648, tmp___3->pid,
                       ucmd.buf_addr, ucmd.cqe_size * (__u32 )entries, npages, page_shift,
                       ncont);
  } else {

  }
#line 650
  *inlen = (int )((unsigned int )((unsigned long )ncont + 34UL) * 8U);
#line 651
  tmp___5 = mlx5_vzalloc((unsigned long )*inlen);
#line 651
  *cqb = (struct mlx5_create_cq_mbox_in *)tmp___5;
#line 652
  if ((unsigned long )*cqb == (unsigned long )((struct mlx5_create_cq_mbox_in *)0)) {
#line 653
    err = -12;
#line 654
    goto err_db;
  } else {

  }
#line 656
  mlx5_ib_populate_pas(dev, cq->buf.umem, page_shift, (__be64 *)(& (*cqb)->pas), 0);
#line 657
  (*cqb)->ctx.log_pg_sz = (unsigned int )((u8 )page_shift) + 244U;
#line 659
  tmp___6 = to_mucontext(context);
#line 659
  *index = (int )(tmp___6->uuari.uars)->index;
#line 661
  return (0);
  err_db: 
#line 664
  tmp___7 = to_mucontext(context);
#line 664
  mlx5_ib_db_unmap_user(tmp___7, & cq->db);
  err_umem: 
#line 667
  ib_umem_release(cq->buf.umem);
#line 668
  return (err);
}
}
#line 671 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void destroy_cq_user(struct mlx5_ib_cq *cq , struct ib_ucontext *context ) 
{ 
  struct mlx5_ib_ucontext *tmp ;

  {
#line 673
  tmp = to_mucontext(context);
#line 673
  mlx5_ib_db_unmap_user(tmp, & cq->db);
#line 674
  ib_umem_release(cq->buf.umem);
#line 675
  return;
}
}
#line 677 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void init_cq_buf(struct mlx5_ib_cq *cq , struct mlx5_ib_cq_buf *buf ) 
{ 
  int i ;
  void *cqe ;
  struct mlx5_cqe64 *cqe64 ;

  {
#line 683
  i = 0;
#line 683
  goto ldv_37881;
  ldv_37880: 
#line 684
  cqe = get_cqe_from_buf(buf, i, buf->cqe_size);
#line 685
  cqe64 = buf->cqe_size != 64 ? (struct mlx5_cqe64 *)cqe + 64U : (struct mlx5_cqe64 *)cqe;
#line 686
  cqe64->op_own = 240U;
#line 683
  i = i + 1;
  ldv_37881: ;
#line 683
  if (buf->nent > i) {
#line 685
    goto ldv_37880;
  } else {

  }

#line 690
  return;
}
}
#line 690 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int create_cq_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_cq *cq , int entries ,
                            int cqe_size , struct mlx5_create_cq_mbox_in **cqb , int *index ,
                            int *inlen ) 
{ 
  int err ;
  void *tmp ;

  {
#line 697
  err = mlx5_db_alloc(dev->mdev, & cq->db);
#line 698
  if (err != 0) {
#line 699
    return (err);
  } else {

  }
#line 701
  cq->mcq.set_ci_db = cq->db.db;
#line 702
  cq->mcq.arm_db = cq->db.db + 1UL;
#line 703
  cq->mcq.cqe_sz = cqe_size;
#line 705
  err = alloc_cq_buf(dev, & cq->buf, entries, cqe_size);
#line 706
  if (err != 0) {
#line 707
    goto err_db;
  } else {

  }
#line 709
  init_cq_buf(cq, & cq->buf);
#line 711
  *inlen = (int )((unsigned int )((unsigned long )cq->buf.buf.npages + 34UL) * 8U);
#line 712
  tmp = mlx5_vzalloc((unsigned long )*inlen);
#line 712
  *cqb = (struct mlx5_create_cq_mbox_in *)tmp;
#line 713
  if ((unsigned long )*cqb == (unsigned long )((struct mlx5_create_cq_mbox_in *)0)) {
#line 714
    err = -12;
#line 715
    goto err_buf;
  } else {

  }
#line 717
  mlx5_fill_page_array(& cq->buf.buf, (__be64 *)(& (*cqb)->pas));
#line 719
  (*cqb)->ctx.log_pg_sz = (unsigned int )cq->buf.buf.page_shift + 244U;
#line 720
  *index = (int )((dev->mdev)->priv.uuari.uars)->index;
#line 722
  return (0);
  err_buf: 
#line 725
  free_cq_buf(dev, & cq->buf);
  err_db: 
#line 728
  mlx5_db_free(dev->mdev, & cq->db);
#line 729
  return (err);
}
}
#line 732 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void destroy_cq_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_cq *cq ) 
{ 


  {
#line 734
  free_cq_buf(dev, & cq->buf);
#line 735
  mlx5_db_free(dev->mdev, & cq->db);
#line 736
  return;
}
}
#line 738 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
struct ib_cq *mlx5_ib_create_cq(struct ib_device *ibdev , struct ib_cq_init_attr  const  *attr ,
                                struct ib_ucontext *context , struct ib_udata *udata ) 
{ 
  int entries ;
  int vector ;
  struct mlx5_create_cq_mbox_in *cqb ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_cq *cq ;
  int index ;
  int inlen ;
  int cqe_size ;
  int irqn ;
  int eqn ;
  int err ;
  void *tmp___0 ;
  void *tmp___1 ;
  unsigned long tmp___2 ;
  void *tmp___3 ;
  __u32 tmp___4 ;
  void *tmp___5 ;
  void *tmp___6 ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  int tmp___7 ;
  int tmp___8 ;
  __u32 tmp___9 ;
  __u16 tmp___10 ;
  __u64 tmp___11 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___12 ;
  long tmp___13 ;
  int tmp___14 ;
  void *tmp___15 ;

  {
#line 743
  entries = (int )attr->cqe;
#line 744
  vector = attr->comp_vector;
#line 745
  cqb = (struct mlx5_create_cq_mbox_in *)0;
#line 746
  tmp = to_mdev(ibdev);
#line 746
  dev = tmp;
#line 748
  index = index;
#line 749
  inlen = inlen;
#line 755
  if ((unsigned int )attr->flags != 0U) {
#line 756
    tmp___0 = ERR_PTR(-22L);
#line 756
    return ((struct ib_cq *)tmp___0);
  } else {

  }
#line 758
  if (entries < 0) {
#line 759
    tmp___1 = ERR_PTR(-22L);
#line 759
    return ((struct ib_cq *)tmp___1);
  } else {

  }
#line 761
  tmp___2 = __roundup_pow_of_two((unsigned long )(entries + 1));
#line 761
  entries = (int )tmp___2;
#line 762
  tmp___4 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 6UL));
#line 762
  if (1 << ((int )(tmp___4 >> 16) & 255) < entries) {
#line 763
    tmp___3 = ERR_PTR(-22L);
#line 763
    return ((struct ib_cq *)tmp___3);
  } else {

  }
#line 765
  tmp___5 = kzalloc(568UL, 208U);
#line 765
  cq = (struct mlx5_ib_cq *)tmp___5;
#line 766
  if ((unsigned long )cq == (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 767
    tmp___6 = ERR_PTR(-12L);
#line 767
    return ((struct ib_cq *)tmp___6);
  } else {

  }
#line 769
  cq->ibcq.cqe = entries + -1;
#line 770
  __mutex_init(& cq->resize_mutex, "&cq->resize_mutex", & __key);
#line 771
  spinlock_check(& cq->lock);
#line 771
  __raw_spin_lock_init(& cq->lock.__annonCompField18.rlock, "&(&cq->lock)->rlock",
                       & __key___0);
#line 772
  cq->resize_buf = (struct mlx5_ib_cq_buf *)0;
#line 773
  cq->resize_umem = (struct ib_umem *)0;
#line 775
  if ((unsigned long )context != (unsigned long )((struct ib_ucontext *)0)) {
#line 776
    err = create_cq_user(dev, udata, context, cq, entries, & cqb, & cqe_size, & index,
                         & inlen);
#line 778
    if (err != 0) {
#line 779
      goto err_create;
    } else {

    }
  } else {
#line 782
    cqe_size = 64;
#line 783
    err = create_cq_kernel(dev, cq, entries, cqe_size, & cqb, & index, & inlen);
#line 785
    if (err != 0) {
#line 786
      goto err_create;
    } else {

    }
  }
#line 789
  cq->cqe_size = cqe_size;
#line 790
  tmp___7 = cqe_sz_to_mlx_sz((int )((u8 )cqe_size));
#line 790
  cqb->ctx.cqe_sz_flags = (int )((u8 )tmp___7) << 5U;
#line 791
  tmp___8 = __ilog2_u32((u32 )entries);
#line 791
  tmp___9 = __fswab32((__u32 )((tmp___8 << 24) | index));
#line 791
  cqb->ctx.log_sz_usr_page = tmp___9;
#line 792
  err = mlx5_vector2eqn(dev->mdev, vector, & eqn, & irqn);
#line 793
  if (err != 0) {
#line 794
    goto err_cqb;
  } else {

  }
#line 796
  tmp___10 = __fswab16((int )((__u16 )eqn));
#line 796
  cqb->ctx.c_eqn = tmp___10;
#line 797
  tmp___11 = __fswab64(cq->db.dma);
#line 797
  cqb->ctx.db_record_addr = tmp___11;
#line 799
  err = mlx5_core_create_cq(dev->mdev, & cq->mcq, cqb, inlen);
#line 800
  if (err != 0) {
#line 801
    goto err_cqb;
  } else {

  }
#line 803
  descriptor.modname = "mlx5_ib";
#line 803
  descriptor.function = "mlx5_ib_create_cq";
#line 803
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c";
#line 803
  descriptor.format = "%s:%s:%d:(pid %d): cqn 0x%x\n";
#line 803
  descriptor.lineno = 803U;
#line 803
  descriptor.flags = 0U;
#line 803
  tmp___13 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 803
  if (tmp___13 != 0L) {
#line 803
    tmp___12 = get_current();
#line 803
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): cqn 0x%x\n", (char *)(& dev->ib_dev.name),
                       "mlx5_ib_create_cq", 803, tmp___12->pid, cq->mcq.cqn);
  } else {

  }
#line 804
  cq->mcq.irqn = irqn;
#line 805
  cq->mcq.comp = & mlx5_ib_cq_comp;
#line 806
  cq->mcq.event = & mlx5_ib_cq_event;
#line 808
  if ((unsigned long )context != (unsigned long )((struct ib_ucontext *)0)) {
#line 809
    tmp___14 = ib_copy_to_udata(udata, (void *)(& cq->mcq.cqn), 4UL);
#line 809
    if (tmp___14 != 0) {
#line 810
      err = -14;
#line 811
      goto err_cmd;
    } else {

    }
  } else {

  }
#line 815
  kvfree((void const   *)cqb);
#line 816
  return (& cq->ibcq);
  err_cmd: 
#line 819
  mlx5_core_destroy_cq(dev->mdev, & cq->mcq);
  err_cqb: 
#line 822
  kvfree((void const   *)cqb);
#line 823
  if ((unsigned long )context != (unsigned long )((struct ib_ucontext *)0)) {
#line 824
    destroy_cq_user(cq, context);
  } else {
#line 826
    destroy_cq_kernel(dev, cq);
  }
  err_create: 
#line 829
  kfree((void const   *)cq);
#line 831
  tmp___15 = ERR_PTR((long )err);
#line 831
  return ((struct ib_cq *)tmp___15);
}
}
#line 835 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
int mlx5_ib_destroy_cq(struct ib_cq *cq ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_cq *mcq ;
  struct mlx5_ib_cq *tmp___0 ;
  struct ib_ucontext *context ;

  {
#line 837
  tmp = to_mdev(cq->device);
#line 837
  dev = tmp;
#line 838
  tmp___0 = to_mcq(cq);
#line 838
  mcq = tmp___0;
#line 839
  context = (struct ib_ucontext *)0;
#line 841
  if ((unsigned long )cq->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 842
    context = (cq->uobject)->context;
  } else {

  }
#line 844
  mlx5_core_destroy_cq(dev->mdev, & mcq->mcq);
#line 845
  if ((unsigned long )context != (unsigned long )((struct ib_ucontext *)0)) {
#line 846
    destroy_cq_user(mcq, context);
  } else {
#line 848
    destroy_cq_kernel(dev, mcq);
  }
#line 850
  kfree((void const   *)mcq);
#line 852
  return (0);
}
}
#line 855 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int is_equal_rsn(struct mlx5_cqe64 *cqe64 , u32 rsn ) 
{ 
  __u32 tmp ;

  {
#line 857
  tmp = __fswab32(cqe64->sop_drop_qpn);
#line 857
  return ((tmp & 16777215U) == rsn);
}
}
#line 860 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
void __mlx5_ib_cq_clean(struct mlx5_ib_cq *cq , u32 rsn , struct mlx5_ib_srq *srq ) 
{ 
  struct mlx5_cqe64 *cqe64 ;
  struct mlx5_cqe64 *dest64 ;
  void *cqe ;
  void *dest ;
  u32 prod_index ;
  int nfreed ;
  u8 owner_bit ;
  void *tmp ;
  __u16 tmp___0 ;
  __u32 tmp___1 ;
  int tmp___2 ;

  {
#line 865
  nfreed = 0;
#line 868
  if ((unsigned long )cq == (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 869
    return;
  } else {

  }
#line 877
  prod_index = cq->mcq.cons_index;
#line 877
  goto ldv_37947;
  ldv_37946: ;
#line 878
  if (cq->mcq.cons_index + (u32 )cq->ibcq.cqe == prod_index) {
#line 879
    goto ldv_37945;
  } else {

  }
#line 877
  prod_index = prod_index + 1U;
  ldv_37947: 
#line 877
  tmp = get_sw_cqe(cq, (int )prod_index);
#line 877
  if ((unsigned long )tmp != (unsigned long )((void *)0)) {
#line 879
    goto ldv_37946;
  } else {

  }
  ldv_37945: ;
#line 884
  goto ldv_37949;
  ldv_37948: 
#line 885
  cqe = get_cqe(cq, (int )((u32 )cq->ibcq.cqe & prod_index));
#line 886
  cqe64 = cq->mcq.cqe_sz != 64 ? (struct mlx5_cqe64 *)cqe + 64U : (struct mlx5_cqe64 *)cqe;
#line 887
  tmp___2 = is_equal_rsn(cqe64, rsn);
#line 887
  if (tmp___2 != 0) {
#line 888
    if ((unsigned long )srq != (unsigned long )((struct mlx5_ib_srq *)0)) {
#line 888
      tmp___1 = __fswab32(cqe64->srqn);
#line 888
      if ((tmp___1 & 16777215U) != 0U) {
#line 889
        tmp___0 = __fswab16((int )cqe64->wqe_counter);
#line 889
        mlx5_ib_free_srq_wqe(srq, (int )tmp___0);
      } else {

      }
    } else {

    }
#line 890
    nfreed = nfreed + 1;
  } else
#line 891
  if (nfreed != 0) {
#line 892
    dest = get_cqe(cq, (int )((prod_index + (u32 )nfreed) & (u32 )cq->ibcq.cqe));
#line 893
    dest64 = cq->mcq.cqe_sz != 64 ? (struct mlx5_cqe64 *)dest + 64U : (struct mlx5_cqe64 *)dest;
#line 894
    owner_bit = (unsigned int )dest64->op_own & 1U;
#line 895
    memcpy(dest, (void const   *)cqe, (size_t )cq->mcq.cqe_sz);
#line 896
    dest64->op_own = (u8 )(((int )((signed char )dest64->op_own) & -2) | (int )((signed char )owner_bit));
  } else {

  }
  ldv_37949: 
#line 884
  prod_index = prod_index - 1U;
#line 884
  if ((int )prod_index - (int )cq->mcq.cons_index >= 0) {
#line 886
    goto ldv_37948;
  } else {

  }

#line 901
  if (nfreed != 0) {
#line 902
    cq->mcq.cons_index = cq->mcq.cons_index + (u32 )nfreed;
#line 906
    __asm__  volatile   ("sfence": : : "memory");
#line 907
    mlx5_cq_set_ci(& cq->mcq);
  } else {

  }
#line 909
  return;
}
}
#line 911 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
void mlx5_ib_cq_clean(struct mlx5_ib_cq *cq , u32 qpn , struct mlx5_ib_srq *srq ) 
{ 


  {
#line 913
  if ((unsigned long )cq == (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 914
    return;
  } else {

  }
#line 916
  spin_lock_irq(& cq->lock);
#line 917
  __mlx5_ib_cq_clean(cq, qpn, srq);
#line 918
  spin_unlock_irq(& cq->lock);
#line 919
  return;
}
}
#line 921 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
int mlx5_ib_modify_cq(struct ib_cq *cq , u16 cq_count , u16 cq_period ) 
{ 
  struct mlx5_modify_cq_mbox_in *in ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_cq *mcq ;
  struct mlx5_ib_cq *tmp___0 ;
  int err ;
  u32 fsel ;
  __u32 tmp___1 ;
  void *tmp___2 ;
  __u32 tmp___3 ;
  __u16 tmp___4 ;
  __u16 tmp___5 ;
  __u32 tmp___6 ;
  struct task_struct *tmp___7 ;

  {
#line 924
  tmp = to_mdev(cq->device);
#line 924
  dev = tmp;
#line 925
  tmp___0 = to_mcq(cq);
#line 925
  mcq = tmp___0;
#line 929
  tmp___1 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 17UL));
#line 929
  if ((tmp___1 & 536870912U) == 0U) {
#line 930
    return (-38);
  } else {

  }
#line 932
  tmp___2 = kzalloc(272UL, 208U);
#line 932
  in = (struct mlx5_modify_cq_mbox_in *)tmp___2;
#line 933
  if ((unsigned long )in == (unsigned long )((struct mlx5_modify_cq_mbox_in *)0)) {
#line 934
    return (-12);
  } else {

  }
#line 936
  tmp___3 = __fswab32(mcq->mcq.cqn);
#line 936
  in->cqn = tmp___3;
#line 937
  fsel = 3U;
#line 938
  tmp___4 = __fswab16((int )cq_period);
#line 938
  in->ctx.cq_period = tmp___4;
#line 939
  tmp___5 = __fswab16((int )cq_count);
#line 939
  in->ctx.cq_max_count = tmp___5;
#line 940
  tmp___6 = __fswab32(fsel);
#line 940
  in->field_select = tmp___6;
#line 941
  err = mlx5_core_modify_cq(dev->mdev, & mcq->mcq, in, 272);
#line 942
  kfree((void const   *)in);
#line 944
  if (err != 0) {
#line 945
    tmp___7 = get_current();
#line 945
    printk("\f%s:%s:%d:(pid %d): modify cq 0x%x failed\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_modify_cq", 945, tmp___7->pid, mcq->mcq.cqn);
  } else {

  }
#line 947
  return (err);
}
}
#line 950 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int resize_user(struct mlx5_ib_dev *dev , struct mlx5_ib_cq *cq , int entries ,
                       struct ib_udata *udata , int *npas , int *page_shift , int *cqe_size ) 
{ 
  struct mlx5_ib_resize_cq ucmd ;
  struct ib_umem *umem ;
  int err ;
  int npages ;
  struct ib_ucontext *context ;
  long tmp ;
  bool tmp___0 ;

  {
#line 958
  context = (cq->buf.umem)->context;
#line 960
  err = ib_copy_from_udata((void *)(& ucmd), udata, 16UL);
#line 961
  if (err != 0) {
#line 962
    return (err);
  } else {

  }
#line 964
  if ((unsigned int )ucmd.reserved0 != 0U || ucmd.reserved1 != 0U) {
#line 965
    return (-22);
  } else {

  }
#line 967
  umem = ib_umem_get(context, (unsigned long )ucmd.buf_addr, (size_t )((int )ucmd.cqe_size * entries),
                     1, 1);
#line 969
  tmp___0 = IS_ERR((void const   *)umem);
#line 969
  if ((int )tmp___0) {
#line 970
    tmp = PTR_ERR((void const   *)umem);
#line 970
    err = (int )tmp;
#line 971
    return (err);
  } else {

  }
#line 974
  mlx5_ib_cont_pages(umem, ucmd.buf_addr, & npages, page_shift, npas, (int *)0);
#line 977
  cq->resize_umem = umem;
#line 978
  *cqe_size = (int )ucmd.cqe_size;
#line 980
  return (0);
}
}
#line 983 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void un_resize_user(struct mlx5_ib_cq *cq ) 
{ 


  {
#line 985
  ib_umem_release(cq->resize_umem);
#line 986
  return;
}
}
#line 988 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int resize_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_cq *cq , int entries ,
                         int cqe_size ) 
{ 
  int err ;
  void *tmp ;

  {
#line 993
  tmp = kzalloc(48UL, 208U);
#line 993
  cq->resize_buf = (struct mlx5_ib_cq_buf *)tmp;
#line 994
  if ((unsigned long )cq->resize_buf == (unsigned long )((struct mlx5_ib_cq_buf *)0)) {
#line 995
    return (-12);
  } else {

  }
#line 997
  err = alloc_cq_buf(dev, cq->resize_buf, entries, cqe_size);
#line 998
  if (err != 0) {
#line 999
    goto ex;
  } else {

  }
#line 1001
  init_cq_buf(cq, cq->resize_buf);
#line 1003
  return (0);
  ex: 
#line 1006
  kfree((void const   *)cq->resize_buf);
#line 1007
  return (err);
}
}
#line 1010 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static void un_resize_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_cq *cq ) 
{ 


  {
#line 1012
  free_cq_buf(dev, cq->resize_buf);
#line 1013
  cq->resize_buf = (struct mlx5_ib_cq_buf *)0;
#line 1014
  return;
}
}
#line 1016 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
static int copy_resize_cqes(struct mlx5_ib_cq *cq ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_cqe64 *scqe64 ;
  struct mlx5_cqe64 *dcqe64 ;
  void *start_cqe ;
  void *scqe ;
  void *dcqe ;
  int ssize ;
  int dsize ;
  int i ;
  u8 sw_own ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;

  {
#line 1018
  tmp = to_mdev(cq->ibcq.device);
#line 1018
  dev = tmp;
#line 1029
  ssize = cq->buf.cqe_size;
#line 1030
  dsize = (cq->resize_buf)->cqe_size;
#line 1031
  if (ssize != dsize) {
#line 1032
    tmp___0 = get_current();
#line 1032
    printk("\f%s:%s:%d:(pid %d): resize from different cqe size is not supported\n",
           (char *)(& dev->ib_dev.name), "copy_resize_cqes", 1032, tmp___0->pid);
#line 1033
    return (-22);
  } else {

  }
#line 1036
  i = (int )cq->mcq.cons_index;
#line 1037
  scqe = get_sw_cqe(cq, i);
#line 1038
  scqe64 = ssize != 64 ? (struct mlx5_cqe64 *)scqe + 64U : (struct mlx5_cqe64 *)scqe;
#line 1039
  start_cqe = scqe;
#line 1040
  if ((unsigned long )scqe == (unsigned long )((void *)0)) {
#line 1041
    tmp___1 = get_current();
#line 1041
    printk("\f%s:%s:%d:(pid %d): expected cqe in sw ownership\n", (char *)(& dev->ib_dev.name),
           "copy_resize_cqes", 1041, tmp___1->pid);
#line 1042
    return (-22);
  } else {

  }
#line 1045
  goto ldv_38011;
  ldv_38010: 
#line 1046
  dcqe = get_cqe_from_buf(cq->resize_buf, (i + 1) & (cq->resize_buf)->nent, dsize);
#line 1049
  dcqe64 = dsize != 64 ? (struct mlx5_cqe64 *)dcqe + 64U : (struct mlx5_cqe64 *)dcqe;
#line 1050
  sw_own = sw_ownership_bit(i + 1, (cq->resize_buf)->nent);
#line 1051
  memcpy(dcqe, (void const   *)scqe, (size_t )dsize);
#line 1052
  dcqe64->op_own = (u8 )(((int )((signed char )dcqe64->op_own) & -2) | (int )((signed char )sw_own));
#line 1054
  i = i + 1;
#line 1055
  scqe = get_sw_cqe(cq, i);
#line 1056
  scqe64 = ssize != 64 ? (struct mlx5_cqe64 *)scqe + 64U : (struct mlx5_cqe64 *)scqe;
#line 1057
  if ((unsigned long )scqe == (unsigned long )((void *)0)) {
#line 1058
    tmp___2 = get_current();
#line 1058
    printk("\f%s:%s:%d:(pid %d): expected cqe in sw ownership\n", (char *)(& dev->ib_dev.name),
           "copy_resize_cqes", 1058, tmp___2->pid);
#line 1059
    return (-22);
  } else {

  }
#line 1062
  if ((unsigned long )scqe == (unsigned long )start_cqe) {
#line 1063
    printk("\fresize CQ failed to get resize CQE, CQN 0x%x\n", cq->mcq.cqn);
#line 1065
    return (-12);
  } else {

  }
  ldv_38011: ;
#line 1045
  if ((unsigned int )((int )scqe64->op_own >> 4) != 5U) {
#line 1047
    goto ldv_38010;
  } else {

  }
#line 1068
  cq->mcq.cons_index = cq->mcq.cons_index + 1U;
#line 1069
  return (0);
}
}
#line 1072 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
int mlx5_ib_resize_cq(struct ib_cq *ibcq , int entries , struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_cq *cq ;
  struct mlx5_ib_cq *tmp___0 ;
  struct mlx5_modify_cq_mbox_in *in ;
  int err ;
  int npas ;
  int page_shift ;
  int inlen ;
  int cqe_size ;
  unsigned long flags ;
  __u32 tmp___1 ;
  unsigned long tmp___2 ;
  __u32 tmp___3 ;
  void *tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  struct mlx5_ib_cq_buf tbuf ;
  int resized ;
  raw_spinlock_t *tmp___9 ;

  {
#line 1074
  tmp = to_mdev(ibcq->device);
#line 1074
  dev = tmp;
#line 1075
  tmp___0 = to_mcq(ibcq);
#line 1075
  cq = tmp___0;
#line 1081
  cqe_size = cqe_size;
#line 1084
  tmp___1 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 17UL));
#line 1084
  if ((tmp___1 & 1073741824U) == 0U) {
#line 1085
    printk("\016Firmware does not support resize CQ\n");
#line 1086
    return (-38);
  } else {

  }
#line 1089
  if (entries <= 0) {
#line 1090
    return (-22);
  } else {

  }
#line 1092
  tmp___2 = __roundup_pow_of_two((unsigned long )(entries + 1));
#line 1092
  entries = (int )tmp___2;
#line 1093
  tmp___3 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 6UL));
#line 1093
  if ((1 << ((int )(tmp___3 >> 16) & 255)) + 1 < entries) {
#line 1094
    return (-22);
  } else {

  }
#line 1096
  if (ibcq->cqe + 1 == entries) {
#line 1097
    return (0);
  } else {

  }
#line 1099
  mutex_lock_nested(& cq->resize_mutex, 0U);
#line 1100
  if ((unsigned long )udata != (unsigned long )((struct ib_udata *)0)) {
#line 1101
    err = resize_user(dev, cq, entries, udata, & npas, & page_shift, & cqe_size);
  } else {
#line 1104
    cqe_size = 64;
#line 1105
    err = resize_kernel(dev, cq, entries, cqe_size);
#line 1106
    if (err == 0) {
#line 1107
      npas = (cq->resize_buf)->buf.npages;
#line 1108
      page_shift = (int )(cq->resize_buf)->buf.page_shift;
    } else {

    }
  }
#line 1112
  if (err != 0) {
#line 1113
    goto ex;
  } else {

  }
#line 1115
  inlen = (int )((unsigned int )((unsigned long )npas + 34UL) * 8U);
#line 1116
  tmp___4 = mlx5_vzalloc((unsigned long )inlen);
#line 1116
  in = (struct mlx5_modify_cq_mbox_in *)tmp___4;
#line 1117
  if ((unsigned long )in == (unsigned long )((struct mlx5_modify_cq_mbox_in *)0)) {
#line 1118
    err = -12;
#line 1119
    goto ex_resize;
  } else {

  }
#line 1122
  if ((unsigned long )udata != (unsigned long )((struct ib_udata *)0)) {
#line 1123
    mlx5_ib_populate_pas(dev, cq->resize_umem, page_shift, (__be64 *)(& in->pas),
                         0);
  } else {
#line 1126
    mlx5_fill_page_array(& (cq->resize_buf)->buf, (__be64 *)(& in->pas));
  }
#line 1128
  in->field_select = 117440512U;
#line 1131
  in->ctx.log_pg_sz = (unsigned int )((u8 )page_shift) + 244U;
#line 1132
  tmp___5 = cqe_sz_to_mlx_sz((int )((u8 )cqe_size));
#line 1132
  in->ctx.cqe_sz_flags = (int )((u8 )tmp___5) << 5U;
#line 1133
  in->ctx.page_offset = 0U;
#line 1134
  tmp___6 = __ilog2_u32((u32 )entries);
#line 1134
  tmp___7 = __fswab32((__u32 )(tmp___6 << 24));
#line 1134
  in->ctx.log_sz_usr_page = tmp___7;
#line 1135
  in->hdr.opmod = 256U;
#line 1136
  tmp___8 = __fswab32(cq->mcq.cqn);
#line 1136
  in->cqn = tmp___8;
#line 1138
  err = mlx5_core_modify_cq(dev->mdev, & cq->mcq, in, inlen);
#line 1139
  if (err != 0) {
#line 1140
    goto ex_alloc;
  } else {

  }
#line 1142
  if ((unsigned long )udata != (unsigned long )((struct ib_udata *)0)) {
#line 1143
    cq->ibcq.cqe = entries + -1;
#line 1144
    ib_umem_release(cq->buf.umem);
#line 1145
    cq->buf.umem = cq->resize_umem;
#line 1146
    cq->resize_umem = (struct ib_umem *)0;
  } else {
#line 1149
    resized = 0;
#line 1151
    tmp___9 = spinlock_check(& cq->lock);
#line 1151
    flags = _raw_spin_lock_irqsave(tmp___9);
#line 1152
    if ((unsigned long )cq->resize_buf != (unsigned long )((struct mlx5_ib_cq_buf *)0)) {
#line 1153
      err = copy_resize_cqes(cq);
#line 1154
      if (err == 0) {
#line 1155
        tbuf = cq->buf;
#line 1156
        cq->buf = *(cq->resize_buf);
#line 1157
        kfree((void const   *)cq->resize_buf);
#line 1158
        cq->resize_buf = (struct mlx5_ib_cq_buf *)0;
#line 1159
        resized = 1;
      } else {

      }
    } else {

    }
#line 1162
    cq->ibcq.cqe = entries + -1;
#line 1163
    spin_unlock_irqrestore(& cq->lock, flags);
#line 1164
    if (resized != 0) {
#line 1165
      free_cq_buf(dev, & tbuf);
    } else {

    }
  }
#line 1167
  mutex_unlock(& cq->resize_mutex);
#line 1169
  kvfree((void const   *)in);
#line 1170
  return (0);
  ex_alloc: 
#line 1173
  kvfree((void const   *)in);
  ex_resize: ;
#line 1176
  if ((unsigned long )udata != (unsigned long )((struct ib_udata *)0)) {
#line 1177
    un_resize_user(cq);
  } else {
#line 1179
    un_resize_kernel(dev, cq);
  }
  ex: 
#line 1181
  mutex_unlock(& cq->resize_mutex);
#line 1182
  return (err);
}
}
#line 1185 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.c"
int mlx5_ib_get_cqe_size(struct mlx5_ib_dev *dev , struct ib_cq *ibcq ) 
{ 
  struct mlx5_ib_cq *cq ;

  {
#line 1189
  if ((unsigned long )ibcq == (unsigned long )((struct ib_cq *)0)) {
#line 1190
    return (128);
  } else {

  }
#line 1192
  cq = to_mcq(ibcq);
#line 1193
  return (cq->cqe_size);
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.o.c.prepared"
bool ldv_queue_work_on_19(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.o.c.prepared"
bool ldv_queue_delayed_work_on_20(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.o.c.prepared"
bool ldv_queue_work_on_21(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.o.c.prepared"
void ldv_flush_workqueue_22(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/cq.o.c.prepared"
bool ldv_queue_delayed_work_on_23(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 48 "include/linux/list.h"
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
#line 61 "include/linux/list.h"
__inline static void list_add(struct list_head *new , struct list_head *head ) 
{ 


  {
#line 63
  __list_add(new, head, head->next);
#line 64
  return;
}
}
#line 113
extern void list_del(struct list_head * ) ;
#line 32 "include/linux/err.h"
__inline static long PTR_ERR(void const   *ptr ) ;
#line 41
__inline static bool IS_ERR(void const   *ptr ) ;
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_33(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_35(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_34(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_37(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_36(struct workqueue_struct *ldv_func_arg1 ) ;
#line 46 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.c"
int mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context , unsigned long virt , struct mlx5_db *db ) 
{ 
  struct mlx5_ib_user_db_page *page ;
  int err ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  void *tmp ;
  long tmp___0 ;
  bool tmp___1 ;

  {
#line 50
  err = 0;
#line 52
  mutex_lock_nested(& context->db_page_mutex, 0U);
#line 54
  __mptr = (struct list_head  const  *)context->db_page_list.next;
#line 54
  page = (struct mlx5_ib_user_db_page *)__mptr;
#line 54
  goto ldv_36942;
  ldv_36941: ;
#line 55
  if (page->user_virt == (virt & 0xfffffffffffff000UL)) {
#line 56
    goto found;
  } else {

  }
#line 54
  __mptr___0 = (struct list_head  const  *)page->list.next;
#line 54
  page = (struct mlx5_ib_user_db_page *)__mptr___0;
  ldv_36942: ;
#line 54
  if ((unsigned long )(& page->list) != (unsigned long )(& context->db_page_list)) {
#line 56
    goto ldv_36941;
  } else {

  }
#line 58
  tmp = kmalloc(40UL, 208U);
#line 58
  page = (struct mlx5_ib_user_db_page *)tmp;
#line 59
  if ((unsigned long )page == (unsigned long )((struct mlx5_ib_user_db_page *)0)) {
#line 60
    err = -12;
#line 61
    goto out;
  } else {

  }
#line 64
  page->user_virt = virt & 0xfffffffffffff000UL;
#line 65
  page->refcnt = 0;
#line 66
  page->umem = ib_umem_get(& context->ibucontext, virt & 0xfffffffffffff000UL, 4096UL,
                           0, 0);
#line 68
  tmp___1 = IS_ERR((void const   *)page->umem);
#line 68
  if ((int )tmp___1) {
#line 69
    tmp___0 = PTR_ERR((void const   *)page->umem);
#line 69
    err = (int )tmp___0;
#line 70
    kfree((void const   *)page);
#line 71
    goto out;
  } else {

  }
#line 74
  list_add(& page->list, & context->db_page_list);
  found: 
#line 77
  db->dma = ((page->umem)->sg_head.sgl)->dma_address + ((unsigned long long )virt & 4095ULL);
#line 78
  db->u.user_page = page;
#line 79
  page->refcnt = page->refcnt + 1;
  out: 
#line 82
  mutex_unlock(& context->db_page_mutex);
#line 84
  return (err);
}
}
#line 87 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.c"
void mlx5_ib_db_unmap_user(struct mlx5_ib_ucontext *context , struct mlx5_db *db ) 
{ 


  {
#line 89
  mutex_lock_nested(& context->db_page_mutex, 0U);
#line 91
  (db->u.user_page)->refcnt = (db->u.user_page)->refcnt - 1;
#line 91
  if ((db->u.user_page)->refcnt == 0) {
#line 92
    list_del(& (db->u.user_page)->list);
#line 93
    ib_umem_release((db->u.user_page)->umem);
#line 94
    kfree((void const   *)db->u.user_page);
  } else {

  }
#line 97
  mutex_unlock(& context->db_page_mutex);
#line 98
  return;
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.o.c.prepared"
bool ldv_queue_work_on_33(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.o.c.prepared"
bool ldv_queue_delayed_work_on_34(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.o.c.prepared"
bool ldv_queue_work_on_35(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.o.c.prepared"
void ldv_flush_workqueue_36(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/doorbell.o.c.prepared"
bool ldv_queue_delayed_work_on_37(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 110 "./arch/x86/include/asm/bitops.h"
__inline static void clear_bit(long nr , unsigned long volatile   *addr ) 
{ 


  {
#line 117
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; btr %1,%0": "+m" (*((long volatile   *)addr)): "Ir" (nr));
#line 119
  return;
}
}
#line 314 "./arch/x86/include/asm/bitops.h"
__inline static int variable_test_bit(long nr , unsigned long const volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 318
  __asm__  volatile   ("bt %2,%1\n\tsbb %0,%0": "=r" (oldbit): "m" (*((unsigned long *)addr)),
                       "Ir" (nr));
#line 323
  return (oldbit);
}
}
#line 23 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) ;
#line 32
__inline static long PTR_ERR(void const   *ptr ) ;
#line 41
__inline static bool IS_ERR(void const   *ptr ) ;
#line 22 "include/linux/spinlock_api_smp.h"
extern void _raw_spin_lock(raw_spinlock_t * ) ;
#line 23
extern void _raw_spin_lock_nested(raw_spinlock_t * , int  ) ;
#line 41
extern void _raw_spin_unlock(raw_spinlock_t * ) ;
#line 310 "include/linux/spinlock.h"
__inline static void spin_lock(spinlock_t *lock ) 
{ 


  {
#line 312
  _raw_spin_lock(& lock->__annonCompField18.rlock);
#line 313
  return;
}
}
#line 355 "include/linux/spinlock.h"
__inline static void spin_unlock(spinlock_t *lock ) 
{ 


  {
#line 357
  _raw_spin_unlock(& lock->__annonCompField18.rlock);
#line 358
  return;
}
}
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_47(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_49(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_48(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_51(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_50(struct workqueue_struct *ldv_func_arg1 ) ;
#line 459
void ldv_flush_workqueue_52(struct workqueue_struct *ldv_func_arg1 ) ;
#line 89 "include/rdma/ib_umem.h"
extern int ib_umem_copy_from(void * , struct ib_umem * , size_t  , size_t  ) ;
#line 1809 "include/rdma/ib_verbs.h"
extern int ib_modify_qp_is_ok(enum ib_qp_state  , enum ib_qp_state  , enum ib_qp_type  ,
                              enum ib_qp_attr_mask  , enum rdma_link_layer  ) ;
#line 798 "include/linux/mlx5/driver.h"
__inline static u8 mlx5_mkey_variant(u32 mkey ) 
{ 


  {
#line 800
  return ((u8 )mkey);
}
}
#line 619 "include/linux/mlx5/qp.h"
extern int mlx5_core_create_qp(struct mlx5_core_dev * , struct mlx5_core_qp * , struct mlx5_create_qp_mbox_in * ,
                               int  ) ;
#line 623
extern int mlx5_core_qp_modify(struct mlx5_core_dev * , enum mlx5_qp_state  , enum mlx5_qp_state  ,
                               struct mlx5_modify_qp_mbox_in * , int  , struct mlx5_core_qp * ) ;
#line 627
extern int mlx5_core_destroy_qp(struct mlx5_core_dev * , struct mlx5_core_qp * ) ;
#line 629
extern int mlx5_core_qp_query(struct mlx5_core_dev * , struct mlx5_core_qp * , struct mlx5_query_qp_mbox_out * ,
                              int  ) ;
#line 632
extern int mlx5_core_xrcd_alloc(struct mlx5_core_dev * , u32 * ) ;
#line 633
extern int mlx5_core_xrcd_dealloc(struct mlx5_core_dev * , u32  ) ;
#line 452 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_xrcd *to_mxrcd(struct ib_xrcd *ibxrcd ) 
{ 
  struct ib_xrcd  const  *__mptr ;

  {
#line 454
  __mptr = (struct ib_xrcd  const  *)ibxrcd;
#line 454
  return ((struct mlx5_ib_xrcd *)__mptr);
}
}
#line 492 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_qp *to_mqp(struct ib_qp *ibqp ) 
{ 
  struct ib_qp  const  *__mptr ;

  {
#line 494
  __mptr = (struct ib_qp  const  *)ibqp;
#line 494
  return ((struct mlx5_ib_qp *)__mptr);
}
}
#line 502 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_mr *to_mmr(struct ib_mr *ibmr ) 
{ 
  struct ib_mr  const  *__mptr ;

  {
#line 504
  __mptr = (struct ib_mr  const  *)ibmr;
#line 504
  return ((struct mlx5_ib_mr *)__mptr);
}
}
#line 507 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_fast_reg_page_list *to_mfrpl(struct ib_fast_reg_page_list *ibfrpl ) 
{ 
  struct ib_fast_reg_page_list  const  *__mptr ;

  {
#line 509
  __mptr = (struct ib_fast_reg_page_list  const  *)ibfrpl;
#line 509
  return ((struct mlx5_ib_fast_reg_page_list *)__mptr);
}
}
#line 517 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static struct mlx5_ib_ah *to_mah(struct ib_ah *ibah ) 
{ 
  struct ib_ah  const  *__mptr ;

  {
#line 519
  __mptr = (struct ib_ah  const  *)ibah;
#line 519
  return ((struct mlx5_ib_ah *)__mptr);
}
}
#line 558
int mlx5_ib_read_user_wqe(struct mlx5_ib_qp *qp , int send , int wqe_index , void *buffer ,
                          u32 length ) ;
#line 599
int mlx5_ib_get_buf_offset(u64 addr , int page_shift , u32 *offset ) ;
#line 638
struct workqueue_struct *mlx5_ib_page_fault_wq ;
#line 643
void mlx5_ib_odp_create_qp(struct mlx5_ib_qp *qp ) ;
#line 648
void mlx5_ib_qp_disable_pagefaults(struct mlx5_ib_qp *qp ) ;
#line 649
void mlx5_ib_qp_enable_pagefaults(struct mlx5_ib_qp *qp ) ;
#line 677 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static u8 convert_access(int acc ) 
{ 


  {
#line 679
  return ((u8 )((((((acc & 8) != 0 ? 64 : 0) | ((acc & 2) != 0 ? 32 : 0)) | ((acc & 4) != 0 ? 16 : 0)) | (acc & 1 ? 8 : 0)) | 4));
}
}
#line 39 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int wq_signature  ;
#line 57 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u32 const   mlx5_ib_opcode[241U]  = 
#line 57
  {      8U,      9U,      10U,      11U, 
        16U,      17U,      18U,      0U, 
        1U,      0U,      37U,      37U, 
        20U,      21U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        0U,      0U,      0U,      0U, 
        37U};
#line 74 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int is_qp0(enum ib_qp_type qp_type ) 
{ 


  {
#line 76
  return ((unsigned int )qp_type == 0U);
}
}
#line 79 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int is_qp1(enum ib_qp_type qp_type ) 
{ 


  {
#line 81
  return ((unsigned int )qp_type == 1U);
}
}
#line 84 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int is_sqp(enum ib_qp_type qp_type ) 
{ 
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 86
  tmp = is_qp0(qp_type);
#line 86
  if (tmp != 0) {
#line 86
    tmp___1 = 1;
  } else {
#line 86
    tmp___0 = is_qp1(qp_type);
#line 86
    if (tmp___0 != 0) {
#line 86
      tmp___1 = 1;
    } else {
#line 86
      tmp___1 = 0;
    }
  }
#line 86
  return (tmp___1);
}
}
#line 89 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void *get_wqe(struct mlx5_ib_qp *qp , int offset ) 
{ 
  void *tmp ;

  {
#line 91
  tmp = mlx5_buf_offset(& qp->buf, offset);
#line 91
  return (tmp);
}
}
#line 94 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void *get_recv_wqe(struct mlx5_ib_qp *qp , int n ) 
{ 
  void *tmp ;

  {
#line 96
  tmp = get_wqe(qp, qp->rq.offset + (n << qp->rq.wqe_shift));
#line 96
  return (tmp);
}
}
#line 99 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
void *mlx5_get_send_wqe(struct mlx5_ib_qp *qp , int n ) 
{ 
  void *tmp ;

  {
#line 101
  tmp = get_wqe(qp, qp->sq.offset + (n << 6));
#line 101
  return (tmp);
}
}
#line 121 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_read_user_wqe(struct mlx5_ib_qp *qp , int send , int wqe_index , void *buffer ,
                          u32 length ) 
{ 
  struct ib_device *ibdev ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_wq *wq ;
  size_t offset ;
  size_t wq_end ;
  struct ib_umem *umem ;
  u32 first_copy_length ;
  int wqe_length ;
  int ret ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  u32 __min1 ;
  u32 __min2 ;
  struct mlx5_wqe_ctrl_seg *ctrl ;
  int ds ;
  __u32 tmp___2 ;

  {
#line 124
  ibdev = qp->ibqp.device;
#line 125
  tmp = to_mdev(ibdev);
#line 125
  dev = tmp;
#line 126
  wq = send != 0 ? & qp->sq : & qp->rq;
#line 129
  umem = qp->umem;
#line 134
  if (wq->wqe_cnt == 0) {
#line 135
    descriptor.modname = "mlx5_ib";
#line 135
    descriptor.function = "mlx5_ib_read_user_wqe";
#line 135
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 135
    descriptor.format = "%s:%s:%d:(pid %d): mlx5_ib_read_user_wqe for a QP with wqe_cnt == 0. qp_type: 0x%x\n";
#line 135
    descriptor.lineno = 136U;
#line 135
    descriptor.flags = 0U;
#line 135
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 135
    if (tmp___1 != 0L) {
#line 135
      tmp___0 = get_current();
#line 135
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): mlx5_ib_read_user_wqe for a QP with wqe_cnt == 0. qp_type: 0x%x\n",
                         (char *)(& dev->ib_dev.name), "mlx5_ib_read_user_wqe", 136,
                         tmp___0->pid, (unsigned int )qp->ibqp.qp_type);
    } else {

    }
#line 137
    return (-22);
  } else {

  }
#line 140
  offset = (size_t )(wq->offset + (wqe_index % wq->wqe_cnt << wq->wqe_shift));
#line 141
  wq_end = (size_t )(wq->offset + (wq->wqe_cnt << wq->wqe_shift));
#line 143
  if (send != 0 && length <= 15U) {
#line 144
    return (-22);
  } else {

  }
#line 146
  if (umem->length < offset || (send != 0 && offset + 16UL > umem->length)) {
#line 148
    return (-22);
  } else {

  }
#line 150
  __min1 = (u32 )offset + length;
#line 150
  __min2 = (u32 )wq_end;
#line 150
  first_copy_length = (__min1 < __min2 ? __min1 : __min2) - (u32 )offset;
#line 151
  ret = ib_umem_copy_from(buffer, umem, offset, (size_t )first_copy_length);
#line 152
  if (ret != 0) {
#line 153
    return (ret);
  } else {

  }
#line 155
  if (send != 0) {
#line 156
    ctrl = (struct mlx5_wqe_ctrl_seg *)buffer;
#line 157
    tmp___2 = __fswab32(ctrl->qpn_ds);
#line 157
    ds = (int )tmp___2 & 63;
#line 159
    wqe_length = ds * 16;
  } else {
#line 161
    wqe_length = 1 << wq->wqe_shift;
  }
#line 164
  if ((u32 )wqe_length <= first_copy_length) {
#line 165
    return ((int )first_copy_length);
  } else {

  }
#line 167
  ret = ib_umem_copy_from(buffer + (unsigned long )first_copy_length, umem, (size_t )wq->offset,
                          (size_t )((u32 )wqe_length - first_copy_length));
#line 169
  if (ret != 0) {
#line 170
    return (ret);
  } else {

  }
#line 172
  return (wqe_length);
}
}
#line 175 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void mlx5_ib_qp_event(struct mlx5_core_qp *qp , int type ) 
{ 
  struct ib_qp *ibqp ;
  struct mlx5_ib_qp *tmp ;
  struct ib_event event ;
  struct mlx5_ib_qp *tmp___0 ;
  struct mlx5_ib_qp *tmp___1 ;

  {
#line 177
  tmp = to_mibqp(qp);
#line 177
  ibqp = & tmp->ibqp;
#line 180
  if (type == 1) {
#line 181
    tmp___0 = to_mibqp(qp);
#line 181
    tmp___1 = to_mibqp(qp);
#line 181
    tmp___0->port = tmp___1->alt_port;
  } else {

  }
#line 183
  if ((unsigned long )ibqp->event_handler != (unsigned long )((void (*)(struct ib_event * ,
                                                                        void * ))0)) {
#line 184
    event.device = ibqp->device;
#line 185
    event.element.qp = ibqp;
#line 186
    switch (type) {
    case 1: 
#line 188
    event.event = 6;
#line 189
    goto ldv_37049;
    case 2: 
#line 191
    event.event = 4;
#line 192
    goto ldv_37049;
    case 3: 
#line 194
    event.event = 5;
#line 195
    goto ldv_37049;
    case 19: 
#line 197
    event.event = 16;
#line 198
    goto ldv_37049;
    case 5: 
#line 200
    event.event = 1;
#line 201
    goto ldv_37049;
    case 7: 
#line 203
    event.event = 7;
#line 204
    goto ldv_37049;
    case 16: 
#line 206
    event.event = 2;
#line 207
    goto ldv_37049;
    case 17: 
#line 209
    event.event = 3;
#line 210
    goto ldv_37049;
    default: 
#line 212
    printk("\fmlx5_ib: Unexpected event type %d on QP %06x\n", type, qp->qpn);
#line 213
    return;
    }
    ldv_37049: 
#line 216
    (*(ibqp->event_handler))(& event, ibqp->qp_context);
  } else {

  }
#line 218
  return;
}
}
#line 220 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_rq_size(struct mlx5_ib_dev *dev , struct ib_qp_cap *cap , int has_rq ,
                       struct mlx5_ib_qp *qp , struct mlx5_ib_create_qp *ucmd ) 
{ 
  int wqe_size ;
  int wq_size ;
  __u32 tmp ;
  unsigned long tmp___0 ;
  unsigned long tmp___1 ;
  int __max1 ;
  int __max2 ;
  struct _ddebug descriptor ;
  __u32 tmp___2 ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  __u32 tmp___5 ;

  {
#line 227
  tmp = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 227
  if (cap->max_recv_wr > (u32 )(1 << ((int )(tmp >> 16) & 255))) {
#line 228
    return (-22);
  } else {

  }
#line 230
  if (has_rq == 0) {
#line 231
    qp->rq.max_gs = 0;
#line 232
    qp->rq.wqe_cnt = 0;
#line 233
    qp->rq.wqe_shift = 0;
  } else
#line 235
  if ((unsigned long )ucmd != (unsigned long )((struct mlx5_ib_create_qp *)0)) {
#line 236
    qp->rq.wqe_cnt = (int )ucmd->rq_wqe_count;
#line 237
    qp->rq.wqe_shift = (int )ucmd->rq_wqe_shift;
#line 238
    qp->rq.max_gs = (int )((unsigned int )((unsigned long )(1 << qp->rq.wqe_shift) / 16UL) - (unsigned int )qp->wq_sig);
#line 239
    qp->rq.max_post = qp->rq.wqe_cnt;
  } else {
#line 241
    wqe_size = qp->wq_sig != 0 ? 16 : 0;
#line 242
    wqe_size = (int )(cap->max_recv_sge * 16U + (unsigned int )wqe_size);
#line 243
    tmp___0 = __roundup_pow_of_two((unsigned long )wqe_size);
#line 243
    wqe_size = (int )tmp___0;
#line 244
    tmp___1 = __roundup_pow_of_two((unsigned long )cap->max_recv_wr);
#line 244
    wq_size = (int )((unsigned int )tmp___1 * (unsigned int )((unsigned long )wqe_size));
#line 245
    __max1 = wq_size;
#line 245
    __max2 = 64;
#line 245
    wq_size = __max1 > __max2 ? __max1 : __max2;
#line 246
    qp->rq.wqe_cnt = wq_size / wqe_size;
#line 247
    tmp___5 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 21UL));
#line 247
    if ((unsigned int )wqe_size > (tmp___5 & 65535U)) {
#line 248
      descriptor.modname = "mlx5_ib";
#line 248
      descriptor.function = "set_rq_size";
#line 248
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 248
      descriptor.format = "%s:%s:%d:(pid %d): wqe_size %d, max %d\n";
#line 248
      descriptor.lineno = 251U;
#line 248
      descriptor.flags = 0U;
#line 248
      tmp___4 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 248
      if (tmp___4 != 0L) {
#line 248
        tmp___2 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 21UL));
#line 248
        tmp___3 = get_current();
#line 248
        __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): wqe_size %d, max %d\n",
                           (char *)(& dev->ib_dev.name), "set_rq_size", 251, tmp___3->pid,
                           wqe_size, tmp___2 & 65535U);
      } else {

      }
#line 252
      return (-22);
    } else {

    }
#line 254
    qp->rq.wqe_shift = __ilog2_u32((u32 )wqe_size);
#line 255
    qp->rq.max_gs = (int )((unsigned int )((unsigned long )(1 << qp->rq.wqe_shift) / 16UL) - (unsigned int )qp->wq_sig);
#line 256
    qp->rq.max_post = qp->rq.wqe_cnt;
  }
#line 260
  return (0);
}
}
#line 263 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int sq_overhead(enum ib_qp_type qp_type ) 
{ 
  int size ;

  {
#line 265
  size = 0;
#line 267
  switch ((unsigned int )qp_type) {
  case 9U: 
#line 269
  size = (int )((unsigned int )size + 16U);
  case 2U: 
#line 272
  size = (int )((unsigned int )size + 48U);
#line 275
  goto ldv_37078;
  case 10U: ;
#line 278
  return (0);
  case 3U: 
#line 281
  size = (int )((unsigned int )size + 144U);
#line 285
  goto ldv_37078;
  case 4U: ;
  case 0U: ;
  case 1U: 
#line 290
  size = (int )((unsigned int )size + 64U);
#line 292
  goto ldv_37078;
  case 4096U: 
#line 295
  size = (int )((unsigned int )size + 128U);
#line 298
  goto ldv_37078;
  default: ;
#line 301
  return (-22);
  }
  ldv_37078: ;
#line 304
  return (size);
}
}
#line 307 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int calc_send_wqe(struct ib_qp_init_attr *attr ) 
{ 
  int inl_size ;
  int size ;
  int __max1 ;
  int __max2 ;
  int __max1___0 ;
  int __max2___0 ;

  {
#line 309
  inl_size = 0;
#line 312
  size = sq_overhead(attr->qp_type);
#line 313
  if (size < 0) {
#line 314
    return (size);
  } else {

  }
#line 316
  if (attr->cap.max_inline_data != 0U) {
#line 317
    inl_size = (int )((attr->cap.max_inline_data + (unsigned int )size) + 4U);
  } else {

  }
#line 321
  size = (int )(attr->cap.max_send_sge * 16U + (unsigned int )size);
#line 323
  if (((int )attr->create_flags & 64) != 0) {
#line 323
    __max1___0 = inl_size;
#line 323
    __max2___0 = size;
#line 323
    if ((((__max1___0 > __max2___0 ? __max1___0 : __max2___0) + 63) & -64) <= 319) {
#line 324
      return (320);
    } else {
#line 326
      __max1 = inl_size;
#line 326
      __max2 = size;
#line 326
      return (((__max1 > __max2 ? __max1 : __max2) + 63) & -64);
    }
  } else {
#line 326
    __max1 = inl_size;
#line 326
    __max2 = size;
#line 326
    return (((__max1 > __max2 ? __max1 : __max2) + 63) & -64);
  }
}
}
#line 329 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int calc_sq_size(struct mlx5_ib_dev *dev , struct ib_qp_init_attr *attr , struct mlx5_ib_qp *qp ) 
{ 
  int wqe_size ;
  int wq_size ;
  struct _ddebug descriptor ;
  struct task_struct *tmp ;
  long tmp___0 ;
  struct _ddebug descriptor___0 ;
  __u32 tmp___1 ;
  struct task_struct *tmp___2 ;
  long tmp___3 ;
  __u32 tmp___4 ;
  int tmp___5 ;
  unsigned long tmp___6 ;
  struct _ddebug descriptor___1 ;
  __u32 tmp___7 ;
  struct task_struct *tmp___8 ;
  long tmp___9 ;
  __u32 tmp___10 ;

  {
#line 335
  if (attr->cap.max_send_wr == 0U) {
#line 336
    return (0);
  } else {

  }
#line 338
  wqe_size = calc_send_wqe(attr);
#line 339
  descriptor.modname = "mlx5_ib";
#line 339
  descriptor.function = "calc_sq_size";
#line 339
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 339
  descriptor.format = "%s:%s:%d:(pid %d): wqe_size %d\n";
#line 339
  descriptor.lineno = 339U;
#line 339
  descriptor.flags = 0U;
#line 339
  tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 339
  if (tmp___0 != 0L) {
#line 339
    tmp = get_current();
#line 339
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): wqe_size %d\n", (char *)(& dev->ib_dev.name),
                       "calc_sq_size", 339, tmp->pid, wqe_size);
  } else {

  }
#line 340
  if (wqe_size < 0) {
#line 341
    return (wqe_size);
  } else {

  }
#line 343
  tmp___4 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 20UL));
#line 343
  if ((unsigned int )wqe_size > (tmp___4 & 65535U)) {
#line 344
    descriptor___0.modname = "mlx5_ib";
#line 344
    descriptor___0.function = "calc_sq_size";
#line 344
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 344
    descriptor___0.format = "%s:%s:%d:(pid %d): wqe_size(%d) > max_sq_desc_sz(%d)\n";
#line 344
    descriptor___0.lineno = 345U;
#line 344
    descriptor___0.flags = 0U;
#line 344
    tmp___3 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 344
    if (tmp___3 != 0L) {
#line 344
      tmp___1 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 20UL));
#line 344
      tmp___2 = get_current();
#line 344
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): wqe_size(%d) > max_sq_desc_sz(%d)\n",
                         (char *)(& dev->ib_dev.name), "calc_sq_size", 345, tmp___2->pid,
                         wqe_size, tmp___1 & 65535U);
    } else {

    }
#line 346
    return (-22);
  } else {

  }
#line 349
  tmp___5 = sq_overhead(attr->qp_type);
#line 349
  qp->max_inline_data = (int )((unsigned int )(wqe_size - tmp___5) - 4U);
#line 351
  attr->cap.max_inline_data = (u32 )qp->max_inline_data;
#line 353
  if (((int )attr->create_flags & 64) != 0) {
#line 354
    qp->signature_en = 1;
  } else {

  }
#line 356
  tmp___6 = __roundup_pow_of_two((unsigned long )(attr->cap.max_send_wr * (u32 )wqe_size));
#line 356
  wq_size = (int )tmp___6;
#line 357
  qp->sq.wqe_cnt = wq_size / 64;
#line 358
  tmp___10 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 358
  if (qp->sq.wqe_cnt > 1 << ((int )(tmp___10 >> 16) & 255)) {
#line 359
    descriptor___1.modname = "mlx5_ib";
#line 359
    descriptor___1.function = "calc_sq_size";
#line 359
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 359
    descriptor___1.format = "%s:%s:%d:(pid %d): wqe count(%d) exceeds limits(%d)\n";
#line 359
    descriptor___1.lineno = 361U;
#line 359
    descriptor___1.flags = 0U;
#line 359
    tmp___9 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 359
    if (tmp___9 != 0L) {
#line 359
      tmp___7 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 359
      tmp___8 = get_current();
#line 359
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): wqe count(%d) exceeds limits(%d)\n",
                         (char *)(& dev->ib_dev.name), "calc_sq_size", 361, tmp___8->pid,
                         qp->sq.wqe_cnt, 1 << ((int )(tmp___7 >> 16) & 255));
    } else {

    }
#line 362
    return (-12);
  } else {

  }
#line 364
  qp->sq.wqe_shift = 6;
#line 365
  qp->sq.max_gs = (int )attr->cap.max_send_sge;
#line 366
  qp->sq.max_post = wq_size / wqe_size;
#line 367
  attr->cap.max_send_wr = (u32 )qp->sq.max_post;
#line 369
  return (wq_size);
}
}
#line 372 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_user_buf_size(struct mlx5_ib_dev *dev , struct mlx5_ib_qp *qp , struct mlx5_ib_create_qp *ucmd ) 
{ 
  int desc_sz ;
  __u32 tmp ;
  struct task_struct *tmp___0 ;
  __u32 tmp___1 ;
  struct task_struct *tmp___2 ;
  int tmp___3 ;
  __u32 tmp___4 ;
  struct task_struct *tmp___5 ;
  __u32 tmp___6 ;

  {
#line 376
  desc_sz = 1 << qp->sq.wqe_shift;
#line 378
  tmp___1 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 20UL));
#line 378
  if ((unsigned int )desc_sz > (tmp___1 & 65535U)) {
#line 379
    tmp = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 20UL));
#line 379
    tmp___0 = get_current();
#line 379
    printk("\f%s:%s:%d:(pid %d): desc_sz %d, max_sq_desc_sz %d\n", (char *)(& dev->ib_dev.name),
           "set_user_buf_size", 380, tmp___0->pid, desc_sz, tmp & 65535U);
#line 381
    return (-22);
  } else {

  }
#line 384
  if (ucmd->sq_wqe_count != 0U) {
#line 384
    tmp___3 = __ilog2_u32(ucmd->sq_wqe_count);
#line 384
    if ((__u32 )(1 << tmp___3) != ucmd->sq_wqe_count) {
#line 385
      tmp___2 = get_current();
#line 385
      printk("\f%s:%s:%d:(pid %d): sq_wqe_count %d, sq_wqe_count %d\n", (char *)(& dev->ib_dev.name),
             "set_user_buf_size", 386, tmp___2->pid, ucmd->sq_wqe_count, ucmd->sq_wqe_count);
#line 387
      return (-22);
    } else {

    }
  } else {

  }
#line 390
  qp->sq.wqe_cnt = (int )ucmd->sq_wqe_count;
#line 392
  tmp___6 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 392
  if (qp->sq.wqe_cnt > 1 << ((int )(tmp___6 >> 16) & 255)) {
#line 393
    tmp___4 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 393
    tmp___5 = get_current();
#line 393
    printk("\f%s:%s:%d:(pid %d): wqe_cnt %d, max_wqes %d\n", (char *)(& dev->ib_dev.name),
           "set_user_buf_size", 395, tmp___5->pid, qp->sq.wqe_cnt, 1 << ((int )(tmp___4 >> 16) & 255));
#line 396
    return (-22);
  } else {

  }
#line 399
  qp->buf_size = (qp->rq.wqe_cnt << qp->rq.wqe_shift) + (qp->sq.wqe_cnt << 6);
#line 402
  return (0);
}
}
#line 405 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int qp_has_rq(struct ib_qp_init_attr *attr ) 
{ 


  {
#line 407
  if (((((unsigned int )attr->qp_type == 9U || (unsigned int )attr->qp_type == 10U) || (unsigned long )attr->srq != (unsigned long )((struct ib_srq *)0)) || (unsigned int )attr->qp_type == 4096U) || attr->cap.max_recv_wr == 0U) {
#line 411
    return (0);
  } else {

  }
#line 413
  return (1);
}
}
#line 416 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int first_med_uuar(void) 
{ 


  {
#line 418
  return (1);
}
}
#line 421 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int next_uuar(int n ) 
{ 


  {
#line 423
  n = n + 1;
#line 425
  goto ldv_37137;
  ldv_37136: 
#line 426
  n = n + 1;
  ldv_37137: ;
#line 425
  if ((n % 4 & 2) != 0) {
#line 427
    goto ldv_37136;
  } else {

  }

#line 428
  return (n);
}
}
#line 431 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int num_med_uuar(struct mlx5_uuar_info *uuari ) 
{ 
  int n ;

  {
#line 435
  n = (uuari->num_uars * 2 - uuari->num_low_latency_uuars) + -1;
#line 438
  return (0 > n ? 0 : n);
}
}
#line 441 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int max_uuari(struct mlx5_uuar_info *uuari ) 
{ 


  {
#line 443
  return (uuari->num_uars * 4);
}
}
#line 446 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int first_hi_uuar(struct mlx5_uuar_info *uuari ) 
{ 
  int med ;
  int i ;
  int t ;
  int tmp ;

  {
#line 452
  med = num_med_uuar(uuari);
#line 453
  t = 0;
#line 453
  i = first_med_uuar();
  ldv_37152: 
#line 454
  t = t + 1;
#line 455
  if (t == med) {
#line 456
    tmp = next_uuar(i);
#line 456
    return (tmp);
  } else {

  }
#line 453
  i = next_uuar(i);
#line 457
  goto ldv_37152;
#line 459
  return (0);
}
}
#line 462 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int alloc_high_class_uuar(struct mlx5_uuar_info *uuari ) 
{ 
  int i ;
  int tmp ;
  int tmp___0 ;

  {
#line 466
  i = first_hi_uuar(uuari);
#line 466
  goto ldv_37158;
  ldv_37157: 
#line 467
  tmp = variable_test_bit((long )i, (unsigned long const volatile   *)uuari->bitmap);
#line 467
  if (tmp == 0) {
#line 468
    set_bit((long )i, (unsigned long volatile   *)uuari->bitmap);
#line 469
    *(uuari->count + (unsigned long )i) = *(uuari->count + (unsigned long )i) + 1U;
#line 470
    return (i);
  } else {

  }
#line 466
  i = next_uuar(i);
  ldv_37158: 
#line 466
  tmp___0 = max_uuari(uuari);
#line 466
  if (tmp___0 > i) {
#line 468
    goto ldv_37157;
  } else {

  }

#line 474
  return (-12);
}
}
#line 477 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int alloc_med_class_uuar(struct mlx5_uuar_info *uuari ) 
{ 
  int minidx ;
  int tmp ;
  int i ;
  int tmp___0 ;

  {
#line 479
  tmp = first_med_uuar();
#line 479
  minidx = tmp;
#line 482
  i = first_med_uuar();
#line 482
  goto ldv_37166;
  ldv_37165: ;
#line 483
  if (*(uuari->count + (unsigned long )i) < *(uuari->count + (unsigned long )minidx)) {
#line 484
    minidx = i;
  } else {

  }
#line 482
  i = next_uuar(i);
  ldv_37166: 
#line 482
  tmp___0 = first_hi_uuar(uuari);
#line 482
  if (tmp___0 > i) {
#line 484
    goto ldv_37165;
  } else {

  }
#line 487
  *(uuari->count + (unsigned long )minidx) = *(uuari->count + (unsigned long )minidx) + 1U;
#line 488
  return (minidx);
}
}
#line 491 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int alloc_uuar(struct mlx5_uuar_info *uuari , enum mlx5_ib_latency_class lat ) 
{ 
  int uuarn ;

  {
#line 494
  uuarn = -22;
#line 496
  mutex_lock_nested(& uuari->lock, 0U);
#line 497
  switch ((unsigned int )lat) {
  case 0U: 
#line 499
  uuarn = 0;
#line 500
  *(uuari->count + (unsigned long )uuarn) = *(uuari->count + (unsigned long )uuarn) + 1U;
#line 501
  goto ldv_37174;
  case 1U: ;
#line 504
  if (uuari->ver <= 1U) {
#line 505
    uuarn = -12;
  } else {
#line 507
    uuarn = alloc_med_class_uuar(uuari);
  }
#line 508
  goto ldv_37174;
  case 2U: ;
#line 511
  if (uuari->ver <= 1U) {
#line 512
    uuarn = -12;
  } else {
#line 514
    uuarn = alloc_high_class_uuar(uuari);
  }
#line 515
  goto ldv_37174;
  case 3U: 
#line 518
  uuarn = 2;
#line 519
  goto ldv_37174;
  }
  ldv_37174: 
#line 521
  mutex_unlock(& uuari->lock);
#line 523
  return (uuarn);
}
}
#line 526 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void free_med_class_uuar(struct mlx5_uuar_info *uuari , int uuarn ) 
{ 


  {
#line 528
  clear_bit((long )uuarn, (unsigned long volatile   *)uuari->bitmap);
#line 529
  *(uuari->count + (unsigned long )uuarn) = *(uuari->count + (unsigned long )uuarn) - 1U;
#line 530
  return;
}
}
#line 532 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void free_high_class_uuar(struct mlx5_uuar_info *uuari , int uuarn ) 
{ 


  {
#line 534
  clear_bit((long )uuarn, (unsigned long volatile   *)uuari->bitmap);
#line 535
  *(uuari->count + (unsigned long )uuarn) = *(uuari->count + (unsigned long )uuarn) - 1U;
#line 536
  return;
}
}
#line 538 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void free_uuar(struct mlx5_uuar_info *uuari , int uuarn ) 
{ 
  int nuuars ;
  int high_uuar ;

  {
#line 540
  nuuars = uuari->num_uars * 4;
#line 541
  high_uuar = nuuars - uuari->num_low_latency_uuars;
#line 543
  mutex_lock_nested(& uuari->lock, 0U);
#line 544
  if (uuarn == 0) {
#line 545
    *(uuari->count + (unsigned long )uuarn) = *(uuari->count + (unsigned long )uuarn) - 1U;
#line 546
    goto out;
  } else {

  }
#line 549
  if (uuarn < high_uuar) {
#line 550
    free_med_class_uuar(uuari, uuarn);
#line 551
    goto out;
  } else {

  }
#line 554
  free_high_class_uuar(uuari, uuarn);
  out: 
#line 557
  mutex_unlock(& uuari->lock);
#line 558
  return;
}
}
#line 560 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static enum mlx5_qp_state to_mlx5_state(enum ib_qp_state state ) 
{ 


  {
#line 562
  switch ((unsigned int )state) {
  case 0U: ;
#line 563
  return (0);
  case 1U: ;
#line 564
  return (1);
  case 2U: ;
#line 565
  return (2);
  case 3U: ;
#line 566
  return (3);
  case 4U: ;
#line 567
  return (5);
  case 5U: ;
#line 568
  return (4);
  case 6U: ;
#line 569
  return (6);
  default: ;
#line 570
  return (4294967295L);
  }
}
}
#line 574 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int to_mlx5_st(enum ib_qp_type type ) 
{ 


  {
#line 576
  switch ((unsigned int )type) {
  case 2U: ;
#line 577
  return (0);
  case 3U: ;
#line 578
  return (1);
  case 4U: ;
#line 579
  return (2);
  case 4096U: ;
#line 580
  return (12);
  case 9U: ;
  case 10U: ;
#line 582
  return (3);
  case 0U: ;
#line 583
  return (7);
  case 1U: ;
#line 584
  return (8);
  case 5U: ;
#line 585
  return (10);
  case 6U: ;
#line 586
  return (9);
  case 8U: ;
  case 11U: ;
  default: ;
#line 589
  return (-22);
  }
}
}
#line 593 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int uuarn_to_uar_index(struct mlx5_uuar_info *uuari , int uuarn ) 
{ 


  {
#line 595
  return ((int )(uuari->uars + (unsigned long )(uuarn / 4))->index);
}
}
#line 598 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int create_user_qp(struct mlx5_ib_dev *dev , struct ib_pd *pd , struct mlx5_ib_qp *qp ,
                          struct ib_udata *udata , struct mlx5_create_qp_mbox_in **in ,
                          struct mlx5_ib_create_qp_resp *resp , int *inlen ) 
{ 
  struct mlx5_ib_ucontext *context ;
  struct mlx5_ib_create_qp ucmd ;
  int page_shift ;
  int uar_index ;
  int npages ;
  u32 offset ;
  int uuarn ;
  int ncont ;
  int err ;
  struct _ddebug descriptor ;
  struct task_struct *tmp ;
  long tmp___0 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___1 ;
  long tmp___2 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___5 ;
  long tmp___6 ;
  struct _ddebug descriptor___3 ;
  struct task_struct *tmp___7 ;
  long tmp___8 ;
  struct task_struct *tmp___9 ;
  struct _ddebug descriptor___4 ;
  struct task_struct *tmp___10 ;
  long tmp___11 ;
  struct _ddebug descriptor___5 ;
  struct task_struct *tmp___12 ;
  long tmp___13 ;
  long tmp___14 ;
  bool tmp___15 ;
  struct task_struct *tmp___16 ;
  struct _ddebug descriptor___6 ;
  struct task_struct *tmp___17 ;
  long tmp___18 ;
  void *tmp___19 ;
  __u32 tmp___20 ;
  __u32 tmp___21 ;
  __u32 tmp___22 ;
  struct _ddebug descriptor___7 ;
  struct task_struct *tmp___23 ;
  long tmp___24 ;
  struct _ddebug descriptor___8 ;
  struct task_struct *tmp___25 ;
  long tmp___26 ;

  {
#line 605
  page_shift = 0;
#line 608
  offset = 0U;
#line 610
  ncont = 0;
#line 613
  err = ib_copy_from_udata((void *)(& ucmd), udata, 32UL);
#line 614
  if (err != 0) {
#line 615
    descriptor.modname = "mlx5_ib";
#line 615
    descriptor.function = "create_user_qp";
#line 615
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 615
    descriptor.format = "%s:%s:%d:(pid %d): copy failed\n";
#line 615
    descriptor.lineno = 615U;
#line 615
    descriptor.flags = 0U;
#line 615
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 615
    if (tmp___0 != 0L) {
#line 615
      tmp = get_current();
#line 615
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): copy failed\n", (char *)(& dev->ib_dev.name),
                         "create_user_qp", 615, tmp->pid);
    } else {

    }
#line 616
    return (err);
  } else {

  }
#line 619
  context = to_mucontext((pd->uobject)->context);
#line 623
  uuarn = alloc_uuar(& context->uuari, 2);
#line 624
  if (uuarn < 0) {
#line 625
    descriptor___0.modname = "mlx5_ib";
#line 625
    descriptor___0.function = "create_user_qp";
#line 625
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 625
    descriptor___0.format = "%s:%s:%d:(pid %d): failed to allocate low latency UUAR\n";
#line 625
    descriptor___0.lineno = 625U;
#line 625
    descriptor___0.flags = 0U;
#line 625
    tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 625
    if (tmp___2 != 0L) {
#line 625
      tmp___1 = get_current();
#line 625
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): failed to allocate low latency UUAR\n",
                         (char *)(& dev->ib_dev.name), "create_user_qp", 625, tmp___1->pid);
    } else {

    }
#line 626
    descriptor___1.modname = "mlx5_ib";
#line 626
    descriptor___1.function = "create_user_qp";
#line 626
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 626
    descriptor___1.format = "%s:%s:%d:(pid %d): reverting to medium latency\n";
#line 626
    descriptor___1.lineno = 626U;
#line 626
    descriptor___1.flags = 0U;
#line 626
    tmp___4 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 626
    if (tmp___4 != 0L) {
#line 626
      tmp___3 = get_current();
#line 626
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): reverting to medium latency\n",
                         (char *)(& dev->ib_dev.name), "create_user_qp", 626, tmp___3->pid);
    } else {

    }
#line 627
    uuarn = alloc_uuar(& context->uuari, 1);
#line 628
    if (uuarn < 0) {
#line 629
      descriptor___2.modname = "mlx5_ib";
#line 629
      descriptor___2.function = "create_user_qp";
#line 629
      descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 629
      descriptor___2.format = "%s:%s:%d:(pid %d): failed to allocate medium latency UUAR\n";
#line 629
      descriptor___2.lineno = 629U;
#line 629
      descriptor___2.flags = 0U;
#line 629
      tmp___6 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 629
      if (tmp___6 != 0L) {
#line 629
        tmp___5 = get_current();
#line 629
        __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): failed to allocate medium latency UUAR\n",
                           (char *)(& dev->ib_dev.name), "create_user_qp", 629, tmp___5->pid);
      } else {

      }
#line 630
      descriptor___3.modname = "mlx5_ib";
#line 630
      descriptor___3.function = "create_user_qp";
#line 630
      descriptor___3.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 630
      descriptor___3.format = "%s:%s:%d:(pid %d): reverting to high latency\n";
#line 630
      descriptor___3.lineno = 630U;
#line 630
      descriptor___3.flags = 0U;
#line 630
      tmp___8 = ldv__builtin_expect((long )descriptor___3.flags & 1L, 0L);
#line 630
      if (tmp___8 != 0L) {
#line 630
        tmp___7 = get_current();
#line 630
        __dynamic_pr_debug(& descriptor___3, "%s:%s:%d:(pid %d): reverting to high latency\n",
                           (char *)(& dev->ib_dev.name), "create_user_qp", 630, tmp___7->pid);
      } else {

      }
#line 631
      uuarn = alloc_uuar(& context->uuari, 0);
#line 632
      if (uuarn < 0) {
#line 633
        tmp___9 = get_current();
#line 633
        printk("\f%s:%s:%d:(pid %d): uuar allocation failed\n", (char *)(& dev->ib_dev.name),
               "create_user_qp", 633, tmp___9->pid);
#line 634
        return (uuarn);
      } else {

      }
    } else {

    }
  } else {

  }
#line 639
  uar_index = uuarn_to_uar_index(& context->uuari, uuarn);
#line 640
  descriptor___4.modname = "mlx5_ib";
#line 640
  descriptor___4.function = "create_user_qp";
#line 640
  descriptor___4.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 640
  descriptor___4.format = "%s:%s:%d:(pid %d): uuarn 0x%x, uar_index 0x%x\n";
#line 640
  descriptor___4.lineno = 640U;
#line 640
  descriptor___4.flags = 0U;
#line 640
  tmp___11 = ldv__builtin_expect((long )descriptor___4.flags & 1L, 0L);
#line 640
  if (tmp___11 != 0L) {
#line 640
    tmp___10 = get_current();
#line 640
    __dynamic_pr_debug(& descriptor___4, "%s:%s:%d:(pid %d): uuarn 0x%x, uar_index 0x%x\n",
                       (char *)(& dev->ib_dev.name), "create_user_qp", 640, tmp___10->pid,
                       uuarn, uar_index);
  } else {

  }
#line 642
  qp->rq.offset = 0;
#line 643
  qp->sq.wqe_shift = 6;
#line 644
  qp->sq.offset = qp->rq.wqe_cnt << qp->rq.wqe_shift;
#line 646
  err = set_user_buf_size(dev, qp, & ucmd);
#line 647
  if (err != 0) {
#line 648
    goto err_uuar;
  } else {

  }
#line 650
  if (ucmd.buf_addr != 0ULL && qp->buf_size != 0) {
#line 651
    qp->umem = ib_umem_get((pd->uobject)->context, (unsigned long )ucmd.buf_addr,
                           (size_t )qp->buf_size, 0, 0);
#line 653
    tmp___15 = IS_ERR((void const   *)qp->umem);
#line 653
    if ((int )tmp___15) {
#line 654
      descriptor___5.modname = "mlx5_ib";
#line 654
      descriptor___5.function = "create_user_qp";
#line 654
      descriptor___5.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 654
      descriptor___5.format = "%s:%s:%d:(pid %d): umem_get failed\n";
#line 654
      descriptor___5.lineno = 654U;
#line 654
      descriptor___5.flags = 0U;
#line 654
      tmp___13 = ldv__builtin_expect((long )descriptor___5.flags & 1L, 0L);
#line 654
      if (tmp___13 != 0L) {
#line 654
        tmp___12 = get_current();
#line 654
        __dynamic_pr_debug(& descriptor___5, "%s:%s:%d:(pid %d): umem_get failed\n",
                           (char *)(& dev->ib_dev.name), "create_user_qp", 654, tmp___12->pid);
      } else {

      }
#line 655
      tmp___14 = PTR_ERR((void const   *)qp->umem);
#line 655
      err = (int )tmp___14;
#line 656
      goto err_uuar;
    } else {

    }
  } else {
#line 659
    qp->umem = (struct ib_umem *)0;
  }
#line 662
  if ((unsigned long )qp->umem != (unsigned long )((struct ib_umem *)0)) {
#line 663
    mlx5_ib_cont_pages(qp->umem, ucmd.buf_addr, & npages, & page_shift, & ncont, (int *)0);
#line 665
    err = mlx5_ib_get_buf_offset(ucmd.buf_addr, page_shift, & offset);
#line 666
    if (err != 0) {
#line 667
      tmp___16 = get_current();
#line 667
      printk("\f%s:%s:%d:(pid %d): bad offset\n", (char *)(& dev->ib_dev.name), "create_user_qp",
             667, tmp___16->pid);
#line 668
      goto err_umem;
    } else {

    }
#line 670
    descriptor___6.modname = "mlx5_ib";
#line 670
    descriptor___6.function = "create_user_qp";
#line 670
    descriptor___6.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 670
    descriptor___6.format = "%s:%s:%d:(pid %d): addr 0x%llx, size %d, npages %d, page_shift %d, ncont %d, offset %d\n";
#line 670
    descriptor___6.lineno = 671U;
#line 670
    descriptor___6.flags = 0U;
#line 670
    tmp___18 = ldv__builtin_expect((long )descriptor___6.flags & 1L, 0L);
#line 670
    if (tmp___18 != 0L) {
#line 670
      tmp___17 = get_current();
#line 670
      __dynamic_pr_debug(& descriptor___6, "%s:%s:%d:(pid %d): addr 0x%llx, size %d, npages %d, page_shift %d, ncont %d, offset %d\n",
                         (char *)(& dev->ib_dev.name), "create_user_qp", 671, tmp___17->pid,
                         ucmd.buf_addr, qp->buf_size, npages, page_shift, ncont, offset);
    } else {

    }
  } else {

  }
#line 674
  *inlen = (int )((unsigned int )((unsigned long )ncont + 34UL) * 8U);
#line 675
  tmp___19 = mlx5_vzalloc((unsigned long )*inlen);
#line 675
  *in = (struct mlx5_create_qp_mbox_in *)tmp___19;
#line 676
  if ((unsigned long )*in == (unsigned long )((struct mlx5_create_qp_mbox_in *)0)) {
#line 677
    err = -12;
#line 678
    goto err_umem;
  } else {

  }
#line 680
  if ((unsigned long )qp->umem != (unsigned long )((struct ib_umem *)0)) {
#line 681
    mlx5_ib_populate_pas(dev, qp->umem, page_shift, (__be64 *)(& (*in)->pas), 0);
  } else {

  }
#line 682
  tmp___20 = __fswab32((__u32 )((page_shift + -12) << 24));
#line 682
  (*in)->ctx.log_pg_sz_remote_qpn = tmp___20;
#line 684
  tmp___21 = __fswab32(offset << 6);
#line 684
  (*in)->ctx.params2 = tmp___21;
#line 686
  tmp___22 = __fswab32((__u32 )uar_index);
#line 686
  (*in)->ctx.qp_counter_set_usr_page = tmp___22;
#line 687
  resp->uuar_index = (__u32 )uuarn;
#line 688
  qp->uuarn = uuarn;
#line 690
  err = mlx5_ib_db_map_user(context, (unsigned long )ucmd.db_addr, & qp->db);
#line 691
  if (err != 0) {
#line 692
    descriptor___7.modname = "mlx5_ib";
#line 692
    descriptor___7.function = "create_user_qp";
#line 692
    descriptor___7.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 692
    descriptor___7.format = "%s:%s:%d:(pid %d): map failed\n";
#line 692
    descriptor___7.lineno = 692U;
#line 692
    descriptor___7.flags = 0U;
#line 692
    tmp___24 = ldv__builtin_expect((long )descriptor___7.flags & 1L, 0L);
#line 692
    if (tmp___24 != 0L) {
#line 692
      tmp___23 = get_current();
#line 692
      __dynamic_pr_debug(& descriptor___7, "%s:%s:%d:(pid %d): map failed\n", (char *)(& dev->ib_dev.name),
                         "create_user_qp", 692, tmp___23->pid);
    } else {

    }
#line 693
    goto err_free;
  } else {

  }
#line 696
  err = ib_copy_to_udata(udata, (void *)resp, 4UL);
#line 697
  if (err != 0) {
#line 698
    descriptor___8.modname = "mlx5_ib";
#line 698
    descriptor___8.function = "create_user_qp";
#line 698
    descriptor___8.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 698
    descriptor___8.format = "%s:%s:%d:(pid %d): copy failed\n";
#line 698
    descriptor___8.lineno = 698U;
#line 698
    descriptor___8.flags = 0U;
#line 698
    tmp___26 = ldv__builtin_expect((long )descriptor___8.flags & 1L, 0L);
#line 698
    if (tmp___26 != 0L) {
#line 698
      tmp___25 = get_current();
#line 698
      __dynamic_pr_debug(& descriptor___8, "%s:%s:%d:(pid %d): copy failed\n", (char *)(& dev->ib_dev.name),
                         "create_user_qp", 698, tmp___25->pid);
    } else {

    }
#line 699
    goto err_unmap;
  } else {

  }
#line 701
  qp->create_type = 0;
#line 703
  return (0);
  err_unmap: 
#line 706
  mlx5_ib_db_unmap_user(context, & qp->db);
  err_free: 
#line 709
  kvfree((void const   *)*in);
  err_umem: ;
#line 712
  if ((unsigned long )qp->umem != (unsigned long )((struct ib_umem *)0)) {
#line 713
    ib_umem_release(qp->umem);
  } else {

  }
  err_uuar: 
#line 716
  free_uuar(& context->uuari, uuarn);
#line 717
  return (err);
}
}
#line 720 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void destroy_qp_user(struct ib_pd *pd , struct mlx5_ib_qp *qp ) 
{ 
  struct mlx5_ib_ucontext *context ;

  {
#line 724
  context = to_mucontext((pd->uobject)->context);
#line 725
  mlx5_ib_db_unmap_user(context, & qp->db);
#line 726
  if ((unsigned long )qp->umem != (unsigned long )((struct ib_umem *)0)) {
#line 727
    ib_umem_release(qp->umem);
  } else {

  }
#line 728
  free_uuar(& context->uuari, qp->uuarn);
#line 729
  return;
}
}
#line 731 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int create_kernel_qp(struct mlx5_ib_dev *dev , struct ib_qp_init_attr *init_attr ,
                            struct mlx5_ib_qp *qp , struct mlx5_create_qp_mbox_in **in ,
                            int *inlen ) 
{ 
  enum mlx5_ib_latency_class lc ;
  struct mlx5_uuar_info *uuari ;
  int uar_index ;
  int uuarn ;
  int err ;
  struct _ddebug descriptor ;
  struct task_struct *tmp ;
  long tmp___0 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___1 ;
  long tmp___2 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  void *tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___8 ;
  long tmp___9 ;
  void *tmp___10 ;
  void *tmp___11 ;
  void *tmp___12 ;
  void *tmp___13 ;
  void *tmp___14 ;

  {
#line 736
  lc = 0;
#line 742
  uuari = & (dev->mdev)->priv.uuari;
#line 743
  if (((int )init_attr->create_flags & -67) != 0) {
#line 744
    return (-22);
  } else {

  }
#line 746
  if ((unsigned int )init_attr->qp_type == 4096U) {
#line 747
    lc = 3;
  } else {

  }
#line 749
  uuarn = alloc_uuar(uuari, lc);
#line 750
  if (uuarn < 0) {
#line 751
    descriptor.modname = "mlx5_ib";
#line 751
    descriptor.function = "create_kernel_qp";
#line 751
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 751
    descriptor.format = "%s:%s:%d:(pid %d): \n";
#line 751
    descriptor.lineno = 751U;
#line 751
    descriptor.flags = 0U;
#line 751
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 751
    if (tmp___0 != 0L) {
#line 751
      tmp = get_current();
#line 751
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name),
                         "create_kernel_qp", 751, tmp->pid);
    } else {

    }
#line 752
    return (-12);
  } else {

  }
#line 755
  qp->bf = uuari->bfs + (unsigned long )uuarn;
#line 756
  uar_index = (int )((qp->bf)->uar)->index;
#line 758
  err = calc_sq_size(dev, init_attr, qp);
#line 759
  if (err < 0) {
#line 760
    descriptor___0.modname = "mlx5_ib";
#line 760
    descriptor___0.function = "create_kernel_qp";
#line 760
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 760
    descriptor___0.format = "%s:%s:%d:(pid %d): err %d\n";
#line 760
    descriptor___0.lineno = 760U;
#line 760
    descriptor___0.flags = 0U;
#line 760
    tmp___2 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 760
    if (tmp___2 != 0L) {
#line 760
      tmp___1 = get_current();
#line 760
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                         "create_kernel_qp", 760, tmp___1->pid, err);
    } else {

    }
#line 761
    goto err_uuar;
  } else {

  }
#line 764
  qp->rq.offset = 0;
#line 765
  qp->sq.offset = qp->rq.wqe_cnt << qp->rq.wqe_shift;
#line 766
  qp->buf_size = (qp->rq.wqe_cnt << qp->rq.wqe_shift) + err;
#line 768
  err = mlx5_buf_alloc(dev->mdev, qp->buf_size, & qp->buf);
#line 769
  if (err != 0) {
#line 770
    descriptor___1.modname = "mlx5_ib";
#line 770
    descriptor___1.function = "create_kernel_qp";
#line 770
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 770
    descriptor___1.format = "%s:%s:%d:(pid %d): err %d\n";
#line 770
    descriptor___1.lineno = 770U;
#line 770
    descriptor___1.flags = 0U;
#line 770
    tmp___4 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 770
    if (tmp___4 != 0L) {
#line 770
      tmp___3 = get_current();
#line 770
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                         "create_kernel_qp", 770, tmp___3->pid, err);
    } else {

    }
#line 771
    goto err_uuar;
  } else {

  }
#line 774
  qp->sq.qend = mlx5_get_send_wqe(qp, qp->sq.wqe_cnt);
#line 775
  *inlen = (int )((unsigned int )((unsigned long )qp->buf.npages + 34UL) * 8U);
#line 776
  tmp___5 = mlx5_vzalloc((unsigned long )*inlen);
#line 776
  *in = (struct mlx5_create_qp_mbox_in *)tmp___5;
#line 777
  if ((unsigned long )*in == (unsigned long )((struct mlx5_create_qp_mbox_in *)0)) {
#line 778
    err = -12;
#line 779
    goto err_buf;
  } else {

  }
#line 781
  tmp___6 = __fswab32((__u32 )uar_index);
#line 781
  (*in)->ctx.qp_counter_set_usr_page = tmp___6;
#line 782
  tmp___7 = __fswab32((__u32 )(((int )qp->buf.page_shift + -12) << 24));
#line 782
  (*in)->ctx.log_pg_sz_remote_qpn = tmp___7;
#line 785
  (*in)->ctx.params1 = (*in)->ctx.params1 | 524288U;
#line 786
  (*in)->ctx.sq_crq_size = (__be16 )((unsigned int )(*in)->ctx.sq_crq_size | 4096U);
#line 788
  mlx5_fill_page_array(& qp->buf, (__be64 *)(& (*in)->pas));
#line 790
  err = mlx5_db_alloc(dev->mdev, & qp->db);
#line 791
  if (err != 0) {
#line 792
    descriptor___2.modname = "mlx5_ib";
#line 792
    descriptor___2.function = "create_kernel_qp";
#line 792
    descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 792
    descriptor___2.format = "%s:%s:%d:(pid %d): err %d\n";
#line 792
    descriptor___2.lineno = 792U;
#line 792
    descriptor___2.flags = 0U;
#line 792
    tmp___9 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 792
    if (tmp___9 != 0L) {
#line 792
      tmp___8 = get_current();
#line 792
      __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                         "create_kernel_qp", 792, tmp___8->pid, err);
    } else {

    }
#line 793
    goto err_free;
  } else {

  }
#line 796
  tmp___10 = kmalloc((unsigned long )qp->sq.wqe_cnt * 8UL, 208U);
#line 796
  qp->sq.wrid = (u64 *)tmp___10;
#line 797
  tmp___11 = kmalloc((unsigned long )qp->sq.wqe_cnt * 4UL, 208U);
#line 797
  qp->sq.wr_data = (u32 *)tmp___11;
#line 798
  tmp___12 = kmalloc((unsigned long )qp->rq.wqe_cnt * 8UL, 208U);
#line 798
  qp->rq.wrid = (u64 *)tmp___12;
#line 799
  tmp___13 = kmalloc((unsigned long )qp->sq.wqe_cnt * 4UL, 208U);
#line 799
  qp->sq.w_list = (struct wr_list *)tmp___13;
#line 800
  tmp___14 = kmalloc((unsigned long )qp->sq.wqe_cnt * 4UL, 208U);
#line 800
  qp->sq.wqe_head = (unsigned int *)tmp___14;
#line 802
  if (((((unsigned long )qp->sq.wrid == (unsigned long )((u64 *)0ULL) || (unsigned long )qp->sq.wr_data == (unsigned long )((u32 *)0U)) || (unsigned long )qp->rq.wrid == (unsigned long )((u64 *)0ULL)) || (unsigned long )qp->sq.w_list == (unsigned long )((struct wr_list *)0)) || (unsigned long )qp->sq.wqe_head == (unsigned long )((unsigned int *)0U)) {
#line 804
    err = -12;
#line 805
    goto err_wrid;
  } else {

  }
#line 807
  qp->create_type = 1;
#line 809
  return (0);
  err_wrid: 
#line 812
  mlx5_db_free(dev->mdev, & qp->db);
#line 813
  kfree((void const   *)qp->sq.wqe_head);
#line 814
  kfree((void const   *)qp->sq.w_list);
#line 815
  kfree((void const   *)qp->sq.wrid);
#line 816
  kfree((void const   *)qp->sq.wr_data);
#line 817
  kfree((void const   *)qp->rq.wrid);
  err_free: 
#line 820
  kvfree((void const   *)*in);
  err_buf: 
#line 823
  mlx5_buf_free(dev->mdev, & qp->buf);
  err_uuar: 
#line 826
  free_uuar(& (dev->mdev)->priv.uuari, uuarn);
#line 827
  return (err);
}
}
#line 830 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void destroy_qp_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_qp *qp ) 
{ 


  {
#line 832
  mlx5_db_free(dev->mdev, & qp->db);
#line 833
  kfree((void const   *)qp->sq.wqe_head);
#line 834
  kfree((void const   *)qp->sq.w_list);
#line 835
  kfree((void const   *)qp->sq.wrid);
#line 836
  kfree((void const   *)qp->sq.wr_data);
#line 837
  kfree((void const   *)qp->rq.wrid);
#line 838
  mlx5_buf_free(dev->mdev, & qp->buf);
#line 839
  free_uuar(& (dev->mdev)->priv.uuari, (qp->bf)->uuarn);
#line 840
  return;
}
}
#line 842 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be32 get_rx_type(struct mlx5_ib_qp *qp , struct ib_qp_init_attr *attr ) 
{ 


  {
#line 844
  if (((unsigned long )attr->srq != (unsigned long )((struct ib_srq *)0) || (unsigned int )attr->qp_type == 10U) || (unsigned int )attr->qp_type == 9U) {
#line 846
    return (1U);
  } else
#line 847
  if (qp->has_rq == 0) {
#line 848
    return (3U);
  } else {
#line 850
    return (0U);
  }
}
}
#line 853 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int is_connected(enum ib_qp_type qp_type ) 
{ 


  {
#line 855
  if ((unsigned int )qp_type == 2U || (unsigned int )qp_type == 3U) {
#line 856
    return (1);
  } else {

  }
#line 858
  return (0);
}
}
#line 861 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int create_qp_common(struct mlx5_ib_dev *dev , struct ib_pd *pd , struct ib_qp_init_attr *init_attr ,
                            struct ib_udata *udata , struct mlx5_ib_qp *qp ) 
{ 
  struct mlx5_ib_resources *devr ;
  struct mlx5_core_dev *mdev ;
  struct mlx5_ib_create_qp_resp resp ;
  struct mlx5_create_qp_mbox_in *in ;
  struct mlx5_ib_create_qp ucmd ;
  int inlen ;
  int err ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp ;
  long tmp___0 ;
  __u32 tmp___1 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___2 ;
  long tmp___3 ;
  int tmp___4 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___5 ;
  long tmp___6 ;
  __u32 max_wqes ;
  __u32 tmp___7 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___8 ;
  long tmp___9 ;
  struct _ddebug descriptor___3 ;
  struct task_struct *tmp___10 ;
  long tmp___11 ;
  struct _ddebug descriptor___4 ;
  struct task_struct *tmp___12 ;
  long tmp___13 ;
  struct _ddebug descriptor___5 ;
  struct task_struct *tmp___14 ;
  long tmp___15 ;
  struct _ddebug descriptor___6 ;
  struct task_struct *tmp___16 ;
  long tmp___17 ;
  struct mlx5_ib_pd *tmp___18 ;
  void *tmp___19 ;
  int tmp___20 ;
  int tmp___21 ;
  __u32 tmp___22 ;
  struct mlx5_ib_pd *tmp___23 ;
  __u32 tmp___24 ;
  int rcqe_sz ;
  int scqe_sz ;
  int tmp___25 ;
  int tmp___26 ;
  int tmp___27 ;
  __u16 tmp___28 ;
  struct mlx5_ib_cq *tmp___29 ;
  __u32 tmp___30 ;
  struct mlx5_ib_cq *tmp___31 ;
  __u32 tmp___32 ;
  struct mlx5_ib_srq *tmp___33 ;
  __u32 tmp___34 ;
  struct mlx5_ib_xrcd *tmp___35 ;
  __u32 tmp___36 ;
  struct mlx5_ib_cq *tmp___37 ;
  __u32 tmp___38 ;
  struct mlx5_ib_xrcd *tmp___39 ;
  __u32 tmp___40 ;
  struct mlx5_ib_srq *tmp___41 ;
  __u32 tmp___42 ;
  struct mlx5_ib_xrcd *tmp___43 ;
  __u32 tmp___44 ;
  struct mlx5_ib_srq *tmp___45 ;
  __u32 tmp___46 ;
  struct mlx5_ib_xrcd *tmp___47 ;
  __u32 tmp___48 ;
  struct mlx5_ib_srq *tmp___49 ;
  __u32 tmp___50 ;
  struct mlx5_ib_cq *tmp___51 ;
  __u32 tmp___52 ;
  struct mlx5_ib_cq *tmp___53 ;
  __u32 tmp___54 ;
  __u64 tmp___55 ;
  struct _ddebug descriptor___7 ;
  struct task_struct *tmp___56 ;
  long tmp___57 ;
  __u32 tmp___58 ;

  {
#line 865
  devr = & dev->devr;
#line 866
  mdev = dev->mdev;
#line 870
  inlen = 272;
#line 873
  mlx5_ib_odp_create_qp(qp);
#line 875
  __mutex_init(& qp->mutex, "&qp->mutex", & __key);
#line 876
  spinlock_check(& qp->sq.lock);
#line 876
  __raw_spin_lock_init(& qp->sq.lock.__annonCompField18.rlock, "&(&qp->sq.lock)->rlock",
                       & __key___0);
#line 877
  spinlock_check(& qp->rq.lock);
#line 877
  __raw_spin_lock_init(& qp->rq.lock.__annonCompField18.rlock, "&(&qp->rq.lock)->rlock",
                       & __key___1);
#line 879
  if (((int )init_attr->create_flags & 2) != 0) {
#line 880
    tmp___1 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 17UL));
#line 880
    if ((tmp___1 & 8388608U) == 0U) {
#line 881
      descriptor.modname = "mlx5_ib";
#line 881
      descriptor.function = "create_qp_common";
#line 881
      descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 881
      descriptor.format = "%s:%s:%d:(pid %d): block multicast loopback isn\'t supported\n";
#line 881
      descriptor.lineno = 881U;
#line 881
      descriptor.flags = 0U;
#line 881
      tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 881
      if (tmp___0 != 0L) {
#line 881
        tmp = get_current();
#line 881
        __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): block multicast loopback isn\'t supported\n",
                           (char *)(& dev->ib_dev.name), "create_qp_common", 881,
                           tmp->pid);
      } else {

      }
#line 882
      return (-22);
    } else {
#line 884
      qp->flags = qp->flags | 1U;
    }
  } else {

  }
#line 888
  if ((unsigned int )init_attr->sq_sig_type == 0U) {
#line 889
    qp->sq_signal_bits = 8U;
  } else {

  }
#line 891
  if ((unsigned long )pd != (unsigned long )((struct ib_pd *)0) && (unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 892
    tmp___4 = ib_copy_from_udata((void *)(& ucmd), udata, 32UL);
#line 892
    if (tmp___4 != 0) {
#line 893
      descriptor___0.modname = "mlx5_ib";
#line 893
      descriptor___0.function = "create_qp_common";
#line 893
      descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 893
      descriptor___0.format = "%s:%s:%d:(pid %d): copy failed\n";
#line 893
      descriptor___0.lineno = 893U;
#line 893
      descriptor___0.flags = 0U;
#line 893
      tmp___3 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 893
      if (tmp___3 != 0L) {
#line 893
        tmp___2 = get_current();
#line 893
        __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): copy failed\n", (char *)(& dev->ib_dev.name),
                           "create_qp_common", 893, tmp___2->pid);
      } else {

      }
#line 894
      return (-14);
    } else {

    }
#line 897
    qp->wq_sig = (int )ucmd.flags & 1;
#line 898
    qp->scat_cqe = (ucmd.flags & 2U) != 0U;
  } else {
#line 900
    qp->wq_sig = wq_signature != 0;
  }
#line 903
  qp->has_rq = qp_has_rq(init_attr);
#line 904
  err = set_rq_size(dev, & init_attr->cap, qp->has_rq, qp, (unsigned long )pd != (unsigned long )((struct ib_pd *)0) && (unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0) ? & ucmd : (struct mlx5_ib_create_qp *)0);
#line 906
  if (err != 0) {
#line 907
    descriptor___1.modname = "mlx5_ib";
#line 907
    descriptor___1.function = "create_qp_common";
#line 907
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 907
    descriptor___1.format = "%s:%s:%d:(pid %d): err %d\n";
#line 907
    descriptor___1.lineno = 907U;
#line 907
    descriptor___1.flags = 0U;
#line 907
    tmp___6 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 907
    if (tmp___6 != 0L) {
#line 907
      tmp___5 = get_current();
#line 907
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                         "create_qp_common", 907, tmp___5->pid, err);
    } else {

    }
#line 908
    return (err);
  } else {

  }
#line 911
  if ((unsigned long )pd != (unsigned long )((struct ib_pd *)0)) {
#line 912
    if ((unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 913
      tmp___7 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 4UL));
#line 913
      max_wqes = (__u32 )(1 << ((int )(tmp___7 >> 16) & 255));
#line 915
      descriptor___2.modname = "mlx5_ib";
#line 915
      descriptor___2.function = "create_qp_common";
#line 915
      descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 915
      descriptor___2.format = "%s:%s:%d:(pid %d): requested sq_wqe_count (%d)\n";
#line 915
      descriptor___2.lineno = 915U;
#line 915
      descriptor___2.flags = 0U;
#line 915
      tmp___9 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 915
      if (tmp___9 != 0L) {
#line 915
        tmp___8 = get_current();
#line 915
        __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): requested sq_wqe_count (%d)\n",
                           (char *)(& dev->ib_dev.name), "create_qp_common", 915,
                           tmp___8->pid, ucmd.sq_wqe_count);
      } else {

      }
#line 916
      if (ucmd.rq_wqe_shift != (__u32 )qp->rq.wqe_shift || ucmd.rq_wqe_count != (__u32 )qp->rq.wqe_cnt) {
#line 918
        descriptor___3.modname = "mlx5_ib";
#line 918
        descriptor___3.function = "create_qp_common";
#line 918
        descriptor___3.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 918
        descriptor___3.format = "%s:%s:%d:(pid %d): invalid rq params\n";
#line 918
        descriptor___3.lineno = 918U;
#line 918
        descriptor___3.flags = 0U;
#line 918
        tmp___11 = ldv__builtin_expect((long )descriptor___3.flags & 1L, 0L);
#line 918
        if (tmp___11 != 0L) {
#line 918
          tmp___10 = get_current();
#line 918
          __dynamic_pr_debug(& descriptor___3, "%s:%s:%d:(pid %d): invalid rq params\n",
                             (char *)(& dev->ib_dev.name), "create_qp_common", 918,
                             tmp___10->pid);
        } else {

        }
#line 919
        return (-22);
      } else {

      }
#line 921
      if (ucmd.sq_wqe_count > max_wqes) {
#line 922
        descriptor___4.modname = "mlx5_ib";
#line 922
        descriptor___4.function = "create_qp_common";
#line 922
        descriptor___4.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 922
        descriptor___4.format = "%s:%s:%d:(pid %d): requested sq_wqe_count (%d) > max allowed (%d)\n";
#line 922
        descriptor___4.lineno = 923U;
#line 922
        descriptor___4.flags = 0U;
#line 922
        tmp___13 = ldv__builtin_expect((long )descriptor___4.flags & 1L, 0L);
#line 922
        if (tmp___13 != 0L) {
#line 922
          tmp___12 = get_current();
#line 922
          __dynamic_pr_debug(& descriptor___4, "%s:%s:%d:(pid %d): requested sq_wqe_count (%d) > max allowed (%d)\n",
                             (char *)(& dev->ib_dev.name), "create_qp_common", 923,
                             tmp___12->pid, ucmd.sq_wqe_count, max_wqes);
        } else {

        }
#line 924
        return (-22);
      } else {

      }
#line 926
      err = create_user_qp(dev, pd, qp, udata, & in, & resp, & inlen);
#line 927
      if (err != 0) {
#line 928
        descriptor___5.modname = "mlx5_ib";
#line 928
        descriptor___5.function = "create_qp_common";
#line 928
        descriptor___5.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 928
        descriptor___5.format = "%s:%s:%d:(pid %d): err %d\n";
#line 928
        descriptor___5.lineno = 928U;
#line 928
        descriptor___5.flags = 0U;
#line 928
        tmp___15 = ldv__builtin_expect((long )descriptor___5.flags & 1L, 0L);
#line 928
        if (tmp___15 != 0L) {
#line 928
          tmp___14 = get_current();
#line 928
          __dynamic_pr_debug(& descriptor___5, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                             "create_qp_common", 928, tmp___14->pid, err);
        } else {

        }
      } else {

      }
    } else {
#line 930
      err = create_kernel_qp(dev, init_attr, qp, & in, & inlen);
#line 931
      if (err != 0) {
#line 932
        descriptor___6.modname = "mlx5_ib";
#line 932
        descriptor___6.function = "create_qp_common";
#line 932
        descriptor___6.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 932
        descriptor___6.format = "%s:%s:%d:(pid %d): err %d\n";
#line 932
        descriptor___6.lineno = 932U;
#line 932
        descriptor___6.flags = 0U;
#line 932
        tmp___17 = ldv__builtin_expect((long )descriptor___6.flags & 1L, 0L);
#line 932
        if (tmp___17 != 0L) {
#line 932
          tmp___16 = get_current();
#line 932
          __dynamic_pr_debug(& descriptor___6, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                             "create_qp_common", 932, tmp___16->pid, err);
        } else {

        }
      } else {
#line 934
        tmp___18 = to_mpd(pd);
#line 934
        qp->pa_lkey = tmp___18->pa_lkey;
      }
    }
#line 937
    if (err != 0) {
#line 938
      return (err);
    } else {

    }
  } else {
#line 940
    tmp___19 = mlx5_vzalloc(272UL);
#line 940
    in = (struct mlx5_create_qp_mbox_in *)tmp___19;
#line 941
    if ((unsigned long )in == (unsigned long )((struct mlx5_create_qp_mbox_in *)0)) {
#line 942
      return (-12);
    } else {

    }
#line 944
    qp->create_type = 2;
  }
#line 947
  tmp___20 = is_sqp(init_attr->qp_type);
#line 947
  if (tmp___20 != 0) {
#line 948
    qp->port = init_attr->port_num;
  } else {

  }
#line 950
  tmp___21 = to_mlx5_st(init_attr->qp_type);
#line 950
  tmp___22 = __fswab32((__u32 )((tmp___21 << 16) | 6144));
#line 950
  in->ctx.flags = tmp___22;
#line 953
  if ((unsigned int )init_attr->qp_type != 4096U) {
#line 954
    tmp___23 = to_mpd((unsigned long )pd == (unsigned long )((struct ib_pd *)0) ? devr->p0 : pd);
#line 954
    tmp___24 = __fswab32(tmp___23->pdn);
#line 954
    in->ctx.flags_pd = tmp___24;
  } else {
#line 956
    in->ctx.flags_pd = 16U;
  }
#line 958
  if (qp->wq_sig != 0) {
#line 959
    in->ctx.flags_pd = in->ctx.flags_pd | 128U;
  } else {

  }
#line 961
  if ((int )qp->flags & 1) {
#line 962
    in->ctx.flags_pd = in->ctx.flags_pd | 64U;
  } else {

  }
#line 964
  if (qp->scat_cqe != 0) {
#line 964
    tmp___25 = is_connected(init_attr->qp_type);
#line 964
    if (tmp___25 != 0) {
#line 968
      rcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);
#line 969
      scqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);
#line 971
      if (rcqe_sz == 128) {
#line 972
        in->ctx.cs_res = 2U;
      } else {
#line 974
        in->ctx.cs_res = 1U;
      }
#line 976
      if ((unsigned int )init_attr->sq_sig_type == 0U) {
#line 977
        if (scqe_sz == 128) {
#line 978
          in->ctx.cs_req = 34U;
        } else {
#line 980
          in->ctx.cs_req = 17U;
        }
      } else {

      }
    } else {

    }
  } else {

  }
#line 984
  if (qp->rq.wqe_cnt != 0) {
#line 985
    in->ctx.rq_size_stride = (unsigned int )((u8 )qp->rq.wqe_shift) + 252U;
#line 986
    tmp___26 = __ilog2_u32((u32 )qp->rq.wqe_cnt);
#line 986
    in->ctx.rq_size_stride = (u8 )((int )((signed char )in->ctx.rq_size_stride) | (int )((signed char )(tmp___26 << 3)));
  } else {

  }
#line 989
  in->ctx.rq_type_srqn = get_rx_type(qp, init_attr);
#line 991
  if (qp->sq.wqe_cnt != 0) {
#line 992
    tmp___27 = __ilog2_u32((u32 )qp->sq.wqe_cnt);
#line 992
    tmp___28 = __fswab16((int )((__u16 )tmp___27) << 11U);
#line 992
    in->ctx.sq_crq_size = (__be16 )((int )in->ctx.sq_crq_size | (int )tmp___28);
  } else {
#line 994
    in->ctx.sq_crq_size = (__be16 )((unsigned int )in->ctx.sq_crq_size | 128U);
  }
#line 997
  switch ((unsigned int )init_attr->qp_type) {
  case 10U: 
#line 999
  tmp___29 = to_mcq(devr->c0);
#line 999
  tmp___30 = __fswab32(tmp___29->mcq.cqn);
#line 999
  in->ctx.cqn_recv = tmp___30;
#line 1000
  tmp___31 = to_mcq(devr->c0);
#line 1000
  tmp___32 = __fswab32(tmp___31->mcq.cqn);
#line 1000
  in->ctx.cqn_send = tmp___32;
#line 1001
  tmp___33 = to_msrq(devr->s0);
#line 1001
  tmp___34 = __fswab32(tmp___33->msrq.srqn);
#line 1001
  in->ctx.rq_type_srqn = in->ctx.rq_type_srqn | tmp___34;
#line 1002
  tmp___35 = to_mxrcd(init_attr->xrcd);
#line 1002
  tmp___36 = __fswab32(tmp___35->xrcdn);
#line 1002
  in->ctx.xrcd = tmp___36;
#line 1003
  goto ldv_37324;
  case 9U: 
#line 1005
  tmp___37 = to_mcq(devr->c0);
#line 1005
  tmp___38 = __fswab32(tmp___37->mcq.cqn);
#line 1005
  in->ctx.cqn_recv = tmp___38;
#line 1006
  tmp___39 = to_mxrcd(devr->x1);
#line 1006
  tmp___40 = __fswab32(tmp___39->xrcdn);
#line 1006
  in->ctx.xrcd = tmp___40;
#line 1007
  tmp___41 = to_msrq(devr->s0);
#line 1007
  tmp___42 = __fswab32(tmp___41->msrq.srqn);
#line 1007
  in->ctx.rq_type_srqn = in->ctx.rq_type_srqn | tmp___42;
#line 1008
  goto ldv_37324;
  default: ;
#line 1010
  if ((unsigned long )init_attr->srq != (unsigned long )((struct ib_srq *)0)) {
#line 1011
    tmp___43 = to_mxrcd(devr->x0);
#line 1011
    tmp___44 = __fswab32(tmp___43->xrcdn);
#line 1011
    in->ctx.xrcd = tmp___44;
#line 1012
    tmp___45 = to_msrq(init_attr->srq);
#line 1012
    tmp___46 = __fswab32(tmp___45->msrq.srqn);
#line 1012
    in->ctx.rq_type_srqn = in->ctx.rq_type_srqn | tmp___46;
  } else {
#line 1014
    tmp___47 = to_mxrcd(devr->x1);
#line 1014
    tmp___48 = __fswab32(tmp___47->xrcdn);
#line 1014
    in->ctx.xrcd = tmp___48;
#line 1015
    tmp___49 = to_msrq(devr->s1);
#line 1015
    tmp___50 = __fswab32(tmp___49->msrq.srqn);
#line 1015
    in->ctx.rq_type_srqn = in->ctx.rq_type_srqn | tmp___50;
  }
  }
  ldv_37324: ;
#line 1020
  if ((unsigned long )init_attr->send_cq != (unsigned long )((struct ib_cq *)0)) {
#line 1021
    tmp___51 = to_mcq(init_attr->send_cq);
#line 1021
    tmp___52 = __fswab32(tmp___51->mcq.cqn);
#line 1021
    in->ctx.cqn_send = tmp___52;
  } else {

  }
#line 1023
  if ((unsigned long )init_attr->recv_cq != (unsigned long )((struct ib_cq *)0)) {
#line 1024
    tmp___53 = to_mcq(init_attr->recv_cq);
#line 1024
    tmp___54 = __fswab32(tmp___53->mcq.cqn);
#line 1024
    in->ctx.cqn_recv = tmp___54;
  } else {

  }
#line 1026
  tmp___55 = __fswab64(qp->db.dma);
#line 1026
  in->ctx.db_rec_addr = tmp___55;
#line 1028
  err = mlx5_core_create_qp(dev->mdev, & qp->mqp, in, inlen);
#line 1029
  if (err != 0) {
#line 1030
    descriptor___7.modname = "mlx5_ib";
#line 1030
    descriptor___7.function = "create_qp_common";
#line 1030
    descriptor___7.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 1030
    descriptor___7.format = "%s:%s:%d:(pid %d): create qp failed\n";
#line 1030
    descriptor___7.lineno = 1030U;
#line 1030
    descriptor___7.flags = 0U;
#line 1030
    tmp___57 = ldv__builtin_expect((long )descriptor___7.flags & 1L, 0L);
#line 1030
    if (tmp___57 != 0L) {
#line 1030
      tmp___56 = get_current();
#line 1030
      __dynamic_pr_debug(& descriptor___7, "%s:%s:%d:(pid %d): create qp failed\n",
                         (char *)(& dev->ib_dev.name), "create_qp_common", 1030, tmp___56->pid);
    } else {

    }
#line 1031
    goto err_create;
  } else {

  }
#line 1034
  kvfree((void const   *)in);
#line 1039
  tmp___58 = __fswab32((__u32 )(qp->mqp.qpn << 8));
#line 1039
  qp->doorbell_qpn = tmp___58;
#line 1041
  qp->mqp.event = & mlx5_ib_qp_event;
#line 1043
  return (0);
  err_create: ;
#line 1046
  if (qp->create_type == 0) {
#line 1047
    destroy_qp_user(pd, qp);
  } else
#line 1048
  if (qp->create_type == 1) {
#line 1049
    destroy_qp_kernel(dev, qp);
  } else {

  }
#line 1051
  kvfree((void const   *)in);
#line 1052
  return (err);
}
}
#line 1055 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void mlx5_ib_lock_cqs(struct mlx5_ib_cq *send_cq , struct mlx5_ib_cq *recv_cq ) 
{ 
  raw_spinlock_t *tmp ;
  raw_spinlock_t *tmp___0 ;

  {
#line 1058
  if ((unsigned long )send_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1059
    if ((unsigned long )recv_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1060
      if (send_cq->mcq.cqn < recv_cq->mcq.cqn) {
#line 1061
        spin_lock_irq(& send_cq->lock);
#line 1062
        tmp = spinlock_check(& recv_cq->lock);
#line 1062
        _raw_spin_lock_nested(tmp, 1);
      } else
#line 1064
      if (send_cq->mcq.cqn == recv_cq->mcq.cqn) {
#line 1065
        spin_lock_irq(& send_cq->lock);
      } else {
#line 1068
        spin_lock_irq(& recv_cq->lock);
#line 1069
        tmp___0 = spinlock_check(& send_cq->lock);
#line 1069
        _raw_spin_lock_nested(tmp___0, 1);
      }
    } else {
#line 1073
      spin_lock_irq(& send_cq->lock);
    }
  } else
#line 1076
  if ((unsigned long )recv_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1077
    spin_lock_irq(& recv_cq->lock);
  } else {

  }
#line 1083
  return;
}
}
#line 1085 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void mlx5_ib_unlock_cqs(struct mlx5_ib_cq *send_cq , struct mlx5_ib_cq *recv_cq ) 
{ 


  {
#line 1088
  if ((unsigned long )send_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1089
    if ((unsigned long )recv_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1090
      if (send_cq->mcq.cqn < recv_cq->mcq.cqn) {
#line 1091
        spin_unlock(& recv_cq->lock);
#line 1092
        spin_unlock_irq(& send_cq->lock);
      } else
#line 1093
      if (send_cq->mcq.cqn == recv_cq->mcq.cqn) {
#line 1095
        spin_unlock_irq(& send_cq->lock);
      } else {
#line 1097
        spin_unlock(& send_cq->lock);
#line 1098
        spin_unlock_irq(& recv_cq->lock);
      }
    } else {
#line 1102
      spin_unlock_irq(& send_cq->lock);
    }
  } else
#line 1104
  if ((unsigned long )recv_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1106
    spin_unlock_irq(& recv_cq->lock);
  } else {

  }
#line 1111
  return;
}
}
#line 1113 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static struct mlx5_ib_pd *get_pd(struct mlx5_ib_qp *qp ) 
{ 
  struct mlx5_ib_pd *tmp ;

  {
#line 1115
  tmp = to_mpd(qp->ibqp.pd);
#line 1115
  return (tmp);
}
}
#line 1118 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void get_cqs(struct mlx5_ib_qp *qp , struct mlx5_ib_cq **send_cq , struct mlx5_ib_cq **recv_cq ) 
{ 


  {
#line 1121
  switch ((unsigned int )qp->ibqp.qp_type) {
  case 10U: 
#line 1123
  *send_cq = (struct mlx5_ib_cq *)0;
#line 1124
  *recv_cq = (struct mlx5_ib_cq *)0;
#line 1125
  goto ldv_37346;
  case 4096U: ;
  case 9U: 
#line 1128
  *send_cq = to_mcq(qp->ibqp.send_cq);
#line 1129
  *recv_cq = (struct mlx5_ib_cq *)0;
#line 1130
  goto ldv_37346;
  case 0U: ;
  case 1U: ;
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 5U: ;
  case 6U: 
#line 1139
  *send_cq = to_mcq(qp->ibqp.send_cq);
#line 1140
  *recv_cq = to_mcq(qp->ibqp.recv_cq);
#line 1141
  goto ldv_37346;
  case 8U: ;
  case 11U: ;
  default: 
#line 1146
  *send_cq = (struct mlx5_ib_cq *)0;
#line 1147
  *recv_cq = (struct mlx5_ib_cq *)0;
#line 1148
  goto ldv_37346;
  }
  ldv_37346: ;
#line 1151
  return;
}
}
#line 1152 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void destroy_qp_common(struct mlx5_ib_dev *dev , struct mlx5_ib_qp *qp ) 
{ 
  struct mlx5_ib_cq *send_cq ;
  struct mlx5_ib_cq *recv_cq ;
  struct mlx5_modify_qp_mbox_in *in ;
  int err ;
  void *tmp ;
  struct task_struct *tmp___0 ;
  enum mlx5_qp_state tmp___1 ;
  int tmp___2 ;
  struct mlx5_ib_srq *tmp___3 ;
  struct mlx5_ib_srq *tmp___4 ;
  struct task_struct *tmp___5 ;
  struct mlx5_ib_pd *tmp___6 ;

  {
#line 1158
  tmp = kzalloc(256UL, 208U);
#line 1158
  in = (struct mlx5_modify_qp_mbox_in *)tmp;
#line 1159
  if ((unsigned long )in == (unsigned long )((struct mlx5_modify_qp_mbox_in *)0)) {
#line 1160
    return;
  } else {

  }
#line 1162
  if ((unsigned int )qp->state != 0U) {
#line 1163
    mlx5_ib_qp_disable_pagefaults(qp);
#line 1164
    tmp___1 = to_mlx5_state((enum ib_qp_state )qp->state);
#line 1164
    tmp___2 = mlx5_core_qp_modify(dev->mdev, tmp___1, 0, in, 0, & qp->mqp);
#line 1164
    if (tmp___2 != 0) {
#line 1166
      tmp___0 = get_current();
#line 1166
      printk("\f%s:%s:%d:(pid %d): mlx5_ib: modify QP %06x to RESET failed\n", (char *)(& dev->ib_dev.name),
             "destroy_qp_common", 1167, tmp___0->pid, qp->mqp.qpn);
    } else {

    }
  } else {

  }
#line 1170
  get_cqs(qp, & send_cq, & recv_cq);
#line 1172
  if (qp->create_type == 1) {
#line 1173
    mlx5_ib_lock_cqs(send_cq, recv_cq);
#line 1174
    if ((unsigned long )qp->ibqp.srq != (unsigned long )((struct ib_srq *)0)) {
#line 1174
      tmp___3 = to_msrq(qp->ibqp.srq);
#line 1174
      tmp___4 = tmp___3;
    } else {
#line 1174
      tmp___4 = (struct mlx5_ib_srq *)0;
    }
#line 1174
    __mlx5_ib_cq_clean(recv_cq, (u32 )qp->mqp.qpn, tmp___4);
#line 1176
    if ((unsigned long )send_cq != (unsigned long )recv_cq) {
#line 1177
      __mlx5_ib_cq_clean(send_cq, (u32 )qp->mqp.qpn, (struct mlx5_ib_srq *)0);
    } else {

    }
#line 1178
    mlx5_ib_unlock_cqs(send_cq, recv_cq);
  } else {

  }
#line 1181
  err = mlx5_core_destroy_qp(dev->mdev, & qp->mqp);
#line 1182
  if (err != 0) {
#line 1183
    tmp___5 = get_current();
#line 1183
    printk("\f%s:%s:%d:(pid %d): failed to destroy QP 0x%x\n", (char *)(& dev->ib_dev.name),
           "destroy_qp_common", 1183, tmp___5->pid, qp->mqp.qpn);
  } else {

  }
#line 1184
  kfree((void const   *)in);
#line 1187
  if (qp->create_type == 1) {
#line 1188
    destroy_qp_kernel(dev, qp);
  } else
#line 1189
  if (qp->create_type == 0) {
#line 1190
    tmp___6 = get_pd(qp);
#line 1190
    destroy_qp_user(& tmp___6->ibpd, qp);
  } else {

  }
#line 1191
  return;
}
}
#line 1193 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static char const   *ib_qp_type_str(enum ib_qp_type type ) 
{ 


  {
#line 1195
  switch ((unsigned int )type) {
  case 0U: ;
#line 1197
  return ("IB_QPT_SMI");
  case 1U: ;
#line 1199
  return ("IB_QPT_GSI");
  case 2U: ;
#line 1201
  return ("IB_QPT_RC");
  case 3U: ;
#line 1203
  return ("IB_QPT_UC");
  case 4U: ;
#line 1205
  return ("IB_QPT_UD");
  case 5U: ;
#line 1207
  return ("IB_QPT_RAW_IPV6");
  case 6U: ;
#line 1209
  return ("IB_QPT_RAW_ETHERTYPE");
  case 9U: ;
#line 1211
  return ("IB_QPT_XRC_INI");
  case 10U: ;
#line 1213
  return ("IB_QPT_XRC_TGT");
  case 8U: ;
#line 1215
  return ("IB_QPT_RAW_PACKET");
  case 4096U: ;
#line 1217
  return ("MLX5_IB_QPT_REG_UMR");
  case 11U: ;
  default: ;
#line 1220
  return ("Invalid QP type");
  }
}
}
#line 1224 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd , struct ib_qp_init_attr *init_attr ,
                                struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_qp *qp ;
  u16 xrcdn ;
  int err ;
  char const   *tmp ;
  void *tmp___0 ;
  struct mlx5_ib_xrcd *tmp___1 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___2 ;
  long tmp___3 ;
  void *tmp___4 ;
  __u32 tmp___5 ;
  struct mlx5_ib_xrcd *tmp___6 ;
  void *tmp___7 ;
  void *tmp___8 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___9 ;
  long tmp___10 ;
  void *tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  struct _ddebug descriptor___1 ;
  struct mlx5_ib_cq *tmp___14 ;
  struct mlx5_ib_cq *tmp___15 ;
  struct task_struct *tmp___16 ;
  long tmp___17 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___18 ;
  long tmp___19 ;
  void *tmp___20 ;

  {
#line 1230
  xrcdn = 0U;
#line 1233
  if ((unsigned long )pd != (unsigned long )((struct ib_pd *)0)) {
#line 1234
    dev = to_mdev(pd->device);
  } else {
#line 1237
    if ((unsigned int )init_attr->qp_type != 10U && (unsigned int )init_attr->qp_type != 4096U) {
#line 1239
      tmp = ib_qp_type_str(init_attr->qp_type);
#line 1239
      printk("\f%s: no PD for transport %s\n", "mlx5_ib_create_qp", tmp);
#line 1241
      tmp___0 = ERR_PTR(-22L);
#line 1241
      return ((struct ib_qp *)tmp___0);
    } else {

    }
#line 1243
    tmp___1 = to_mxrcd(init_attr->xrcd);
#line 1243
    dev = to_mdev(tmp___1->ibxrcd.device);
  }
#line 1246
  switch ((unsigned int )init_attr->qp_type) {
  case 10U: ;
  case 9U: 
#line 1249
  tmp___5 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 17UL));
#line 1249
  if ((tmp___5 & 8U) == 0U) {
#line 1250
    descriptor.modname = "mlx5_ib";
#line 1250
    descriptor.function = "mlx5_ib_create_qp";
#line 1250
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 1250
    descriptor.format = "%s:%s:%d:(pid %d): XRC not supported\n";
#line 1250
    descriptor.lineno = 1250U;
#line 1250
    descriptor.flags = 0U;
#line 1250
    tmp___3 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1250
    if (tmp___3 != 0L) {
#line 1250
      tmp___2 = get_current();
#line 1250
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): XRC not supported\n", (char *)(& dev->ib_dev.name),
                         "mlx5_ib_create_qp", 1250, tmp___2->pid);
    } else {

    }
#line 1251
    tmp___4 = ERR_PTR(-38L);
#line 1251
    return ((struct ib_qp *)tmp___4);
  } else {

  }
#line 1253
  init_attr->recv_cq = (struct ib_cq *)0;
#line 1254
  if ((unsigned int )init_attr->qp_type == 10U) {
#line 1255
    tmp___6 = to_mxrcd(init_attr->xrcd);
#line 1255
    xrcdn = (u16 )tmp___6->xrcdn;
#line 1256
    init_attr->send_cq = (struct ib_cq *)0;
  } else {

  }
  case 2U: ;
  case 3U: ;
  case 4U: ;
  case 0U: ;
  case 1U: ;
  case 4096U: 
#line 1266
  tmp___7 = kzalloc(1448UL, 208U);
#line 1266
  qp = (struct mlx5_ib_qp *)tmp___7;
#line 1267
  if ((unsigned long )qp == (unsigned long )((struct mlx5_ib_qp *)0)) {
#line 1268
    tmp___8 = ERR_PTR(-12L);
#line 1268
    return ((struct ib_qp *)tmp___8);
  } else {

  }
#line 1270
  err = create_qp_common(dev, pd, init_attr, udata, qp);
#line 1271
  if (err != 0) {
#line 1272
    descriptor___0.modname = "mlx5_ib";
#line 1272
    descriptor___0.function = "mlx5_ib_create_qp";
#line 1272
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 1272
    descriptor___0.format = "%s:%s:%d:(pid %d): create_qp_common failed\n";
#line 1272
    descriptor___0.lineno = 1272U;
#line 1272
    descriptor___0.flags = 0U;
#line 1272
    tmp___10 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 1272
    if (tmp___10 != 0L) {
#line 1272
      tmp___9 = get_current();
#line 1272
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): create_qp_common failed\n",
                         (char *)(& dev->ib_dev.name), "mlx5_ib_create_qp", 1272,
                         tmp___9->pid);
    } else {

    }
#line 1273
    kfree((void const   *)qp);
#line 1274
    tmp___11 = ERR_PTR((long )err);
#line 1274
    return ((struct ib_qp *)tmp___11);
  } else {

  }
#line 1277
  tmp___13 = is_qp0(init_attr->qp_type);
#line 1277
  if (tmp___13 != 0) {
#line 1278
    qp->ibqp.qp_num = 0U;
  } else {
#line 1279
    tmp___12 = is_qp1(init_attr->qp_type);
#line 1279
    if (tmp___12 != 0) {
#line 1280
      qp->ibqp.qp_num = 1U;
    } else {
#line 1282
      qp->ibqp.qp_num = (u32 )qp->mqp.qpn;
    }
  }
#line 1284
  descriptor___1.modname = "mlx5_ib";
#line 1284
  descriptor___1.function = "mlx5_ib_create_qp";
#line 1284
  descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 1284
  descriptor___1.format = "%s:%s:%d:(pid %d): ib qpnum 0x%x, mlx qpn 0x%x, rcqn 0x%x, scqn 0x%x\n";
#line 1284
  descriptor___1.lineno = 1286U;
#line 1284
  descriptor___1.flags = 0U;
#line 1284
  tmp___17 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 1284
  if (tmp___17 != 0L) {
#line 1284
    tmp___14 = to_mcq(init_attr->send_cq);
#line 1284
    tmp___15 = to_mcq(init_attr->recv_cq);
#line 1284
    tmp___16 = get_current();
#line 1284
    __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): ib qpnum 0x%x, mlx qpn 0x%x, rcqn 0x%x, scqn 0x%x\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_create_qp", 1286, tmp___16->pid,
                       qp->ibqp.qp_num, qp->mqp.qpn, tmp___15->mcq.cqn, tmp___14->mcq.cqn);
  } else {

  }
#line 1288
  qp->xrcdn = xrcdn;
#line 1290
  goto ldv_37405;
  case 5U: ;
  case 6U: ;
  case 8U: ;
  case 11U: ;
  default: 
#line 1297
  descriptor___2.modname = "mlx5_ib";
#line 1297
  descriptor___2.function = "mlx5_ib_create_qp";
#line 1297
  descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c";
#line 1297
  descriptor___2.format = "%s:%s:%d:(pid %d): unsupported qp type %d\n";
#line 1297
  descriptor___2.lineno = 1298U;
#line 1297
  descriptor___2.flags = 0U;
#line 1297
  tmp___19 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 1297
  if (tmp___19 != 0L) {
#line 1297
    tmp___18 = get_current();
#line 1297
    __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): unsupported qp type %d\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_create_qp", 1298, tmp___18->pid,
                       (unsigned int )init_attr->qp_type);
  } else {

  }
#line 1300
  tmp___20 = ERR_PTR(-22L);
#line 1300
  return ((struct ib_qp *)tmp___20);
  }
  ldv_37405: ;
#line 1303
  return (& qp->ibqp);
}
}
#line 1306 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_destroy_qp(struct ib_qp *qp ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_qp *mqp ;
  struct mlx5_ib_qp *tmp___0 ;

  {
#line 1308
  tmp = to_mdev(qp->device);
#line 1308
  dev = tmp;
#line 1309
  tmp___0 = to_mqp(qp);
#line 1309
  mqp = tmp___0;
#line 1311
  destroy_qp_common(dev, mqp);
#line 1313
  kfree((void const   *)mqp);
#line 1315
  return (0);
}
}
#line 1318 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be32 to_mlx5_access_flags(struct mlx5_ib_qp *qp , struct ib_qp_attr  const  *attr ,
                                   int attr_mask ) 
{ 
  u32 hw_access_flags ;
  u8 dest_rd_atomic ;
  u32 access_flags ;
  __u32 tmp ;

  {
#line 1321
  hw_access_flags = 0U;
#line 1325
  if ((attr_mask & 131072) != 0) {
#line 1326
    dest_rd_atomic = attr->max_dest_rd_atomic;
  } else {
#line 1328
    dest_rd_atomic = qp->resp_depth;
  }
#line 1330
  if ((attr_mask & 8) != 0) {
#line 1331
    access_flags = (u32 )attr->qp_access_flags;
  } else {
#line 1333
    access_flags = (u32 )qp->atomic_rd_en;
  }
#line 1335
  if ((unsigned int )dest_rd_atomic == 0U) {
#line 1336
    access_flags = access_flags & 2U;
  } else {

  }
#line 1338
  if ((access_flags & 4U) != 0U) {
#line 1339
    hw_access_flags = hw_access_flags | 32768U;
  } else {

  }
#line 1340
  if ((access_flags & 8U) != 0U) {
#line 1341
    hw_access_flags = hw_access_flags | 139264U;
  } else {

  }
#line 1342
  if ((access_flags & 2U) != 0U) {
#line 1343
    hw_access_flags = hw_access_flags | 16384U;
  } else {

  }
#line 1345
  tmp = __fswab32(hw_access_flags);
#line 1345
  return (tmp);
}
}
#line 1354 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int ib_rate_to_mlx5(struct mlx5_ib_dev *dev , u8 rate ) 
{ 
  __u32 tmp ;

  {
#line 1356
  if ((unsigned int )rate == 0U) {
#line 1357
    return (0);
  } else
#line 1358
  if ((unsigned int )rate <= 1U || (unsigned int )rate > 18U) {
#line 1359
    return (-22);
  } else {
#line 1361
    goto ldv_37434;
    ldv_37433: 
#line 1364
    rate = (u8 )((int )rate - 1);
    ldv_37434: ;
#line 1361
    if ((unsigned int )rate != 2U) {
#line 1361
      tmp = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 15UL));
#line 1361
      if (((unsigned int )(1 << ((int )rate + 5)) & (tmp >> 16)) == 0U) {
#line 1364
        goto ldv_37433;
      } else {
#line 1367
        goto ldv_37435;
      }
    } else {

    }
    ldv_37435: ;
  }
#line 1367
  return ((int )rate + 5);
}
}
#line 1370 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int mlx5_set_path(struct mlx5_ib_dev *dev , struct ib_ah_attr  const  *ah ,
                         struct mlx5_qp_path *path , u8 port , int attr_mask , u32 path_flags ,
                         struct ib_qp_attr  const  *attr ) 
{ 
  int err ;
  __u16 tmp ;
  __u32 tmp___0 ;

  {
#line 1376
  path->fl = (int )path_flags & 1 ? 128U : 0U;
#line 1377
  path->free_ar = (path_flags & 2U) != 0U ? 128U : 0U;
#line 1379
  if ((attr_mask & 16) != 0) {
#line 1380
    path->pkey_index = (u8 )attr->pkey_index;
  } else {

  }
#line 1382
  path->grh_mlid = (unsigned int )((u8 )ah->src_path_bits) & 127U;
#line 1383
  tmp = __fswab16((int )ah->dlid);
#line 1383
  path->rlid = tmp;
#line 1385
  if ((int )ah->ah_flags & 1) {
#line 1386
    if ((int )ah->grh.sgid_index >= (dev->mdev)->port_caps[(int )port + -1].gid_table_len) {
#line 1388
      printk("\vsgid_index (%u) too large. max is %d\n", (int )ah->grh.sgid_index,
             (dev->mdev)->port_caps[(int )port + -1].gid_table_len);
#line 1391
      return (-22);
    } else {

    }
#line 1393
    path->grh_mlid = (u8 )((unsigned int )path->grh_mlid | 128U);
#line 1394
    path->mgid_index = ah->grh.sgid_index;
#line 1395
    path->hop_limit = ah->grh.hop_limit;
#line 1396
    tmp___0 = __fswab32((unsigned int )((int )ah->grh.traffic_class << 20) | (unsigned int )ah->grh.flow_label);
#line 1396
    path->tclass_flowlabel = tmp___0;
#line 1399
    memcpy((void *)(& path->rgid), (void const   *)(& ah->grh.dgid.raw), 16UL);
  } else {

  }
#line 1402
  err = ib_rate_to_mlx5(dev, (int )ah->static_rate);
#line 1403
  if (err < 0) {
#line 1404
    return (err);
  } else {

  }
#line 1405
  path->static_rate = (u8 )err;
#line 1406
  path->port = port;
#line 1408
  if ((attr_mask & 512) != 0) {
#line 1409
    path->ackto_lt = (int )((u8 )attr->timeout) << 3U;
  } else {

  }
#line 1411
  path->sl = (unsigned int )((u8 )ah->sl) & 15U;
#line 1413
  return (0);
}
}
#line 1416 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static enum mlx5_qp_optpar opt_mask[10U][10U][13U]  = { { {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}}, 
   { {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          65566,          65560,          65584}, 
     {          31,          25,          48,          31, 
                48}}, 
   { {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          1103,          1033,          32}}, 
   { {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          1103,          1033,          786464}}, 
   { {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          0,          0,          0,          0, 
                0,          0,          0,          0, 
                0,          0,          0,          0, 
                0}, 
     {          78,          8,          32,          0, 
                32}}};
#line 1494 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int ib_nr_to_mlx5_nr(int ib_mask ) 
{ 


  {
#line 1496
  switch (ib_mask) {
  case 1: ;
#line 1498
  return (0);
  case 2: ;
#line 1500
  return (0);
  case 4: ;
#line 1502
  return (0);
  case 8: ;
#line 1504
  return (14);
  case 16: ;
#line 1507
  return (16);
  case 32: ;
#line 1509
  return (65536);
  case 64: ;
#line 1511
  return (32);
  case 128: ;
#line 1513
  return (65664);
  case 256: ;
#line 1516
  return (0);
  case 512: ;
#line 1518
  return (16384);
  case 1024: ;
#line 1520
  return (4096);
  case 2048: ;
#line 1522
  return (8192);
  case 4096: ;
#line 1524
  return (0);
  case 8192: ;
#line 1526
  return (256);
  case 16384: ;
#line 1528
  return (1);
  case 32768: ;
#line 1530
  return (64);
  case 65536: ;
#line 1532
  return (0);
  case 131072: ;
#line 1534
  return (526);
  case 262144: ;
#line 1537
  return (1024);
  case 524288: ;
#line 1539
  return (0);
  case 1048576: ;
#line 1541
  return (0);
  }
#line 1543
  return (0);
}
}
#line 1546 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int ib_mask_to_mlx5_opt(int ib_mask ) 
{ 
  int result ;
  int i ;
  int tmp ;

  {
#line 1548
  result = 0;
#line 1551
  i = 0;
#line 1551
  goto ldv_37477;
  ldv_37476: ;
#line 1552
  if ((ib_mask >> i) & 1) {
#line 1553
    tmp = ib_nr_to_mlx5_nr(1 << i);
#line 1553
    result = tmp | result;
  } else {

  }
#line 1551
  i = i + 1;
  ldv_37477: ;
#line 1551
  if ((unsigned int )i <= 31U) {
#line 1553
    goto ldv_37476;
  } else {

  }

#line 1556
  return (result);
}
}
#line 1559 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int __mlx5_ib_modify_qp(struct ib_qp *ibqp , struct ib_qp_attr  const  *attr ,
                               int attr_mask , enum ib_qp_state cur_state , enum ib_qp_state new_state ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_qp *qp ;
  struct mlx5_ib_qp *tmp___0 ;
  struct mlx5_ib_cq *send_cq ;
  struct mlx5_ib_cq *recv_cq ;
  struct mlx5_qp_context *context ;
  struct mlx5_modify_qp_mbox_in *in ;
  struct mlx5_ib_pd *pd ;
  enum mlx5_qp_state mlx5_cur ;
  enum mlx5_qp_state mlx5_new ;
  enum mlx5_qp_optpar optpar ;
  int sqd_event ;
  int mlx5_st ;
  int err ;
  void *tmp___1 ;
  __u32 tmp___2 ;
  struct task_struct *tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  int tmp___6 ;
  struct mlx5_ib_pd *tmp___7 ;
  u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  __u32 tmp___12 ;
  __u32 tmp___13 ;
  int tmp___14 ;
  __u32 tmp___15 ;
  __u32 tmp___16 ;
  int tmp___17 ;
  __u32 tmp___18 ;
  __be32 tmp___19 ;
  __u32 tmp___20 ;
  __u32 tmp___21 ;
  __u32 tmp___22 ;
  __u64 tmp___23 ;
  int tmp___24 ;
  __u32 tmp___25 ;
  enum mlx5_qp_state tmp___26 ;
  enum mlx5_qp_state tmp___27 ;
  struct mlx5_ib_srq *tmp___28 ;
  struct mlx5_ib_srq *tmp___29 ;

  {
#line 1563
  tmp = to_mdev(ibqp->device);
#line 1563
  dev = tmp;
#line 1564
  tmp___0 = to_mqp(ibqp);
#line 1564
  qp = tmp___0;
#line 1575
  tmp___1 = kzalloc(256UL, 208U);
#line 1575
  in = (struct mlx5_modify_qp_mbox_in *)tmp___1;
#line 1576
  if ((unsigned long )in == (unsigned long )((struct mlx5_modify_qp_mbox_in *)0)) {
#line 1577
    return (-12);
  } else {

  }
#line 1579
  context = & in->ctx;
#line 1580
  err = to_mlx5_st(ibqp->qp_type);
#line 1581
  if (err < 0) {
#line 1582
    goto out;
  } else {

  }
#line 1584
  tmp___2 = __fswab32((__u32 )(err << 16));
#line 1584
  context->flags = tmp___2;
#line 1586
  if ((attr_mask & 262144) == 0) {
#line 1587
    context->flags = context->flags | 1572864U;
  } else {
#line 1589
    switch ((unsigned int )attr->path_mig_state) {
    case 0U: 
#line 1591
    context->flags = context->flags | 1572864U;
#line 1592
    goto ldv_37501;
    case 1U: 
#line 1594
    context->flags = context->flags | 524288U;
#line 1595
    goto ldv_37501;
    case 2U: 
#line 1597
    context->flags = context->flags;
#line 1598
    goto ldv_37501;
    }
    ldv_37501: ;
  }
#line 1602
  if ((unsigned int )ibqp->qp_type == 1U || (unsigned int )ibqp->qp_type == 0U) {
#line 1603
    context->mtu_msgmax = 40U;
  } else
#line 1604
  if ((unsigned int )ibqp->qp_type == 4U || (unsigned int )ibqp->qp_type == 4096U) {
#line 1606
    context->mtu_msgmax = 172U;
  } else
#line 1607
  if ((attr_mask & 256) != 0) {
#line 1608
    if ((unsigned int )attr->path_mtu == 0U || (unsigned int )attr->path_mtu > 5U) {
#line 1610
      tmp___3 = get_current();
#line 1610
      printk("\f%s:%s:%d:(pid %d): invalid mtu %d\n", (char *)(& dev->ib_dev.name),
             "__mlx5_ib_modify_qp", 1610, tmp___3->pid, (unsigned int )attr->path_mtu);
#line 1611
      err = -22;
#line 1612
      goto out;
    } else {

    }
#line 1614
    tmp___4 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 14UL));
#line 1614
    context->mtu_msgmax = (unsigned int )((int )((u8 )attr->path_mtu) << 5U) | ((unsigned int )((u8 )(tmp___4 >> 24)) & 31U);
  } else {

  }
#line 1618
  if ((attr_mask & 1048576) != 0) {
#line 1619
    tmp___5 = __fswab32(attr->dest_qp_num);
#line 1619
    context->log_pg_sz_remote_qpn = tmp___5;
  } else {

  }
#line 1621
  if ((attr_mask & 16) != 0) {
#line 1622
    context->pri_path.pkey_index = (u8 )attr->pkey_index;
  } else {

  }
#line 1626
  tmp___6 = is_sqp(ibqp->qp_type);
#line 1626
  if (tmp___6 != 0) {
#line 1627
    context->pri_path.port = qp->port;
  } else {

  }
#line 1629
  if ((attr_mask & 32) != 0) {
#line 1630
    context->pri_path.port = attr->port_num;
  } else {

  }
#line 1632
  if ((attr_mask & 128) != 0) {
#line 1633
    err = mlx5_set_path(dev, & attr->ah_attr, & context->pri_path, (attr_mask & 32) != 0 ? (int )attr->port_num : (int )qp->port,
                        attr_mask, 0U, attr);
#line 1636
    if (err != 0) {
#line 1637
      goto out;
    } else {

    }
  } else {

  }
#line 1640
  if ((attr_mask & 512) != 0) {
#line 1641
    context->pri_path.ackto_lt = (u8 )((int )((signed char )context->pri_path.ackto_lt) | (int )((signed char )((int )attr->timeout << 3)));
  } else {

  }
#line 1643
  if ((attr_mask & 16384) != 0) {
#line 1644
    err = mlx5_set_path(dev, & attr->alt_ah_attr, & context->alt_path, (int )attr->alt_port_num,
                        attr_mask, 0U, attr);
#line 1646
    if (err != 0) {
#line 1647
      goto out;
    } else {

    }
  } else {

  }
#line 1650
  pd = get_pd(qp);
#line 1651
  get_cqs(qp, & send_cq, & recv_cq);
#line 1653
  if ((unsigned long )pd != (unsigned long )((struct mlx5_ib_pd *)0)) {
#line 1653
    tmp___8 = pd->pdn;
  } else {
#line 1653
    tmp___7 = to_mpd(dev->devr.p0);
#line 1653
    tmp___8 = tmp___7->pdn;
  }
#line 1653
  tmp___9 = __fswab32(tmp___8);
#line 1653
  context->flags_pd = tmp___9;
#line 1654
  if ((unsigned long )send_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1654
    tmp___10 = __fswab32(send_cq->mcq.cqn);
#line 1654
    context->cqn_send = tmp___10;
  } else {
#line 1654
    context->cqn_send = 0U;
  }
#line 1655
  if ((unsigned long )recv_cq != (unsigned long )((struct mlx5_ib_cq *)0)) {
#line 1655
    tmp___11 = __fswab32(recv_cq->mcq.cqn);
#line 1655
    context->cqn_recv = tmp___11;
  } else {
#line 1655
    context->cqn_recv = 0U;
  }
#line 1656
  context->params1 = 128U;
#line 1658
  if ((attr_mask & 2048) != 0) {
#line 1659
    tmp___12 = __fswab32((__u32 )((int )attr->rnr_retry << 13));
#line 1659
    context->params1 = context->params1 | tmp___12;
  } else {

  }
#line 1661
  if ((attr_mask & 1024) != 0) {
#line 1662
    tmp___13 = __fswab32((__u32 )((int )attr->retry_cnt << 16));
#line 1662
    context->params1 = context->params1 | tmp___13;
  } else {

  }
#line 1664
  if ((attr_mask & 8192) != 0) {
#line 1665
    if ((unsigned int )((unsigned char )attr->max_rd_atomic) != 0U) {
#line 1666
      tmp___14 = fls((int )attr->max_rd_atomic + -1);
#line 1666
      tmp___15 = __fswab32((__u32 )(tmp___14 << 21));
#line 1666
      context->params1 = context->params1 | tmp___15;
    } else {

    }
  } else {

  }
#line 1670
  if ((attr_mask & 65536) != 0) {
#line 1671
    tmp___16 = __fswab32(attr->sq_psn);
#line 1671
    context->next_send_psn = tmp___16;
  } else {

  }
#line 1673
  if ((attr_mask & 131072) != 0) {
#line 1674
    if ((unsigned int )((unsigned char )attr->max_dest_rd_atomic) != 0U) {
#line 1675
      tmp___17 = fls((int )attr->max_dest_rd_atomic + -1);
#line 1675
      tmp___18 = __fswab32((__u32 )(tmp___17 << 21));
#line 1675
      context->params2 = context->params2 | tmp___18;
    } else {

    }
  } else {

  }
#line 1679
  if ((attr_mask & 131080) != 0) {
#line 1680
    tmp___19 = to_mlx5_access_flags(qp, attr, attr_mask);
#line 1680
    context->params2 = context->params2 | tmp___19;
  } else {

  }
#line 1682
  if ((attr_mask & 32768) != 0) {
#line 1683
    tmp___20 = __fswab32((__u32 )((int )attr->min_rnr_timer << 24));
#line 1683
    context->rnr_nextrecvpsn = context->rnr_nextrecvpsn | tmp___20;
  } else {

  }
#line 1685
  if ((attr_mask & 4096) != 0) {
#line 1686
    tmp___21 = __fswab32(attr->rq_psn);
#line 1686
    context->rnr_nextrecvpsn = context->rnr_nextrecvpsn | tmp___21;
  } else {

  }
#line 1688
  if ((attr_mask & 64) != 0) {
#line 1689
    tmp___22 = __fswab32(attr->qkey);
#line 1689
    context->qkey = tmp___22;
  } else {

  }
#line 1691
  if ((qp->rq.wqe_cnt != 0 && (unsigned int )cur_state == 0U) && (unsigned int )new_state == 1U) {
#line 1692
    tmp___23 = __fswab64(qp->db.dma);
#line 1692
    context->db_rec_addr = tmp___23;
  } else {

  }
#line 1694
  if ((((unsigned int )cur_state == 3U && (unsigned int )new_state == 4U) && (attr_mask & 4) != 0) && (unsigned int )((unsigned char )attr->en_sqd_async_notify) != 0U) {
#line 1696
    sqd_event = 1;
  } else {
#line 1698
    sqd_event = 0;
  }
#line 1700
  if (((unsigned long )ibqp->uobject == (unsigned long )((struct ib_uobject *)0) && (unsigned int )cur_state == 0U) && (unsigned int )new_state == 1U) {
#line 1701
    context->sq_crq_size = (__be16 )((unsigned int )context->sq_crq_size | 4096U);
  } else {

  }
#line 1704
  mlx5_cur = to_mlx5_state(cur_state);
#line 1705
  mlx5_new = to_mlx5_state(new_state);
#line 1706
  mlx5_st = to_mlx5_st(ibqp->qp_type);
#line 1707
  if (mlx5_st < 0) {
#line 1708
    goto out;
  } else {

  }
#line 1715
  if (((unsigned int )cur_state != 0U && (unsigned int )cur_state != 6U) && ((unsigned int )new_state == 0U || (unsigned int )new_state == 6U)) {
#line 1717
    mlx5_ib_qp_disable_pagefaults(qp);
  } else {

  }
#line 1719
  tmp___24 = ib_mask_to_mlx5_opt(attr_mask);
#line 1719
  optpar = (enum mlx5_qp_optpar )tmp___24;
#line 1720
  optpar = (enum mlx5_qp_optpar )((unsigned int )opt_mask[(unsigned int )mlx5_cur][(unsigned int )mlx5_new][mlx5_st] & (unsigned int )optpar);
#line 1721
  tmp___25 = __fswab32((__u32 )optpar);
#line 1721
  in->optparam = tmp___25;
#line 1722
  tmp___26 = to_mlx5_state(new_state);
#line 1722
  tmp___27 = to_mlx5_state(cur_state);
#line 1722
  err = mlx5_core_qp_modify(dev->mdev, tmp___27, tmp___26, in, sqd_event, & qp->mqp);
#line 1725
  if (err != 0) {
#line 1726
    goto out;
  } else {

  }
#line 1728
  if ((unsigned int )cur_state == 0U && (unsigned int )new_state == 1U) {
#line 1729
    mlx5_ib_qp_enable_pagefaults(qp);
  } else {

  }
#line 1731
  qp->state = (u8 )new_state;
#line 1733
  if ((attr_mask & 8) != 0) {
#line 1734
    qp->atomic_rd_en = (u8 )attr->qp_access_flags;
  } else {

  }
#line 1735
  if ((attr_mask & 131072) != 0) {
#line 1736
    qp->resp_depth = attr->max_dest_rd_atomic;
  } else {

  }
#line 1737
  if ((attr_mask & 32) != 0) {
#line 1738
    qp->port = attr->port_num;
  } else {

  }
#line 1739
  if ((attr_mask & 16384) != 0) {
#line 1740
    qp->alt_port = attr->alt_port_num;
  } else {

  }
#line 1746
  if ((unsigned int )new_state == 0U && (unsigned long )ibqp->uobject == (unsigned long )((struct ib_uobject *)0)) {
#line 1747
    if ((unsigned long )ibqp->srq != (unsigned long )((struct ib_srq *)0)) {
#line 1747
      tmp___28 = to_msrq(ibqp->srq);
#line 1747
      tmp___29 = tmp___28;
    } else {
#line 1747
      tmp___29 = (struct mlx5_ib_srq *)0;
    }
#line 1747
    mlx5_ib_cq_clean(recv_cq, (u32 )qp->mqp.qpn, tmp___29);
#line 1749
    if ((unsigned long )send_cq != (unsigned long )recv_cq) {
#line 1750
      mlx5_ib_cq_clean(send_cq, (u32 )qp->mqp.qpn, (struct mlx5_ib_srq *)0);
    } else {

    }
#line 1752
    qp->rq.head = 0U;
#line 1753
    qp->rq.tail = 0U;
#line 1754
    qp->sq.head = 0U;
#line 1755
    qp->sq.tail = 0U;
#line 1756
    qp->sq.cur_post = 0U;
#line 1757
    qp->sq.last_poll = 0U;
#line 1758
    *(qp->db.db) = 0U;
#line 1759
    *(qp->db.db + 1UL) = 0U;
  } else {

  }
  out: 
#line 1763
  kfree((void const   *)in);
#line 1764
  return (err);
}
}
#line 1767 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_modify_qp(struct ib_qp *ibqp , struct ib_qp_attr *attr , int attr_mask ,
                      struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_qp *qp ;
  struct mlx5_ib_qp *tmp___0 ;
  enum ib_qp_state cur_state ;
  enum ib_qp_state new_state ;
  int err ;
  int port ;
  int tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;

  {
#line 1770
  tmp = to_mdev(ibqp->device);
#line 1770
  dev = tmp;
#line 1771
  tmp___0 = to_mqp(ibqp);
#line 1771
  qp = tmp___0;
#line 1773
  err = -22;
#line 1776
  mutex_lock_nested(& qp->mutex, 0U);
#line 1778
  cur_state = (attr_mask & 2) != 0 ? attr->cur_qp_state : (enum ib_qp_state )qp->state;
#line 1779
  new_state = attr_mask & 1 ? attr->qp_state : cur_state;
#line 1781
  if ((unsigned int )ibqp->qp_type != 4096U) {
#line 1781
    tmp___1 = ib_modify_qp_is_ok(cur_state, new_state, ibqp->qp_type, (enum ib_qp_attr_mask )attr_mask,
                                 0);
#line 1781
    if (tmp___1 == 0) {
#line 1784
      goto out;
    } else {

    }
  } else {

  }
#line 1786
  if ((attr_mask & 32) != 0) {
#line 1786
    if ((unsigned int )attr->port_num == 0U) {
#line 1789
      goto out;
    } else {
#line 1786
      tmp___2 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 13UL));
#line 1786
      if ((unsigned int )attr->port_num > (tmp___2 & 255U)) {
#line 1789
        goto out;
      } else {

      }
    }
  } else {

  }
#line 1791
  if ((attr_mask & 16) != 0) {
#line 1792
    port = (attr_mask & 32) != 0 ? (int )attr->port_num : (int )qp->port;
#line 1793
    if ((int )attr->pkey_index >= (dev->mdev)->port_caps[port + -1].pkey_table_len) {
#line 1795
      goto out;
    } else {

    }
  } else {

  }
#line 1798
  if ((attr_mask & 8192) != 0) {
#line 1798
    tmp___3 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 10UL));
#line 1798
    if ((int )attr->max_rd_atomic > 1 << ((int )tmp___3 & 63)) {
#line 1801
      goto out;
    } else {

    }
  } else {

  }
#line 1803
  if ((attr_mask & 131072) != 0) {
#line 1803
    tmp___4 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 10UL));
#line 1803
    if ((int )attr->max_dest_rd_atomic > 1 << ((int )(tmp___4 >> 16) & 63)) {
#line 1806
      goto out;
    } else {

    }
  } else {

  }
#line 1808
  if ((unsigned int )cur_state == (unsigned int )new_state && (unsigned int )cur_state == 0U) {
#line 1809
    err = 0;
#line 1810
    goto out;
  } else {

  }
#line 1813
  err = __mlx5_ib_modify_qp(ibqp, (struct ib_qp_attr  const  *)attr, attr_mask, cur_state,
                            new_state);
  out: 
#line 1816
  mutex_unlock(& qp->mutex);
#line 1817
  return (err);
}
}
#line 1820 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int mlx5_wq_overflow(struct mlx5_ib_wq *wq , int nreq , struct ib_cq *ib_cq ) 
{ 
  struct mlx5_ib_cq *cq ;
  unsigned int cur ;
  long tmp ;

  {
#line 1825
  cur = wq->head - wq->tail;
#line 1826
  tmp = ldv__builtin_expect(cur + (unsigned int )nreq < (unsigned int )wq->max_post,
                         1L);
#line 1826
  if (tmp != 0L) {
#line 1827
    return (0);
  } else {

  }
#line 1829
  cq = to_mcq(ib_cq);
#line 1830
  spin_lock(& cq->lock);
#line 1831
  cur = wq->head - wq->tail;
#line 1832
  spin_unlock(& cq->lock);
#line 1834
  return (cur + (unsigned int )nreq >= (unsigned int )wq->max_post);
}
}
#line 1837 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
__inline static void set_raddr_seg(struct mlx5_wqe_raddr_seg *rseg , u64 remote_addr ,
                                   u32 rkey ) 
{ 
  __u64 tmp ;
  __u32 tmp___0 ;

  {
#line 1840
  tmp = __fswab64(remote_addr);
#line 1840
  rseg->raddr = tmp;
#line 1841
  tmp___0 = __fswab32(rkey);
#line 1841
  rseg->rkey = tmp___0;
#line 1842
  rseg->reserved = 0U;
#line 1843
  return;
}
}
#line 1845 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_datagram_seg(struct mlx5_wqe_datagram_seg *dseg , struct ib_send_wr *wr ) 
{ 
  struct mlx5_ib_ah *tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;

  {
#line 1848
  tmp = to_mah(wr->wr.ud.ah);
#line 1848
  memcpy((void *)(& dseg->av), (void const   *)(& tmp->av), 48UL);
#line 1849
  tmp___0 = __fswab32(wr->wr.ud.remote_qpn | 2147483648U);
#line 1849
  dseg->av.dqp_dct = tmp___0;
#line 1850
  tmp___1 = __fswab32(wr->wr.ud.remote_qkey);
#line 1850
  dseg->av.key.qkey.qkey = tmp___1;
#line 1851
  return;
}
}
#line 1853 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_data_ptr_seg(struct mlx5_wqe_data_seg *dseg , struct ib_sge *sg ) 
{ 
  __u32 tmp ;
  __u32 tmp___0 ;
  __u64 tmp___1 ;

  {
#line 1855
  tmp = __fswab32(sg->length);
#line 1855
  dseg->byte_count = tmp;
#line 1856
  tmp___0 = __fswab32(sg->lkey);
#line 1856
  dseg->lkey = tmp___0;
#line 1857
  tmp___1 = __fswab64(sg->addr);
#line 1857
  dseg->addr = tmp___1;
#line 1858
  return;
}
}
#line 1860 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be16 get_klm_octo(int npages ) 
{ 
  __u16 tmp ;

  {
#line 1862
  tmp = __fswab16((int )((__u16 )(((npages + 7) & -8) / 2)));
#line 1862
  return (tmp);
}
}
#line 1865 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be64 frwr_mkey_mask(void) 
{ 
  u64 result ;
  __u64 tmp ;

  {
#line 1869
  result = 549331267ULL;
#line 1882
  tmp = __fswab64(result);
#line 1882
  return (tmp);
}
}
#line 1885 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be64 sig_mkey_mask(void) 
{ 
  u64 result ;
  __u64 tmp ;

  {
#line 1889
  result = 547238723ULL;
#line 1903
  tmp = __fswab64(result);
#line 1903
  return (tmp);
}
}
#line 1906 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_frwr_umr_segment(struct mlx5_wqe_umr_ctrl_seg *umr , struct ib_send_wr *wr ,
                                 int li ) 
{ 


  {
#line 1909
  memset((void *)umr, 0, 48UL);
#line 1911
  if (li != 0) {
#line 1912
    umr->mkey_mask = 137438953472ULL;
#line 1913
    umr->flags = 128U;
#line 1914
    return;
  } else {

  }
#line 1917
  umr->flags = 32U;
#line 1918
  umr->klm_octowords = get_klm_octo((int )wr->wr.fast_reg.page_list_len);
#line 1919
  umr->mkey_mask = frwr_mkey_mask();
#line 1920
  return;
}
}
#line 1922 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be64 get_umr_reg_mr_mask(void) 
{ 
  u64 result ;
  __u64 tmp ;

  {
#line 1926
  result = 540942531ULL;
#line 1938
  tmp = __fswab64(result);
#line 1938
  return (tmp);
}
}
#line 1941 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be64 get_umr_unreg_mr_mask(void) 
{ 
  u64 result ;
  __u64 tmp ;

  {
#line 1945
  result = 536870912ULL;
#line 1947
  tmp = __fswab64(result);
#line 1947
  return (tmp);
}
}
#line 1950 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be64 get_umr_update_mtt_mask(void) 
{ 
  u64 result ;
  __u64 tmp ;

  {
#line 1954
  result = 536870912ULL;
#line 1956
  tmp = __fswab64(result);
#line 1956
  return (tmp);
}
}
#line 1959 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_reg_umr_segment(struct mlx5_wqe_umr_ctrl_seg *umr , struct ib_send_wr *wr ) 
{ 
  struct mlx5_umr_wr *umrwr ;

  {
#line 1962
  umrwr = (struct mlx5_umr_wr *)(& wr->wr.fast_reg);
#line 1964
  memset((void *)umr, 0, 48UL);
#line 1966
  if ((wr->send_flags & 134217728) != 0) {
#line 1967
    umr->flags = 64U;
  } else {
#line 1969
    umr->flags = 32U;
  }
#line 1971
  if ((wr->send_flags & 67108864) == 0) {
#line 1972
    umr->klm_octowords = get_klm_octo((int )umrwr->npages);
#line 1973
    if ((wr->send_flags & 268435456) != 0) {
#line 1974
      umr->mkey_mask = get_umr_update_mtt_mask();
#line 1975
      umr->bsf_octowords = get_klm_octo((int )umrwr->target.offset);
#line 1976
      umr->flags = (u8 )((unsigned int )umr->flags | 16U);
    } else {
#line 1978
      umr->mkey_mask = get_umr_reg_mr_mask();
    }
  } else {
#line 1981
    umr->mkey_mask = get_umr_unreg_mr_mask();
  }
#line 1984
  if (wr->num_sge == 0) {
#line 1985
    umr->flags = (u8 )((unsigned int )umr->flags | 128U);
  } else {

  }
#line 1986
  return;
}
}
#line 1988 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u8 get_umr_flags(int acc ) 
{ 


  {
#line 1990
  return ((u8 )((((((acc & 8) != 0 ? 64 : 0) | ((acc & 2) != 0 ? 32 : 0)) | ((acc & 4) != 0 ? 16 : 0)) | (acc & 1 ? 8 : 0)) | -124));
}
}
#line 1997 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_mkey_segment(struct mlx5_mkey_seg *seg , struct ib_send_wr *wr , int li ,
                             int *writ ) 
{ 
  u8 tmp ;
  __u32 tmp___0 ;
  __u64 tmp___1 ;
  __u64 tmp___2 ;
  __u32 tmp___3 ;

  {
#line 2000
  memset((void *)seg, 0, 64UL);
#line 2001
  if (li != 0) {
#line 2002
    seg->status = 64U;
#line 2003
    return;
  } else {

  }
#line 2006
  tmp = get_umr_flags(wr->wr.fast_reg.access_flags);
#line 2006
  seg->flags = (u8 )((unsigned int )tmp | 1U);
#line 2008
  *writ = (int )seg->flags & 10;
#line 2009
  tmp___0 = __fswab32(wr->wr.fast_reg.rkey | 4294967040U);
#line 2009
  seg->qpn_mkey7_0 = tmp___0;
#line 2010
  seg->flags_pd = 1U;
#line 2011
  tmp___1 = __fswab64(wr->wr.fast_reg.iova_start);
#line 2011
  seg->start_addr = tmp___1;
#line 2012
  tmp___2 = __fswab64((__u64 )wr->wr.fast_reg.length);
#line 2012
  seg->len = tmp___2;
#line 2013
  tmp___3 = __fswab32((wr->wr.fast_reg.page_list_len + 1U) / 2U);
#line 2013
  seg->xlt_oct_size = tmp___3;
#line 2014
  seg->log2_page_size = (u8 )wr->wr.fast_reg.page_shift;
#line 2015
  return;
}
}
#line 2017 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_reg_mkey_segment(struct mlx5_mkey_seg *seg , struct ib_send_wr *wr ) 
{ 
  struct mlx5_umr_wr *umrwr ;
  struct mlx5_ib_pd *tmp ;
  __u32 tmp___0 ;
  __u64 tmp___1 ;
  __u64 tmp___2 ;
  u8 tmp___3 ;
  __u32 tmp___4 ;

  {
#line 2019
  umrwr = (struct mlx5_umr_wr *)(& wr->wr.fast_reg);
#line 2021
  memset((void *)seg, 0, 64UL);
#line 2022
  if ((wr->send_flags & 67108864) != 0) {
#line 2023
    seg->status = 64U;
#line 2024
    return;
  } else {

  }
#line 2027
  seg->flags = convert_access(umrwr->access_flags);
#line 2028
  if ((wr->send_flags & 268435456) == 0) {
#line 2029
    tmp = to_mpd(umrwr->pd);
#line 2029
    tmp___0 = __fswab32(tmp->pdn);
#line 2029
    seg->flags_pd = tmp___0;
#line 2030
    tmp___1 = __fswab64(umrwr->target.virt_addr);
#line 2030
    seg->start_addr = tmp___1;
  } else {

  }
#line 2032
  tmp___2 = __fswab64((__u64 )umrwr->length);
#line 2032
  seg->len = tmp___2;
#line 2033
  seg->log2_page_size = (u8 )umrwr->page_shift;
#line 2034
  tmp___3 = mlx5_mkey_variant(umrwr->mkey);
#line 2034
  tmp___4 = __fswab32((unsigned int )tmp___3 | 4294967040U);
#line 2034
  seg->qpn_mkey7_0 = tmp___4;
#line 2035
  return;
}
}
#line 2038 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_frwr_pages(struct mlx5_wqe_data_seg *dseg , struct ib_send_wr *wr ,
                           struct mlx5_core_dev *mdev , struct mlx5_ib_pd *pd , int writ ) 
{ 
  struct mlx5_ib_fast_reg_page_list *mfrpl ;
  struct mlx5_ib_fast_reg_page_list *tmp ;
  u64 *page_list ;
  u64 perm ;
  int i ;
  __u64 tmp___0 ;
  __u64 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;

  {
#line 2044
  tmp = to_mfrpl(wr->wr.fast_reg.page_list);
#line 2044
  mfrpl = tmp;
#line 2045
  page_list = (wr->wr.fast_reg.page_list)->page_list;
#line 2046
  perm = writ != 0 ? 3ULL : 1ULL;
#line 2049
  i = 0;
#line 2049
  goto ldv_37597;
  ldv_37596: 
#line 2050
  tmp___0 = __fswab64(*(page_list + (unsigned long )i) | perm);
#line 2050
  *(mfrpl->mapped_page_list + (unsigned long )i) = tmp___0;
#line 2049
  i = i + 1;
  ldv_37597: ;
#line 2049
  if ((unsigned int )i < wr->wr.fast_reg.page_list_len) {
#line 2051
    goto ldv_37596;
  } else {

  }
#line 2051
  tmp___1 = __fswab64(mfrpl->map);
#line 2051
  dseg->addr = tmp___1;
#line 2052
  tmp___2 = __fswab32((wr->wr.fast_reg.page_list_len * 8U + 63U) & 4294967232U);
#line 2052
  dseg->byte_count = tmp___2;
#line 2053
  tmp___3 = __fswab32(pd->pa_lkey);
#line 2053
  dseg->lkey = tmp___3;
#line 2054
  return;
}
}
#line 2056 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static __be32 send_ieth(struct ib_send_wr *wr ) 
{ 
  __u32 tmp ;

  {
#line 2058
  switch ((unsigned int )wr->opcode) {
  case 3U: ;
  case 1U: ;
#line 2061
  return (wr->ex.imm_data);
  case 8U: 
#line 2064
  tmp = __fswab32(wr->ex.invalidate_rkey);
#line 2064
  return (tmp);
  default: ;
#line 2067
  return (0U);
  }
}
}
#line 2071 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u8 calc_sig(void *wqe , int size ) 
{ 
  u8 *p ;
  u8 res ;
  int i ;

  {
#line 2073
  p = (u8 *)wqe;
#line 2074
  res = 0U;
#line 2077
  i = 0;
#line 2077
  goto ldv_37614;
  ldv_37613: 
#line 2078
  res = (u8 )((int )*(p + (unsigned long )i) ^ (int )res);
#line 2077
  i = i + 1;
  ldv_37614: ;
#line 2077
  if (i < size) {
#line 2079
    goto ldv_37613;
  } else {

  }

#line 2080
  return (~ ((int )res));
}
}
#line 2083 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u8 wq_sig(void *wqe ) 
{ 
  u8 tmp ;

  {
#line 2085
  tmp = calc_sig(wqe, ((int )*((u8 *)wqe + 8UL) & 63) << 4);
#line 2085
  return (tmp);
}
}
#line 2088 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_data_inl_seg(struct mlx5_ib_qp *qp , struct ib_send_wr *wr , void *wqe ,
                            int *sz ) 
{ 
  struct mlx5_wqe_inline_seg *seg ;
  void *qend ;
  void *addr ;
  int inl___0 ;
  int copy ;
  int len ;
  int i ;
  long tmp ;
  long tmp___0 ;
  __u32 tmp___1 ;

  {
#line 2092
  qend = qp->sq.qend;
#line 2094
  inl___0 = 0;
#line 2099
  seg = (struct mlx5_wqe_inline_seg *)wqe;
#line 2100
  wqe = wqe + 4UL;
#line 2101
  i = 0;
#line 2101
  goto ldv_37633;
  ldv_37632: 
#line 2102
  addr = (void *)(wr->sg_list + (unsigned long )i)->addr;
#line 2103
  len = (int )(wr->sg_list + (unsigned long )i)->length;
#line 2104
  inl___0 = inl___0 + len;
#line 2106
  tmp = ldv__builtin_expect(qp->max_inline_data < inl___0, 0L);
#line 2106
  if (tmp != 0L) {
#line 2107
    return (-12);
  } else {

  }
#line 2109
  tmp___0 = ldv__builtin_expect((unsigned long )(wqe + (unsigned long )len) > (unsigned long )qend,
                             0L);
#line 2109
  if (tmp___0 != 0L) {
#line 2110
    copy = (int )((unsigned int )((long )qend) - (unsigned int )((long )wqe));
#line 2111
    memcpy(wqe, (void const   *)addr, (size_t )copy);
#line 2112
    addr = addr + (unsigned long )copy;
#line 2113
    len = len - copy;
#line 2114
    wqe = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2116
  memcpy(wqe, (void const   *)addr, (size_t )len);
#line 2117
  wqe = wqe + (unsigned long )len;
#line 2101
  i = i + 1;
  ldv_37633: ;
#line 2101
  if (wr->num_sge > i) {
#line 2103
    goto ldv_37632;
  } else {

  }
#line 2120
  tmp___1 = __fswab32((unsigned int )inl___0 | 2147483648U);
#line 2120
  seg->byte_count = tmp___1;
#line 2122
  *sz = (int )((((unsigned long )inl___0 + 19UL) & 0xfffffffffffffff0UL) / 16UL);
#line 2124
  return (0);
}
}
#line 2127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u16 prot_field_size(enum ib_signature_type type ) 
{ 


  {
#line 2129
  switch ((unsigned int )type) {
  case 1U: ;
#line 2131
  return (8U);
  default: ;
#line 2133
  return (0U);
  }
}
}
#line 2137 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u8 bs_selector(int block_size ) 
{ 


  {
#line 2139
  switch (block_size) {
  case 512: ;
#line 2140
  return (1U);
  case 520: ;
#line 2141
  return (2U);
  case 4096: ;
#line 2142
  return (3U);
  case 4160: ;
#line 2143
  return (4U);
  case 1073741824: ;
#line 2144
  return (5U);
  default: ;
#line 2145
  return (0U);
  }
}
}
#line 2149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void mlx5_fill_inl_bsf(struct ib_sig_domain *domain , struct mlx5_bsf_inl *inl___0 ) 
{ 
  __u16 tmp ;
  __u32 tmp___0 ;
  __u16 tmp___1 ;

  {
#line 2153
  inl___0->vld_refresh = 192U;
#line 2155
  tmp = __fswab16((int )domain->sig.dif.app_tag);
#line 2155
  inl___0->dif_apptag = tmp;
#line 2156
  tmp___0 = __fswab32(domain->sig.dif.ref_tag);
#line 2156
  inl___0->dif_reftag = tmp___0;
#line 2158
  inl___0->rp_inv_seed = 128U;
#line 2159
  inl___0->sig_type = (unsigned int )domain->sig.dif.bg_type == 0U ? 1U : 2U;
#line 2162
  if ((int )domain->sig.dif.ref_remap) {
#line 2163
    inl___0->dif_inc_ref_guard_check = (u8 )((unsigned int )inl___0->dif_inc_ref_guard_check | 64U);
  } else {

  }
#line 2165
  if ((int )domain->sig.dif.app_escape) {
#line 2166
    if ((int )domain->sig.dif.ref_escape) {
#line 2167
      inl___0->dif_inc_ref_guard_check = (u8 )((unsigned int )inl___0->dif_inc_ref_guard_check | 2U);
    } else {
#line 2169
      inl___0->dif_inc_ref_guard_check = (u8 )((unsigned int )inl___0->dif_inc_ref_guard_check | 1U);
    }
  } else {

  }
#line 2172
  tmp___1 = __fswab16((int )domain->sig.dif.apptag_check_mask);
#line 2172
  inl___0->dif_app_bitmask_check = tmp___1;
#line 2174
  return;
}
}
#line 2176 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int mlx5_set_bsf(struct ib_mr *sig_mr , struct ib_sig_attrs *sig_attrs , struct mlx5_bsf *bsf ,
                        u32 data_size ) 
{ 
  struct mlx5_core_sig_ctx *msig ;
  struct mlx5_ib_mr *tmp ;
  struct mlx5_bsf_basic *basic ;
  struct ib_sig_domain *mem ;
  struct ib_sig_domain *wire ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;

  {
#line 2180
  tmp = to_mmr(sig_mr);
#line 2180
  msig = tmp->sig;
#line 2181
  basic = & bsf->basic;
#line 2182
  mem = & sig_attrs->mem;
#line 2183
  wire = & sig_attrs->wire;
#line 2185
  memset((void *)bsf, 0, 64UL);
#line 2188
  basic->bsf_size_sbs = 128U;
#line 2190
  basic->check_byte_mask = sig_attrs->check_mask;
#line 2191
  tmp___0 = __fswab32(data_size);
#line 2191
  basic->raw_data_size = tmp___0;
#line 2194
  switch ((unsigned int )sig_attrs->mem.sig_type) {
  case 0U: ;
#line 2196
  goto ldv_37664;
  case 1U: 
#line 2198
  basic->mem.bs_selector = bs_selector((int )mem->sig.dif.pi_interval);
#line 2199
  tmp___1 = __fswab32(msig->psv_memory.psv_idx);
#line 2199
  basic->m_bfs_psv = tmp___1;
#line 2200
  mlx5_fill_inl_bsf(mem, & bsf->m_inl);
#line 2201
  goto ldv_37664;
  default: ;
#line 2203
  return (-22);
  }
  ldv_37664: ;
#line 2207
  switch ((unsigned int )sig_attrs->wire.sig_type) {
  case 0U: ;
#line 2209
  goto ldv_37668;
  case 1U: ;
#line 2211
  if ((int )mem->sig.dif.pi_interval == (int )wire->sig.dif.pi_interval && (unsigned int )mem->sig_type == (unsigned int )wire->sig_type) {
#line 2214
    basic->bsf_size_sbs = (u8 )((unsigned int )basic->bsf_size_sbs | 16U);
#line 2215
    if ((unsigned int )mem->sig.dif.bg_type == (unsigned int )wire->sig.dif.bg_type) {
#line 2216
      basic->wire.copy_byte_mask = (u8 )((unsigned int )basic->wire.copy_byte_mask | 192U);
    } else {

    }
#line 2217
    if ((int )mem->sig.dif.app_tag == (int )wire->sig.dif.app_tag) {
#line 2218
      basic->wire.copy_byte_mask = (u8 )((unsigned int )basic->wire.copy_byte_mask | 48U);
    } else {

    }
#line 2219
    if (mem->sig.dif.ref_tag == wire->sig.dif.ref_tag) {
#line 2220
      basic->wire.copy_byte_mask = (u8 )((unsigned int )basic->wire.copy_byte_mask | 15U);
    } else {

    }
  } else {
#line 2222
    basic->wire.bs_selector = bs_selector((int )wire->sig.dif.pi_interval);
  }
#line 2224
  tmp___2 = __fswab32(msig->psv_wire.psv_idx);
#line 2224
  basic->w_bfs_psv = tmp___2;
#line 2225
  mlx5_fill_inl_bsf(wire, & bsf->w_inl);
#line 2226
  goto ldv_37668;
  default: ;
#line 2228
  return (-22);
  }
  ldv_37668: ;
#line 2231
  return (0);
}
}
#line 2234 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_sig_data_segment(struct ib_send_wr *wr , struct mlx5_ib_qp *qp , void **seg ,
                                int *size ) 
{ 
  struct ib_sig_attrs *sig_attrs ;
  struct ib_mr *sig_mr ;
  struct mlx5_bsf *bsf ;
  u32 data_len ;
  u32 data_key ;
  u64 data_va ;
  int ret ;
  int wqe_size ;
  struct mlx5_klm *data_klm ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u64 tmp___1 ;
  struct mlx5_stride_block_ctrl_seg *sblock_ctrl ;
  struct mlx5_stride_block_entry *data_sentry ;
  struct mlx5_stride_block_entry *prot_sentry ;
  u32 prot_key ;
  u64 prot_va ;
  u16 block_size ;
  int prot_size ;
  u16 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;
  __u16 tmp___5 ;
  __u32 tmp___6 ;
  __u64 tmp___7 ;
  __u16 tmp___8 ;
  __u16 tmp___9 ;
  __u32 tmp___10 ;
  __u64 tmp___11 ;
  __u16 tmp___12 ;
  long tmp___13 ;
  long tmp___14 ;

  {
#line 2237
  sig_attrs = wr->wr.sig_handover.sig_attrs;
#line 2238
  sig_mr = wr->wr.sig_handover.sig_mr;
#line 2240
  data_len = (wr->sg_list)->length;
#line 2241
  data_key = (wr->sg_list)->lkey;
#line 2242
  data_va = (wr->sg_list)->addr;
#line 2246
  if ((unsigned long )wr->wr.sig_handover.prot == (unsigned long )((struct ib_sge *)0) || (((wr->wr.sig_handover.prot)->lkey == data_key && (wr->wr.sig_handover.prot)->addr == data_va) && (wr->wr.sig_handover.prot)->length == data_len)) {
#line 2260
    data_klm = (struct mlx5_klm *)*seg;
#line 2262
    tmp = __fswab32(data_len);
#line 2262
    data_klm->bcount = tmp;
#line 2263
    tmp___0 = __fswab32(data_key);
#line 2263
    data_klm->key = tmp___0;
#line 2264
    tmp___1 = __fswab64(data_va);
#line 2264
    data_klm->va = tmp___1;
#line 2265
    wqe_size = 64;
  } else {
#line 2283
    prot_key = (wr->wr.sig_handover.prot)->lkey;
#line 2284
    prot_va = (wr->wr.sig_handover.prot)->addr;
#line 2285
    block_size = sig_attrs->mem.sig.dif.pi_interval;
#line 2288
    sblock_ctrl = (struct mlx5_stride_block_ctrl_seg *)*seg;
#line 2289
    data_sentry = (struct mlx5_stride_block_entry *)sblock_ctrl + 16U;
#line 2290
    prot_sentry = data_sentry + 16U;
#line 2292
    tmp___2 = prot_field_size(sig_attrs->mem.sig_type);
#line 2292
    prot_size = (int )tmp___2;
#line 2293
    if (prot_size == 0) {
#line 2294
      printk("\vBad block size given: %u\n", (int )block_size);
#line 2295
      return (-22);
    } else {

    }
#line 2297
    tmp___3 = __fswab32((__u32 )((int )block_size + prot_size));
#line 2297
    sblock_ctrl->bcount_per_cycle = tmp___3;
#line 2299
    sblock_ctrl->op = 262144U;
#line 2300
    tmp___4 = __fswab32(data_len / (u32 )block_size);
#line 2300
    sblock_ctrl->repeat_count = tmp___4;
#line 2301
    sblock_ctrl->num_entries = 512U;
#line 2303
    tmp___5 = __fswab16((int )block_size);
#line 2303
    data_sentry->bcount = tmp___5;
#line 2304
    tmp___6 = __fswab32(data_key);
#line 2304
    data_sentry->key = tmp___6;
#line 2305
    tmp___7 = __fswab64(data_va);
#line 2305
    data_sentry->va = tmp___7;
#line 2306
    tmp___8 = __fswab16((int )block_size);
#line 2306
    data_sentry->stride = tmp___8;
#line 2308
    tmp___9 = __fswab16((int )((__u16 )prot_size));
#line 2308
    prot_sentry->bcount = tmp___9;
#line 2309
    tmp___10 = __fswab32(prot_key);
#line 2309
    prot_sentry->key = tmp___10;
#line 2310
    tmp___11 = __fswab64(prot_va);
#line 2310
    prot_sentry->va = tmp___11;
#line 2311
    tmp___12 = __fswab16((int )((__u16 )prot_size));
#line 2311
    prot_sentry->stride = tmp___12;
#line 2313
    wqe_size = 64;
  }
#line 2317
  *seg = *seg + (unsigned long )wqe_size;
#line 2318
  *size = *size + wqe_size / 16;
#line 2319
  tmp___13 = ldv__builtin_expect((unsigned long )*seg == (unsigned long )qp->sq.qend,
                              0L);
#line 2319
  if (tmp___13 != 0L) {
#line 2320
    *seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2322
  bsf = (struct mlx5_bsf *)*seg;
#line 2323
  ret = mlx5_set_bsf(sig_mr, sig_attrs, bsf, data_len);
#line 2324
  if (ret != 0) {
#line 2325
    return (-22);
  } else {

  }
#line 2327
  *seg = *seg + 64UL;
#line 2328
  *size = (int )((unsigned int )*size + 4U);
#line 2329
  tmp___14 = ldv__builtin_expect((unsigned long )*seg == (unsigned long )qp->sq.qend,
                              0L);
#line 2329
  if (tmp___14 != 0L) {
#line 2330
    *seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2332
  return (0);
}
}
#line 2335 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_sig_mkey_segment(struct mlx5_mkey_seg *seg , struct ib_send_wr *wr ,
                                 u32 nelements , u32 length , u32 pdn ) 
{ 
  struct ib_mr *sig_mr ;
  u32 sig_key ;
  u8 sigerr ;
  struct mlx5_ib_mr *tmp ;
  u8 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u64 tmp___3 ;
  __be16 tmp___4 ;
  __u16 tmp___5 ;
  __u32 tmp___6 ;

  {
#line 2339
  sig_mr = wr->wr.sig_handover.sig_mr;
#line 2340
  sig_key = sig_mr->rkey;
#line 2341
  tmp = to_mmr(sig_mr);
#line 2341
  sigerr = (unsigned int )((u8 )(tmp->sig)->sigerr_count) & 1U;
#line 2343
  memset((void *)seg, 0, 64UL);
#line 2345
  tmp___0 = get_umr_flags(wr->wr.sig_handover.access_flags);
#line 2345
  seg->flags = (u8 )((unsigned int )tmp___0 | 2U);
#line 2347
  tmp___1 = __fswab32(sig_key | 4294967040U);
#line 2347
  seg->qpn_mkey7_0 = tmp___1;
#line 2348
  tmp___2 = __fswab32(((u32 )((int )sigerr << 26) | pdn) | 1090519040U);
#line 2348
  seg->flags_pd = tmp___2;
#line 2350
  tmp___3 = __fswab64((__u64 )length);
#line 2350
  seg->len = tmp___3;
#line 2351
  tmp___4 = get_klm_octo((int )nelements);
#line 2351
  tmp___5 = __fswab16((int )tmp___4);
#line 2351
  tmp___6 = __fswab32((__u32 )tmp___5);
#line 2351
  seg->xlt_oct_size = tmp___6;
#line 2352
  seg->bsfs_octo_size = 67108864U;
#line 2353
  return;
}
}
#line 2355 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_sig_umr_segment(struct mlx5_wqe_umr_ctrl_seg *umr , struct ib_send_wr *wr ,
                                u32 nelements ) 
{ 


  {
#line 2358
  memset((void *)umr, 0, 48UL);
#line 2360
  umr->flags = 160U;
#line 2361
  umr->klm_octowords = get_klm_octo((int )nelements);
#line 2362
  umr->bsf_octowords = 1024U;
#line 2363
  umr->mkey_mask = sig_mkey_mask();
#line 2364
  return;
}
}
#line 2367 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_sig_umr_wr(struct ib_send_wr *wr , struct mlx5_ib_qp *qp , void **seg ,
                          int *size ) 
{ 
  struct mlx5_ib_mr *sig_mr ;
  struct mlx5_ib_mr *tmp ;
  u32 pdn ;
  struct mlx5_ib_pd *tmp___0 ;
  u32 klm_oct_size ;
  int region_len ;
  int ret ;
  long tmp___1 ;
  long tmp___2 ;
  long tmp___3 ;
  long tmp___4 ;
  long tmp___5 ;
  long tmp___6 ;
  long tmp___7 ;

  {
#line 2370
  tmp = to_mmr(wr->wr.sig_handover.sig_mr);
#line 2370
  sig_mr = tmp;
#line 2371
  tmp___0 = get_pd(qp);
#line 2371
  pdn = tmp___0->pdn;
#line 2375
  tmp___1 = ldv__builtin_expect(wr->num_sge != 1, 0L);
#line 2375
  if (tmp___1 != 0L) {
#line 2380
    return (-22);
  } else {
#line 2375
    tmp___2 = ldv__builtin_expect((wr->wr.sig_handover.access_flags & 8) != 0, 0L);
#line 2375
    if (tmp___2 != 0L) {
#line 2380
      return (-22);
    } else {
#line 2375
      tmp___3 = ldv__builtin_expect((unsigned long )sig_mr->sig == (unsigned long )((struct mlx5_core_sig_ctx *)0),
                                 0L);
#line 2375
      if (tmp___3 != 0L) {
#line 2380
        return (-22);
      } else {
#line 2375
        tmp___4 = ldv__builtin_expect((long )(! qp->signature_en), 0L);
#line 2375
        if (tmp___4 != 0L) {
#line 2380
          return (-22);
        } else {
#line 2375
          tmp___5 = ldv__builtin_expect((long )(! (sig_mr->sig)->sig_status_checked),
                                     0L);
#line 2375
          if (tmp___5 != 0L) {
#line 2380
            return (-22);
          } else {

          }
        }
      }
    }
  }
#line 2383
  region_len = (int )(wr->sg_list)->length;
#line 2384
  if ((unsigned long )wr->wr.sig_handover.prot != (unsigned long )((struct ib_sge *)0) && (((wr->wr.sig_handover.prot)->lkey != (wr->sg_list)->lkey || (wr->wr.sig_handover.prot)->addr != (wr->sg_list)->addr) || (wr->wr.sig_handover.prot)->length != (wr->sg_list)->length)) {
#line 2388
    region_len = (int )((wr->wr.sig_handover.prot)->length + (u32 )region_len);
  } else {

  }
#line 2395
  klm_oct_size = (unsigned long )wr->wr.sig_handover.prot != (unsigned long )((struct ib_sge *)0) ? 3U : 1U;
#line 2397
  set_sig_umr_segment((struct mlx5_wqe_umr_ctrl_seg *)*seg, wr, klm_oct_size);
#line 2398
  *seg = *seg + 48UL;
#line 2399
  *size = (int )((unsigned int )*size + 3U);
#line 2400
  tmp___6 = ldv__builtin_expect((unsigned long )*seg == (unsigned long )qp->sq.qend,
                             0L);
#line 2400
  if (tmp___6 != 0L) {
#line 2401
    *seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2403
  set_sig_mkey_segment((struct mlx5_mkey_seg *)*seg, wr, klm_oct_size, (u32 )region_len,
                       pdn);
#line 2404
  *seg = *seg + 64UL;
#line 2405
  *size = (int )((unsigned int )*size + 4U);
#line 2406
  tmp___7 = ldv__builtin_expect((unsigned long )*seg == (unsigned long )qp->sq.qend,
                             0L);
#line 2406
  if (tmp___7 != 0L) {
#line 2407
    *seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2409
  ret = set_sig_data_segment(wr, qp, seg, size);
#line 2410
  if (ret != 0) {
#line 2411
    return (ret);
  } else {

  }
#line 2413
  (sig_mr->sig)->sig_status_checked = 0;
#line 2414
  return (0);
}
}
#line 2417 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_psv_wr(struct ib_sig_domain *domain , u32 psv_idx , void **seg , int *size ) 
{ 
  struct mlx5_seg_set_psv *psv_seg ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;

  {
#line 2420
  psv_seg = (struct mlx5_seg_set_psv *)*seg;
#line 2422
  memset((void *)psv_seg, 0, 16UL);
#line 2423
  tmp = __fswab32(psv_idx);
#line 2423
  psv_seg->psv_num = tmp;
#line 2424
  switch ((unsigned int )domain->sig_type) {
  case 0U: ;
#line 2426
  goto ldv_37727;
  case 1U: 
#line 2428
  tmp___0 = __fswab32((__u32 )(((int )domain->sig.dif.bg << 16) | (int )domain->sig.dif.app_tag));
#line 2428
  psv_seg->transient_sig = tmp___0;
#line 2430
  tmp___1 = __fswab32(domain->sig.dif.ref_tag);
#line 2430
  psv_seg->ref_tag = tmp___1;
#line 2431
  goto ldv_37727;
  default: 
#line 2433
  printk("\vBad signature type given.\n");
#line 2434
  return (1);
  }
  ldv_37727: 
#line 2437
  *seg = *seg + 16UL;
#line 2438
  *size = (int )((unsigned int )*size + 1U);
#line 2440
  return (0);
}
}
#line 2443 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int set_frwr_li_wr(void **seg , struct ib_send_wr *wr , int *size , struct mlx5_core_dev *mdev ,
                          struct mlx5_ib_pd *pd , struct mlx5_ib_qp *qp ) 
{ 
  int writ ;
  int li ;
  long tmp ;
  long tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;

  {
#line 2446
  writ = 0;
#line 2449
  li = (unsigned int )wr->opcode == 10U;
#line 2450
  tmp = ldv__builtin_expect((wr->send_flags & 8) != 0, 0L);
#line 2450
  if (tmp != 0L) {
#line 2451
    return (-22);
  } else {

  }
#line 2453
  set_frwr_umr_segment((struct mlx5_wqe_umr_ctrl_seg *)*seg, wr, li);
#line 2454
  *seg = *seg + 48UL;
#line 2455
  *size = (int )((unsigned int )*size + 3U);
#line 2456
  tmp___0 = ldv__builtin_expect((unsigned long )*seg == (unsigned long )qp->sq.qend,
                             0L);
#line 2456
  if (tmp___0 != 0L) {
#line 2457
    *seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2458
  set_mkey_segment((struct mlx5_mkey_seg *)*seg, wr, li, & writ);
#line 2459
  *seg = *seg + 64UL;
#line 2460
  *size = (int )((unsigned int )*size + 4U);
#line 2461
  tmp___1 = ldv__builtin_expect((unsigned long )*seg == (unsigned long )qp->sq.qend,
                             0L);
#line 2461
  if (tmp___1 != 0L) {
#line 2462
    *seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2463
  if (li == 0) {
#line 2464
    tmp___2 = ldv__builtin_expect(wr->wr.fast_reg.page_list_len > (wr->wr.fast_reg.page_list)->max_page_list_len,
                               0L);
#line 2464
    if (tmp___2 != 0L) {
#line 2466
      return (-12);
    } else {

    }
#line 2468
    set_frwr_pages((struct mlx5_wqe_data_seg *)*seg, wr, mdev, pd, writ);
#line 2469
    *seg = *seg + 16UL;
#line 2470
    *size = (int )((unsigned int )*size + 1U);
  } else {

  }
#line 2472
  return (0);
}
}
#line 2513 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static u8 get_fence(u8 fence , struct ib_send_wr *wr ) 
{ 
  long tmp ;
  long tmp___0 ;

  {
#line 2515
  tmp = ldv__builtin_expect((long )((unsigned int )wr->opcode == 10U && wr->send_flags & 1),
                         0L);
#line 2515
  if (tmp != 0L) {
#line 2517
    return (96U);
  } else {

  }
#line 2519
  tmp___0 = ldv__builtin_expect((unsigned int )fence != 0U, 0L);
#line 2519
  if (tmp___0 != 0L) {
#line 2520
    if (wr->send_flags & 1) {
#line 2521
      return (128U);
    } else {
#line 2523
      return (fence);
    }
  } else {
#line 2526
    return (0U);
  }
}
}
#line 2530 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int begin_wqe(struct mlx5_ib_qp *qp , void **seg , struct mlx5_wqe_ctrl_seg **ctrl ,
                     struct ib_send_wr *wr , unsigned int *idx , int *size , int nreq ) 
{ 
  int err ;
  int tmp ;
  long tmp___0 ;

  {
#line 2535
  err = 0;
#line 2537
  tmp = mlx5_wq_overflow(& qp->sq, nreq, qp->ibqp.send_cq);
#line 2537
  tmp___0 = ldv__builtin_expect(tmp != 0, 0L);
#line 2537
  if (tmp___0 != 0L) {
#line 2538
    err = -12;
#line 2539
    return (err);
  } else {

  }
#line 2542
  *idx = (unsigned int )((int )qp->sq.cur_post & (qp->sq.wqe_cnt + -1));
#line 2543
  *seg = mlx5_get_send_wqe(qp, (int )*idx);
#line 2544
  *ctrl = (struct mlx5_wqe_ctrl_seg *)*seg;
#line 2545
  *((uint32_t *)*seg + 8U) = 0U;
#line 2546
  (*ctrl)->imm = send_ieth(wr);
#line 2547
  (*ctrl)->fm_ce_se = (u8 )(((int )((signed char )qp->sq_signal_bits) | ((wr->send_flags & 2) != 0 ? 8 : 0)) | ((wr->send_flags & 4) != 0 ? 2 : 0));
#line 2553
  *seg = *seg + 16UL;
#line 2554
  *size = 1;
#line 2556
  return (err);
}
}
#line 2559 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void finish_wqe(struct mlx5_ib_qp *qp , struct mlx5_wqe_ctrl_seg *ctrl , u8 size ,
                       unsigned int idx , u64 wr_id , int nreq , u8 fence , u8 next_fence ,
                       u32 mlx5_opcode ) 
{ 
  u8 opmod ;
  __u32 tmp ;
  __u32 tmp___0 ;
  long tmp___1 ;

  {
#line 2565
  opmod = 0U;
#line 2567
  tmp = __fswab32((((unsigned int )qp->sq.cur_post << 8) | mlx5_opcode) | ((unsigned int )opmod << 24));
#line 2567
  ctrl->opmod_idx_opcode = tmp;
#line 2569
  tmp___0 = __fswab32((__u32 )((int )size | (qp->mqp.qpn << 8)));
#line 2569
  ctrl->qpn_ds = tmp___0;
#line 2570
  ctrl->fm_ce_se = (u8 )((int )ctrl->fm_ce_se | (int )fence);
#line 2571
  qp->fm_cache = next_fence;
#line 2572
  tmp___1 = ldv__builtin_expect(qp->wq_sig != 0, 0L);
#line 2572
  if (tmp___1 != 0L) {
#line 2573
    ctrl->signature = wq_sig((void *)ctrl);
  } else {

  }
#line 2575
  *(qp->sq.wrid + (unsigned long )idx) = wr_id;
#line 2576
  (qp->sq.w_list + (unsigned long )idx)->opcode = (u16 )mlx5_opcode;
#line 2577
  *(qp->sq.wqe_head + (unsigned long )idx) = qp->sq.head + (unsigned int )nreq;
#line 2578
  qp->sq.cur_post = (int )qp->sq.cur_post + (int )((u16 )((((int )size + 4) * 16 + -1) / 64));
#line 2579
  (qp->sq.w_list + (unsigned long )idx)->next = qp->sq.cur_post;
#line 2580
  return;
}
}
#line 2583 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_post_send(struct ib_qp *ibqp , struct ib_send_wr *wr , struct ib_send_wr **bad_wr ) 
{ 
  struct mlx5_wqe_ctrl_seg *ctrl ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  struct mlx5_ib_qp *qp ;
  struct mlx5_ib_qp *tmp___0 ;
  struct mlx5_ib_mr *mr ;
  struct mlx5_wqe_data_seg *dpseg ;
  struct mlx5_wqe_xrc_seg *xrc ;
  struct mlx5_bf *bf ;
  int size ;
  void *qend ;
  unsigned long flags ;
  unsigned int idx ;
  int err ;
  int inl___0 ;
  int num_sge ;
  void *seg ;
  int nreq ;
  int i ;
  u8 next_fence ;
  u8 fence ;
  raw_spinlock_t *tmp___1 ;
  struct task_struct *tmp___2 ;
  long tmp___3 ;
  struct task_struct *tmp___4 ;
  long tmp___5 ;
  struct task_struct *tmp___6 ;
  __u32 tmp___7 ;
  struct task_struct *tmp___8 ;
  __u32 tmp___9 ;
  struct mlx5_ib_pd *tmp___10 ;
  struct task_struct *tmp___11 ;
  __u32 tmp___12 ;
  struct mlx5_ib_pd *tmp___13 ;
  struct task_struct *tmp___14 ;
  __u32 tmp___15 ;
  struct task_struct *tmp___16 ;
  u8 tmp___17 ;
  struct task_struct *tmp___18 ;
  struct task_struct *tmp___19 ;
  u8 tmp___20 ;
  struct task_struct *tmp___21 ;
  struct task_struct *tmp___22 ;
  u8 tmp___23 ;
  long tmp___24 ;
  struct task_struct *tmp___25 ;
  __u32 tmp___26 ;
  long tmp___27 ;
  long tmp___28 ;
  int sz ;
  struct task_struct *tmp___29 ;
  long tmp___30 ;
  long tmp___31 ;
  long tmp___32 ;
  u8 tmp___33 ;
  __u32 tmp___34 ;
  long tmp___35 ;

  {
#line 2586
  ctrl = (struct mlx5_wqe_ctrl_seg *)0;
#line 2587
  tmp = to_mdev(ibqp->device);
#line 2587
  dev = tmp;
#line 2588
  mdev = dev->mdev;
#line 2589
  tmp___0 = to_mqp(ibqp);
#line 2589
  qp = tmp___0;
#line 2593
  bf = qp->bf;
#line 2594
  size = size;
#line 2595
  qend = qp->sq.qend;
#line 2598
  err = 0;
#line 2599
  inl___0 = 0;
#line 2604
  next_fence = 0U;
#line 2607
  tmp___1 = spinlock_check(& qp->sq.lock);
#line 2607
  flags = _raw_spin_lock_irqsave(tmp___1);
#line 2609
  nreq = 0;
#line 2609
  goto ldv_37853;
  ldv_37852: 
#line 2610
  tmp___3 = ldv__builtin_expect((unsigned int )wr->opcode > 240U, 0L);
#line 2610
  if (tmp___3 != 0L) {
#line 2611
    tmp___2 = get_current();
#line 2611
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2611, tmp___2->pid);
#line 2612
    err = -22;
#line 2613
    *bad_wr = wr;
#line 2614
    goto out;
  } else {

  }
#line 2617
  fence = qp->fm_cache;
#line 2618
  num_sge = wr->num_sge;
#line 2619
  tmp___5 = ldv__builtin_expect(qp->sq.max_gs < num_sge, 0L);
#line 2619
  if (tmp___5 != 0L) {
#line 2620
    tmp___4 = get_current();
#line 2620
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2620, tmp___4->pid);
#line 2621
    err = -12;
#line 2622
    *bad_wr = wr;
#line 2623
    goto out;
  } else {

  }
#line 2626
  err = begin_wqe(qp, & seg, & ctrl, wr, & idx, & size, nreq);
#line 2627
  if (err != 0) {
#line 2628
    tmp___6 = get_current();
#line 2628
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2628, tmp___6->pid);
#line 2629
    err = -12;
#line 2630
    *bad_wr = wr;
#line 2631
    goto out;
  } else {

  }
#line 2634
  switch ((unsigned int )ibqp->qp_type) {
  case 9U: 
#line 2636
  xrc = (struct mlx5_wqe_xrc_seg *)seg;
#line 2637
  tmp___7 = __fswab32(wr->xrc_remote_srq_num);
#line 2637
  xrc->xrc_srqn = tmp___7;
#line 2638
  seg = seg + 16UL;
#line 2639
  size = (int )((unsigned int )size + 1U);
  case 2U: ;
#line 2642
  switch ((unsigned int )wr->opcode) {
  case 4U: ;
  case 0U: ;
  case 1U: 
#line 2646
  set_raddr_seg((struct mlx5_wqe_raddr_seg *)seg, wr->wr.rdma.remote_addr, wr->wr.rdma.rkey);
#line 2648
  seg = seg + 16UL;
#line 2649
  size = (int )((unsigned int )size + 1U);
#line 2650
  goto ldv_37828;
  case 5U: ;
  case 6U: ;
  case 12U: 
#line 2655
  tmp___8 = get_current();
#line 2655
  printk("\f%s:%s:%d:(pid %d): Atomic operations are not supported yet\n", (char *)(& dev->ib_dev.name),
         "mlx5_ib_post_send", 2655, tmp___8->pid);
#line 2656
  err = -38;
#line 2657
  *bad_wr = wr;
#line 2658
  goto out;
  case 10U: 
#line 2661
  next_fence = 32U;
#line 2662
  *(qp->sq.wr_data + (unsigned long )idx) = 10U;
#line 2663
  tmp___9 = __fswab32(wr->ex.invalidate_rkey);
#line 2663
  ctrl->imm = tmp___9;
#line 2664
  tmp___10 = to_mpd(ibqp->pd);
#line 2664
  err = set_frwr_li_wr(& seg, wr, & size, mdev, tmp___10, qp);
#line 2665
  if (err != 0) {
#line 2666
    tmp___11 = get_current();
#line 2666
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2666, tmp___11->pid);
#line 2667
    *bad_wr = wr;
#line 2668
    goto out;
  } else {

  }
#line 2670
  num_sge = 0;
#line 2671
  goto ldv_37828;
  case 11U: 
#line 2674
  next_fence = 32U;
#line 2675
  *(qp->sq.wr_data + (unsigned long )idx) = 11U;
#line 2676
  tmp___12 = __fswab32(wr->wr.fast_reg.rkey);
#line 2676
  ctrl->imm = tmp___12;
#line 2677
  tmp___13 = to_mpd(ibqp->pd);
#line 2677
  err = set_frwr_li_wr(& seg, wr, & size, mdev, tmp___13, qp);
#line 2678
  if (err != 0) {
#line 2679
    tmp___14 = get_current();
#line 2679
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2679, tmp___14->pid);
#line 2680
    *bad_wr = wr;
#line 2681
    goto out;
  } else {

  }
#line 2683
  num_sge = 0;
#line 2684
  goto ldv_37828;
  case 15U: 
#line 2687
  *(qp->sq.wr_data + (unsigned long )idx) = 15U;
#line 2688
  mr = to_mmr(wr->wr.sig_handover.sig_mr);
#line 2690
  tmp___15 = __fswab32(mr->ibmr.rkey);
#line 2690
  ctrl->imm = tmp___15;
#line 2691
  err = set_sig_umr_wr(wr, qp, & seg, & size);
#line 2692
  if (err != 0) {
#line 2693
    tmp___16 = get_current();
#line 2693
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2693, tmp___16->pid);
#line 2694
    *bad_wr = wr;
#line 2695
    goto out;
  } else {

  }
#line 2698
  tmp___17 = get_fence((int )fence, wr);
#line 2698
  finish_wqe(qp, ctrl, (int )((u8 )size), idx, wr->wr_id, nreq, (int )tmp___17, (int )next_fence,
             37U);
#line 2705
  wr->send_flags = wr->send_flags & -3;
#line 2706
  wr->send_flags = wr->send_flags | 4;
#line 2707
  err = begin_wqe(qp, & seg, & ctrl, wr, & idx, & size, nreq);
#line 2709
  if (err != 0) {
#line 2710
    tmp___18 = get_current();
#line 2710
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2710, tmp___18->pid);
#line 2711
    err = -12;
#line 2712
    *bad_wr = wr;
#line 2713
    goto out;
  } else {

  }
#line 2716
  err = set_psv_wr(& (wr->wr.sig_handover.sig_attrs)->mem, (mr->sig)->psv_memory.psv_idx,
                   & seg, & size);
#line 2719
  if (err != 0) {
#line 2720
    tmp___19 = get_current();
#line 2720
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2720, tmp___19->pid);
#line 2721
    *bad_wr = wr;
#line 2722
    goto out;
  } else {

  }
#line 2725
  tmp___20 = get_fence((int )fence, wr);
#line 2725
  finish_wqe(qp, ctrl, (int )((u8 )size), idx, wr->wr_id, nreq, (int )tmp___20, (int )next_fence,
             32U);
#line 2728
  err = begin_wqe(qp, & seg, & ctrl, wr, & idx, & size, nreq);
#line 2730
  if (err != 0) {
#line 2731
    tmp___21 = get_current();
#line 2731
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2731, tmp___21->pid);
#line 2732
    err = -12;
#line 2733
    *bad_wr = wr;
#line 2734
    goto out;
  } else {

  }
#line 2737
  next_fence = 32U;
#line 2738
  err = set_psv_wr(& (wr->wr.sig_handover.sig_attrs)->wire, (mr->sig)->psv_wire.psv_idx,
                   & seg, & size);
#line 2741
  if (err != 0) {
#line 2742
    tmp___22 = get_current();
#line 2742
    printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2742, tmp___22->pid);
#line 2743
    *bad_wr = wr;
#line 2744
    goto out;
  } else {

  }
#line 2747
  tmp___23 = get_fence((int )fence, wr);
#line 2747
  finish_wqe(qp, ctrl, (int )((u8 )size), idx, wr->wr_id, nreq, (int )tmp___23, (int )next_fence,
             32U);
#line 2750
  num_sge = 0;
#line 2751
  goto skip_psv;
  default: ;
#line 2754
  goto ldv_37828;
  }
  ldv_37828: ;
#line 2756
  goto ldv_37837;
  case 3U: ;
#line 2759
  switch ((unsigned int )wr->opcode) {
  case 0U: ;
  case 1U: 
#line 2762
  set_raddr_seg((struct mlx5_wqe_raddr_seg *)seg, wr->wr.rdma.remote_addr, wr->wr.rdma.rkey);
#line 2764
  seg = seg + 16UL;
#line 2765
  size = (int )((unsigned int )size + 1U);
#line 2766
  goto ldv_37841;
  default: ;
#line 2769
  goto ldv_37841;
  }
  ldv_37841: ;
#line 2771
  goto ldv_37837;
  case 4U: ;
  case 0U: ;
  case 1U: 
#line 2776
  set_datagram_seg((struct mlx5_wqe_datagram_seg *)seg, wr);
#line 2777
  seg = seg + 48UL;
#line 2778
  size = (int )((unsigned int )size + 3U);
#line 2779
  tmp___24 = ldv__builtin_expect((unsigned long )seg == (unsigned long )qend, 0L);
#line 2779
  if (tmp___24 != 0L) {
#line 2780
    seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2781
  goto ldv_37837;
  case 4096U: ;
#line 2784
  if ((unsigned int )wr->opcode != 240U) {
#line 2785
    err = -22;
#line 2786
    tmp___25 = get_current();
#line 2786
    printk("\f%s:%s:%d:(pid %d): bad opcode\n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
           2786, tmp___25->pid);
#line 2787
    goto out;
  } else {

  }
#line 2789
  *(qp->sq.wr_data + (unsigned long )idx) = 240U;
#line 2790
  tmp___26 = __fswab32(wr->wr.fast_reg.rkey);
#line 2790
  ctrl->imm = tmp___26;
#line 2791
  set_reg_umr_segment((struct mlx5_wqe_umr_ctrl_seg *)seg, wr);
#line 2792
  seg = seg + 48UL;
#line 2793
  size = (int )((unsigned int )size + 3U);
#line 2794
  tmp___27 = ldv__builtin_expect((unsigned long )seg == (unsigned long )qend, 0L);
#line 2794
  if (tmp___27 != 0L) {
#line 2795
    seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2796
  set_reg_mkey_segment((struct mlx5_mkey_seg *)seg, wr);
#line 2797
  seg = seg + 64UL;
#line 2798
  size = (int )((unsigned int )size + 4U);
#line 2799
  tmp___28 = ldv__builtin_expect((unsigned long )seg == (unsigned long )qend, 0L);
#line 2799
  if (tmp___28 != 0L) {
#line 2800
    seg = mlx5_get_send_wqe(qp, 0);
  } else {

  }
#line 2801
  goto ldv_37837;
  default: ;
#line 2804
  goto ldv_37837;
  }
  ldv_37837: ;
#line 2807
  if ((wr->send_flags & 8) != 0 && num_sge != 0) {
#line 2808
    sz = sz;
#line 2810
    err = set_data_inl_seg(qp, wr, seg, & sz);
#line 2811
    tmp___30 = ldv__builtin_expect(err != 0, 0L);
#line 2811
    if (tmp___30 != 0L) {
#line 2812
      tmp___29 = get_current();
#line 2812
      printk("\f%s:%s:%d:(pid %d): \n", (char *)(& dev->ib_dev.name), "mlx5_ib_post_send",
             2812, tmp___29->pid);
#line 2813
      *bad_wr = wr;
#line 2814
      goto out;
    } else {

    }
#line 2816
    inl___0 = 1;
#line 2817
    size = size + sz;
  } else {
#line 2819
    dpseg = (struct mlx5_wqe_data_seg *)seg;
#line 2820
    i = 0;
#line 2820
    goto ldv_37850;
    ldv_37849: 
#line 2821
    tmp___31 = ldv__builtin_expect((unsigned long )((void *)dpseg) == (unsigned long )qend,
                                0L);
#line 2821
    if (tmp___31 != 0L) {
#line 2822
      seg = mlx5_get_send_wqe(qp, 0);
#line 2823
      dpseg = (struct mlx5_wqe_data_seg *)seg;
    } else {

    }
#line 2825
    tmp___32 = ldv__builtin_expect((wr->sg_list + (unsigned long )i)->length != 0U, 1L);
#line 2825
    if (tmp___32 != 0L) {
#line 2826
      set_data_ptr_seg(dpseg, wr->sg_list + (unsigned long )i);
#line 2827
      size = (int )((unsigned int )size + 1U);
#line 2828
      dpseg = dpseg + 1;
    } else {

    }
#line 2820
    i = i + 1;
    ldv_37850: ;
#line 2820
    if (i < num_sge) {
#line 2822
      goto ldv_37849;
    } else {

    }

  }
#line 2833
  tmp___33 = get_fence((int )fence, wr);
#line 2833
  finish_wqe(qp, ctrl, (int )((u8 )size), idx, wr->wr_id, nreq, (int )tmp___33, (int )next_fence,
             mlx5_ib_opcode[(unsigned int )wr->opcode]);
  skip_psv: 
#line 2609
  nreq = nreq + 1;
#line 2609
  wr = wr->next;
  ldv_37853: ;
#line 2609
  if ((unsigned long )wr != (unsigned long )((struct ib_send_wr *)0)) {
#line 2611
    goto ldv_37852;
  } else {

  }

  out: 
#line 2842
  tmp___35 = ldv__builtin_expect(nreq != 0, 1L);
#line 2842
  if (tmp___35 != 0L) {
#line 2843
    qp->sq.head = qp->sq.head + (unsigned int )nreq;
#line 2848
    __asm__  volatile   ("sfence": : : "memory");
#line 2850
    tmp___34 = __fswab32((__u32 )qp->sq.cur_post);
#line 2850
    *(qp->db.db + 1UL) = tmp___34;
#line 2854
    __asm__  volatile   ("sfence": : : "memory");
#line 2856
    if (bf->need_lock != 0) {
#line 2857
      spin_lock(& bf->lock);
    } else {

    }
#line 2866
    mlx5_write64((__be32 *)ctrl, bf->regreg + bf->offset, (spinlock_t *)0);
#line 2871
    __asm__  volatile   ("": : : "memory");
#line 2873
    bf->offset = bf->offset ^ (unsigned long )bf->buf_size;
#line 2874
    if (bf->need_lock != 0) {
#line 2875
      spin_unlock(& bf->lock);
    } else {

    }
  } else {

  }
#line 2880
  spin_unlock_irqrestore(& qp->sq.lock, flags);
#line 2882
  return (err);
}
}
#line 2885 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void set_sig_seg(struct mlx5_rwqe_sig *sig , int size ) 
{ 


  {
#line 2887
  sig->signature = calc_sig((void *)sig, size);
#line 2888
  return;
}
}
#line 2890 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_post_recv(struct ib_qp *ibqp , struct ib_recv_wr *wr , struct ib_recv_wr **bad_wr ) 
{ 
  struct mlx5_ib_qp *qp ;
  struct mlx5_ib_qp *tmp ;
  struct mlx5_wqe_data_seg *scat ;
  struct mlx5_rwqe_sig *sig ;
  unsigned long flags ;
  int err ;
  int nreq ;
  int ind ;
  int i ;
  raw_spinlock_t *tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  void *tmp___3 ;
  __u32 tmp___4 ;
  long tmp___5 ;

  {
#line 2893
  tmp = to_mqp(ibqp);
#line 2893
  qp = tmp;
#line 2897
  err = 0;
#line 2902
  tmp___0 = spinlock_check(& qp->rq.lock);
#line 2902
  flags = _raw_spin_lock_irqsave(tmp___0);
#line 2904
  ind = (int )(qp->rq.head & (unsigned int )(qp->rq.wqe_cnt + -1));
#line 2906
  nreq = 0;
#line 2906
  goto ldv_37880;
  ldv_37879: 
#line 2907
  tmp___1 = mlx5_wq_overflow(& qp->rq, nreq, qp->ibqp.recv_cq);
#line 2907
  if (tmp___1 != 0) {
#line 2908
    err = -12;
#line 2909
    *bad_wr = wr;
#line 2910
    goto out;
  } else {

  }
#line 2913
  tmp___2 = ldv__builtin_expect(wr->num_sge > qp->rq.max_gs, 0L);
#line 2913
  if (tmp___2 != 0L) {
#line 2914
    err = -22;
#line 2915
    *bad_wr = wr;
#line 2916
    goto out;
  } else {

  }
#line 2919
  tmp___3 = get_recv_wqe(qp, ind);
#line 2919
  scat = (struct mlx5_wqe_data_seg *)tmp___3;
#line 2920
  if (qp->wq_sig != 0) {
#line 2921
    scat = scat + 1;
  } else {

  }
#line 2923
  i = 0;
#line 2923
  goto ldv_37877;
  ldv_37876: 
#line 2924
  set_data_ptr_seg(scat + (unsigned long )i, wr->sg_list + (unsigned long )i);
#line 2923
  i = i + 1;
  ldv_37877: ;
#line 2923
  if (wr->num_sge > i) {
#line 2925
    goto ldv_37876;
  } else {

  }

#line 2926
  if (qp->rq.max_gs > i) {
#line 2927
    (scat + (unsigned long )i)->byte_count = 0U;
#line 2928
    (scat + (unsigned long )i)->lkey = 65536U;
#line 2929
    (scat + (unsigned long )i)->addr = 0ULL;
  } else {

  }
#line 2932
  if (qp->wq_sig != 0) {
#line 2933
    sig = (struct mlx5_rwqe_sig *)scat;
#line 2934
    set_sig_seg(sig, (qp->rq.max_gs + 1) << 2);
  } else {

  }
#line 2937
  *(qp->rq.wrid + (unsigned long )ind) = wr->wr_id;
#line 2939
  ind = (ind + 1) & (qp->rq.wqe_cnt + -1);
#line 2906
  nreq = nreq + 1;
#line 2906
  wr = wr->next;
  ldv_37880: ;
#line 2906
  if ((unsigned long )wr != (unsigned long )((struct ib_recv_wr *)0)) {
#line 2908
    goto ldv_37879;
  } else {

  }

  out: 
#line 2943
  tmp___5 = ldv__builtin_expect(nreq != 0, 1L);
#line 2943
  if (tmp___5 != 0L) {
#line 2944
    qp->rq.head = qp->rq.head + (unsigned int )nreq;
#line 2949
    __asm__  volatile   ("sfence": : : "memory");
#line 2951
    tmp___4 = __fswab32(qp->rq.head & 65535U);
#line 2951
    *(qp->db.db) = tmp___4;
  } else {

  }
#line 2954
  spin_unlock_irqrestore(& qp->rq.lock, flags);
#line 2956
  return (err);
}
}
#line 2959 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
__inline static enum ib_qp_state to_ib_qp_state(enum mlx5_qp_state mlx5_state ) 
{ 


  {
#line 2961
  switch ((unsigned int )mlx5_state) {
  case 0U: ;
#line 2962
  return (0);
  case 1U: ;
#line 2963
  return (1);
  case 2U: ;
#line 2964
  return (2);
  case 3U: ;
#line 2965
  return (3);
  case 7U: ;
  case 5U: ;
#line 2967
  return (4);
  case 4U: ;
#line 2968
  return (5);
  case 6U: ;
#line 2969
  return (6);
  default: ;
#line 2970
  return (4294967295L);
  }
}
}
#line 2974 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
__inline static enum ib_mig_state to_ib_mig_state(int mlx5_mig_state ) 
{ 


  {
#line 2976
  switch (mlx5_mig_state) {
  case 0: ;
#line 2977
  return (2);
  case 1: ;
#line 2978
  return (1);
  case 3: ;
#line 2979
  return (0);
  default: ;
#line 2980
  return (4294967295L);
  }
}
}
#line 2984 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static int to_ib_qp_access_flags(int mlx5_flags ) 
{ 
  int ib_flags ;

  {
#line 2986
  ib_flags = 0;
#line 2988
  if ((mlx5_flags & 32768) != 0) {
#line 2989
    ib_flags = ib_flags | 4;
  } else {

  }
#line 2990
  if ((mlx5_flags & 16384) != 0) {
#line 2991
    ib_flags = ib_flags | 2;
  } else {

  }
#line 2992
  if ((mlx5_flags & 8192) != 0) {
#line 2993
    ib_flags = ib_flags | 8;
  } else {

  }
#line 2995
  return (ib_flags);
}
}
#line 2998 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
static void to_ib_ah_attr(struct mlx5_ib_dev *ibdev , struct ib_ah_attr *ib_ah_attr ,
                          struct mlx5_qp_path *path ) 
{ 
  struct mlx5_core_dev *dev ;
  __u32 tmp ;
  __u16 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;

  {
#line 3001
  dev = ibdev->mdev;
#line 3003
  memset((void *)ib_ah_attr, 0, 40UL);
#line 3004
  ib_ah_attr->port_num = path->port;
#line 3006
  if ((unsigned int )ib_ah_attr->port_num == 0U) {
#line 3008
    return;
  } else {
#line 3006
    tmp = __fswab32(*((__be32 *)(& dev->hca_caps_cur) + 13UL));
#line 3006
    if ((unsigned int )ib_ah_attr->port_num > (tmp & 255U)) {
#line 3008
      return;
    } else {

    }
  }
#line 3010
  ib_ah_attr->sl = (unsigned int )path->sl & 15U;
#line 3012
  tmp___0 = __fswab16((int )path->rlid);
#line 3012
  ib_ah_attr->dlid = tmp___0;
#line 3013
  ib_ah_attr->src_path_bits = (unsigned int )path->grh_mlid & 127U;
#line 3014
  ib_ah_attr->static_rate = (unsigned int )path->static_rate != 0U ? (unsigned int )path->static_rate + 251U : 0U;
#line 3015
  ib_ah_attr->ah_flags = (int )((signed char )path->grh_mlid) < 0;
#line 3016
  if ((unsigned int )ib_ah_attr->ah_flags != 0U) {
#line 3017
    ib_ah_attr->grh.sgid_index = path->mgid_index;
#line 3018
    ib_ah_attr->grh.hop_limit = path->hop_limit;
#line 3019
    tmp___1 = __fswab32(path->tclass_flowlabel);
#line 3019
    ib_ah_attr->grh.traffic_class = (u8 )(tmp___1 >> 20);
#line 3021
    tmp___2 = __fswab32(path->tclass_flowlabel);
#line 3021
    ib_ah_attr->grh.flow_label = tmp___2 & 1048575U;
#line 3023
    memcpy((void *)(& ib_ah_attr->grh.dgid.raw), (void const   *)(& path->rgid),
             16UL);
  } else {

  }
#line 3025
  return;
}
}
#line 3028 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_query_qp(struct ib_qp *ibqp , struct ib_qp_attr *qp_attr , int qp_attr_mask ,
                     struct ib_qp_init_attr *qp_init_attr ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_qp *qp ;
  struct mlx5_ib_qp *tmp___0 ;
  struct mlx5_query_qp_mbox_out *outb___0 ;
  struct mlx5_qp_context *context ;
  int mlx5_state ;
  int err ;
  void *tmp___1 ;
  __u32 tmp___2 ;
  enum ib_qp_state tmp___3 ;
  __u32 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  __u32 tmp___8 ;
  __u32 tmp___9 ;
  __u32 tmp___10 ;
  __u32 tmp___11 ;
  __u32 tmp___12 ;
  __u32 tmp___13 ;
  __u32 tmp___14 ;

  {
#line 3031
  tmp = to_mdev(ibqp->device);
#line 3031
  dev = tmp;
#line 3032
  tmp___0 = to_mqp(ibqp);
#line 3032
  qp = tmp___0;
#line 3036
  err = 0;
#line 3043
  ldv_flush_workqueue_52(mlx5_ib_page_fault_wq);
#line 3046
  mutex_lock_nested(& qp->mutex, 0U);
#line 3047
  tmp___1 = kzalloc(272UL, 208U);
#line 3047
  outb___0 = (struct mlx5_query_qp_mbox_out *)tmp___1;
#line 3048
  if ((unsigned long )outb___0 == (unsigned long )((struct mlx5_query_qp_mbox_out *)0)) {
#line 3049
    err = -12;
#line 3050
    goto out;
  } else {

  }
#line 3052
  context = & outb___0->ctx;
#line 3053
  err = mlx5_core_qp_query(dev->mdev, & qp->mqp, outb___0, 272);
#line 3054
  if (err != 0) {
#line 3055
    goto out_free;
  } else {

  }
#line 3057
  tmp___2 = __fswab32(context->flags);
#line 3057
  mlx5_state = (int )(tmp___2 >> 28);
#line 3059
  tmp___3 = to_ib_qp_state((enum mlx5_qp_state )mlx5_state);
#line 3059
  qp->state = (u8 )tmp___3;
#line 3060
  qp_attr->qp_state = (enum ib_qp_state )qp->state;
#line 3061
  qp_attr->path_mtu = (enum ib_mtu )((int )context->mtu_msgmax >> 5);
#line 3062
  tmp___4 = __fswab32(context->flags);
#line 3062
  qp_attr->path_mig_state = to_ib_mig_state((int )(tmp___4 >> 11) & 3);
#line 3064
  tmp___5 = __fswab32(context->qkey);
#line 3064
  qp_attr->qkey = tmp___5;
#line 3065
  tmp___6 = __fswab32(context->rnr_nextrecvpsn);
#line 3065
  qp_attr->rq_psn = tmp___6 & 16777215U;
#line 3066
  tmp___7 = __fswab32(context->next_send_psn);
#line 3066
  qp_attr->sq_psn = tmp___7 & 16777215U;
#line 3067
  tmp___8 = __fswab32(context->log_pg_sz_remote_qpn);
#line 3067
  qp_attr->dest_qp_num = tmp___8 & 16777215U;
#line 3068
  tmp___9 = __fswab32(context->params2);
#line 3068
  qp_attr->qp_access_flags = to_ib_qp_access_flags((int )tmp___9);
#line 3071
  if ((unsigned int )qp->ibqp.qp_type == 2U || (unsigned int )qp->ibqp.qp_type == 3U) {
#line 3072
    to_ib_ah_attr(dev, & qp_attr->ah_attr, & context->pri_path);
#line 3073
    to_ib_ah_attr(dev, & qp_attr->alt_ah_attr, & context->alt_path);
#line 3074
    qp_attr->alt_pkey_index = (unsigned int )((u16 )context->alt_path.pkey_index) & 127U;
#line 3075
    qp_attr->alt_port_num = qp_attr->alt_ah_attr.port_num;
  } else {

  }
#line 3078
  qp_attr->pkey_index = (unsigned int )((u16 )context->pri_path.pkey_index) & 127U;
#line 3079
  qp_attr->port_num = context->pri_path.port;
#line 3082
  qp_attr->sq_draining = mlx5_state == 7;
#line 3084
  tmp___10 = __fswab32(context->params1);
#line 3084
  qp_attr->max_rd_atomic = (u8 )(1 << ((int )(tmp___10 >> 21) & 7));
#line 3086
  tmp___11 = __fswab32(context->params2);
#line 3086
  qp_attr->max_dest_rd_atomic = (u8 )(1 << ((int )(tmp___11 >> 21) & 7));
#line 3088
  tmp___12 = __fswab32(context->rnr_nextrecvpsn);
#line 3088
  qp_attr->min_rnr_timer = (unsigned int )((u8 )(tmp___12 >> 24)) & 31U;
#line 3090
  qp_attr->timeout = (u8 )((int )context->pri_path.ackto_lt >> 3);
#line 3091
  tmp___13 = __fswab32(context->params1);
#line 3091
  qp_attr->retry_cnt = (unsigned int )((u8 )(tmp___13 >> 16)) & 7U;
#line 3092
  tmp___14 = __fswab32(context->params1);
#line 3092
  qp_attr->rnr_retry = (unsigned int )((u8 )(tmp___14 >> 13)) & 7U;
#line 3093
  qp_attr->alt_timeout = (u8 )((int )context->alt_path.ackto_lt >> 3);
#line 3094
  qp_attr->cur_qp_state = qp_attr->qp_state;
#line 3095
  qp_attr->cap.max_recv_wr = (u32 )qp->rq.wqe_cnt;
#line 3096
  qp_attr->cap.max_recv_sge = (u32 )qp->rq.max_gs;
#line 3098
  if ((unsigned long )ibqp->uobject == (unsigned long )((struct ib_uobject *)0)) {
#line 3099
    qp_attr->cap.max_send_wr = (u32 )qp->sq.wqe_cnt;
#line 3100
    qp_attr->cap.max_send_sge = (u32 )qp->sq.max_gs;
  } else {
#line 3102
    qp_attr->cap.max_send_wr = 0U;
#line 3103
    qp_attr->cap.max_send_sge = 0U;
  }
#line 3109
  qp_attr->cap.max_inline_data = 0U;
#line 3111
  qp_init_attr->cap = qp_attr->cap;
#line 3113
  qp_init_attr->create_flags = 0;
#line 3114
  if ((int )qp->flags & 1) {
#line 3115
    qp_init_attr->create_flags = (enum ib_qp_create_flags )((int )qp_init_attr->create_flags | 2);
  } else {

  }
#line 3117
  qp_init_attr->sq_sig_type = ((int )qp->sq_signal_bits & 8) == 0;
  out_free: 
#line 3121
  kfree((void const   *)outb___0);
  out: 
#line 3124
  mutex_unlock(& qp->mutex);
#line 3125
  return (err);
}
}
#line 3128 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
struct ib_xrcd *mlx5_ib_alloc_xrcd(struct ib_device *ibdev , struct ib_ucontext *context ,
                                   struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_xrcd *xrcd ;
  int err ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;

  {
#line 3132
  tmp = to_mdev(ibdev);
#line 3132
  dev = tmp;
#line 3136
  tmp___1 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 17UL));
#line 3136
  if ((tmp___1 & 8U) == 0U) {
#line 3137
    tmp___0 = ERR_PTR(-38L);
#line 3137
    return ((struct ib_xrcd *)tmp___0);
  } else {

  }
#line 3139
  tmp___2 = kmalloc(208UL, 208U);
#line 3139
  xrcd = (struct mlx5_ib_xrcd *)tmp___2;
#line 3140
  if ((unsigned long )xrcd == (unsigned long )((struct mlx5_ib_xrcd *)0)) {
#line 3141
    tmp___3 = ERR_PTR(-12L);
#line 3141
    return ((struct ib_xrcd *)tmp___3);
  } else {

  }
#line 3143
  err = mlx5_core_xrcd_alloc(dev->mdev, & xrcd->xrcdn);
#line 3144
  if (err != 0) {
#line 3145
    kfree((void const   *)xrcd);
#line 3146
    tmp___4 = ERR_PTR(-12L);
#line 3146
    return ((struct ib_xrcd *)tmp___4);
  } else {

  }
#line 3149
  return (& xrcd->ibxrcd);
}
}
#line 3152 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.c"
int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  u32 xrcdn ;
  struct mlx5_ib_xrcd *tmp___0 ;
  int err ;
  struct task_struct *tmp___1 ;

  {
#line 3154
  tmp = to_mdev(xrcd->device);
#line 3154
  dev = tmp;
#line 3155
  tmp___0 = to_mxrcd(xrcd);
#line 3155
  xrcdn = tmp___0->xrcdn;
#line 3158
  err = mlx5_core_xrcd_dealloc(dev->mdev, xrcdn);
#line 3159
  if (err != 0) {
#line 3160
    tmp___1 = get_current();
#line 3160
    printk("\f%s:%s:%d:(pid %d): failed to dealloc xrcdn 0x%x\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_dealloc_xrcd", 3160, tmp___1->pid, xrcdn);
#line 3161
    return (err);
  } else {

  }
#line 3164
  kfree((void const   *)xrcd);
#line 3166
  return (0);
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.o.c.prepared"
bool ldv_queue_work_on_47(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.o.c.prepared"
bool ldv_queue_delayed_work_on_48(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.o.c.prepared"
bool ldv_queue_work_on_49(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.o.c.prepared"
void ldv_flush_workqueue_50(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.o.c.prepared"
bool ldv_queue_delayed_work_on_51(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 179 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/qp.o.c.prepared"
void ldv_flush_workqueue_52(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 182
  flush_workqueue(ldv_func_arg1);
#line 184
  call_and_disable_all_3(2);
#line 185
  return;
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 42 "include/asm-generic/bitops/find.h"
extern unsigned long find_first_bit(unsigned long const   * , unsigned long  ) ;
#line 40 "include/linux/log2.h"
__inline static int __ilog2_u64(u64 n ) 
{ 
  int tmp ;

  {
#line 42
  tmp = fls64(n);
#line 42
  return (tmp + -1);
}
}
#line 71 "include/asm-generic/bug.h"
extern void warn_slowpath_null(char const   * , int const    ) ;
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_63(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_65(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_64(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_67(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_66(struct workqueue_struct *ldv_func_arg1 ) ;
#line 250 "include/linux/scatterlist.h"
extern struct scatterlist *sg_next(struct scatterlist * ) ;
#line 88 "include/rdma/ib_umem.h"
extern int ib_umem_page_count(struct ib_umem * ) ;
#line 623 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
void __mlx5_ib_populate_pas(struct mlx5_ib_dev *dev , struct ib_umem *umem , int page_shift ,
                            size_t offset , size_t num_pages , __be64 *pas , int access_flags ) ;
#line 45 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c"
void mlx5_ib_cont_pages(struct ib_umem *umem , u64 addr , int *count , int *shift ,
                        int *ncont , int *order ) 
{ 
  unsigned long tmp ;
  unsigned long m ;
  int i ;
  int k ;
  u64 base ;
  int p ;
  int skip ;
  int mask ;
  u64 len ;
  u64 pfn ;
  struct scatterlist *sg ;
  int entry ;
  unsigned long page_shift ;
  int tmp___0 ;
  unsigned long tmp___1 ;
  unsigned long __min1 ;
  unsigned long __min2 ;
  unsigned long tmp___2 ;
  unsigned long __min1___0 ;
  unsigned long tmp___3 ;
  int tmp___4 ;
  unsigned long __min2___0 ;
  unsigned long tmp___5 ;

  {
#line 51
  base = 0ULL;
#line 52
  p = 0;
#line 59
  tmp___0 = __ilog2_u32((u32 )umem->page_size);
#line 59
  page_shift = (unsigned long )tmp___0;
#line 62
  if ((unsigned long )umem->odp_data != (unsigned long )((struct ib_umem_odp *)0)) {
#line 63
    *count = ib_umem_page_count(umem);
#line 64
    *shift = 12;
#line 65
    *ncont = *count;
#line 66
    if ((unsigned long )order != (unsigned long )((int *)0)) {
#line 67
      tmp___1 = __roundup_pow_of_two((unsigned long )*count);
#line 67
      *order = __ilog2_u64((u64 )tmp___1);
    } else {

    }
#line 69
    return;
  } else {

  }
#line 72
  addr = addr >> (int )page_shift;
#line 73
  tmp = (unsigned long )addr;
#line 74
  m = find_first_bit((unsigned long const   *)(& tmp), 8UL);
#line 75
  skip = 1 << (int )m;
#line 76
  mask = skip + -1;
#line 77
  i = 0;
#line 78
  entry = 0;
#line 78
  sg = umem->sg_head.sgl;
#line 78
  goto ldv_37031;
  ldv_37030: 
#line 79
  len = (u64 )(sg->dma_length >> (int )page_shift);
#line 80
  pfn = sg->dma_address >> (int )page_shift;
#line 81
  k = 0;
#line 81
  goto ldv_37028;
  ldv_37027: ;
#line 82
  if ((i & mask) == 0) {
#line 83
    tmp = (unsigned long )pfn;
#line 84
    __min1 = m;
#line 84
    tmp___2 = find_first_bit((unsigned long const   *)(& tmp), 8UL);
#line 84
    __min2 = tmp___2;
#line 84
    m = __min1 < __min2 ? __min1 : __min2;
#line 85
    skip = 1 << (int )m;
#line 86
    mask = skip + -1;
#line 87
    base = pfn;
#line 88
    p = 0;
  } else
#line 90
  if ((u64 )p + base != pfn) {
#line 91
    tmp = (unsigned long )p;
#line 92
    m = find_first_bit((unsigned long const   *)(& tmp), 8UL);
#line 93
    skip = 1 << (int )m;
#line 94
    mask = skip + -1;
#line 95
    base = pfn;
#line 96
    p = 0;
  } else {

  }
#line 99
  p = p + 1;
#line 100
  i = i + 1;
#line 81
  k = k + 1;
  ldv_37028: ;
#line 81
  if ((u64 )k < len) {
#line 83
    goto ldv_37027;
  } else {

  }
#line 78
  entry = entry + 1;
#line 78
  sg = sg_next(sg);
  ldv_37031: ;
#line 78
  if (umem->nmap > entry) {
#line 80
    goto ldv_37030;
  } else {

  }

#line 104
  if (i != 0) {
#line 105
    tmp___3 = __roundup_pow_of_two((unsigned long )i);
#line 105
    tmp___4 = __ilog2_u64((u64 )tmp___3);
#line 105
    __min1___0 = (unsigned long )tmp___4;
#line 105
    __min2___0 = m;
#line 105
    m = __min1___0 < __min2___0 ? __min1___0 : __min2___0;
#line 107
    if ((unsigned long )order != (unsigned long )((int *)0)) {
#line 108
      tmp___5 = __roundup_pow_of_two((unsigned long )i);
#line 108
      *order = __ilog2_u64((u64 )(tmp___5 >> (int )m));
    } else {

    }
#line 110
    *ncont = (((1 << (int )m) + i) + -1) / (1 << (int )m);
  } else {
#line 112
    m = 0UL;
#line 114
    if ((unsigned long )order != (unsigned long )((int *)0)) {
#line 115
      *order = 0;
    } else {

    }
#line 117
    *ncont = 0;
  }
#line 119
  *shift = (int )((unsigned int )page_shift + (unsigned int )m);
#line 120
  *count = i;
#line 121
  return;
}
}
#line 124 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c"
static u64 umem_dma_to_mtt(dma_addr_t umem_dma ) 
{ 
  u64 mtt_entry ;

  {
#line 126
  mtt_entry = umem_dma & 0xfffffffffffffffcULL;
#line 128
  if ((int )umem_dma & 1) {
#line 129
    mtt_entry = mtt_entry | 1ULL;
  } else {

  }
#line 130
  if ((umem_dma & 2ULL) != 0ULL) {
#line 131
    mtt_entry = mtt_entry | 2ULL;
  } else {

  }
#line 133
  return (mtt_entry);
}
}
#line 150 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c"
void __mlx5_ib_populate_pas(struct mlx5_ib_dev *dev , struct ib_umem *umem , int page_shift ,
                            size_t offset , size_t num_pages , __be64 *pas , int access_flags ) 
{ 
  unsigned long umem_page_shift ;
  int tmp ;
  int shift ;
  int mask ;
  int i ;
  int k ;
  u64 cur ;
  u64 base ;
  int len ;
  struct scatterlist *sg ;
  int entry ;
  bool odp ;
  int __ret_warn_on ;
  long tmp___0 ;
  int __ret_warn_on___0 ;
  long tmp___1 ;
  dma_addr_t pa ;
  u64 tmp___2 ;
  __u64 tmp___3 ;
  __u64 tmp___4 ;
  struct _ddebug descriptor ;
  __u64 tmp___5 ;
  struct task_struct *tmp___6 ;
  long tmp___7 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___8 ;
  long tmp___9 ;

  {
#line 154
  tmp = __ilog2_u32((u32 )umem->page_size);
#line 154
  umem_page_shift = (unsigned long )tmp;
#line 155
  shift = (int )((unsigned int )page_shift - (unsigned int )umem_page_shift);
#line 156
  mask = (1 << shift) + -1;
#line 158
  cur = 0ULL;
#line 164
  odp = (unsigned long )umem->odp_data != (unsigned long )((struct ib_umem_odp *)0);
#line 166
  if ((int )odp) {
#line 167
    __ret_warn_on = shift != 0;
#line 167
    tmp___0 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
#line 167
    if (tmp___0 != 0L) {
#line 167
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c",
                         167);
    } else {

    }
#line 167
    ldv__builtin_expect(__ret_warn_on != 0, 0L);
#line 168
    __ret_warn_on___0 = access_flags != 3;
#line 168
    tmp___1 = ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
#line 168
    if (tmp___1 != 0L) {
#line 168
      warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c",
                         168);
    } else {

    }
#line 168
    ldv__builtin_expect(__ret_warn_on___0 != 0, 0L);
#line 170
    i = 0;
#line 170
    goto ldv_37066;
    ldv_37065: 
#line 171
    pa = *((umem->odp_data)->dma_list + ((size_t )i + offset));
#line 173
    tmp___2 = umem_dma_to_mtt(pa);
#line 173
    tmp___3 = __fswab64(tmp___2);
#line 173
    *(pas + (unsigned long )i) = tmp___3;
#line 170
    i = i + 1;
    ldv_37066: ;
#line 170
    if ((size_t )i < num_pages) {
#line 172
      goto ldv_37065;
    } else {

    }

#line 175
    return;
  } else {

  }
#line 179
  i = 0;
#line 180
  entry = 0;
#line 180
  sg = umem->sg_head.sgl;
#line 180
  goto ldv_37075;
  ldv_37074: 
#line 181
  len = (int )(sg->dma_length >> (int )umem_page_shift);
#line 182
  base = sg->dma_address;
#line 183
  k = 0;
#line 183
  goto ldv_37072;
  ldv_37071: ;
#line 184
  if ((i & mask) == 0) {
#line 185
    cur = (u64 )(k << (int )umem_page_shift) + base;
#line 186
    cur = (u64 )access_flags | cur;
#line 188
    tmp___4 = __fswab64(cur);
#line 188
    *(pas + (unsigned long )(i >> shift)) = tmp___4;
#line 189
    descriptor.modname = "mlx5_ib";
#line 189
    descriptor.function = "__mlx5_ib_populate_pas";
#line 189
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c";
#line 189
    descriptor.format = "%s:%s:%d:(pid %d): pas[%d] 0x%llx\n";
#line 189
    descriptor.lineno = 190U;
#line 189
    descriptor.flags = 0U;
#line 189
    tmp___7 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 189
    if (tmp___7 != 0L) {
#line 189
      tmp___5 = __fswab64(*(pas + (unsigned long )(i >> shift)));
#line 189
      tmp___6 = get_current();
#line 189
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): pas[%d] 0x%llx\n", (char *)(& dev->ib_dev.name),
                         "__mlx5_ib_populate_pas", 190, tmp___6->pid, i >> shift,
                         tmp___5);
    } else {

    }
  } else {
#line 192
    descriptor___0.modname = "mlx5_ib";
#line 192
    descriptor___0.function = "__mlx5_ib_populate_pas";
#line 192
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c";
#line 192
    descriptor___0.format = "%s:%s:%d:(pid %d): =====> 0x%llx\n";
#line 192
    descriptor___0.lineno = 193U;
#line 192
    descriptor___0.flags = 0U;
#line 192
    tmp___9 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 192
    if (tmp___9 != 0L) {
#line 192
      tmp___8 = get_current();
#line 192
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): =====> 0x%llx\n", (char *)(& dev->ib_dev.name),
                         "__mlx5_ib_populate_pas", 193, tmp___8->pid, (u64 )(k << (int )umem_page_shift) + base);
    } else {

    }
  }
#line 194
  i = i + 1;
#line 183
  k = k + 1;
  ldv_37072: ;
#line 183
  if (k < len) {
#line 185
    goto ldv_37071;
  } else {

  }
#line 180
  entry = entry + 1;
#line 180
  sg = sg_next(sg);
  ldv_37075: ;
#line 180
  if (umem->nmap > entry) {
#line 182
    goto ldv_37074;
  } else {

  }

#line 187
  return;
}
}
#line 199 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c"
void mlx5_ib_populate_pas(struct mlx5_ib_dev *dev , struct ib_umem *umem , int page_shift ,
                          __be64 *pas , int access_flags ) 
{ 


  {
#line 202
  return;
}
}
#line 206 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.c"
int mlx5_ib_get_buf_offset(u64 addr , int page_shift , u32 *offset ) 
{ 
  u64 page_size ;
  u64 page_mask ;
  u64 off_size ;
  u64 off_mask ;
  u64 buf_off ;
  int tmp ;

  {
#line 214
  page_size = 1ULL << page_shift;
#line 215
  page_mask = page_size - 1ULL;
#line 216
  buf_off = addr & page_mask;
#line 217
  off_size = page_size >> 6;
#line 218
  off_mask = off_size - 1ULL;
#line 220
  if ((buf_off & off_mask) != 0ULL) {
#line 221
    return (-22);
  } else {

  }
#line 223
  tmp = __ilog2_u64(off_size);
#line 223
  *offset = (u32 )(buf_off >> tmp);
#line 224
  return (0);
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.o.c.prepared"
bool ldv_queue_work_on_63(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.o.c.prepared"
bool ldv_queue_delayed_work_on_64(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.o.c.prepared"
bool ldv_queue_work_on_65(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.o.c.prepared"
void ldv_flush_workqueue_66(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mem.o.c.prepared"
bool ldv_queue_delayed_work_on_67(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 23 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) ;
#line 32
__inline static long PTR_ERR(void const   *ptr ) ;
#line 41
__inline static bool IS_ERR(void const   *ptr ) ;
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_77(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_79(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_78(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_81(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_80(struct workqueue_struct *ldv_func_arg1 ) ;
#line 681 "include/linux/mlx5/driver.h"
extern int mlx5_core_create_srq(struct mlx5_core_dev * , struct mlx5_core_srq * ,
                                struct mlx5_create_srq_mbox_in * , int  , int  ) ;
#line 684
extern int mlx5_core_destroy_srq(struct mlx5_core_dev * , struct mlx5_core_srq * ) ;
#line 685
extern int mlx5_core_query_srq(struct mlx5_core_dev * , struct mlx5_core_srq * , struct mlx5_query_srq_mbox_out * ) ;
#line 687
extern int mlx5_core_arm_srq(struct mlx5_core_dev * , struct mlx5_core_srq * , u16  ,
                             int  ) ;
#line 44 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static int srq_signature  ;
#line 46 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static void *get_wqe___0(struct mlx5_ib_srq *srq , int n ) 
{ 
  void *tmp ;

  {
#line 48
  tmp = mlx5_buf_offset(& srq->buf, n << srq->msrq.wqe_shift);
#line 48
  return (tmp);
}
}
#line 51 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static void mlx5_ib_srq_event(struct mlx5_core_srq *srq , enum mlx5_event type ) 
{ 
  struct ib_event event ;
  struct ib_srq *ibsrq ;
  struct mlx5_ib_srq *tmp ;

  {
#line 54
  tmp = to_mibsrq(srq);
#line 54
  ibsrq = & tmp->ibsrq;
#line 56
  if ((unsigned long )ibsrq->event_handler != (unsigned long )((void (*)(struct ib_event * ,
                                                                         void * ))0)) {
#line 57
    event.device = ibsrq->device;
#line 58
    event.element.srq = ibsrq;
#line 59
    switch ((unsigned int )type) {
    case 20U: 
#line 61
    event.event = 15;
#line 62
    goto ldv_37645;
    case 18U: 
#line 64
    event.event = 14;
#line 65
    goto ldv_37645;
    default: 
#line 67
    printk("\fmlx5_ib: Unexpected event type %d on SRQ %06x\n", (unsigned int )type,
           srq->srqn);
#line 69
    return;
    }
    ldv_37645: 
#line 72
    (*(ibsrq->event_handler))(& event, ibsrq->srq_context);
  } else {

  }
#line 74
  return;
}
}
#line 76 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static int create_srq_user(struct ib_pd *pd , struct mlx5_ib_srq *srq , struct mlx5_create_srq_mbox_in **in ,
                           struct ib_udata *udata , int buf_size , int *inlen ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_create_srq ucmd ;
  size_t ucmdlen ;
  int err ;
  int npages ;
  int page_shift ;
  int ncont ;
  u32 offset ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  int tmp___2 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  long tmp___5 ;
  bool tmp___6 ;
  struct task_struct *tmp___7 ;
  void *tmp___8 ;
  struct mlx5_ib_ucontext *tmp___9 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___10 ;
  long tmp___11 ;
  __u32 tmp___12 ;

  {
#line 80
  tmp = to_mdev(pd->device);
#line 80
  dev = tmp;
#line 89
  ucmdlen = udata->inlen - 8UL <= 23UL ? 20UL : 24UL;
#line 94
  tmp___2 = ib_copy_from_udata((void *)(& ucmd), udata, ucmdlen);
#line 94
  if (tmp___2 != 0) {
#line 95
    descriptor.modname = "mlx5_ib";
#line 95
    descriptor.function = "create_srq_user";
#line 95
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 95
    descriptor.format = "%s:%s:%d:(pid %d): failed copy udata\n";
#line 95
    descriptor.lineno = 95U;
#line 95
    descriptor.flags = 0U;
#line 95
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 95
    if (tmp___1 != 0L) {
#line 95
      tmp___0 = get_current();
#line 95
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): failed copy udata\n", (char *)(& dev->ib_dev.name),
                         "create_srq_user", 95, tmp___0->pid);
    } else {

    }
#line 96
    return (-14);
  } else {

  }
#line 99
  if (ucmdlen == 24UL && ucmd.reserved != 0U) {
#line 101
    return (-22);
  } else {

  }
#line 103
  srq->wq_sig = (int )ucmd.flags & 1;
#line 105
  srq->umem = ib_umem_get((pd->uobject)->context, (unsigned long )ucmd.buf_addr, (size_t )buf_size,
                          0, 0);
#line 107
  tmp___6 = IS_ERR((void const   *)srq->umem);
#line 107
  if ((int )tmp___6) {
#line 108
    descriptor___0.modname = "mlx5_ib";
#line 108
    descriptor___0.function = "create_srq_user";
#line 108
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 108
    descriptor___0.format = "%s:%s:%d:(pid %d): failed umem get, size %d\n";
#line 108
    descriptor___0.lineno = 108U;
#line 108
    descriptor___0.flags = 0U;
#line 108
    tmp___4 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 108
    if (tmp___4 != 0L) {
#line 108
      tmp___3 = get_current();
#line 108
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): failed umem get, size %d\n",
                         (char *)(& dev->ib_dev.name), "create_srq_user", 108, tmp___3->pid,
                         buf_size);
    } else {

    }
#line 109
    tmp___5 = PTR_ERR((void const   *)srq->umem);
#line 109
    err = (int )tmp___5;
#line 110
    return (err);
  } else {

  }
#line 113
  mlx5_ib_cont_pages(srq->umem, ucmd.buf_addr, & npages, & page_shift, & ncont, (int *)0);
#line 115
  err = mlx5_ib_get_buf_offset(ucmd.buf_addr, page_shift, & offset);
#line 117
  if (err != 0) {
#line 118
    tmp___7 = get_current();
#line 118
    printk("\f%s:%s:%d:(pid %d): bad offset\n", (char *)(& dev->ib_dev.name), "create_srq_user",
           118, tmp___7->pid);
#line 119
    goto err_umem;
  } else {

  }
#line 122
  *inlen = (int )((unsigned int )((unsigned long )ncont + 34UL) * 8U);
#line 123
  tmp___8 = mlx5_vzalloc((unsigned long )*inlen);
#line 123
  *in = (struct mlx5_create_srq_mbox_in *)tmp___8;
#line 124
  if ((unsigned long )*in == (unsigned long )((struct mlx5_create_srq_mbox_in *)0)) {
#line 125
    err = -12;
#line 126
    goto err_umem;
  } else {

  }
#line 129
  mlx5_ib_populate_pas(dev, srq->umem, page_shift, (__be64 *)(& (*in)->pas), 0);
#line 131
  tmp___9 = to_mucontext((pd->uobject)->context);
#line 131
  err = mlx5_ib_db_map_user(tmp___9, (unsigned long )ucmd.db_addr, & srq->db);
#line 133
  if (err != 0) {
#line 134
    descriptor___1.modname = "mlx5_ib";
#line 134
    descriptor___1.function = "create_srq_user";
#line 134
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 134
    descriptor___1.format = "%s:%s:%d:(pid %d): map doorbell failed\n";
#line 134
    descriptor___1.lineno = 134U;
#line 134
    descriptor___1.flags = 0U;
#line 134
    tmp___11 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 134
    if (tmp___11 != 0L) {
#line 134
      tmp___10 = get_current();
#line 134
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): map doorbell failed\n",
                         (char *)(& dev->ib_dev.name), "create_srq_user", 134, tmp___10->pid);
    } else {

    }
#line 135
    goto err_in;
  } else {

  }
#line 138
  (*in)->ctx.log_pg_sz = (unsigned int )((u8 )page_shift) + 244U;
#line 139
  tmp___12 = __fswab32(offset << 26);
#line 139
  (*in)->ctx.pgoff_cqn = tmp___12;
#line 141
  return (0);
  err_in: 
#line 144
  kvfree((void const   *)*in);
  err_umem: 
#line 147
  ib_umem_release(srq->umem);
#line 149
  return (err);
}
}
#line 152 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static int create_srq_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_srq *srq , struct mlx5_create_srq_mbox_in **in ,
                             int buf_size , int *inlen ) 
{ 
  int err ;
  int i ;
  struct mlx5_wqe_srq_next_seg *next ;
  int page_shift ;
  int npages ;
  struct task_struct *tmp ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  int tmp___2 ;
  void *tmp___3 ;
  __u16 tmp___4 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___5 ;
  long tmp___6 ;
  void *tmp___7 ;
  void *tmp___8 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___9 ;
  long tmp___10 ;

  {
#line 162
  err = mlx5_db_alloc(dev->mdev, & srq->db);
#line 163
  if (err != 0) {
#line 164
    tmp = get_current();
#line 164
    printk("\f%s:%s:%d:(pid %d): alloc dbell rec failed\n", (char *)(& dev->ib_dev.name),
           "create_srq_kernel", 164, tmp->pid);
#line 165
    return (err);
  } else {

  }
#line 168
  tmp___2 = mlx5_buf_alloc(dev->mdev, buf_size, & srq->buf);
#line 168
  if (tmp___2 != 0) {
#line 169
    descriptor.modname = "mlx5_ib";
#line 169
    descriptor.function = "create_srq_kernel";
#line 169
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 169
    descriptor.format = "%s:%s:%d:(pid %d): buf alloc failed\n";
#line 169
    descriptor.lineno = 169U;
#line 169
    descriptor.flags = 0U;
#line 169
    tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 169
    if (tmp___1 != 0L) {
#line 169
      tmp___0 = get_current();
#line 169
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): buf alloc failed\n", (char *)(& dev->ib_dev.name),
                         "create_srq_kernel", 169, tmp___0->pid);
    } else {

    }
#line 170
    err = -12;
#line 171
    goto err_db;
  } else {

  }
#line 173
  page_shift = (int )srq->buf.page_shift;
#line 175
  srq->head = 0;
#line 176
  srq->tail = srq->msrq.max + -1;
#line 177
  srq->wqe_ctr = 0U;
#line 179
  i = 0;
#line 179
  goto ldv_37686;
  ldv_37685: 
#line 180
  tmp___3 = get_wqe___0(srq, i);
#line 180
  next = (struct mlx5_wqe_srq_next_seg *)tmp___3;
#line 181
  tmp___4 = __fswab16((int )((__u16 )((int )((short )((unsigned int )((unsigned short )i) + 1U)) & (int )((short )((unsigned int )((unsigned short )srq->msrq.max) + 65535U)))));
#line 181
  next->next_wqe_index = tmp___4;
#line 179
  i = i + 1;
  ldv_37686: ;
#line 179
  if (srq->msrq.max > i) {
#line 181
    goto ldv_37685;
  } else {

  }
#line 185
  npages = ((srq->buf.npages + (1 << (page_shift + -12))) + -1) / (1 << (page_shift + -12));
#line 186
  descriptor___0.modname = "mlx5_ib";
#line 186
  descriptor___0.function = "create_srq_kernel";
#line 186
  descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 186
  descriptor___0.format = "%s:%s:%d:(pid %d): buf_size %d, page_shift %d, npages %d, calc npages %d\n";
#line 186
  descriptor___0.lineno = 187U;
#line 186
  descriptor___0.flags = 0U;
#line 186
  tmp___6 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 186
  if (tmp___6 != 0L) {
#line 186
    tmp___5 = get_current();
#line 186
    __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): buf_size %d, page_shift %d, npages %d, calc npages %d\n",
                       (char *)(& dev->ib_dev.name), "create_srq_kernel", 187, tmp___5->pid,
                       buf_size, page_shift, srq->buf.npages, npages);
  } else {

  }
#line 188
  *inlen = (int )((unsigned int )((unsigned long )npages + 34UL) * 8U);
#line 189
  tmp___7 = mlx5_vzalloc((unsigned long )*inlen);
#line 189
  *in = (struct mlx5_create_srq_mbox_in *)tmp___7;
#line 190
  if ((unsigned long )*in == (unsigned long )((struct mlx5_create_srq_mbox_in *)0)) {
#line 191
    err = -12;
#line 192
    goto err_buf;
  } else {

  }
#line 194
  mlx5_fill_page_array(& srq->buf, (__be64 *)(& (*in)->pas));
#line 196
  tmp___8 = kmalloc((unsigned long )srq->msrq.max * 8UL, 208U);
#line 196
  srq->wrid = (u64 *)tmp___8;
#line 197
  if ((unsigned long )srq->wrid == (unsigned long )((u64 *)0ULL)) {
#line 198
    descriptor___1.modname = "mlx5_ib";
#line 198
    descriptor___1.function = "create_srq_kernel";
#line 198
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 198
    descriptor___1.format = "%s:%s:%d:(pid %d): kmalloc failed %lu\n";
#line 198
    descriptor___1.lineno = 199U;
#line 198
    descriptor___1.flags = 0U;
#line 198
    tmp___10 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 198
    if (tmp___10 != 0L) {
#line 198
      tmp___9 = get_current();
#line 198
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): kmalloc failed %lu\n",
                         (char *)(& dev->ib_dev.name), "create_srq_kernel", 199, tmp___9->pid,
                         (unsigned long )srq->msrq.max * 8UL);
    } else {

    }
#line 200
    err = -12;
#line 201
    goto err_in;
  } else {

  }
#line 203
  srq->wq_sig = srq_signature != 0;
#line 205
  (*in)->ctx.log_pg_sz = (unsigned int )((u8 )page_shift) + 244U;
#line 207
  return (0);
  err_in: 
#line 210
  kvfree((void const   *)*in);
  err_buf: 
#line 213
  mlx5_buf_free(dev->mdev, & srq->buf);
  err_db: 
#line 216
  mlx5_db_free(dev->mdev, & srq->db);
#line 217
  return (err);
}
}
#line 220 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static void destroy_srq_user(struct ib_pd *pd , struct mlx5_ib_srq *srq ) 
{ 
  struct mlx5_ib_ucontext *tmp ;

  {
#line 222
  tmp = to_mucontext((pd->uobject)->context);
#line 222
  mlx5_ib_db_unmap_user(tmp, & srq->db);
#line 223
  ib_umem_release(srq->umem);
#line 224
  return;
}
}
#line 227 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
static void destroy_srq_kernel(struct mlx5_ib_dev *dev , struct mlx5_ib_srq *srq ) 
{ 


  {
#line 229
  kfree((void const   *)srq->wrid);
#line 230
  mlx5_buf_free(dev->mdev, & srq->buf);
#line 231
  mlx5_db_free(dev->mdev, & srq->db);
#line 232
  return;
}
}
#line 234 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
struct ib_srq *mlx5_ib_create_srq(struct ib_pd *pd , struct ib_srq_init_attr *init_attr ,
                                  struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_srq *srq ;
  int desc_size ;
  int buf_size ;
  int err ;
  struct mlx5_create_srq_mbox_in *in ;
  int inlen ;
  int is_xrc ;
  u32 flgs ;
  u32 xrcdn ;
  __u32 max_srq_wqes ;
  __u32 tmp___0 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___1 ;
  long tmp___2 ;
  void *tmp___3 ;
  void *tmp___4 ;
  void *tmp___5 ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  unsigned long tmp___6 ;
  unsigned long tmp___7 ;
  int __max1 ;
  int __max2 ;
  struct _ddebug descriptor___0 ;
  struct task_struct *tmp___8 ;
  long tmp___9 ;
  struct task_struct *tmp___10 ;
  int tmp___11 ;
  struct mlx5_ib_xrcd *tmp___12 ;
  struct mlx5_ib_cq *tmp___13 ;
  __u32 tmp___14 ;
  struct mlx5_ib_xrcd *tmp___15 ;
  struct mlx5_ib_cq *tmp___16 ;
  __u32 tmp___17 ;
  __u32 tmp___18 ;
  struct mlx5_ib_pd *tmp___19 ;
  __u32 tmp___20 ;
  __u64 tmp___21 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___22 ;
  long tmp___23 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___24 ;
  long tmp___25 ;
  struct _ddebug descriptor___3 ;
  struct task_struct *tmp___26 ;
  long tmp___27 ;
  int tmp___28 ;
  void *tmp___29 ;

  {
#line 238
  tmp = to_mdev(pd->device);
#line 238
  dev = tmp;
#line 243
  in = in;
#line 244
  inlen = inlen;
#line 247
  tmp___0 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 4UL));
#line 247
  max_srq_wqes = (__u32 )(1 << (int )(tmp___0 >> 24));
#line 250
  if (init_attr->attr.max_wr >= max_srq_wqes) {
#line 251
    descriptor.modname = "mlx5_ib";
#line 251
    descriptor.function = "mlx5_ib_create_srq";
#line 251
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 251
    descriptor.format = "%s:%s:%d:(pid %d): max_wr %d, cap %d\n";
#line 251
    descriptor.lineno = 253U;
#line 251
    descriptor.flags = 0U;
#line 251
    tmp___2 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 251
    if (tmp___2 != 0L) {
#line 251
      tmp___1 = get_current();
#line 251
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): max_wr %d, cap %d\n", (char *)(& dev->ib_dev.name),
                         "mlx5_ib_create_srq", 253, tmp___1->pid, init_attr->attr.max_wr,
                         max_srq_wqes);
    } else {

    }
#line 254
    tmp___3 = ERR_PTR(-22L);
#line 254
    return ((struct ib_srq *)tmp___3);
  } else {

  }
#line 257
  tmp___4 = kmalloc(648UL, 208U);
#line 257
  srq = (struct mlx5_ib_srq *)tmp___4;
#line 258
  if ((unsigned long )srq == (unsigned long )((struct mlx5_ib_srq *)0)) {
#line 259
    tmp___5 = ERR_PTR(-12L);
#line 259
    return ((struct ib_srq *)tmp___5);
  } else {

  }
#line 261
  __mutex_init(& srq->mutex, "&srq->mutex", & __key);
#line 262
  spinlock_check(& srq->lock);
#line 262
  __raw_spin_lock_init(& srq->lock.__annonCompField18.rlock, "&(&srq->lock)->rlock",
                       & __key___0);
#line 263
  tmp___6 = __roundup_pow_of_two((unsigned long )(init_attr->attr.max_wr + 1U));
#line 263
  srq->msrq.max = (int )tmp___6;
#line 264
  srq->msrq.max_gs = (int )init_attr->attr.max_sge;
#line 266
  desc_size = (int )((unsigned int )((unsigned long )srq->msrq.max_gs + 1UL) * 16U);
#line 268
  tmp___7 = __roundup_pow_of_two((unsigned long )desc_size);
#line 268
  desc_size = (int )tmp___7;
#line 269
  __max1 = 32;
#line 269
  __max2 = desc_size;
#line 269
  desc_size = __max1 > __max2 ? __max1 : __max2;
#line 270
  srq->msrq.max_avail_gather = (int )(((unsigned long )desc_size - 16UL) / 16UL);
#line 272
  srq->msrq.wqe_shift = __ilog2_u32((u32 )desc_size);
#line 273
  buf_size = srq->msrq.max * desc_size;
#line 274
  descriptor___0.modname = "mlx5_ib";
#line 274
  descriptor___0.function = "mlx5_ib_create_srq";
#line 274
  descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 274
  descriptor___0.format = "%s:%s:%d:(pid %d): desc_size 0x%x, req wr 0x%x, srq size 0x%x, max_gs 0x%x, max_avail_gather 0x%x\n";
#line 274
  descriptor___0.lineno = 276U;
#line 274
  descriptor___0.flags = 0U;
#line 274
  tmp___9 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 274
  if (tmp___9 != 0L) {
#line 274
    tmp___8 = get_current();
#line 274
    __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): desc_size 0x%x, req wr 0x%x, srq size 0x%x, max_gs 0x%x, max_avail_gather 0x%x\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_create_srq", 276, tmp___8->pid,
                       desc_size, init_attr->attr.max_wr, srq->msrq.max, srq->msrq.max_gs,
                       srq->msrq.max_avail_gather);
  } else {

  }
#line 278
  if ((unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 279
    err = create_srq_user(pd, srq, & in, udata, buf_size, & inlen);
  } else {
#line 281
    err = create_srq_kernel(dev, srq, & in, buf_size, & inlen);
  }
#line 283
  if (err != 0) {
#line 284
    tmp___10 = get_current();
#line 284
    printk("\f%s:%s:%d:(pid %d): create srq %s failed, err %d\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_create_srq", 285, tmp___10->pid, (unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0) ? (char *)"user" : (char *)"kernel",
           err);
#line 286
    goto err_srq;
  } else {

  }
#line 289
  is_xrc = (unsigned int )init_attr->srq_type == 1U;
#line 290
  tmp___11 = __ilog2_u32((u32 )srq->msrq.max);
#line 290
  in->ctx.state_log_sz = (u8 )tmp___11;
#line 291
  flgs = (u32 )((((srq->msrq.wqe_shift + -4) | (is_xrc << 5)) | (srq->wq_sig << 7)) << 24);
#line 292
  xrcdn = 0U;
#line 293
  if (is_xrc != 0) {
#line 294
    tmp___12 = to_mxrcd(init_attr->ext.xrc.xrcd);
#line 294
    xrcdn = tmp___12->xrcdn;
#line 295
    tmp___13 = to_mcq(init_attr->ext.xrc.cq);
#line 295
    tmp___14 = __fswab32(tmp___13->mcq.cqn);
#line 295
    in->ctx.pgoff_cqn = in->ctx.pgoff_cqn | tmp___14;
  } else
#line 296
  if ((unsigned int )init_attr->srq_type == 0U) {
#line 297
    tmp___15 = to_mxrcd(dev->devr.x0);
#line 297
    xrcdn = tmp___15->xrcdn;
#line 298
    tmp___16 = to_mcq(dev->devr.c0);
#line 298
    tmp___17 = __fswab32(tmp___16->mcq.cqn);
#line 298
    in->ctx.pgoff_cqn = in->ctx.pgoff_cqn | tmp___17;
  } else {

  }
#line 301
  tmp___18 = __fswab32((flgs & 4278190080U) | (xrcdn & 16777215U));
#line 301
  in->ctx.flags_xrcd = tmp___18;
#line 303
  tmp___19 = to_mpd(pd);
#line 303
  tmp___20 = __fswab32(tmp___19->pdn);
#line 303
  in->ctx.pd = tmp___20;
#line 304
  tmp___21 = __fswab64(srq->db.dma);
#line 304
  in->ctx.db_record = tmp___21;
#line 305
  err = mlx5_core_create_srq(dev->mdev, & srq->msrq, in, inlen, is_xrc);
#line 306
  kvfree((void const   *)in);
#line 307
  if (err != 0) {
#line 308
    descriptor___1.modname = "mlx5_ib";
#line 308
    descriptor___1.function = "mlx5_ib_create_srq";
#line 308
    descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 308
    descriptor___1.format = "%s:%s:%d:(pid %d): create SRQ failed, err %d\n";
#line 308
    descriptor___1.lineno = 308U;
#line 308
    descriptor___1.flags = 0U;
#line 308
    tmp___23 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 308
    if (tmp___23 != 0L) {
#line 308
      tmp___22 = get_current();
#line 308
      __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): create SRQ failed, err %d\n",
                         (char *)(& dev->ib_dev.name), "mlx5_ib_create_srq", 308,
                         tmp___22->pid, err);
    } else {

    }
#line 309
    goto err_usr_kern_srq;
  } else {

  }
#line 312
  descriptor___2.modname = "mlx5_ib";
#line 312
  descriptor___2.function = "mlx5_ib_create_srq";
#line 312
  descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 312
  descriptor___2.format = "%s:%s:%d:(pid %d): create SRQ with srqn 0x%x\n";
#line 312
  descriptor___2.lineno = 312U;
#line 312
  descriptor___2.flags = 0U;
#line 312
  tmp___25 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 312
  if (tmp___25 != 0L) {
#line 312
    tmp___24 = get_current();
#line 312
    __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): create SRQ with srqn 0x%x\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_create_srq", 312, tmp___24->pid,
                       srq->msrq.srqn);
  } else {

  }
#line 314
  srq->msrq.event = & mlx5_ib_srq_event;
#line 315
  srq->ibsrq.ext.xrc.srq_num = srq->msrq.srqn;
#line 317
  if ((unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 318
    tmp___28 = ib_copy_to_udata(udata, (void *)(& srq->msrq.srqn), 4UL);
#line 318
    if (tmp___28 != 0) {
#line 319
      descriptor___3.modname = "mlx5_ib";
#line 319
      descriptor___3.function = "mlx5_ib_create_srq";
#line 319
      descriptor___3.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c";
#line 319
      descriptor___3.format = "%s:%s:%d:(pid %d): copy to user failed\n";
#line 319
      descriptor___3.lineno = 319U;
#line 319
      descriptor___3.flags = 0U;
#line 319
      tmp___27 = ldv__builtin_expect((long )descriptor___3.flags & 1L, 0L);
#line 319
      if (tmp___27 != 0L) {
#line 319
        tmp___26 = get_current();
#line 319
        __dynamic_pr_debug(& descriptor___3, "%s:%s:%d:(pid %d): copy to user failed\n",
                           (char *)(& dev->ib_dev.name), "mlx5_ib_create_srq", 319,
                           tmp___26->pid);
      } else {

      }
#line 320
      err = -14;
#line 321
      goto err_core;
    } else {

    }
  } else {

  }
#line 324
  init_attr->attr.max_wr = (u32 )(srq->msrq.max + -1);
#line 326
  return (& srq->ibsrq);
  err_core: 
#line 329
  mlx5_core_destroy_srq(dev->mdev, & srq->msrq);
  err_usr_kern_srq: ;
#line 332
  if ((unsigned long )pd->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 333
    destroy_srq_user(pd, srq);
  } else {
#line 335
    destroy_srq_kernel(dev, srq);
  }
  err_srq: 
#line 338
  kfree((void const   *)srq);
#line 340
  tmp___29 = ERR_PTR((long )err);
#line 340
  return ((struct ib_srq *)tmp___29);
}
}
#line 343 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
int mlx5_ib_modify_srq(struct ib_srq *ibsrq , struct ib_srq_attr *attr , enum ib_srq_attr_mask attr_mask ,
                       struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_srq *srq ;
  struct mlx5_ib_srq *tmp___0 ;
  int ret ;

  {
#line 346
  tmp = to_mdev(ibsrq->device);
#line 346
  dev = tmp;
#line 347
  tmp___0 = to_msrq(ibsrq);
#line 347
  srq = tmp___0;
#line 351
  if ((int )attr_mask & 1) {
#line 352
    return (-22);
  } else {

  }
#line 354
  if (((unsigned int )attr_mask & 2U) != 0U) {
#line 355
    if (attr->srq_limit >= (u32 )srq->msrq.max) {
#line 356
      return (-22);
    } else {

    }
#line 358
    mutex_lock_nested(& srq->mutex, 0U);
#line 359
    ret = mlx5_core_arm_srq(dev->mdev, & srq->msrq, (int )((u16 )attr->srq_limit),
                            1);
#line 360
    mutex_unlock(& srq->mutex);
#line 362
    if (ret != 0) {
#line 363
      return (ret);
    } else {

    }
  } else {

  }
#line 366
  return (0);
}
}
#line 369 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
int mlx5_ib_query_srq(struct ib_srq *ibsrq , struct ib_srq_attr *srq_attr ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_srq *srq ;
  struct mlx5_ib_srq *tmp___0 ;
  int ret ;
  struct mlx5_query_srq_mbox_out *out ;
  void *tmp___1 ;
  __u16 tmp___2 ;

  {
#line 371
  tmp = to_mdev(ibsrq->device);
#line 371
  dev = tmp;
#line 372
  tmp___0 = to_msrq(ibsrq);
#line 372
  srq = tmp___0;
#line 376
  tmp___1 = kzalloc(96UL, 208U);
#line 376
  out = (struct mlx5_query_srq_mbox_out *)tmp___1;
#line 377
  if ((unsigned long )out == (unsigned long )((struct mlx5_query_srq_mbox_out *)0)) {
#line 378
    return (-12);
  } else {

  }
#line 380
  ret = mlx5_core_query_srq(dev->mdev, & srq->msrq, out);
#line 381
  if (ret != 0) {
#line 382
    goto out_box;
  } else {

  }
#line 384
  tmp___2 = __fswab16((int )out->ctx.lwm);
#line 384
  srq_attr->srq_limit = (u32 )tmp___2;
#line 385
  srq_attr->max_wr = (u32 )(srq->msrq.max + -1);
#line 386
  srq_attr->max_sge = (u32 )srq->msrq.max_gs;
  out_box: 
#line 389
  kfree((void const   *)out);
#line 390
  return (ret);
}
}
#line 393 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
int mlx5_ib_destroy_srq(struct ib_srq *srq ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_srq *msrq ;
  struct mlx5_ib_srq *tmp___0 ;
  struct mlx5_ib_ucontext *tmp___1 ;

  {
#line 395
  tmp = to_mdev(srq->device);
#line 395
  dev = tmp;
#line 396
  tmp___0 = to_msrq(srq);
#line 396
  msrq = tmp___0;
#line 398
  mlx5_core_destroy_srq(dev->mdev, & msrq->msrq);
#line 400
  if ((unsigned long )srq->uobject != (unsigned long )((struct ib_uobject *)0)) {
#line 401
    tmp___1 = to_mucontext((srq->uobject)->context);
#line 401
    mlx5_ib_db_unmap_user(tmp___1, & msrq->db);
#line 402
    ib_umem_release(msrq->umem);
  } else {
#line 404
    destroy_srq_kernel(dev, msrq);
  }
#line 407
  kfree((void const   *)srq);
#line 408
  return (0);
}
}
#line 411 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
void mlx5_ib_free_srq_wqe(struct mlx5_ib_srq *srq , int wqe_index ) 
{ 
  struct mlx5_wqe_srq_next_seg *next ;
  void *tmp ;
  __u16 tmp___0 ;

  {
#line 416
  spin_lock(& srq->lock);
#line 418
  tmp = get_wqe___0(srq, srq->tail);
#line 418
  next = (struct mlx5_wqe_srq_next_seg *)tmp;
#line 419
  tmp___0 = __fswab16((int )((__u16 )wqe_index));
#line 419
  next->next_wqe_index = tmp___0;
#line 420
  srq->tail = wqe_index;
#line 422
  spin_unlock(& srq->lock);
#line 423
  return;
}
}
#line 425 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.c"
int mlx5_ib_post_srq_recv(struct ib_srq *ibsrq , struct ib_recv_wr *wr , struct ib_recv_wr **bad_wr ) 
{ 
  struct mlx5_ib_srq *srq ;
  struct mlx5_ib_srq *tmp ;
  struct mlx5_wqe_srq_next_seg *next ;
  struct mlx5_wqe_data_seg *scat ;
  unsigned long flags ;
  int err ;
  int nreq ;
  int i ;
  raw_spinlock_t *tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;
  void *tmp___3 ;
  __u16 tmp___4 ;
  __u32 tmp___5 ;
  __u32 tmp___6 ;
  __u64 tmp___7 ;
  __u32 tmp___8 ;
  long tmp___9 ;

  {
#line 428
  tmp = to_msrq(ibsrq);
#line 428
  srq = tmp;
#line 432
  err = 0;
#line 436
  tmp___0 = spinlock_check(& srq->lock);
#line 436
  flags = _raw_spin_lock_irqsave(tmp___0);
#line 438
  nreq = 0;
#line 438
  goto ldv_37778;
  ldv_37777: 
#line 439
  tmp___1 = ldv__builtin_expect(wr->num_sge > srq->msrq.max_gs, 0L);
#line 439
  if (tmp___1 != 0L) {
#line 440
    err = -22;
#line 441
    *bad_wr = wr;
#line 442
    goto ldv_37773;
  } else {

  }
#line 445
  tmp___2 = ldv__builtin_expect(srq->head == srq->tail, 0L);
#line 445
  if (tmp___2 != 0L) {
#line 446
    err = -12;
#line 447
    *bad_wr = wr;
#line 448
    goto ldv_37773;
  } else {

  }
#line 451
  *(srq->wrid + (unsigned long )srq->head) = wr->wr_id;
#line 453
  tmp___3 = get_wqe___0(srq, srq->head);
#line 453
  next = (struct mlx5_wqe_srq_next_seg *)tmp___3;
#line 454
  tmp___4 = __fswab16((int )next->next_wqe_index);
#line 454
  srq->head = (int )tmp___4;
#line 455
  scat = (struct mlx5_wqe_data_seg *)next + 1U;
#line 457
  i = 0;
#line 457
  goto ldv_37775;
  ldv_37774: 
#line 458
  tmp___5 = __fswab32((wr->sg_list + (unsigned long )i)->length);
#line 458
  (scat + (unsigned long )i)->byte_count = tmp___5;
#line 459
  tmp___6 = __fswab32((wr->sg_list + (unsigned long )i)->lkey);
#line 459
  (scat + (unsigned long )i)->lkey = tmp___6;
#line 460
  tmp___7 = __fswab64((wr->sg_list + (unsigned long )i)->addr);
#line 460
  (scat + (unsigned long )i)->addr = tmp___7;
#line 457
  i = i + 1;
  ldv_37775: ;
#line 457
  if (wr->num_sge > i) {
#line 459
    goto ldv_37774;
  } else {

  }

#line 463
  if (srq->msrq.max_avail_gather > i) {
#line 464
    (scat + (unsigned long )i)->byte_count = 0U;
#line 465
    (scat + (unsigned long )i)->lkey = 65536U;
#line 466
    (scat + (unsigned long )i)->addr = 0ULL;
  } else {

  }
#line 438
  nreq = nreq + 1;
#line 438
  wr = wr->next;
  ldv_37778: ;
#line 438
  if ((unsigned long )wr != (unsigned long )((struct ib_recv_wr *)0)) {
#line 440
    goto ldv_37777;
  } else {

  }
  ldv_37773: 
#line 470
  tmp___9 = ldv__builtin_expect(nreq != 0, 1L);
#line 470
  if (tmp___9 != 0L) {
#line 471
    srq->wqe_ctr = (int )srq->wqe_ctr + (int )((u16 )nreq);
#line 476
    __asm__  volatile   ("sfence": : : "memory");
#line 478
    tmp___8 = __fswab32((__u32 )srq->wqe_ctr);
#line 478
    *(srq->db.db) = tmp___8;
  } else {

  }
#line 481
  spin_unlock_irqrestore(& srq->lock, flags);
#line 483
  return (err);
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.o.c.prepared"
bool ldv_queue_work_on_77(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.o.c.prepared"
bool ldv_queue_delayed_work_on_78(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.o.c.prepared"
bool ldv_queue_work_on_79(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.o.c.prepared"
void ldv_flush_workqueue_80(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/srq.o.c.prepared"
bool ldv_queue_delayed_work_on_81(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 405 "include/linux/kernel.h"
extern int snprintf(char * , size_t  , char const   *  , ...) ;
#line 417
extern int sscanf(char const   * , char const   *  , ...) ;
#line 75 "include/linux/list.h"
__inline static void list_add_tail(struct list_head *new , struct list_head *head ) 
{ 


  {
#line 77
  __list_add(new, head->prev, head);
#line 78
  return;
}
}
#line 187 "include/linux/list.h"
__inline static int list_empty(struct list_head  const  *head ) 
{ 


  {
#line 189
  return ((unsigned long )((struct list_head  const  *)head->next) == (unsigned long )head);
}
}
#line 23 "./arch/x86/include/asm/page_64.h"
extern unsigned long __phys_addr(unsigned long  ) ;
#line 23 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) ;
#line 32
__inline static long PTR_ERR(void const   *ptr ) ;
#line 41
__inline static bool IS_ERR(void const   *ptr ) ;
#line 49 "./arch/x86/include/asm/atomic.h"
__inline static void atomic_add(int i , atomic_t *v ) 
{ 


  {
#line 51
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; addl %1,%0": "+m" (v->counter): "ir" (i));
#line 53
  return;
}
}
#line 63 "./arch/x86/include/asm/atomic.h"
__inline static void atomic_sub(int i , atomic_t *v ) 
{ 


  {
#line 65
  __asm__  volatile   (".pushsection .smp_locks,\"a\"\n.balign 4\n.long 671f - .\n.popsection\n671:\n\tlock; subl %1,%0": "+m" (v->counter): "ir" (i));
#line 67
  return;
}
}
#line 26 "include/linux/rwlock_api_smp.h"
extern unsigned long _raw_write_lock_irqsave(rwlock_t * ) ;
#line 40
extern void _raw_write_unlock_irqrestore(rwlock_t * , unsigned long  ) ;
#line 72 "include/linux/wait.h"
extern void __init_waitqueue_head(wait_queue_head_t * , char const   * , struct lock_class_key * ) ;
#line 73 "include/linux/completion.h"
__inline static void init_completion(struct completion *x ) 
{ 
  struct lock_class_key __key ;

  {
#line 75
  x->done = 0U;
#line 76
  __init_waitqueue_head(& x->wait, "&x->wait", & __key);
#line 78
  return;
}
}
#line 91
extern void wait_for_completion(struct completion * ) ;
#line 78 "include/linux/jiffies.h"
extern unsigned long volatile   jiffies ;
#line 292
extern unsigned long __msecs_to_jiffies(unsigned int const    ) ;
#line 354 "include/linux/jiffies.h"
__inline static unsigned long msecs_to_jiffies(unsigned int const   m ) 
{ 
  unsigned long tmp___0 ;

  {
#line 361
  tmp___0 = __msecs_to_jiffies(m);
#line 361
  return (tmp___0);
}
}
#line 88 "include/linux/timer.h"
extern void init_timer_key(struct timer_list * , unsigned int  , char const   * ,
                           struct lock_class_key * ) ;
#line 170
extern int mod_timer(struct timer_list * , unsigned long  ) ;
#line 173
int ldv_mod_timer_96(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
#line 177
int ldv_mod_timer_97(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) ;
#line 229
extern int del_timer_sync(struct timer_list * ) ;
#line 232
int ldv_del_timer_sync_101(struct timer_list *ldv_func_arg1 ) ;
#line 20 "include/linux/workqueue.h"
extern void delayed_work_timer_fn(unsigned long  ) ;
#line 181
extern void __init_work(struct work_struct * , int  ) ;
#line 361
extern struct workqueue_struct *__alloc_workqueue_key(char const   * , unsigned int  ,
                                                      int  , struct lock_class_key * ,
                                                      char const   *  , ...) ;
#line 421
extern void destroy_workqueue(struct workqueue_struct * ) ;
#line 424
void ldv_destroy_workqueue_100(struct workqueue_struct *ldv_func_arg1 ) ;
#line 437
bool ldv_queue_work_on_91(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 441
bool ldv_queue_work_on_93(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) ;
#line 447
bool ldv_queue_delayed_work_on_92(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 451
bool ldv_queue_delayed_work_on_95(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 459
void ldv_flush_workqueue_94(struct workqueue_struct *ldv_func_arg1 ) ;
#line 463
void ldv_flush_workqueue_99(struct workqueue_struct *ldv_func_arg1 ) ;
#line 475
extern bool cancel_delayed_work(struct delayed_work * ) ;
#line 478
bool ldv_cancel_delayed_work_98(struct delayed_work *ldv_func_arg1 ) ;
#line 469 "include/linux/workqueue.h"
__inline static bool queue_work(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
#line 472
  tmp = ldv_queue_work_on_91(8192, wq, work);
#line 472
  return (tmp);
}
}
#line 483 "include/linux/workqueue.h"
__inline static bool queue_delayed_work(struct workqueue_struct *wq , struct delayed_work *dwork ,
                                        unsigned long delay ) 
{ 
  bool tmp ;

  {
#line 487
  tmp = ldv_queue_delayed_work_on_92(8192, wq, dwork, delay);
#line 487
  return (tmp);
}
}
#line 134 "include/linux/srcu.h"
extern void synchronize_srcu(struct srcu_struct * ) ;
#line 353 "include/linux/gfp.h"
extern unsigned long get_zeroed_page(gfp_t  ) ;
#line 367
extern void free_pages(unsigned long  , unsigned int  ) ;
#line 76 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void call_and_disable_work_1(struct work_struct *work ) ;
#line 78
void activate_pending_timer_4(struct timer_list *timer , unsigned long data , int pending_flag ) ;
#line 79
void call_and_disable_all_2(int state ) ;
#line 80
void call_and_disable_all_1(int state ) ;
#line 81
void activate_work_2(struct work_struct *work , int state ) ;
#line 84
void activate_work_1(struct work_struct *work , int state ) ;
#line 85
void choose_timer_4(void) ;
#line 87
void disable_suitable_timer_4(struct timer_list *timer ) ;
#line 88
void disable_work_3(struct work_struct *work ) ;
#line 89
void disable_work_2(struct work_struct *work ) ;
#line 90
void disable_work_1(struct work_struct *work ) ;
#line 91
int reg_timer_4(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) ;
#line 94
void invoke_work_1(void) ;
#line 98
void ldv_timer_4(int state , struct timer_list *timer ) ;
#line 99
void activate_suitable_timer_4(struct timer_list *timer , unsigned long data ) ;
#line 100
void call_and_disable_work_2(struct work_struct *work ) ;
#line 101
void invoke_work_2(void) ;
#line 265 "include/linux/radix-tree.h"
extern int radix_tree_insert(struct radix_tree_root * , unsigned long  , void * ) ;
#line 39 "include/linux/semaphore.h"
extern void down(struct semaphore * ) ;
#line 44
extern void up(struct semaphore * ) ;
#line 2801 "include/linux/fs.h"
extern int simple_open(struct inode * , struct file * ) ;
#line 49 "include/linux/debugfs.h"
extern struct dentry *debugfs_create_file(char const   * , umode_t  , struct dentry * ,
                                          void * , struct file_operations  const  * ) ;
#line 58
extern struct dentry *debugfs_create_dir(char const   * , struct dentry * ) ;
#line 69
extern void debugfs_remove_recursive(struct dentry * ) ;
#line 78
extern struct dentry *debugfs_create_u32(char const   * , umode_t  , struct dentry * ,
                                         u32 * ) ;
#line 48 "include/linux/delay.h"
extern void usleep_range(unsigned long  , unsigned long  ) ;
#line 61 "include/rdma/ib_umem.h"
__inline static int ib_umem_offset(struct ib_umem *umem ) 
{ 


  {
#line 63
  return ((int )((unsigned int )umem->address & ((unsigned int )umem->page_size - 1U)));
}
}
#line 67 "include/rdma/ib_umem.h"
__inline static unsigned long ib_umem_start(struct ib_umem *umem ) 
{ 
  int tmp ;

  {
#line 69
  tmp = ib_umem_offset(umem);
#line 69
  return (umem->address - (unsigned long )tmp);
}
}
#line 73 "include/rdma/ib_umem.h"
__inline static unsigned long ib_umem_end(struct ib_umem *umem ) 
{ 


  {
#line 75
  return (((umem->address + umem->length) + 4095UL) & 0xfffffffffffff000UL);
}
}
#line 78 "include/rdma/ib_umem.h"
__inline static size_t ib_umem_num_pages(struct ib_umem *umem ) 
{ 
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
#line 80
  tmp = ib_umem_end(umem);
#line 80
  tmp___0 = ib_umem_start(umem);
#line 80
  return ((tmp - tmp___0) >> 12);
}
}
#line 73 "include/linux/dma-mapping.h"
__inline static int valid_dma_direction(int dma_direction ) 
{ 


  {
#line 75
  return ((dma_direction == 0 || dma_direction == 1) || dma_direction == 2);
}
}
#line 131 "include/linux/kmemcheck.h"
__inline static void kmemcheck_mark_initialized(void *address , unsigned int n ) 
{ 


  {
#line 133
  return;
}
}
#line 37 "include/linux/dma-debug.h"
extern void debug_dma_map_page(struct device * , struct page * , size_t  , size_t  ,
                               int  , dma_addr_t  , bool  ) ;
#line 42
extern void debug_dma_mapping_error(struct device * , dma_addr_t  ) ;
#line 44
extern void debug_dma_unmap_page(struct device * , dma_addr_t  , size_t  , int  ,
                                 bool  ) ;
#line 59
extern void debug_dma_sync_single_for_cpu(struct device * , dma_addr_t  , size_t  ,
                                          int  ) ;
#line 63
extern void debug_dma_sync_single_for_device(struct device * , dma_addr_t  , size_t  ,
                                             int  ) ;
#line 30 "./arch/x86/include/asm/dma-mapping.h"
extern struct dma_map_ops *dma_ops ;
#line 32 "./arch/x86/include/asm/dma-mapping.h"
__inline static struct dma_map_ops *get_dma_ops(struct device *dev ) 
{ 
  long tmp ;

  {
#line 37
  tmp = ldv__builtin_expect((unsigned long )dev == (unsigned long )((struct device *)0),
                         0L);
#line 37
  if (tmp != 0L || (unsigned long )dev->archdata.dma_ops == (unsigned long )((struct dma_map_ops *)0)) {
#line 38
    return (dma_ops);
  } else {
#line 40
    return (dev->archdata.dma_ops);
  }
}
}
#line 10 "include/asm-generic/dma-mapping-common.h"
__inline static dma_addr_t dma_map_single_attrs(struct device *dev , void *ptr , size_t size ,
                                                enum dma_data_direction dir , struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  dma_addr_t addr ;
  int tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;

  {
#line 15
  tmp = get_dma_ops(dev);
#line 15
  ops = tmp;
#line 18
  kmemcheck_mark_initialized(ptr, (unsigned int )size);
#line 19
  tmp___0 = valid_dma_direction((int )dir);
#line 19
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
#line 19
  if (tmp___1 != 0L) {
#line 19
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (19), "i" (12UL));
    ldv_28900: ;
#line 19
    goto ldv_28900;
  } else {

  }
#line 20
  tmp___2 = __phys_addr((unsigned long )ptr);
#line 20
  addr = (*(ops->map_page))(dev, (struct page *)-24189255811072L + (tmp___2 >> 12),
                            (unsigned long )ptr & 4095UL, size, dir, attrs);
#line 23
  tmp___3 = __phys_addr((unsigned long )ptr);
#line 23
  debug_dma_map_page(dev, (struct page *)-24189255811072L + (tmp___3 >> 12), (unsigned long )ptr & 4095UL,
                     size, (int )dir, addr, 1);
#line 26
  return (addr);
}
}
#line 29 "include/asm-generic/dma-mapping-common.h"
__inline static void dma_unmap_single_attrs(struct device *dev , dma_addr_t addr ,
                                            size_t size , enum dma_data_direction dir ,
                                            struct dma_attrs *attrs ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
#line 34
  tmp = get_dma_ops(dev);
#line 34
  ops = tmp;
#line 36
  tmp___0 = valid_dma_direction((int )dir);
#line 36
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
#line 36
  if (tmp___1 != 0L) {
#line 36
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (36), "i" (12UL));
    ldv_28909: ;
#line 36
    goto ldv_28909;
  } else {

  }
#line 37
  if ((unsigned long )ops->unmap_page != (unsigned long )((void (*)(struct device * ,
                                                                    dma_addr_t  ,
                                                                    size_t  , enum dma_data_direction  ,
                                                                    struct dma_attrs * ))0)) {
#line 38
    (*(ops->unmap_page))(dev, addr, size, dir, attrs);
  } else {

  }
#line 39
  debug_dma_unmap_page(dev, addr, size, (int )dir, 1);
#line 40
  return;
}
}
#line 102 "include/asm-generic/dma-mapping-common.h"
__inline static void dma_sync_single_for_cpu(struct device *dev , dma_addr_t addr ,
                                             size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
#line 106
  tmp = get_dma_ops(dev);
#line 106
  ops = tmp;
#line 108
  tmp___0 = valid_dma_direction((int )dir);
#line 108
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
#line 108
  if (tmp___1 != 0L) {
#line 108
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (108), "i" (12UL));
    ldv_28960: ;
#line 108
    goto ldv_28960;
  } else {

  }
#line 109
  if ((unsigned long )ops->sync_single_for_cpu != (unsigned long )((void (*)(struct device * ,
                                                                             dma_addr_t  ,
                                                                             size_t  ,
                                                                             enum dma_data_direction  ))0)) {
#line 110
    (*(ops->sync_single_for_cpu))(dev, addr, size, dir);
  } else {

  }
#line 111
  debug_dma_sync_single_for_cpu(dev, addr, size, (int )dir);
#line 112
  return;
}
}
#line 114 "include/asm-generic/dma-mapping-common.h"
__inline static void dma_sync_single_for_device(struct device *dev , dma_addr_t addr ,
                                                size_t size , enum dma_data_direction dir ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;
  long tmp___1 ;

  {
#line 118
  tmp = get_dma_ops(dev);
#line 118
  ops = tmp;
#line 120
  tmp___0 = valid_dma_direction((int )dir);
#line 120
  tmp___1 = ldv__builtin_expect(tmp___0 == 0, 0L);
#line 120
  if (tmp___1 != 0L) {
#line 120
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"include/asm-generic/dma-mapping-common.h"),
                         "i" (120), "i" (12UL));
    ldv_28968: ;
#line 120
    goto ldv_28968;
  } else {

  }
#line 121
  if ((unsigned long )ops->sync_single_for_device != (unsigned long )((void (*)(struct device * ,
                                                                                dma_addr_t  ,
                                                                                size_t  ,
                                                                                enum dma_data_direction  ))0)) {
#line 122
    (*(ops->sync_single_for_device))(dev, addr, size, dir);
  } else {

  }
#line 123
  debug_dma_sync_single_for_device(dev, addr, size, (int )dir);
#line 124
  return;
}
}
#line 47 "./arch/x86/include/asm/dma-mapping.h"
__inline static int dma_mapping_error(struct device *dev , dma_addr_t dma_addr ) 
{ 
  struct dma_map_ops *ops ;
  struct dma_map_ops *tmp ;
  int tmp___0 ;

  {
#line 49
  tmp = get_dma_ops(dev);
#line 49
  ops = tmp;
#line 50
  debug_dma_mapping_error(dev, dma_addr);
#line 51
  if ((unsigned long )ops->mapping_error != (unsigned long )((int (*)(struct device * ,
                                                                      dma_addr_t  ))0)) {
#line 52
    tmp___0 = (*(ops->mapping_error))(dev, dma_addr);
#line 52
    return (tmp___0);
  } else {

  }
#line 54
  return (dma_addr == 0ULL);
}
}
#line 131
extern void *dma_alloc_attrs(struct device * , size_t  , dma_addr_t * , gfp_t  , struct dma_attrs * ) ;
#line 136
extern void dma_free_attrs(struct device * , size_t  , void * , dma_addr_t  , struct dma_attrs * ) ;
#line 2342 "include/rdma/ib_verbs.h"
__inline static int ib_post_send(struct ib_qp *qp , struct ib_send_wr *send_wr , struct ib_send_wr **bad_send_wr ) 
{ 
  int tmp ;

  {
#line 2346
  tmp = (*((qp->device)->post_send))(qp, send_wr, bad_send_wr);
#line 2346
  return (tmp);
}
}
#line 2419 "include/rdma/ib_verbs.h"
__inline static int ib_poll_cq(struct ib_cq *cq , int num_entries , struct ib_wc *wc ) 
{ 
  int tmp ;

  {
#line 2422
  tmp = (*((cq->device)->poll_cq))(cq, num_entries, wc);
#line 2422
  return (tmp);
}
}
#line 615 "include/linux/mlx5/driver.h"
extern struct dentry *mlx5_debugfs_root ;
#line 781
extern int mlx5_core_create_psv(struct mlx5_core_dev * , u32  , int  , u32 * ) ;
#line 783
extern int mlx5_core_destroy_psv(struct mlx5_core_dev * , int  ) ;
#line 793 "include/linux/mlx5/driver.h"
__inline static u32 mlx5_idx_to_mkey(u32 mkey_idx ) 
{ 


  {
#line 795
  return (mkey_idx << 8);
}
}
#line 342 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static void mlx5_ib_init_umr_context(struct mlx5_ib_umr_context *context ) 
{ 


  {
#line 344
  context->status = 4294967295L;
#line 345
  init_completion(& context->done);
#line 346
  return;
}
}
#line 573
int mlx5_ib_update_mtt(struct mlx5_ib_mr *mr , u64 start_page_index , int npages ,
                       int zap ) ;
#line 50 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static __be64 mlx5_ib_update_mtt_emergency_buffer[8U]  ;
#line 53 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static struct mutex mlx5_ib_update_mtt_emergency_buffer_mutex  =    {{1}, {{{{{0}}, 3735899821U, 4294967295U, (void *)-1, {0, {0, 0}, "mlx5_ib_update_mtt_emergency_buffer_mutex.wait_lock",
                                                          0, 0UL}}}}, {& mlx5_ib_update_mtt_emergency_buffer_mutex.wait_list,
                                                                       & mlx5_ib_update_mtt_emergency_buffer_mutex.wait_list},
    0, (void *)(& mlx5_ib_update_mtt_emergency_buffer_mutex), {0, {0, 0}, "mlx5_ib_update_mtt_emergency_buffer_mutex",
                                                               0, 0UL}};
#line 56
static int clean_mr(struct mlx5_ib_mr *mr ) ;
#line 58 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int destroy_mkey(struct mlx5_ib_dev *dev , struct mlx5_ib_mr *mr ) 
{ 
  int err ;
  int tmp ;

  {
#line 60
  tmp = mlx5_core_destroy_mkey(dev->mdev, & mr->mmr);
#line 60
  err = tmp;
#line 64
  synchronize_srcu(& dev->mr_srcu);
#line 67
  return (err);
}
}
#line 70 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int order2idx(struct mlx5_ib_dev *dev , int order ) 
{ 
  struct mlx5_mr_cache *cache ;

  {
#line 72
  cache = & dev->cache;
#line 74
  if ((u32 )order < cache->ent[0].order) {
#line 75
    return (0);
  } else {
#line 77
    return ((int )((u32 )order - cache->ent[0].order));
  }
}
}
#line 80 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void reg_mr_callback(int status , void *context ) 
{ 
  struct mlx5_ib_mr *mr ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_mr_cache *cache ;
  int c ;
  int tmp ;
  struct mlx5_cache_ent *ent ;
  u8 key ;
  unsigned long flags ;
  struct mlx5_mr_table *table ;
  int err ;
  raw_spinlock_t *tmp___0 ;
  struct task_struct *tmp___1 ;
  __u32 tmp___2 ;
  struct task_struct *tmp___3 ;
  raw_spinlock_t *tmp___4 ;
  u8 tmp___5 ;
  __u32 tmp___6 ;
  u32 tmp___7 ;
  raw_spinlock_t *tmp___8 ;
  u32 tmp___9 ;

  {
#line 82
  mr = (struct mlx5_ib_mr *)context;
#line 83
  dev = mr->dev;
#line 84
  cache = & dev->cache;
#line 85
  tmp = order2idx(dev, mr->order);
#line 85
  c = tmp;
#line 86
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )c;
#line 89
  table = & (dev->mdev)->priv.mr_table;
#line 92
  tmp___0 = spinlock_check(& ent->lock);
#line 92
  flags = _raw_spin_lock_irqsave(tmp___0);
#line 93
  ent->pending = ent->pending - 1;
#line 94
  spin_unlock_irqrestore(& ent->lock, flags);
#line 95
  if (status != 0) {
#line 96
    tmp___1 = get_current();
#line 96
    printk("\f%s:%s:%d:(pid %d): async reg mr failed. status %d\n", (char *)(& dev->ib_dev.name),
           "reg_mr_callback", 96, tmp___1->pid, status);
#line 97
    kfree((void const   *)mr);
#line 98
    dev->fill_delay = 1;
#line 99
    ldv_mod_timer_96(& dev->delay_timer, (unsigned long )jiffies + 250UL);
#line 100
    return;
  } else {

  }
#line 103
  if ((unsigned int )mr->out.hdr.status != 0U) {
#line 104
    tmp___2 = __fswab32(mr->out.hdr.syndrome);
#line 104
    tmp___3 = get_current();
#line 104
    printk("\f%s:%s:%d:(pid %d): failed - status %d, syndorme 0x%x\n", (char *)(& dev->ib_dev.name),
           "reg_mr_callback", 106, tmp___3->pid, (int )mr->out.hdr.status, tmp___2);
#line 107
    kfree((void const   *)mr);
#line 108
    dev->fill_delay = 1;
#line 109
    ldv_mod_timer_97(& dev->delay_timer, (unsigned long )jiffies + 250UL);
#line 110
    return;
  } else {

  }
#line 113
  tmp___4 = spinlock_check(& (dev->mdev)->priv.mkey_lock);
#line 113
  flags = _raw_spin_lock_irqsave(tmp___4);
#line 114
  tmp___5 = (dev->mdev)->priv.mkey_key;
#line 114
  (dev->mdev)->priv.mkey_key = (u8 )((int )(dev->mdev)->priv.mkey_key + 1);
#line 114
  key = tmp___5;
#line 115
  spin_unlock_irqrestore(& (dev->mdev)->priv.mkey_lock, flags);
#line 116
  tmp___6 = __fswab32(mr->out.mkey);
#line 116
  tmp___7 = mlx5_idx_to_mkey(tmp___6 & 16777215U);
#line 116
  mr->mmr.key = tmp___7 | (u32 )key;
#line 118
  cache->last_add = jiffies;
#line 120
  tmp___8 = spinlock_check(& ent->lock);
#line 120
  flags = _raw_spin_lock_irqsave(tmp___8);
#line 121
  list_add_tail(& mr->list, & ent->head);
#line 122
  ent->cur = ent->cur + 1U;
#line 123
  ent->size = ent->size + 1U;
#line 124
  spin_unlock_irqrestore(& ent->lock, flags);
#line 126
  flags = _raw_write_lock_irqsave(& table->lock);
#line 127
  tmp___9 = mlx5_base_mkey(mr->mmr.key);
#line 127
  err = radix_tree_insert(& table->tree, (unsigned long )tmp___9, (void *)(& mr->mmr));
#line 129
  if (err != 0) {
#line 130
    printk("\vError inserting to mr tree. 0x%x\n", - err);
  } else {

  }
#line 131
  _raw_write_unlock_irqrestore(& table->lock, flags);
#line 132
  return;
}
}
#line 134 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int add_keys(struct mlx5_ib_dev *dev , int c , int num ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_cache_ent *ent ;
  struct mlx5_create_mkey_mbox_in *in ;
  struct mlx5_ib_mr *mr ;
  int npages ;
  int err ;
  int i ;
  void *tmp ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  struct task_struct *tmp___2 ;

  {
#line 136
  cache = & dev->cache;
#line 137
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )c;
#line 140
  npages = 1 << (int )ent->order;
#line 141
  err = 0;
#line 144
  tmp = kzalloc(272UL, 208U);
#line 144
  in = (struct mlx5_create_mkey_mbox_in *)tmp;
#line 145
  if ((unsigned long )in == (unsigned long )((struct mlx5_create_mkey_mbox_in *)0)) {
#line 146
    return (-12);
  } else {

  }
#line 148
  i = 0;
#line 148
  goto ldv_40949;
  ldv_40948: ;
#line 149
  if (ent->pending > 7) {
#line 150
    err = -11;
#line 151
    goto ldv_40946;
  } else {

  }
#line 154
  tmp___0 = kzalloc(152UL, 208U);
#line 154
  mr = (struct mlx5_ib_mr *)tmp___0;
#line 155
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 156
    err = -12;
#line 157
    goto ldv_40946;
  } else {

  }
#line 159
  mr->order = (int )ent->order;
#line 160
  mr->umred = 1;
#line 161
  mr->dev = dev;
#line 162
  in->seg.status = 64U;
#line 163
  tmp___1 = __fswab32((__u32 )((npages + 1) / 2));
#line 163
  in->seg.xlt_oct_size = tmp___1;
#line 164
  in->seg.qpn_mkey7_0 = 16777215U;
#line 165
  in->seg.flags = 129U;
#line 166
  in->seg.log2_page_size = 12U;
#line 168
  spin_lock_irq(& ent->lock);
#line 169
  ent->pending = ent->pending + 1;
#line 170
  spin_unlock_irq(& ent->lock);
#line 171
  err = mlx5_core_create_mkey(dev->mdev, & mr->mmr, in, 272, & reg_mr_callback, (void *)mr,
                              & mr->out);
#line 174
  if (err != 0) {
#line 175
    spin_lock_irq(& ent->lock);
#line 176
    ent->pending = ent->pending - 1;
#line 177
    spin_unlock_irq(& ent->lock);
#line 178
    tmp___2 = get_current();
#line 178
    printk("\f%s:%s:%d:(pid %d): create mkey failed %d\n", (char *)(& dev->ib_dev.name),
           "add_keys", 178, tmp___2->pid, err);
#line 179
    kfree((void const   *)mr);
#line 180
    goto ldv_40946;
  } else {

  }
#line 148
  i = i + 1;
  ldv_40949: ;
#line 148
  if (i < num) {
#line 150
    goto ldv_40948;
  } else {

  }
  ldv_40946: 
#line 184
  kfree((void const   *)in);
#line 185
  return (err);
}
}
#line 188 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void remove_keys(struct mlx5_ib_dev *dev , int c , int num ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_cache_ent *ent ;
  struct mlx5_ib_mr *mr ;
  int err ;
  int i ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct task_struct *tmp___0 ;

  {
#line 190
  cache = & dev->cache;
#line 191
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )c;
#line 196
  i = 0;
#line 196
  goto ldv_40964;
  ldv_40963: 
#line 197
  spin_lock_irq(& ent->lock);
#line 198
  tmp = list_empty((struct list_head  const  *)(& ent->head));
#line 198
  if (tmp != 0) {
#line 199
    spin_unlock_irq(& ent->lock);
#line 200
    return;
  } else {

  }
#line 202
  __mptr = (struct list_head  const  *)ent->head.next;
#line 202
  mr = (struct mlx5_ib_mr *)__mptr + 0xffffffffffffffb0UL;
#line 203
  list_del(& mr->list);
#line 204
  ent->cur = ent->cur - 1U;
#line 205
  ent->size = ent->size - 1U;
#line 206
  spin_unlock_irq(& ent->lock);
#line 207
  err = destroy_mkey(dev, mr);
#line 208
  if (err != 0) {
#line 209
    tmp___0 = get_current();
#line 209
    printk("\f%s:%s:%d:(pid %d): failed destroy mkey\n", (char *)(& dev->ib_dev.name),
           "remove_keys", 209, tmp___0->pid);
  } else {
#line 211
    kfree((void const   *)mr);
  }
#line 196
  i = i + 1;
  ldv_40964: ;
#line 196
  if (i < num) {
#line 198
    goto ldv_40963;
  } else {

  }

#line 203
  return;
}
}
#line 215 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static ssize_t size_write(struct file *filp , char const   *buf , size_t count , loff_t *pos ) 
{ 
  struct mlx5_cache_ent *ent ;
  struct mlx5_ib_dev *dev ;
  char lbuf[20U] ;
  u32 var ;
  int err ;
  int c ;
  unsigned long tmp ;
  int tmp___0 ;

  {
#line 218
  ent = (struct mlx5_cache_ent *)filp->private_data;
#line 219
  dev = ent->dev;
#line 225
  tmp = copy_from_user((void *)(& lbuf), (void const   *)buf, 20UL);
#line 225
  if (tmp != 0UL) {
#line 226
    return (-14L);
  } else {

  }
#line 228
  c = order2idx(dev, (int )ent->order);
#line 229
  lbuf[19UL] = 0;
#line 231
  tmp___0 = sscanf((char const   *)(& lbuf), "%u", & var);
#line 231
  if (tmp___0 != 1) {
#line 232
    return (-22L);
  } else {

  }
#line 234
  if (ent->limit > var) {
#line 235
    return (-22L);
  } else {

  }
#line 237
  if (ent->size < var) {
    ldv_40978: 
#line 239
    err = add_keys(dev, c, (int )(var - ent->size));
#line 240
    if (err != 0 && err != -11) {
#line 241
      return ((ssize_t )err);
    } else {

    }
#line 243
    usleep_range(3000UL, 5000UL);
#line 244
    if (err != 0) {
#line 246
      goto ldv_40978;
    } else {

    }

  } else
#line 245
  if (ent->size > var) {
#line 246
    remove_keys(dev, c, (int )(ent->size - var));
  } else {

  }
#line 249
  return ((ssize_t )count);
}
}
#line 252 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static ssize_t size_read(struct file *filp , char *buf , size_t count , loff_t *pos ) 
{ 
  struct mlx5_cache_ent *ent ;
  char lbuf[20U] ;
  int err ;
  unsigned long tmp ;

  {
#line 255
  ent = (struct mlx5_cache_ent *)filp->private_data;
#line 259
  if (*pos != 0LL) {
#line 260
    return (0L);
  } else {

  }
#line 262
  err = snprintf((char *)(& lbuf), 20UL, "%d\n", ent->size);
#line 263
  if (err < 0) {
#line 264
    return ((ssize_t )err);
  } else {

  }
#line 266
  tmp = copy_to_user((void *)buf, (void const   *)(& lbuf), (unsigned long )err);
#line 266
  if (tmp != 0UL) {
#line 267
    return (-14L);
  } else {

  }
#line 269
  *pos = *pos + (loff_t )err;
#line 271
  return ((ssize_t )err);
}
}
#line 274 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static struct file_operations  const  size_fops  = 
#line 274
     {& __this_module, 0, & size_read, & size_write, 0, 0, 0, 0, 0, 0, 0, 0, & simple_open,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
#line 281 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static ssize_t limit_write(struct file *filp , char const   *buf , size_t count ,
                           loff_t *pos ) 
{ 
  struct mlx5_cache_ent *ent ;
  struct mlx5_ib_dev *dev ;
  char lbuf[20U] ;
  u32 var ;
  int err ;
  int c ;
  unsigned long tmp ;
  int tmp___0 ;

  {
#line 284
  ent = (struct mlx5_cache_ent *)filp->private_data;
#line 285
  dev = ent->dev;
#line 291
  tmp = copy_from_user((void *)(& lbuf), (void const   *)buf, 20UL);
#line 291
  if (tmp != 0UL) {
#line 292
    return (-14L);
  } else {

  }
#line 294
  c = order2idx(dev, (int )ent->order);
#line 295
  lbuf[19UL] = 0;
#line 297
  tmp___0 = sscanf((char const   *)(& lbuf), "%u", & var);
#line 297
  if (tmp___0 != 1) {
#line 298
    return (-22L);
  } else {

  }
#line 300
  if (ent->size < var) {
#line 301
    return (-22L);
  } else {

  }
#line 303
  ent->limit = var;
#line 305
  if (ent->cur < ent->limit) {
#line 306
    err = add_keys(dev, c, (int )(ent->limit * 2U - ent->cur));
#line 307
    if (err != 0) {
#line 308
      return ((ssize_t )err);
    } else {

    }
  } else {

  }
#line 311
  return ((ssize_t )count);
}
}
#line 314 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static ssize_t limit_read(struct file *filp , char *buf , size_t count , loff_t *pos ) 
{ 
  struct mlx5_cache_ent *ent ;
  char lbuf[20U] ;
  int err ;
  unsigned long tmp ;

  {
#line 317
  ent = (struct mlx5_cache_ent *)filp->private_data;
#line 321
  if (*pos != 0LL) {
#line 322
    return (0L);
  } else {

  }
#line 324
  err = snprintf((char *)(& lbuf), 20UL, "%d\n", ent->limit);
#line 325
  if (err < 0) {
#line 326
    return ((ssize_t )err);
  } else {

  }
#line 328
  tmp = copy_to_user((void *)buf, (void const   *)(& lbuf), (unsigned long )err);
#line 328
  if (tmp != 0UL) {
#line 329
    return (-14L);
  } else {

  }
#line 331
  *pos = *pos + (loff_t )err;
#line 333
  return ((ssize_t )err);
}
}
#line 336 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static struct file_operations  const  limit_fops  = 
#line 336
     {& __this_module, 0, & limit_read, & limit_write, 0, 0, 0, 0, 0, 0, 0, 0, & simple_open,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
#line 343 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int someone_adding(struct mlx5_mr_cache *cache ) 
{ 
  int i ;

  {
#line 347
  i = 0;
#line 347
  goto ldv_41017;
  ldv_41016: ;
#line 348
  if (cache->ent[i].cur < cache->ent[i].limit) {
#line 349
    return (1);
  } else {

  }
#line 347
  i = i + 1;
  ldv_41017: ;
#line 347
  if (i <= 15) {
#line 349
    goto ldv_41016;
  } else {

  }

#line 352
  return (0);
}
}
#line 355 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void __cache_work_func(struct mlx5_cache_ent *ent ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_mr_cache *cache ;
  int i ;
  int tmp ;
  int err ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;
  struct task_struct *tmp___3 ;
  unsigned long tmp___4 ;
  int tmp___5 ;

  {
#line 357
  dev = ent->dev;
#line 358
  cache = & dev->cache;
#line 359
  tmp = order2idx(dev, (int )ent->order);
#line 359
  i = tmp;
#line 362
  if (cache->stopped != 0) {
#line 363
    return;
  } else {

  }
#line 365
  ent = (struct mlx5_cache_ent *)(& dev->cache.ent) + (unsigned long )i;
#line 366
  if (ent->cur < ent->limit * 2U && dev->fill_delay == 0) {
#line 367
    err = add_keys(dev, i, 1);
#line 368
    if (ent->cur < ent->limit * 2U) {
#line 369
      if (err == -11) {
#line 370
        descriptor.modname = "mlx5_ib";
#line 370
        descriptor.function = "__cache_work_func";
#line 370
        descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 370
        descriptor.format = "%s:%s:%d:(pid %d): returned eagain, order %d\n";
#line 370
        descriptor.lineno = 371U;
#line 370
        descriptor.flags = 0U;
#line 370
        tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 370
        if (tmp___1 != 0L) {
#line 370
          tmp___0 = get_current();
#line 370
          __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): returned eagain, order %d\n",
                             (char *)(& dev->ib_dev.name), "__cache_work_func", 371,
                             tmp___0->pid, i + 2);
        } else {

        }
#line 372
        tmp___2 = msecs_to_jiffies(3U);
#line 372
        queue_delayed_work(cache->wq, & ent->dwork, tmp___2);
      } else
#line 374
      if (err != 0) {
#line 375
        tmp___3 = get_current();
#line 375
        printk("\f%s:%s:%d:(pid %d): command failed order %d, err %d\n", (char *)(& dev->ib_dev.name),
               "__cache_work_func", 376, tmp___3->pid, i + 2, err);
#line 377
        tmp___4 = msecs_to_jiffies(1000U);
#line 377
        queue_delayed_work(cache->wq, & ent->dwork, tmp___4);
      } else {
#line 380
        queue_work(cache->wq, & ent->work);
      }
    } else {

    }
  } else
#line 383
  if (ent->cur > ent->limit * 2U) {
#line 384
    tmp___5 = someone_adding(cache);
#line 385
    if (tmp___5 == 0 && (long )((cache->last_add - (unsigned long )jiffies) + 75000UL) < 0L) {
#line 386
      remove_keys(dev, i, 1);
#line 387
      if (ent->cur > ent->limit) {
#line 388
        queue_work(cache->wq, & ent->work);
      } else {

      }
    } else {
#line 390
      queue_delayed_work(cache->wq, & ent->dwork, 75000UL);
    }
  } else {

  }
#line 391
  return;
}
}
#line 395 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void delayed_cache_work_func(struct work_struct *work ) 
{ 
  struct mlx5_cache_ent *ent ;
  struct work_struct  const  *__mptr ;

  {
#line 399
  __mptr = (struct work_struct  const  *)work;
#line 399
  ent = (struct mlx5_cache_ent *)__mptr + 0xffffffffffffff10UL;
#line 400
  __cache_work_func(ent);
#line 401
  return;
}
}
#line 403 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void cache_work_func(struct work_struct *work ) 
{ 
  struct mlx5_cache_ent *ent ;
  struct work_struct  const  *__mptr ;

  {
#line 407
  __mptr = (struct work_struct  const  *)work;
#line 407
  ent = (struct mlx5_cache_ent *)__mptr + 0xffffffffffffff60UL;
#line 408
  __cache_work_func(ent);
#line 409
  return;
}
}
#line 411 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static struct mlx5_ib_mr *alloc_cached_mr(struct mlx5_ib_dev *dev , int order ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_ib_mr *mr ;
  struct mlx5_cache_ent *ent ;
  int c ;
  int i ;
  struct task_struct *tmp ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  struct list_head  const  *__mptr ;
  int tmp___2 ;

  {
#line 413
  cache = & dev->cache;
#line 414
  mr = (struct mlx5_ib_mr *)0;
#line 419
  c = order2idx(dev, order);
#line 420
  if (c < 0 || c > 15) {
#line 421
    tmp = get_current();
#line 421
    printk("\f%s:%s:%d:(pid %d): order %d, cache index %d\n", (char *)(& dev->ib_dev.name),
           "alloc_cached_mr", 421, tmp->pid, order, c);
#line 422
    return ((struct mlx5_ib_mr *)0);
  } else {

  }
#line 425
  i = c;
#line 425
  goto ldv_41061;
  ldv_41060: 
#line 426
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )i;
#line 428
  descriptor.modname = "mlx5_ib";
#line 428
  descriptor.function = "alloc_cached_mr";
#line 428
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 428
  descriptor.format = "%s:%s:%d:(pid %d): order %d, cache index %d\n";
#line 428
  descriptor.lineno = 428U;
#line 428
  descriptor.flags = 0U;
#line 428
  tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 428
  if (tmp___1 != 0L) {
#line 428
    tmp___0 = get_current();
#line 428
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): order %d, cache index %d\n",
                       (char *)(& dev->ib_dev.name), "alloc_cached_mr", 428, tmp___0->pid,
                       ent->order, i);
  } else {

  }
#line 430
  spin_lock_irq(& ent->lock);
#line 431
  tmp___2 = list_empty((struct list_head  const  *)(& ent->head));
#line 431
  if (tmp___2 == 0) {
#line 432
    __mptr = (struct list_head  const  *)ent->head.next;
#line 432
    mr = (struct mlx5_ib_mr *)__mptr + 0xffffffffffffffb0UL;
#line 434
    list_del(& mr->list);
#line 435
    ent->cur = ent->cur - 1U;
#line 436
    spin_unlock_irq(& ent->lock);
#line 437
    if (ent->cur < ent->limit) {
#line 438
      queue_work(cache->wq, & ent->work);
    } else {

    }
#line 439
    goto ldv_41059;
  } else {

  }
#line 441
  spin_unlock_irq(& ent->lock);
#line 443
  queue_work(cache->wq, & ent->work);
#line 445
  if ((unsigned long )mr != (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 446
    goto ldv_41059;
  } else {

  }
#line 425
  i = i + 1;
  ldv_41061: ;
#line 425
  if (i <= 15) {
#line 427
    goto ldv_41060;
  } else {

  }
  ldv_41059: ;
#line 449
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 450
    cache->ent[c].miss = cache->ent[c].miss + 1U;
  } else {

  }
#line 452
  return (mr);
}
}
#line 455 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void free_cached_mr(struct mlx5_ib_dev *dev , struct mlx5_ib_mr *mr ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_cache_ent *ent ;
  int shrink ;
  int c ;
  struct task_struct *tmp ;

  {
#line 457
  cache = & dev->cache;
#line 459
  shrink = 0;
#line 462
  c = order2idx(dev, mr->order);
#line 463
  if (c < 0 || c > 15) {
#line 464
    tmp = get_current();
#line 464
    printk("\f%s:%s:%d:(pid %d): order %d, cache index %d\n", (char *)(& dev->ib_dev.name),
           "free_cached_mr", 464, tmp->pid, mr->order, c);
#line 465
    return;
  } else {

  }
#line 467
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )c;
#line 468
  spin_lock_irq(& ent->lock);
#line 469
  list_add_tail(& mr->list, & ent->head);
#line 470
  ent->cur = ent->cur + 1U;
#line 471
  if (ent->cur > ent->limit * 2U) {
#line 472
    shrink = 1;
  } else {

  }
#line 473
  spin_unlock_irq(& ent->lock);
#line 475
  if (shrink != 0) {
#line 476
    queue_work(cache->wq, & ent->work);
  } else {

  }
#line 477
  return;
}
}
#line 479 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void clean_keys(struct mlx5_ib_dev *dev , int c ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_cache_ent *ent ;
  struct mlx5_ib_mr *mr ;
  int err ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct task_struct *tmp___0 ;

  {
#line 481
  cache = & dev->cache;
#line 482
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )c;
#line 486
  ldv_cancel_delayed_work_98(& ent->dwork);
  ldv_41082: 
#line 488
  spin_lock_irq(& ent->lock);
#line 489
  tmp = list_empty((struct list_head  const  *)(& ent->head));
#line 489
  if (tmp != 0) {
#line 490
    spin_unlock_irq(& ent->lock);
#line 491
    return;
  } else {

  }
#line 493
  __mptr = (struct list_head  const  *)ent->head.next;
#line 493
  mr = (struct mlx5_ib_mr *)__mptr + 0xffffffffffffffb0UL;
#line 494
  list_del(& mr->list);
#line 495
  ent->cur = ent->cur - 1U;
#line 496
  ent->size = ent->size - 1U;
#line 497
  spin_unlock_irq(& ent->lock);
#line 498
  err = destroy_mkey(dev, mr);
#line 499
  if (err != 0) {
#line 500
    tmp___0 = get_current();
#line 500
    printk("\f%s:%s:%d:(pid %d): failed destroy mkey\n", (char *)(& dev->ib_dev.name),
           "clean_keys", 500, tmp___0->pid);
  } else {
#line 502
    kfree((void const   *)mr);
  }
#line 503
  goto ldv_41082;
}
}
#line 506 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int mlx5_mr_cache_debugfs_init(struct mlx5_ib_dev *dev ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_cache_ent *ent ;
  int i ;

  {
#line 508
  cache = & dev->cache;
#line 512
  if ((unsigned long )mlx5_debugfs_root == (unsigned long )((struct dentry *)0)) {
#line 513
    return (0);
  } else {

  }
#line 515
  cache->root = debugfs_create_dir("mr_cache", (dev->mdev)->priv.dbg_root);
#line 516
  if ((unsigned long )cache->root == (unsigned long )((struct dentry *)0)) {
#line 517
    return (-12);
  } else {

  }
#line 519
  i = 0;
#line 519
  goto ldv_41090;
  ldv_41089: 
#line 520
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )i;
#line 521
  sprintf((char *)(& ent->name), "%d", ent->order);
#line 522
  ent->dir = debugfs_create_dir((char const   *)(& ent->name), cache->root);
#line 523
  if ((unsigned long )ent->dir == (unsigned long )((struct dentry *)0)) {
#line 524
    return (-12);
  } else {

  }
#line 526
  ent->fsize = debugfs_create_file("size", 384, ent->dir, (void *)ent, & size_fops);
#line 528
  if ((unsigned long )ent->fsize == (unsigned long )((struct dentry *)0)) {
#line 529
    return (-12);
  } else {

  }
#line 531
  ent->flimit = debugfs_create_file("limit", 384, ent->dir, (void *)ent, & limit_fops);
#line 533
  if ((unsigned long )ent->flimit == (unsigned long )((struct dentry *)0)) {
#line 534
    return (-12);
  } else {

  }
#line 536
  ent->fcur = debugfs_create_u32("cur", 256, ent->dir, & ent->cur);
#line 538
  if ((unsigned long )ent->fcur == (unsigned long )((struct dentry *)0)) {
#line 539
    return (-12);
  } else {

  }
#line 541
  ent->fmiss = debugfs_create_u32("miss", 384, ent->dir, & ent->miss);
#line 543
  if ((unsigned long )ent->fmiss == (unsigned long )((struct dentry *)0)) {
#line 544
    return (-12);
  } else {

  }
#line 519
  i = i + 1;
  ldv_41090: ;
#line 519
  if (i <= 15) {
#line 521
    goto ldv_41089;
  } else {

  }

#line 547
  return (0);
}
}
#line 550 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void mlx5_mr_cache_debugfs_cleanup(struct mlx5_ib_dev *dev ) 
{ 


  {
#line 552
  if ((unsigned long )mlx5_debugfs_root == (unsigned long )((struct dentry *)0)) {
#line 553
    return;
  } else {

  }
#line 555
  debugfs_remove_recursive(dev->cache.root);
#line 556
  return;
}
}
#line 558 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void delay_time_func(unsigned long ctx ) 
{ 
  struct mlx5_ib_dev *dev ;

  {
#line 560
  dev = (struct mlx5_ib_dev *)ctx;
#line 562
  dev->fill_delay = 0;
#line 563
  return;
}
}
#line 565 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
int mlx5_mr_cache_init(struct mlx5_ib_dev *dev ) 
{ 
  struct mlx5_mr_cache *cache ;
  struct mlx5_cache_ent *ent ;
  int limit ;
  int err ;
  int i ;
  struct lock_class_key __key ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp ;
  struct task_struct *tmp___0 ;
  struct lock_class_key __key___0 ;
  struct lock_class_key __key___1 ;
  struct lock_class_key __key___2 ;
  atomic_long_t __constr_expr_0 ;
  struct lock_class_key __key___3 ;
  atomic_long_t __constr_expr_1 ;
  struct lock_class_key __key___4 ;
  struct task_struct *tmp___1 ;

  {
#line 567
  cache = & dev->cache;
#line 573
  __lock_name = "\"%s\"\"mkey_cache\"";
#line 573
  tmp = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)"mkey_cache");
#line 573
  cache->wq = tmp;
#line 574
  if ((unsigned long )cache->wq == (unsigned long )((struct workqueue_struct *)0)) {
#line 575
    tmp___0 = get_current();
#line 575
    printk("\f%s:%s:%d:(pid %d): failed to create work queue\n", (char *)(& dev->ib_dev.name),
           "mlx5_mr_cache_init", 575, tmp___0->pid);
#line 576
    return (-12);
  } else {

  }
#line 579
  reg_timer_4(& dev->delay_timer, & delay_time_func, (unsigned long )dev);
#line 580
  i = 0;
#line 580
  goto ldv_41119;
  ldv_41118: 
#line 581
  INIT_LIST_HEAD(& cache->ent[i].head);
#line 582
  spinlock_check(& cache->ent[i].lock);
#line 582
  __raw_spin_lock_init(& cache->ent[i].lock.__annonCompField18.rlock, "&(&cache->ent[i].lock)->rlock",
                       & __key___0);
#line 584
  ent = (struct mlx5_cache_ent *)(& cache->ent) + (unsigned long )i;
#line 585
  INIT_LIST_HEAD(& ent->head);
#line 586
  spinlock_check(& ent->lock);
#line 586
  __raw_spin_lock_init(& ent->lock.__annonCompField18.rlock, "&(&ent->lock)->rlock",
                       & __key___1);
#line 587
  ent->order = (u32 )(i + 2);
#line 588
  ent->dev = dev;
#line 590
  if ((((dev->mdev)->profile)->mask & 2ULL) != 0ULL) {
#line 591
    limit = ((dev->mdev)->profile)->mr_cache[i].limit;
  } else {
#line 593
    limit = 0;
  }
#line 595
  __init_work(& ent->work, 0);
#line 595
  __constr_expr_0.counter = 137438953408L;
#line 595
  ent->work.data = __constr_expr_0;
#line 595
  lockdep_init_map(& ent->work.lockdep_map, "(&ent->work)", & __key___2, 0);
#line 595
  INIT_LIST_HEAD(& ent->work.entry);
#line 595
  ent->work.func = & cache_work_func;
#line 596
  __init_work(& ent->dwork.work, 0);
#line 596
  __constr_expr_1.counter = 137438953408L;
#line 596
  ent->dwork.work.data = __constr_expr_1;
#line 596
  lockdep_init_map(& ent->dwork.work.lockdep_map, "(&(&ent->dwork)->work)", & __key___3,
                   0);
#line 596
  INIT_LIST_HEAD(& ent->dwork.work.entry);
#line 596
  ent->dwork.work.func = & delayed_cache_work_func;
#line 596
  init_timer_key(& ent->dwork.timer, 2097152U, "(&(&ent->dwork)->timer)", & __key___4);
#line 596
  ent->dwork.timer.function = & delayed_work_timer_fn;
#line 596
  ent->dwork.timer.data = (unsigned long )(& ent->dwork);
#line 597
  ent->limit = (u32 )limit;
#line 598
  queue_work(cache->wq, & ent->work);
#line 580
  i = i + 1;
  ldv_41119: ;
#line 580
  if (i <= 15) {
#line 582
    goto ldv_41118;
  } else {

  }
#line 601
  err = mlx5_mr_cache_debugfs_init(dev);
#line 602
  if (err != 0) {
#line 603
    tmp___1 = get_current();
#line 603
    printk("\f%s:%s:%d:(pid %d): cache debugfs failure\n", (char *)(& dev->ib_dev.name),
           "mlx5_mr_cache_init", 603, tmp___1->pid);
  } else {

  }
#line 605
  return (0);
}
}
#line 608 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
int mlx5_mr_cache_cleanup(struct mlx5_ib_dev *dev ) 
{ 
  int i ;

  {
#line 612
  dev->cache.stopped = 1;
#line 613
  ldv_flush_workqueue_99(dev->cache.wq);
#line 615
  mlx5_mr_cache_debugfs_cleanup(dev);
#line 617
  i = 0;
#line 617
  goto ldv_41126;
  ldv_41125: 
#line 618
  clean_keys(dev, i);
#line 617
  i = i + 1;
  ldv_41126: ;
#line 617
  if (i <= 15) {
#line 619
    goto ldv_41125;
  } else {

  }
#line 620
  ldv_destroy_workqueue_100(dev->cache.wq);
#line 621
  ldv_del_timer_sync_101(& dev->delay_timer);
#line 623
  return (0);
}
}
#line 626 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
struct ib_mr *mlx5_ib_get_dma_mr(struct ib_pd *pd , int acc ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  struct mlx5_create_mkey_mbox_in *in ;
  struct mlx5_mkey_seg *seg ;
  struct mlx5_ib_mr *mr ;
  int err ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  struct mlx5_ib_pd *tmp___3 ;
  __u32 tmp___4 ;
  void *tmp___5 ;

  {
#line 628
  tmp = to_mdev(pd->device);
#line 628
  dev = tmp;
#line 629
  mdev = dev->mdev;
#line 635
  tmp___0 = kzalloc(152UL, 208U);
#line 635
  mr = (struct mlx5_ib_mr *)tmp___0;
#line 636
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 637
    tmp___1 = ERR_PTR(-12L);
#line 637
    return ((struct ib_mr *)tmp___1);
  } else {

  }
#line 639
  tmp___2 = kzalloc(272UL, 208U);
#line 639
  in = (struct mlx5_create_mkey_mbox_in *)tmp___2;
#line 640
  if ((unsigned long )in == (unsigned long )((struct mlx5_create_mkey_mbox_in *)0)) {
#line 641
    err = -12;
#line 642
    goto err_free;
  } else {

  }
#line 645
  seg = & in->seg;
#line 646
  seg->flags = convert_access(acc);
#line 647
  tmp___3 = to_mpd(pd);
#line 647
  tmp___4 = __fswab32(tmp___3->pdn | 2147483648U);
#line 647
  seg->flags_pd = tmp___4;
#line 648
  seg->qpn_mkey7_0 = 16777215U;
#line 649
  seg->start_addr = 0ULL;
#line 651
  err = mlx5_core_create_mkey(mdev, & mr->mmr, in, 272, (void (*)(int  , void * ))0,
                              (void *)0, (struct mlx5_create_mkey_mbox_out *)0);
#line 653
  if (err != 0) {
#line 654
    goto err_in;
  } else {

  }
#line 656
  kfree((void const   *)in);
#line 657
  mr->ibmr.lkey = mr->mmr.key;
#line 658
  mr->ibmr.rkey = mr->mmr.key;
#line 659
  mr->umem = (struct ib_umem *)0;
#line 661
  return (& mr->ibmr);
  err_in: 
#line 664
  kfree((void const   *)in);
  err_free: 
#line 667
  kfree((void const   *)mr);
#line 669
  tmp___5 = ERR_PTR((long )err);
#line 669
  return ((struct ib_mr *)tmp___5);
}
}
#line 672 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int get_octo_len(u64 addr , u64 len , int page_size ) 
{ 
  u64 offset ;
  int npages ;
  int tmp ;

  {
#line 677
  offset = (u64 )(page_size + -1) & addr;
#line 678
  tmp = __ilog2_u32((u32 )page_size);
#line 678
  npages = (int )(((((len + offset) + (unsigned long long )page_size) - 1ULL) & - ((unsigned long long )page_size)) >> tmp);
#line 679
  return ((npages + 1) / 2);
}
}
#line 682 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int use_umr(int order ) 
{ 


  {
#line 684
  return (order <= 16);
}
}
#line 687 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void prep_umr_reg_wqe(struct ib_pd *pd , struct ib_send_wr *wr , struct ib_sge *sg ,
                             u64 dma , int n , u32 key , int page_shift , u64 virt_addr ,
                             u64 len , int access_flags ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct ib_mr *mr ;
  struct mlx5_umr_wr *umrwr ;

  {
#line 692
  tmp = to_mdev(pd->device);
#line 692
  dev = tmp;
#line 693
  mr = dev->umrc.mr;
#line 694
  umrwr = (struct mlx5_umr_wr *)(& wr->wr.fast_reg);
#line 696
  sg->addr = dma;
#line 697
  sg->length = ((u32 )((unsigned long )n) * 8U + 63U) & 4294967232U;
#line 698
  sg->lkey = mr->lkey;
#line 700
  wr->next = (struct ib_send_wr *)0;
#line 701
  wr->send_flags = 0;
#line 702
  wr->sg_list = sg;
#line 703
  if (n != 0) {
#line 704
    wr->num_sge = 1;
  } else {
#line 706
    wr->num_sge = 0;
  }
#line 708
  wr->opcode = 240;
#line 710
  umrwr->npages = (unsigned int )n;
#line 711
  umrwr->page_shift = (unsigned int )page_shift;
#line 712
  umrwr->mkey = key;
#line 713
  umrwr->target.virt_addr = virt_addr;
#line 714
  umrwr->length = (u32 )len;
#line 715
  umrwr->access_flags = access_flags;
#line 716
  umrwr->pd = pd;
#line 717
  return;
}
}
#line 719 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static void prep_umr_unreg_wqe(struct mlx5_ib_dev *dev , struct ib_send_wr *wr , u32 key ) 
{ 
  struct mlx5_umr_wr *umrwr ;

  {
#line 722
  umrwr = (struct mlx5_umr_wr *)(& wr->wr.fast_reg);
#line 724
  wr->send_flags = 201326592;
#line 725
  wr->opcode = 240;
#line 726
  umrwr->mkey = key;
#line 727
  return;
}
}
#line 729 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
void mlx5_umr_cq_handler(struct ib_cq *cq , void *cq_context ) 
{ 
  struct mlx5_ib_umr_context *context ;
  struct ib_wc wc ;
  int err ;

  {
  ldv_41179: 
#line 736
  err = ib_poll_cq(cq, 1, & wc);
#line 737
  if (err < 0) {
#line 738
    printk("\fpoll cq error %d\n", err);
#line 739
    return;
  } else {

  }
#line 741
  if (err == 0) {
#line 742
    goto ldv_41178;
  } else {

  }
#line 744
  context = (struct mlx5_ib_umr_context *)wc.wr_id;
#line 745
  context->status = wc.status;
#line 746
  complete(& context->done);
#line 747
  goto ldv_41179;
  ldv_41178: 
#line 748
  ib_req_notify_cq(cq, 2);
#line 749
  return;
}
}
#line 751 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static struct mlx5_ib_mr *reg_umr(struct ib_pd *pd , struct ib_umem *umem , u64 virt_addr ,
                                  u64 len , int npages , int page_shift , int order ,
                                  int access_flags ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct device *ddev ;
  struct umr_common *umrc ;
  struct mlx5_ib_umr_context umr_context ;
  struct ib_send_wr wr ;
  struct ib_send_wr *bad ;
  struct mlx5_ib_mr *mr ;
  struct ib_sge sg ;
  int size ;
  __be64 *mr_pas ;
  __be64 *pas ;
  dma_addr_t dma ;
  int err ;
  int i ;
  int tmp___0 ;
  struct task_struct *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  int tmp___4 ;
  struct task_struct *tmp___5 ;
  struct task_struct *tmp___6 ;
  struct mlx5_ib_pd *tmp___7 ;
  void *tmp___8 ;

  {
#line 755
  tmp = to_mdev(pd->device);
#line 755
  dev = tmp;
#line 756
  ddev = dev->ib_dev.dma_device;
#line 757
  umrc = & dev->umrc;
#line 766
  err = 0;
#line 769
  i = 0;
#line 769
  goto ldv_41207;
  ldv_41206: 
#line 770
  mr = alloc_cached_mr(dev, order);
#line 771
  if ((unsigned long )mr != (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 772
    goto ldv_41204;
  } else {

  }
#line 774
  tmp___0 = order2idx(dev, order);
#line 774
  err = add_keys(dev, tmp___0, 1);
#line 775
  if (err != 0 && err != -11) {
#line 776
    tmp___1 = get_current();
#line 776
    printk("\f%s:%s:%d:(pid %d): add_keys failed, err %d\n", (char *)(& dev->ib_dev.name),
           "reg_umr", 776, tmp___1->pid, err);
#line 777
    goto ldv_41204;
  } else {

  }
#line 769
  i = i + 1;
  ldv_41207: ;
#line 769
  if (i <= 0) {
#line 771
    goto ldv_41206;
  } else {

  }
  ldv_41204: ;
#line 781
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 782
    tmp___2 = ERR_PTR(-11L);
#line 782
    return ((struct mlx5_ib_mr *)tmp___2);
  } else {

  }
#line 787
  size = (int )((unsigned int )((unsigned long )npages) * 8U + 63U) & -64;
#line 788
  tmp___3 = kmalloc((size_t )(size + 2047), 208U);
#line 788
  mr_pas = (__be64 *)tmp___3;
#line 789
  if ((unsigned long )mr_pas == (unsigned long )((__be64 *)0ULL)) {
#line 790
    err = -12;
#line 791
    goto free_mr;
  } else {

  }
#line 794
  pas = (__be64 *)(((unsigned long )mr_pas + 2047UL) & 0xfffffffffffff800UL);
#line 795
  mlx5_ib_populate_pas(dev, umem, page_shift, pas, 3);
#line 797
  memset((void *)pas + (unsigned long )npages, 0, (unsigned long )size - (unsigned long )npages * 8UL);
#line 799
  dma = dma_map_single_attrs(ddev, (void *)pas, (size_t )size, 1, (struct dma_attrs *)0);
#line 800
  tmp___4 = dma_mapping_error(ddev, dma);
#line 800
  if (tmp___4 != 0) {
#line 801
    err = -12;
#line 802
    goto free_pas;
  } else {

  }
#line 805
  memset((void *)(& wr), 0, 96UL);
#line 806
  wr.wr_id = (unsigned long long )(& umr_context);
#line 807
  prep_umr_reg_wqe(pd, & wr, & sg, dma, npages, mr->mmr.key, page_shift, virt_addr,
                   len, access_flags);
#line 810
  mlx5_ib_init_umr_context(& umr_context);
#line 811
  down(& umrc->sem);
#line 812
  err = ib_post_send(umrc->qp, & wr, & bad);
#line 813
  if (err != 0) {
#line 814
    tmp___5 = get_current();
#line 814
    printk("\f%s:%s:%d:(pid %d): post send failed, err %d\n", (char *)(& dev->ib_dev.name),
           "reg_umr", 814, tmp___5->pid, err);
#line 815
    goto unmap_dma;
  } else {
#line 817
    wait_for_completion(& umr_context.done);
#line 818
    if ((unsigned int )umr_context.status != 0U) {
#line 819
      tmp___6 = get_current();
#line 819
      printk("\f%s:%s:%d:(pid %d): reg umr failed\n", (char *)(& dev->ib_dev.name),
             "reg_umr", 819, tmp___6->pid);
#line 820
      err = -14;
    } else {

    }
  }
#line 824
  mr->mmr.iova = virt_addr;
#line 825
  mr->mmr.size = len;
#line 826
  tmp___7 = to_mpd(pd);
#line 826
  mr->mmr.pd = tmp___7->pdn;
#line 828
  mr->live = 1;
  unmap_dma: 
#line 831
  up(& umrc->sem);
#line 832
  dma_unmap_single_attrs(ddev, dma, (size_t )size, 1, (struct dma_attrs *)0);
  free_pas: 
#line 835
  kfree((void const   *)mr_pas);
  free_mr: ;
#line 838
  if (err != 0) {
#line 839
    free_cached_mr(dev, mr);
#line 840
    tmp___8 = ERR_PTR((long )err);
#line 840
    return ((struct mlx5_ib_mr *)tmp___8);
  } else {

  }
#line 843
  return (mr);
}
}
#line 847 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
int mlx5_ib_update_mtt(struct mlx5_ib_mr *mr , u64 start_page_index , int npages ,
                       int zap ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct device *ddev ;
  struct umr_common *umrc ;
  struct mlx5_ib_umr_context umr_context ;
  struct ib_umem *umem ;
  int size ;
  __be64 *pas ;
  dma_addr_t dma ;
  struct ib_send_wr wr ;
  struct ib_send_wr *bad ;
  struct mlx5_umr_wr *umrwr ;
  struct ib_sge sg ;
  int err ;
  int page_index_alignment ;
  int page_index_mask ;
  size_t pages_mapped ;
  size_t pages_to_map ;
  size_t pages_iter ;
  int use_emergency_buf ;
  int __min1 ;
  int __min2 ;
  unsigned long tmp ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  size_t __min1___0 ;
  size_t __min2___0 ;
  size_t tmp___3 ;
  struct task_struct *tmp___4 ;
  struct task_struct *tmp___5 ;

  {
#line 850
  dev = mr->dev;
#line 851
  ddev = dev->ib_dev.dma_device;
#line 852
  umrc = & dev->umrc;
#line 854
  umem = mr->umem;
#line 859
  umrwr = (struct mlx5_umr_wr *)(& wr.wr.fast_reg);
#line 861
  err = 0;
#line 862
  page_index_alignment = 8;
#line 863
  page_index_mask = page_index_alignment + -1;
#line 864
  pages_mapped = 0UL;
#line 865
  pages_to_map = 0UL;
#line 866
  pages_iter = 0UL;
#line 867
  use_emergency_buf = 0;
#line 871
  if (((u64 )page_index_mask & start_page_index) != 0ULL) {
#line 872
    npages = (int )(((unsigned int )start_page_index & (unsigned int )page_index_mask) + (unsigned int )npages);
#line 873
    start_page_index = (u64 )(~ page_index_mask) & start_page_index;
  } else {

  }
#line 876
  pages_to_map = (size_t )(((page_index_alignment + -1) + npages) & - page_index_alignment);
#line 878
  if (start_page_index + (unsigned long long )pages_to_map > 65536ULL) {
#line 879
    return (-22);
  } else {

  }
#line 881
  size = (int )((unsigned int )pages_to_map * 8U);
#line 882
  __min1 = 4096;
#line 882
  __min2 = size;
#line 882
  size = __min1 < __min2 ? __min1 : __min2;
#line 886
  tmp = get_zeroed_page(32U);
#line 886
  pas = (__be64 *)tmp;
#line 887
  if ((unsigned long )pas == (unsigned long )((__be64 *)0ULL)) {
#line 888
    tmp___0 = get_current();
#line 888
    printk("\f%s:%s:%d:(pid %d): unable to allocate memory during MTT update, falling back to slower chunked mechanism.\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_update_mtt", 888, tmp___0->pid);
#line 889
    pas = (__be64 *)(& mlx5_ib_update_mtt_emergency_buffer);
#line 890
    size = 64;
#line 891
    use_emergency_buf = 1;
#line 892
    mutex_lock_nested(& mlx5_ib_update_mtt_emergency_buffer_mutex, 0U);
#line 893
    memset((void *)pas, 0, (size_t )size);
  } else {

  }
#line 895
  pages_iter = (unsigned long )size / 8UL;
#line 896
  dma = dma_map_single_attrs(ddev, (void *)pas, (size_t )size, 1, (struct dma_attrs *)0);
#line 897
  tmp___2 = dma_mapping_error(ddev, dma);
#line 897
  if (tmp___2 != 0) {
#line 898
    tmp___1 = get_current();
#line 898
    printk("\v%s:%s:%d:(pid %d): unable to map DMA during MTT update.\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_update_mtt", 898, tmp___1->pid);
#line 899
    err = -12;
#line 900
    goto free_pas;
  } else {

  }
#line 903
  pages_mapped = 0UL;
#line 903
  goto ldv_41245;
  ldv_41244: 
#line 906
  dma_sync_single_for_cpu(ddev, dma, (size_t )size, 1);
#line 908
  __min1___0 = pages_iter;
#line 908
  tmp___3 = ib_umem_num_pages(umem);
#line 908
  __min2___0 = (size_t )((unsigned long long )tmp___3 - start_page_index);
#line 908
  npages = (int )(__min1___0 < __min2___0 ? __min1___0 : __min2___0);
#line 912
  if (zap == 0) {
#line 913
    __mlx5_ib_populate_pas(dev, umem, 12, (size_t )start_page_index, (size_t )npages,
                           pas, 3);
#line 918
    memset((void *)pas + (unsigned long )npages, 0, (unsigned long )size - (unsigned long )npages * 8UL);
  } else {

  }
#line 921
  dma_sync_single_for_device(ddev, dma, (size_t )size, 1);
#line 923
  memset((void *)(& wr), 0, 96UL);
#line 924
  wr.wr_id = (unsigned long long )(& umr_context);
#line 926
  sg.addr = dma;
#line 927
  sg.length = ((u32 )((unsigned long )npages) * 8U + 63U) & 4294967232U;
#line 929
  sg.lkey = (dev->umrc.mr)->lkey;
#line 931
  wr.send_flags = 402653184;
#line 933
  wr.sg_list = & sg;
#line 934
  wr.num_sge = 1;
#line 935
  wr.opcode = 240;
#line 936
  umrwr->npages = sg.length / 8U;
#line 937
  umrwr->page_shift = 12U;
#line 938
  umrwr->mkey = mr->mmr.key;
#line 939
  umrwr->target.offset = start_page_index;
#line 941
  mlx5_ib_init_umr_context(& umr_context);
#line 942
  down(& umrc->sem);
#line 943
  err = ib_post_send(umrc->qp, & wr, & bad);
#line 944
  if (err != 0) {
#line 945
    tmp___4 = get_current();
#line 945
    printk("\v%s:%s:%d:(pid %d): UMR post send failed, err %d\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_update_mtt", 945, tmp___4->pid, err);
  } else {
#line 947
    wait_for_completion(& umr_context.done);
#line 948
    if ((unsigned int )umr_context.status != 0U) {
#line 949
      tmp___5 = get_current();
#line 949
      printk("\v%s:%s:%d:(pid %d): UMR completion failed, code %d\n", (char *)(& dev->ib_dev.name),
             "mlx5_ib_update_mtt", 950, tmp___5->pid, (unsigned int )umr_context.status);
#line 951
      err = -14;
    } else {

    }
  }
#line 954
  up(& umrc->sem);
#line 905
  pages_mapped = pages_mapped + pages_iter;
#line 905
  start_page_index = start_page_index + (unsigned long long )pages_iter;
  ldv_41245: ;
#line 903
  if (pages_mapped < pages_to_map && err == 0) {
#line 906
    goto ldv_41244;
  } else {

  }
#line 956
  dma_unmap_single_attrs(ddev, dma, (size_t )size, 1, (struct dma_attrs *)0);
  free_pas: ;
#line 959
  if (use_emergency_buf == 0) {
#line 960
    free_pages((unsigned long )pas, 0U);
  } else {
#line 962
    mutex_unlock(& mlx5_ib_update_mtt_emergency_buffer_mutex);
  }
#line 964
  return (err);
}
}
#line 968 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static struct mlx5_ib_mr *reg_create(struct ib_pd *pd , u64 virt_addr , u64 length ,
                                     struct ib_umem *umem , int npages , int page_shift ,
                                     int access_flags ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_create_mkey_mbox_in *in ;
  struct mlx5_ib_mr *mr ;
  int inlen ;
  int err ;
  bool pg_cap ;
  __u32 tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  u8 tmp___4 ;
  struct mlx5_ib_pd *tmp___5 ;
  __u32 tmp___6 ;
  __u64 tmp___7 ;
  __u64 tmp___8 ;
  int tmp___9 ;
  __u32 tmp___10 ;
  int tmp___11 ;
  __u32 tmp___12 ;
  struct task_struct *tmp___13 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___14 ;
  long tmp___15 ;
  void *tmp___16 ;

  {
#line 973
  tmp = to_mdev(pd->device);
#line 973
  dev = tmp;
#line 978
  tmp___0 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 17UL));
#line 978
  pg_cap = (tmp___0 & 16777216U) != 0U;
#line 980
  tmp___1 = kzalloc(152UL, 208U);
#line 980
  mr = (struct mlx5_ib_mr *)tmp___1;
#line 981
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 982
    tmp___2 = ERR_PTR(-12L);
#line 982
    return ((struct mlx5_ib_mr *)tmp___2);
  } else {

  }
#line 984
  inlen = (int )((unsigned int )((unsigned long )((npages + 1) / 2) + 17UL) * 16U);
#line 985
  tmp___3 = mlx5_vzalloc((unsigned long )inlen);
#line 985
  in = (struct mlx5_create_mkey_mbox_in *)tmp___3;
#line 986
  if ((unsigned long )in == (unsigned long )((struct mlx5_create_mkey_mbox_in *)0)) {
#line 987
    err = -12;
#line 988
    goto err_1;
  } else {

  }
#line 990
  mlx5_ib_populate_pas(dev, umem, page_shift, (__be64 *)(& in->pas), (int )pg_cap ? 3 : 0);
#line 995
  in->flags = (int )pg_cap ? 128U : 0U;
#line 996
  tmp___4 = convert_access(access_flags);
#line 996
  in->seg.flags = (u8 )((unsigned int )tmp___4 | 1U);
#line 998
  tmp___5 = to_mpd(pd);
#line 998
  tmp___6 = __fswab32(tmp___5->pdn);
#line 998
  in->seg.flags_pd = tmp___6;
#line 999
  tmp___7 = __fswab64(virt_addr);
#line 999
  in->seg.start_addr = tmp___7;
#line 1000
  tmp___8 = __fswab64(length);
#line 1000
  in->seg.len = tmp___8;
#line 1001
  in->seg.bsfs_octo_size = 0U;
#line 1002
  tmp___9 = get_octo_len(virt_addr, length, 1 << page_shift);
#line 1002
  tmp___10 = __fswab32((__u32 )tmp___9);
#line 1002
  in->seg.xlt_oct_size = tmp___10;
#line 1003
  in->seg.log2_page_size = (u8 )page_shift;
#line 1004
  in->seg.qpn_mkey7_0 = 16777215U;
#line 1005
  tmp___11 = get_octo_len(virt_addr, length, 1 << page_shift);
#line 1005
  tmp___12 = __fswab32((__u32 )tmp___11);
#line 1005
  in->xlat_oct_act_size = tmp___12;
#line 1007
  err = mlx5_core_create_mkey(dev->mdev, & mr->mmr, in, inlen, (void (*)(int  , void * ))0,
                              (void *)0, (struct mlx5_create_mkey_mbox_out *)0);
#line 1009
  if (err != 0) {
#line 1010
    tmp___13 = get_current();
#line 1010
    printk("\f%s:%s:%d:(pid %d): create mkey failed\n", (char *)(& dev->ib_dev.name),
           "reg_create", 1010, tmp___13->pid);
#line 1011
    goto err_2;
  } else {

  }
#line 1013
  mr->umem = umem;
#line 1014
  mr->dev = dev;
#line 1015
  mr->live = 1;
#line 1016
  kvfree((void const   *)in);
#line 1018
  descriptor.modname = "mlx5_ib";
#line 1018
  descriptor.function = "reg_create";
#line 1018
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1018
  descriptor.format = "%s:%s:%d:(pid %d): mkey = 0x%x\n";
#line 1018
  descriptor.lineno = 1018U;
#line 1018
  descriptor.flags = 0U;
#line 1018
  tmp___15 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1018
  if (tmp___15 != 0L) {
#line 1018
    tmp___14 = get_current();
#line 1018
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): mkey = 0x%x\n", (char *)(& dev->ib_dev.name),
                       "reg_create", 1018, tmp___14->pid, mr->mmr.key);
  } else {

  }
#line 1020
  return (mr);
  err_2: 
#line 1023
  kvfree((void const   *)in);
  err_1: 
#line 1026
  kfree((void const   *)mr);
#line 1028
  tmp___16 = ERR_PTR((long )err);
#line 1028
  return ((struct mlx5_ib_mr *)tmp___16);
}
}
#line 1031 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
struct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd , u64 start , u64 length , u64 virt_addr ,
                                  int access_flags , struct ib_udata *udata ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_mr *mr ;
  struct ib_umem *umem ;
  int page_shift ;
  int npages ;
  int ncont ;
  int order ;
  int err ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;
  struct _ddebug descriptor___0 ;
  long tmp___2 ;
  struct task_struct *tmp___3 ;
  long tmp___4 ;
  bool tmp___5 ;
  struct task_struct *tmp___6 ;
  struct _ddebug descriptor___1 ;
  struct task_struct *tmp___7 ;
  long tmp___8 ;
  struct _ddebug descriptor___2 ;
  struct task_struct *tmp___9 ;
  long tmp___10 ;
  long tmp___11 ;
  int tmp___12 ;
  long tmp___13 ;
  bool tmp___14 ;
  struct _ddebug descriptor___3 ;
  struct task_struct *tmp___15 ;
  long tmp___16 ;
  void *tmp___17 ;

  {
#line 1035
  tmp = to_mdev(pd->device);
#line 1035
  dev = tmp;
#line 1036
  mr = (struct mlx5_ib_mr *)0;
#line 1044
  descriptor.modname = "mlx5_ib";
#line 1044
  descriptor.function = "mlx5_ib_reg_user_mr";
#line 1044
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1044
  descriptor.format = "%s:%s:%d:(pid %d): start 0x%llx, virt_addr 0x%llx, length 0x%llx, access_flags 0x%x\n";
#line 1044
  descriptor.lineno = 1045U;
#line 1044
  descriptor.flags = 0U;
#line 1044
  tmp___1 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1044
  if (tmp___1 != 0L) {
#line 1044
    tmp___0 = get_current();
#line 1044
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): start 0x%llx, virt_addr 0x%llx, length 0x%llx, access_flags 0x%x\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_reg_user_mr", 1045,
                       tmp___0->pid, start, virt_addr, length, access_flags);
  } else {

  }
#line 1046
  umem = ib_umem_get((pd->uobject)->context, (unsigned long )start, (size_t )length,
                     access_flags, 0);
#line 1048
  tmp___5 = IS_ERR((void const   *)umem);
#line 1048
  if ((int )tmp___5) {
#line 1049
    descriptor___0.modname = "mlx5_ib";
#line 1049
    descriptor___0.function = "mlx5_ib_reg_user_mr";
#line 1049
    descriptor___0.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1049
    descriptor___0.format = "%s:%s:%d:(pid %d): umem get failed (%ld)\n";
#line 1049
    descriptor___0.lineno = 1049U;
#line 1049
    descriptor___0.flags = 0U;
#line 1049
    tmp___4 = ldv__builtin_expect((long )descriptor___0.flags & 1L, 0L);
#line 1049
    if (tmp___4 != 0L) {
#line 1049
      tmp___2 = PTR_ERR((void const   *)umem);
#line 1049
      tmp___3 = get_current();
#line 1049
      __dynamic_pr_debug(& descriptor___0, "%s:%s:%d:(pid %d): umem get failed (%ld)\n",
                         (char *)(& dev->ib_dev.name), "mlx5_ib_reg_user_mr", 1049,
                         tmp___3->pid, tmp___2);
    } else {

    }
#line 1050
    return ((struct ib_mr *)umem);
  } else {

  }
#line 1053
  mlx5_ib_cont_pages(umem, start, & npages, & page_shift, & ncont, & order);
#line 1054
  if (npages == 0) {
#line 1055
    tmp___6 = get_current();
#line 1055
    printk("\f%s:%s:%d:(pid %d): avoid zero region\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_reg_user_mr", 1055, tmp___6->pid);
#line 1056
    err = -22;
#line 1057
    goto error;
  } else {

  }
#line 1060
  descriptor___1.modname = "mlx5_ib";
#line 1060
  descriptor___1.function = "mlx5_ib_reg_user_mr";
#line 1060
  descriptor___1.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1060
  descriptor___1.format = "%s:%s:%d:(pid %d): npages %d, ncont %d, order %d, page_shift %d\n";
#line 1060
  descriptor___1.lineno = 1061U;
#line 1060
  descriptor___1.flags = 0U;
#line 1060
  tmp___8 = ldv__builtin_expect((long )descriptor___1.flags & 1L, 0L);
#line 1060
  if (tmp___8 != 0L) {
#line 1060
    tmp___7 = get_current();
#line 1060
    __dynamic_pr_debug(& descriptor___1, "%s:%s:%d:(pid %d): npages %d, ncont %d, order %d, page_shift %d\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_reg_user_mr", 1061,
                       tmp___7->pid, npages, ncont, order, page_shift);
  } else {

  }
#line 1063
  tmp___12 = use_umr(order);
#line 1063
  if (tmp___12 != 0) {
#line 1064
    mr = reg_umr(pd, umem, virt_addr, length, ncont, page_shift, order, access_flags);
#line 1066
    tmp___11 = PTR_ERR((void const   *)mr);
#line 1066
    if (tmp___11 == -11L) {
#line 1067
      descriptor___2.modname = "mlx5_ib";
#line 1067
      descriptor___2.function = "mlx5_ib_reg_user_mr";
#line 1067
      descriptor___2.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1067
      descriptor___2.format = "%s:%s:%d:(pid %d): cache empty for order %d";
#line 1067
      descriptor___2.lineno = 1067U;
#line 1067
      descriptor___2.flags = 0U;
#line 1067
      tmp___10 = ldv__builtin_expect((long )descriptor___2.flags & 1L, 0L);
#line 1067
      if (tmp___10 != 0L) {
#line 1067
        tmp___9 = get_current();
#line 1067
        __dynamic_pr_debug(& descriptor___2, "%s:%s:%d:(pid %d): cache empty for order %d",
                           (char *)(& dev->ib_dev.name), "mlx5_ib_reg_user_mr", 1067,
                           tmp___9->pid, order);
      } else {

      }
#line 1068
      mr = (struct mlx5_ib_mr *)0;
    } else {

    }
  } else
#line 1070
  if ((access_flags & 64) != 0) {
#line 1071
    err = -22;
#line 1072
    printk("\vGot MR registration for ODP MR > 512MB, not supported for Connect-IB");
#line 1073
    goto error;
  } else {

  }
#line 1076
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 1077
    mr = reg_create(pd, virt_addr, length, umem, ncont, page_shift, access_flags);
  } else {

  }
#line 1080
  tmp___14 = IS_ERR((void const   *)mr);
#line 1080
  if ((int )tmp___14) {
#line 1081
    tmp___13 = PTR_ERR((void const   *)mr);
#line 1081
    err = (int )tmp___13;
#line 1082
    goto error;
  } else {

  }
#line 1085
  descriptor___3.modname = "mlx5_ib";
#line 1085
  descriptor___3.function = "mlx5_ib_reg_user_mr";
#line 1085
  descriptor___3.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1085
  descriptor___3.format = "%s:%s:%d:(pid %d): mkey 0x%x\n";
#line 1085
  descriptor___3.lineno = 1085U;
#line 1085
  descriptor___3.flags = 0U;
#line 1085
  tmp___16 = ldv__builtin_expect((long )descriptor___3.flags & 1L, 0L);
#line 1085
  if (tmp___16 != 0L) {
#line 1085
    tmp___15 = get_current();
#line 1085
    __dynamic_pr_debug(& descriptor___3, "%s:%s:%d:(pid %d): mkey 0x%x\n", (char *)(& dev->ib_dev.name),
                       "mlx5_ib_reg_user_mr", 1085, tmp___15->pid, mr->mmr.key);
  } else {

  }
#line 1087
  mr->umem = umem;
#line 1088
  mr->npages = npages;
#line 1089
  atomic_add(npages, & (dev->mdev)->priv.reg_pages);
#line 1090
  mr->ibmr.lkey = mr->mmr.key;
#line 1091
  mr->ibmr.rkey = mr->mmr.key;
#line 1094
  if ((unsigned long )umem->odp_data != (unsigned long )((struct ib_umem_odp *)0)) {
#line 1102
    __asm__  volatile   ("": : : "memory");
#line 1103
    ((mr->umem)->odp_data)->private = (void *)mr;
#line 1114
    __asm__  volatile   ("": : : "memory");
  } else {

  }
#line 1118
  return (& mr->ibmr);
  error: 
#line 1131
  ib_umem_release(umem);
#line 1133
  clean_mr(mr);
#line 1134
  tmp___17 = ERR_PTR((long )err);
#line 1134
  return ((struct ib_mr *)tmp___17);
}
}
#line 1137 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int unreg_umr(struct mlx5_ib_dev *dev , struct mlx5_ib_mr *mr ) 
{ 
  struct umr_common *umrc ;
  struct mlx5_ib_umr_context umr_context ;
  struct ib_send_wr wr ;
  struct ib_send_wr *bad ;
  int err ;
  struct _ddebug descriptor ;
  struct task_struct *tmp ;
  long tmp___0 ;
  struct task_struct *tmp___1 ;

  {
#line 1139
  umrc = & dev->umrc;
#line 1144
  memset((void *)(& wr), 0, 96UL);
#line 1145
  wr.wr_id = (unsigned long long )(& umr_context);
#line 1146
  prep_umr_unreg_wqe(dev, & wr, mr->mmr.key);
#line 1148
  mlx5_ib_init_umr_context(& umr_context);
#line 1149
  down(& umrc->sem);
#line 1150
  err = ib_post_send(umrc->qp, & wr, & bad);
#line 1151
  if (err != 0) {
#line 1152
    up(& umrc->sem);
#line 1153
    descriptor.modname = "mlx5_ib";
#line 1153
    descriptor.function = "unreg_umr";
#line 1153
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c";
#line 1153
    descriptor.format = "%s:%s:%d:(pid %d): err %d\n";
#line 1153
    descriptor.lineno = 1153U;
#line 1153
    descriptor.flags = 0U;
#line 1153
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 1153
    if (tmp___0 != 0L) {
#line 1153
      tmp = get_current();
#line 1153
      __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name),
                         "unreg_umr", 1153, tmp->pid, err);
    } else {

    }
#line 1154
    goto error;
  } else {
#line 1156
    wait_for_completion(& umr_context.done);
#line 1157
    up(& umrc->sem);
  }
#line 1159
  if ((unsigned int )umr_context.status != 0U) {
#line 1160
    tmp___1 = get_current();
#line 1160
    printk("\f%s:%s:%d:(pid %d): unreg umr failed\n", (char *)(& dev->ib_dev.name),
           "unreg_umr", 1160, tmp___1->pid);
#line 1161
    err = -14;
#line 1162
    goto error;
  } else {

  }
#line 1164
  return (0);
  error: ;
#line 1167
  return (err);
}
}
#line 1170 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
static int clean_mr(struct mlx5_ib_mr *mr ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int umred ;
  int err ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;

  {
#line 1172
  tmp = to_mdev(mr->ibmr.device);
#line 1172
  dev = tmp;
#line 1173
  umred = mr->umred;
#line 1176
  if (umred == 0) {
#line 1177
    err = destroy_mkey(dev, mr);
#line 1178
    if (err != 0) {
#line 1179
      tmp___0 = get_current();
#line 1179
      printk("\f%s:%s:%d:(pid %d): failed to destroy mkey 0x%x (%d)\n", (char *)(& dev->ib_dev.name),
             "clean_mr", 1180, tmp___0->pid, mr->mmr.key, err);
#line 1181
      return (err);
    } else {

    }
  } else {
#line 1184
    err = unreg_umr(dev, mr);
#line 1185
    if (err != 0) {
#line 1186
      tmp___1 = get_current();
#line 1186
      printk("\f%s:%s:%d:(pid %d): failed unregister\n", (char *)(& dev->ib_dev.name),
             "clean_mr", 1186, tmp___1->pid);
#line 1187
      return (err);
    } else {

    }
#line 1189
    free_cached_mr(dev, mr);
  }
#line 1192
  if (umred == 0) {
#line 1193
    kfree((void const   *)mr);
  } else {

  }
#line 1195
  return (0);
}
}
#line 1198 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
int mlx5_ib_dereg_mr(struct ib_mr *ibmr ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_mr *mr ;
  struct mlx5_ib_mr *tmp___0 ;
  int npages ;
  struct ib_umem *umem ;
  unsigned long tmp___1 ;
  unsigned long tmp___2 ;

  {
#line 1200
  tmp = to_mdev(ibmr->device);
#line 1200
  dev = tmp;
#line 1201
  tmp___0 = to_mmr(ibmr);
#line 1201
  mr = tmp___0;
#line 1202
  npages = mr->npages;
#line 1203
  umem = mr->umem;
#line 1206
  if ((unsigned long )umem != (unsigned long )((struct ib_umem *)0) && (unsigned long )umem->odp_data != (unsigned long )((struct ib_umem_odp *)0)) {
#line 1208
    mr->live = 0;
#line 1210
    synchronize_srcu(& dev->mr_srcu);
#line 1212
    tmp___1 = ib_umem_end(umem);
#line 1212
    tmp___2 = ib_umem_start(umem);
#line 1212
    mlx5_ib_invalidate_range(umem, tmp___2, tmp___1);
#line 1219
    ib_umem_release(umem);
#line 1220
    atomic_sub(npages, & (dev->mdev)->priv.reg_pages);
#line 1223
    umem = (struct ib_umem *)0;
  } else {

  }
#line 1227
  clean_mr(mr);
#line 1229
  if ((unsigned long )umem != (unsigned long )((struct ib_umem *)0)) {
#line 1230
    ib_umem_release(umem);
#line 1231
    atomic_sub(npages, & (dev->mdev)->priv.reg_pages);
  } else {

  }
#line 1234
  return (0);
}
}
#line 1237 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
struct ib_mr *mlx5_ib_create_mr(struct ib_pd *pd , struct ib_mr_init_attr *mr_init_attr ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_create_mkey_mbox_in *in ;
  struct mlx5_ib_mr *mr ;
  int access_mode ;
  int err ;
  int ndescs ;
  int __y ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  __u32 tmp___3 ;
  struct mlx5_ib_pd *tmp___4 ;
  __u32 tmp___5 ;
  u32 psv_index[2U] ;
  __u32 tmp___6 ;
  __u32 tmp___7 ;
  void *tmp___8 ;
  struct mlx5_ib_pd *tmp___9 ;
  struct task_struct *tmp___10 ;
  int tmp___11 ;
  struct task_struct *tmp___12 ;
  int tmp___13 ;
  void *tmp___14 ;

  {
#line 1240
  tmp = to_mdev(pd->device);
#line 1240
  dev = tmp;
#line 1244
  __y = 4;
#line 1244
  ndescs = ((mr_init_attr->max_reg_descriptors + (__y + -1)) / __y) * __y;
#line 1246
  tmp___0 = kzalloc(152UL, 208U);
#line 1246
  mr = (struct mlx5_ib_mr *)tmp___0;
#line 1247
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 1248
    tmp___1 = ERR_PTR(-12L);
#line 1248
    return ((struct ib_mr *)tmp___1);
  } else {

  }
#line 1250
  tmp___2 = kzalloc(272UL, 208U);
#line 1250
  in = (struct mlx5_create_mkey_mbox_in *)tmp___2;
#line 1251
  if ((unsigned long )in == (unsigned long )((struct mlx5_create_mkey_mbox_in *)0)) {
#line 1252
    err = -12;
#line 1253
    goto err_free;
  } else {

  }
#line 1256
  in->seg.status = 64U;
#line 1257
  tmp___3 = __fswab32((__u32 )ndescs);
#line 1257
  in->seg.xlt_oct_size = tmp___3;
#line 1258
  in->seg.qpn_mkey7_0 = 16777215U;
#line 1259
  tmp___4 = to_mpd(pd);
#line 1259
  tmp___5 = __fswab32(tmp___4->pdn);
#line 1259
  in->seg.flags_pd = tmp___5;
#line 1260
  access_mode = 1;
#line 1262
  if ((int )mr_init_attr->flags & 1) {
#line 1265
    tmp___6 = __fswab32(in->seg.flags_pd);
#line 1265
    tmp___7 = __fswab32(tmp___6 | 1073741824U);
#line 1265
    in->seg.flags_pd = tmp___7;
#line 1267
    in->seg.bsfs_octo_size = 67108864U;
#line 1268
    tmp___8 = kzalloc(80UL, 208U);
#line 1268
    mr->sig = (struct mlx5_core_sig_ctx *)tmp___8;
#line 1269
    if ((unsigned long )mr->sig == (unsigned long )((struct mlx5_core_sig_ctx *)0)) {
#line 1270
      err = -12;
#line 1271
      goto err_free_in;
    } else {

    }
#line 1275
    tmp___9 = to_mpd(pd);
#line 1275
    err = mlx5_core_create_psv(dev->mdev, tmp___9->pdn, 2, (u32 *)(& psv_index));
#line 1277
    if (err != 0) {
#line 1278
      goto err_free_sig;
    } else {

    }
#line 1280
    access_mode = 2;
#line 1281
    (mr->sig)->psv_memory.psv_idx = psv_index[0];
#line 1282
    (mr->sig)->psv_wire.psv_idx = psv_index[1];
#line 1284
    (mr->sig)->sig_status_checked = 1;
#line 1285
    (mr->sig)->sig_err_exists = 0;
#line 1287
    (mr->sig)->sigerr_count = (mr->sig)->sigerr_count + 1U;
  } else {

  }
#line 1290
  in->seg.flags = (u8 )((int )((signed char )access_mode) | -128);
#line 1291
  err = mlx5_core_create_mkey(dev->mdev, & mr->mmr, in, 272, (void (*)(int  , void * ))0,
                              (void *)0, (struct mlx5_create_mkey_mbox_out *)0);
#line 1293
  if (err != 0) {
#line 1294
    goto err_destroy_psv;
  } else {

  }
#line 1296
  mr->ibmr.lkey = mr->mmr.key;
#line 1297
  mr->ibmr.rkey = mr->mmr.key;
#line 1298
  mr->umem = (struct ib_umem *)0;
#line 1299
  kfree((void const   *)in);
#line 1301
  return (& mr->ibmr);
  err_destroy_psv: ;
#line 1304
  if ((unsigned long )mr->sig != (unsigned long )((struct mlx5_core_sig_ctx *)0)) {
#line 1305
    tmp___11 = mlx5_core_destroy_psv(dev->mdev, (int )(mr->sig)->psv_memory.psv_idx);
#line 1305
    if (tmp___11 != 0) {
#line 1307
      tmp___10 = get_current();
#line 1307
      printk("\f%s:%s:%d:(pid %d): failed to destroy mem psv %d\n", (char *)(& dev->ib_dev.name),
             "mlx5_ib_create_mr", 1308, tmp___10->pid, (mr->sig)->psv_memory.psv_idx);
    } else {

    }
#line 1309
    tmp___13 = mlx5_core_destroy_psv(dev->mdev, (int )(mr->sig)->psv_wire.psv_idx);
#line 1309
    if (tmp___13 != 0) {
#line 1311
      tmp___12 = get_current();
#line 1311
      printk("\f%s:%s:%d:(pid %d): failed to destroy wire psv %d\n", (char *)(& dev->ib_dev.name),
             "mlx5_ib_create_mr", 1312, tmp___12->pid, (mr->sig)->psv_wire.psv_idx);
    } else {

    }
  } else {

  }
  err_free_sig: 
#line 1315
  kfree((void const   *)mr->sig);
  err_free_in: 
#line 1317
  kfree((void const   *)in);
  err_free: 
#line 1319
  kfree((void const   *)mr);
#line 1320
  tmp___14 = ERR_PTR((long )err);
#line 1320
  return ((struct ib_mr *)tmp___14);
}
}
#line 1323 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
int mlx5_ib_destroy_mr(struct ib_mr *ibmr ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_mr *mr ;
  struct mlx5_ib_mr *tmp___0 ;
  int err ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  struct task_struct *tmp___3 ;
  int tmp___4 ;
  struct task_struct *tmp___5 ;

  {
#line 1325
  tmp = to_mdev(ibmr->device);
#line 1325
  dev = tmp;
#line 1326
  tmp___0 = to_mmr(ibmr);
#line 1326
  mr = tmp___0;
#line 1329
  if ((unsigned long )mr->sig != (unsigned long )((struct mlx5_core_sig_ctx *)0)) {
#line 1330
    tmp___2 = mlx5_core_destroy_psv(dev->mdev, (int )(mr->sig)->psv_memory.psv_idx);
#line 1330
    if (tmp___2 != 0) {
#line 1332
      tmp___1 = get_current();
#line 1332
      printk("\f%s:%s:%d:(pid %d): failed to destroy mem psv %d\n", (char *)(& dev->ib_dev.name),
             "mlx5_ib_destroy_mr", 1333, tmp___1->pid, (mr->sig)->psv_memory.psv_idx);
    } else {

    }
#line 1334
    tmp___4 = mlx5_core_destroy_psv(dev->mdev, (int )(mr->sig)->psv_wire.psv_idx);
#line 1334
    if (tmp___4 != 0) {
#line 1336
      tmp___3 = get_current();
#line 1336
      printk("\f%s:%s:%d:(pid %d): failed to destroy wire psv %d\n", (char *)(& dev->ib_dev.name),
             "mlx5_ib_destroy_mr", 1337, tmp___3->pid, (mr->sig)->psv_wire.psv_idx);
    } else {

    }
#line 1338
    kfree((void const   *)mr->sig);
  } else {

  }
#line 1341
  err = destroy_mkey(dev, mr);
#line 1342
  if (err != 0) {
#line 1343
    tmp___5 = get_current();
#line 1343
    printk("\f%s:%s:%d:(pid %d): failed to destroy mkey 0x%x (%d)\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_destroy_mr", 1344, tmp___5->pid, mr->mmr.key, err);
#line 1345
    return (err);
  } else {

  }
#line 1348
  kfree((void const   *)mr);
#line 1350
  return (err);
}
}
#line 1353 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
struct ib_mr *mlx5_ib_alloc_fast_reg_mr(struct ib_pd *pd , int max_page_list_len ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_create_mkey_mbox_in *in ;
  struct mlx5_ib_mr *mr ;
  int err ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  __u32 tmp___3 ;
  struct mlx5_ib_pd *tmp___4 ;
  __u32 tmp___5 ;
  void *tmp___6 ;

  {
#line 1356
  tmp = to_mdev(pd->device);
#line 1356
  dev = tmp;
#line 1361
  tmp___0 = kzalloc(152UL, 208U);
#line 1361
  mr = (struct mlx5_ib_mr *)tmp___0;
#line 1362
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0)) {
#line 1363
    tmp___1 = ERR_PTR(-12L);
#line 1363
    return ((struct ib_mr *)tmp___1);
  } else {

  }
#line 1365
  tmp___2 = kzalloc(272UL, 208U);
#line 1365
  in = (struct mlx5_create_mkey_mbox_in *)tmp___2;
#line 1366
  if ((unsigned long )in == (unsigned long )((struct mlx5_create_mkey_mbox_in *)0)) {
#line 1367
    err = -12;
#line 1368
    goto err_free;
  } else {

  }
#line 1371
  in->seg.status = 64U;
#line 1372
  tmp___3 = __fswab32((__u32 )((max_page_list_len + 1) / 2));
#line 1372
  in->seg.xlt_oct_size = tmp___3;
#line 1373
  in->seg.qpn_mkey7_0 = 16777215U;
#line 1374
  in->seg.flags = 129U;
#line 1375
  tmp___4 = to_mpd(pd);
#line 1375
  tmp___5 = __fswab32(tmp___4->pdn);
#line 1375
  in->seg.flags_pd = tmp___5;
#line 1378
  in->seg.log2_page_size = 12U;
#line 1380
  err = mlx5_core_create_mkey(dev->mdev, & mr->mmr, in, 272, (void (*)(int  , void * ))0,
                              (void *)0, (struct mlx5_create_mkey_mbox_out *)0);
#line 1382
  kfree((void const   *)in);
#line 1383
  if (err != 0) {
#line 1384
    goto err_free;
  } else {

  }
#line 1386
  mr->ibmr.lkey = mr->mmr.key;
#line 1387
  mr->ibmr.rkey = mr->mmr.key;
#line 1388
  mr->umem = (struct ib_umem *)0;
#line 1390
  return (& mr->ibmr);
  err_free: 
#line 1393
  kfree((void const   *)mr);
#line 1394
  tmp___6 = ERR_PTR((long )err);
#line 1394
  return ((struct ib_mr *)tmp___6);
}
}
#line 1397 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
struct ib_fast_reg_page_list *mlx5_ib_alloc_fast_reg_page_list(struct ib_device *ibdev ,
                                                               int page_list_len ) 
{ 
  struct mlx5_ib_fast_reg_page_list *mfrpl ;
  int size ;
  void *tmp ;
  void *tmp___0 ;
  void *tmp___1 ;
  void *tmp___2 ;
  int __ret_warn_on ;
  long tmp___3 ;
  void *tmp___4 ;

  {
#line 1401
  size = (int )((unsigned int )page_list_len * 8U);
#line 1403
  tmp = kmalloc(40UL, 208U);
#line 1403
  mfrpl = (struct mlx5_ib_fast_reg_page_list *)tmp;
#line 1404
  if ((unsigned long )mfrpl == (unsigned long )((struct mlx5_ib_fast_reg_page_list *)0)) {
#line 1405
    tmp___0 = ERR_PTR(-12L);
#line 1405
    return ((struct ib_fast_reg_page_list *)tmp___0);
  } else {

  }
#line 1407
  tmp___1 = kmalloc((size_t )size, 208U);
#line 1407
  mfrpl->ibfrpl.page_list = (u64 *)tmp___1;
#line 1408
  if ((unsigned long )mfrpl->ibfrpl.page_list == (unsigned long )((u64 *)0ULL)) {
#line 1409
    goto err_free;
  } else {

  }
#line 1411
  tmp___2 = dma_alloc_attrs(ibdev->dma_device, (size_t )size, & mfrpl->map, 208U,
                            (struct dma_attrs *)0);
#line 1411
  mfrpl->mapped_page_list = (__be64 *)tmp___2;
#line 1414
  if ((unsigned long )mfrpl->mapped_page_list == (unsigned long )((__be64 *)0ULL)) {
#line 1415
    goto err_free;
  } else {

  }
#line 1417
  __ret_warn_on = (mfrpl->map & 63ULL) != 0ULL;
#line 1417
  tmp___3 = ldv__builtin_expect(__ret_warn_on != 0, 0L);
#line 1417
  if (tmp___3 != 0L) {
#line 1417
    warn_slowpath_null("/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c",
                       1417);
  } else {

  }
#line 1417
  ldv__builtin_expect(__ret_warn_on != 0, 0L);
#line 1419
  return (& mfrpl->ibfrpl);
  err_free: 
#line 1422
  kfree((void const   *)mfrpl->ibfrpl.page_list);
#line 1423
  kfree((void const   *)mfrpl);
#line 1424
  tmp___4 = ERR_PTR(-12L);
#line 1424
  return ((struct ib_fast_reg_page_list *)tmp___4);
}
}
#line 1427 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
void mlx5_ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list ) 
{ 
  struct mlx5_ib_fast_reg_page_list *mfrpl ;
  struct mlx5_ib_fast_reg_page_list *tmp ;
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp___0 ;
  int size ;

  {
#line 1429
  tmp = to_mfrpl(page_list);
#line 1429
  mfrpl = tmp;
#line 1430
  tmp___0 = to_mdev(page_list->device);
#line 1430
  dev = tmp___0;
#line 1431
  size = (int )(page_list->max_page_list_len * 8U);
#line 1433
  dma_free_attrs(& ((dev->mdev)->pdev)->dev, (size_t )size, (void *)mfrpl->mapped_page_list,
                 mfrpl->map, (struct dma_attrs *)0);
#line 1435
  kfree((void const   *)mfrpl->ibfrpl.page_list);
#line 1436
  kfree((void const   *)mfrpl);
#line 1437
  return;
}
}
#line 1439 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.c"
int mlx5_ib_check_mr_status(struct ib_mr *ibmr , u32 check_mask , struct ib_mr_status *mr_status ) 
{ 
  struct mlx5_ib_mr *mmr ;
  struct mlx5_ib_mr *tmp ;
  int ret ;

  {
#line 1442
  tmp = to_mmr(ibmr);
#line 1442
  mmr = tmp;
#line 1443
  ret = 0;
#line 1445
  if ((check_mask & 4294967294U) != 0U) {
#line 1446
    printk("\vInvalid status check mask\n");
#line 1447
    ret = -22;
#line 1448
    goto done;
  } else {

  }
#line 1451
  mr_status->fail_status = 0U;
#line 1452
  if ((int )check_mask & 1) {
#line 1453
    if ((unsigned long )mmr->sig == (unsigned long )((struct mlx5_core_sig_ctx *)0)) {
#line 1454
      ret = -22;
#line 1455
      printk("\vsignature status check requested on a non-signature enabled MR\n");
#line 1456
      goto done;
    } else {

    }
#line 1459
    (mmr->sig)->sig_status_checked = 1;
#line 1460
    if (! (mmr->sig)->sig_err_exists) {
#line 1461
      goto done;
    } else {

    }
#line 1463
    if (ibmr->lkey == (mmr->sig)->err_item.key) {
#line 1464
      memcpy((void *)(& mr_status->sig_err), (void const   *)(& (mmr->sig)->err_item),
               32UL);
    } else {
#line 1467
      mr_status->sig_err.err_type = 0;
#line 1468
      mr_status->sig_err.sig_err_offset = 0ULL;
#line 1469
      mr_status->sig_err.key = (mmr->sig)->err_item.key;
    }
#line 1472
    (mmr->sig)->sig_err_exists = 0;
#line 1473
    mr_status->fail_status = mr_status->fail_status | 1U;
  } else {

  }
  done: ;
#line 1477
  return (ret);
}
}
#line 103 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
int ldv_retval_0  ;
#line 104
extern int ldv_release_6(void) ;
#line 105
extern int ldv_release_5(void) ;
#line 106 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
int ldv_retval_2  ;
#line 109 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_file_operations_6(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
#line 110
  tmp = ldv_init_zalloc(1000UL);
#line 110
  size_fops_group1 = (struct inode *)tmp;
#line 111
  tmp___0 = ldv_init_zalloc(504UL);
#line 111
  size_fops_group2 = (struct file *)tmp___0;
#line 112
  return;
}
}
#line 115 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void call_and_disable_work_1(struct work_struct *work ) 
{ 


  {
#line 118
  if ((ldv_work_1_0 == 2 || ldv_work_1_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_0) {
#line 120
    cache_work_func(work);
#line 121
    ldv_work_1_0 = 1;
#line 122
    return;
  } else {

  }
#line 124
  if ((ldv_work_1_1 == 2 || ldv_work_1_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_1) {
#line 126
    cache_work_func(work);
#line 127
    ldv_work_1_1 = 1;
#line 128
    return;
  } else {

  }
#line 130
  if ((ldv_work_1_2 == 2 || ldv_work_1_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_2) {
#line 132
    cache_work_func(work);
#line 133
    ldv_work_1_2 = 1;
#line 134
    return;
  } else {

  }
#line 136
  if ((ldv_work_1_3 == 2 || ldv_work_1_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_1_3) {
#line 138
    cache_work_func(work);
#line 139
    ldv_work_1_3 = 1;
#line 140
    return;
  } else {

  }
#line 142
  return;
}
}
#line 145 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void work_init_2(void) 
{ 


  {
#line 146
  ldv_work_2_0 = 0;
#line 147
  ldv_work_2_1 = 0;
#line 148
  ldv_work_2_2 = 0;
#line 149
  ldv_work_2_3 = 0;
#line 150
  return;
}
}
#line 153 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void activate_pending_timer_4(struct timer_list *timer , unsigned long data , int pending_flag ) 
{ 


  {
#line 154
  if ((unsigned long )ldv_timer_list_4_0 == (unsigned long )timer) {
#line 155
    if (ldv_timer_4_0 == 2 || pending_flag != 0) {
#line 156
      ldv_timer_list_4_0 = timer;
#line 157
      ldv_timer_list_4_0->data = data;
#line 158
      ldv_timer_4_0 = 1;
    } else {

    }
#line 160
    return;
  } else {

  }
#line 163
  if ((unsigned long )ldv_timer_list_4_1 == (unsigned long )timer) {
#line 164
    if (ldv_timer_4_1 == 2 || pending_flag != 0) {
#line 165
      ldv_timer_list_4_1 = timer;
#line 166
      ldv_timer_list_4_1->data = data;
#line 167
      ldv_timer_4_1 = 1;
    } else {

    }
#line 169
    return;
  } else {

  }
#line 172
  if ((unsigned long )ldv_timer_list_4_2 == (unsigned long )timer) {
#line 173
    if (ldv_timer_4_2 == 2 || pending_flag != 0) {
#line 174
      ldv_timer_list_4_2 = timer;
#line 175
      ldv_timer_list_4_2->data = data;
#line 176
      ldv_timer_4_2 = 1;
    } else {

    }
#line 178
    return;
  } else {

  }
#line 181
  if ((unsigned long )ldv_timer_list_4_3 == (unsigned long )timer) {
#line 182
    if (ldv_timer_4_3 == 2 || pending_flag != 0) {
#line 183
      ldv_timer_list_4_3 = timer;
#line 184
      ldv_timer_list_4_3->data = data;
#line 185
      ldv_timer_4_3 = 1;
    } else {

    }
#line 187
    return;
  } else {

  }
#line 189
  activate_suitable_timer_4(timer, data);
#line 190
  return;
}
}
#line 193 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void call_and_disable_all_2(int state ) 
{ 


  {
#line 195
  if (ldv_work_2_0 == state) {
#line 196
    call_and_disable_work_2(ldv_work_struct_2_0);
  } else {

  }
#line 197
  if (ldv_work_2_1 == state) {
#line 198
    call_and_disable_work_2(ldv_work_struct_2_1);
  } else {

  }
#line 199
  if (ldv_work_2_2 == state) {
#line 200
    call_and_disable_work_2(ldv_work_struct_2_2);
  } else {

  }
#line 201
  if (ldv_work_2_3 == state) {
#line 202
    call_and_disable_work_2(ldv_work_struct_2_3);
  } else {

  }
#line 203
  return;
}
}
#line 206 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void call_and_disable_all_1(int state ) 
{ 


  {
#line 208
  if (ldv_work_1_0 == state) {
#line 209
    call_and_disable_work_1(ldv_work_struct_1_0);
  } else {

  }
#line 210
  if (ldv_work_1_1 == state) {
#line 211
    call_and_disable_work_1(ldv_work_struct_1_1);
  } else {

  }
#line 212
  if (ldv_work_1_2 == state) {
#line 213
    call_and_disable_work_1(ldv_work_struct_1_2);
  } else {

  }
#line 214
  if (ldv_work_1_3 == state) {
#line 215
    call_and_disable_work_1(ldv_work_struct_1_3);
  } else {

  }
#line 216
  return;
}
}
#line 219 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void activate_work_2(struct work_struct *work , int state ) 
{ 


  {
#line 220
  if (ldv_work_2_0 == 0) {
#line 221
    ldv_work_struct_2_0 = work;
#line 222
    ldv_work_2_0 = state;
#line 223
    return;
  } else {

  }
#line 226
  if (ldv_work_2_1 == 0) {
#line 227
    ldv_work_struct_2_1 = work;
#line 228
    ldv_work_2_1 = state;
#line 229
    return;
  } else {

  }
#line 232
  if (ldv_work_2_2 == 0) {
#line 233
    ldv_work_struct_2_2 = work;
#line 234
    ldv_work_2_2 = state;
#line 235
    return;
  } else {

  }
#line 238
  if (ldv_work_2_3 == 0) {
#line 239
    ldv_work_struct_2_3 = work;
#line 240
    ldv_work_2_3 = state;
#line 241
    return;
  } else {

  }
#line 243
  return;
}
}
#line 246 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void timer_init_4(void) 
{ 


  {
#line 247
  ldv_timer_4_0 = 0;
#line 248
  ldv_timer_4_1 = 0;
#line 249
  ldv_timer_4_2 = 0;
#line 250
  ldv_timer_4_3 = 0;
#line 251
  return;
}
}
#line 254 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void activate_work_1(struct work_struct *work , int state ) 
{ 


  {
#line 255
  if (ldv_work_1_0 == 0) {
#line 256
    ldv_work_struct_1_0 = work;
#line 257
    ldv_work_1_0 = state;
#line 258
    return;
  } else {

  }
#line 261
  if (ldv_work_1_1 == 0) {
#line 262
    ldv_work_struct_1_1 = work;
#line 263
    ldv_work_1_1 = state;
#line 264
    return;
  } else {

  }
#line 267
  if (ldv_work_1_2 == 0) {
#line 268
    ldv_work_struct_1_2 = work;
#line 269
    ldv_work_1_2 = state;
#line 270
    return;
  } else {

  }
#line 273
  if (ldv_work_1_3 == 0) {
#line 274
    ldv_work_struct_1_3 = work;
#line 275
    ldv_work_1_3 = state;
#line 276
    return;
  } else {

  }
#line 278
  return;
}
}
#line 281 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void choose_timer_4(void) 
{ 
  int tmp ;

  {
#line 282
  tmp = __VERIFIER_nondet_int();
#line 282
  switch (tmp) {
  case 0: ;
#line 284
  if (ldv_timer_4_0 == 1) {
#line 285
    ldv_timer_4_0 = 2;
#line 286
    ldv_timer_4(ldv_timer_4_0, ldv_timer_list_4_0);
  } else {

  }
#line 289
  goto ldv_41415;
  case 1: ;
#line 291
  if (ldv_timer_4_1 == 1) {
#line 292
    ldv_timer_4_1 = 2;
#line 293
    ldv_timer_4(ldv_timer_4_1, ldv_timer_list_4_1);
  } else {

  }
#line 296
  goto ldv_41415;
  case 2: ;
#line 298
  if (ldv_timer_4_2 == 1) {
#line 299
    ldv_timer_4_2 = 2;
#line 300
    ldv_timer_4(ldv_timer_4_2, ldv_timer_list_4_2);
  } else {

  }
#line 303
  goto ldv_41415;
  case 3: ;
#line 305
  if (ldv_timer_4_3 == 1) {
#line 306
    ldv_timer_4_3 = 2;
#line 307
    ldv_timer_4(ldv_timer_4_3, ldv_timer_list_4_3);
  } else {

  }
#line 310
  goto ldv_41415;
  default: 
#line 311
  ldv_stop();
  }
  ldv_41415: ;
#line 313
  return;
}
}
#line 317 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void disable_suitable_timer_4(struct timer_list *timer ) 
{ 


  {
#line 318
  if (ldv_timer_4_0 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_4_0) {
#line 319
    ldv_timer_4_0 = 0;
#line 320
    return;
  } else {

  }
#line 322
  if (ldv_timer_4_1 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_4_1) {
#line 323
    ldv_timer_4_1 = 0;
#line 324
    return;
  } else {

  }
#line 326
  if (ldv_timer_4_2 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_4_2) {
#line 327
    ldv_timer_4_2 = 0;
#line 328
    return;
  } else {

  }
#line 330
  if (ldv_timer_4_3 != 0 && (unsigned long )timer == (unsigned long )ldv_timer_list_4_3) {
#line 331
    ldv_timer_4_3 = 0;
#line 332
    return;
  } else {

  }
#line 334
  return;
}
}
#line 338 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void disable_work_2(struct work_struct *work ) 
{ 


  {
#line 340
  if ((ldv_work_2_0 == 3 || ldv_work_2_0 == 2) && (unsigned long )ldv_work_struct_2_0 == (unsigned long )work) {
#line 342
    ldv_work_2_0 = 1;
  } else {

  }
#line 344
  if ((ldv_work_2_1 == 3 || ldv_work_2_1 == 2) && (unsigned long )ldv_work_struct_2_1 == (unsigned long )work) {
#line 346
    ldv_work_2_1 = 1;
  } else {

  }
#line 348
  if ((ldv_work_2_2 == 3 || ldv_work_2_2 == 2) && (unsigned long )ldv_work_struct_2_2 == (unsigned long )work) {
#line 350
    ldv_work_2_2 = 1;
  } else {

  }
#line 352
  if ((ldv_work_2_3 == 3 || ldv_work_2_3 == 2) && (unsigned long )ldv_work_struct_2_3 == (unsigned long )work) {
#line 354
    ldv_work_2_3 = 1;
  } else {

  }
#line 355
  return;
}
}
#line 359 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void disable_work_1(struct work_struct *work ) 
{ 


  {
#line 361
  if ((ldv_work_1_0 == 3 || ldv_work_1_0 == 2) && (unsigned long )ldv_work_struct_1_0 == (unsigned long )work) {
#line 363
    ldv_work_1_0 = 1;
  } else {

  }
#line 365
  if ((ldv_work_1_1 == 3 || ldv_work_1_1 == 2) && (unsigned long )ldv_work_struct_1_1 == (unsigned long )work) {
#line 367
    ldv_work_1_1 = 1;
  } else {

  }
#line 369
  if ((ldv_work_1_2 == 3 || ldv_work_1_2 == 2) && (unsigned long )ldv_work_struct_1_2 == (unsigned long )work) {
#line 371
    ldv_work_1_2 = 1;
  } else {

  }
#line 373
  if ((ldv_work_1_3 == 3 || ldv_work_1_3 == 2) && (unsigned long )ldv_work_struct_1_3 == (unsigned long )work) {
#line 375
    ldv_work_1_3 = 1;
  } else {

  }
#line 376
  return;
}
}
#line 380 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
int reg_timer_4(struct timer_list *timer , void (*function)(unsigned long  ) , unsigned long data ) 
{ 


  {
#line 381
  if ((unsigned long )function == (unsigned long )(& delay_time_func)) {
#line 382
    activate_suitable_timer_4(timer, data);
  } else {

  }
#line 383
  return (0);
}
}
#line 387 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void work_init_1(void) 
{ 


  {
#line 388
  ldv_work_1_0 = 0;
#line 389
  ldv_work_1_1 = 0;
#line 390
  ldv_work_1_2 = 0;
#line 391
  ldv_work_1_3 = 0;
#line 392
  return;
}
}
#line 395 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void invoke_work_1(void) 
{ 
  int tmp ;

  {
#line 397
  tmp = __VERIFIER_nondet_int();
#line 397
  switch (tmp) {
  case 0: ;
#line 399
  if (ldv_work_1_0 == 2 || ldv_work_1_0 == 3) {
#line 400
    ldv_work_1_0 = 4;
#line 401
    cache_work_func(ldv_work_struct_1_0);
#line 402
    ldv_work_1_0 = 1;
  } else {

  }
#line 405
  goto ldv_41444;
  case 1: ;
#line 407
  if (ldv_work_1_1 == 2 || ldv_work_1_1 == 3) {
#line 408
    ldv_work_1_1 = 4;
#line 409
    cache_work_func(ldv_work_struct_1_0);
#line 410
    ldv_work_1_1 = 1;
  } else {

  }
#line 413
  goto ldv_41444;
  case 2: ;
#line 415
  if (ldv_work_1_2 == 2 || ldv_work_1_2 == 3) {
#line 416
    ldv_work_1_2 = 4;
#line 417
    cache_work_func(ldv_work_struct_1_0);
#line 418
    ldv_work_1_2 = 1;
  } else {

  }
#line 421
  goto ldv_41444;
  case 3: ;
#line 423
  if (ldv_work_1_3 == 2 || ldv_work_1_3 == 3) {
#line 424
    ldv_work_1_3 = 4;
#line 425
    cache_work_func(ldv_work_struct_1_0);
#line 426
    ldv_work_1_3 = 1;
  } else {

  }
#line 429
  goto ldv_41444;
  default: 
#line 430
  ldv_stop();
  }
  ldv_41444: ;
#line 432
  return;
}
}
#line 436 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_file_operations_5(void) 
{ 
  void *tmp ;
  void *tmp___0 ;

  {
#line 437
  tmp = ldv_init_zalloc(1000UL);
#line 437
  limit_fops_group1 = (struct inode *)tmp;
#line 438
  tmp___0 = ldv_init_zalloc(504UL);
#line 438
  limit_fops_group2 = (struct file *)tmp___0;
#line 439
  return;
}
}
#line 442 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_timer_4(int state , struct timer_list *timer ) 
{ 


  {
#line 443
  LDV_IN_INTERRUPT = 2;
#line 444
  delay_time_func(timer->data);
#line 445
  LDV_IN_INTERRUPT = 1;
#line 446
  return;
}
}
#line 449 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void activate_suitable_timer_4(struct timer_list *timer , unsigned long data ) 
{ 


  {
#line 450
  if (ldv_timer_4_0 == 0 || ldv_timer_4_0 == 2) {
#line 451
    ldv_timer_list_4_0 = timer;
#line 452
    ldv_timer_list_4_0->data = data;
#line 453
    ldv_timer_4_0 = 1;
#line 454
    return;
  } else {

  }
#line 456
  if (ldv_timer_4_1 == 0 || ldv_timer_4_1 == 2) {
#line 457
    ldv_timer_list_4_1 = timer;
#line 458
    ldv_timer_list_4_1->data = data;
#line 459
    ldv_timer_4_1 = 1;
#line 460
    return;
  } else {

  }
#line 462
  if (ldv_timer_4_2 == 0 || ldv_timer_4_2 == 2) {
#line 463
    ldv_timer_list_4_2 = timer;
#line 464
    ldv_timer_list_4_2->data = data;
#line 465
    ldv_timer_4_2 = 1;
#line 466
    return;
  } else {

  }
#line 468
  if (ldv_timer_4_3 == 0 || ldv_timer_4_3 == 2) {
#line 469
    ldv_timer_list_4_3 = timer;
#line 470
    ldv_timer_list_4_3->data = data;
#line 471
    ldv_timer_4_3 = 1;
#line 472
    return;
  } else {

  }
#line 474
  return;
}
}
#line 478 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void call_and_disable_work_2(struct work_struct *work ) 
{ 


  {
#line 481
  if ((ldv_work_2_0 == 2 || ldv_work_2_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_0) {
#line 483
    delayed_cache_work_func(work);
#line 484
    ldv_work_2_0 = 1;
#line 485
    return;
  } else {

  }
#line 487
  if ((ldv_work_2_1 == 2 || ldv_work_2_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_1) {
#line 489
    delayed_cache_work_func(work);
#line 490
    ldv_work_2_1 = 1;
#line 491
    return;
  } else {

  }
#line 493
  if ((ldv_work_2_2 == 2 || ldv_work_2_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_2) {
#line 495
    delayed_cache_work_func(work);
#line 496
    ldv_work_2_2 = 1;
#line 497
    return;
  } else {

  }
#line 499
  if ((ldv_work_2_3 == 2 || ldv_work_2_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_2_3) {
#line 501
    delayed_cache_work_func(work);
#line 502
    ldv_work_2_3 = 1;
#line 503
    return;
  } else {

  }
#line 505
  return;
}
}
#line 508 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void invoke_work_2(void) 
{ 
  int tmp ;

  {
#line 510
  tmp = __VERIFIER_nondet_int();
#line 510
  switch (tmp) {
  case 0: ;
#line 512
  if (ldv_work_2_0 == 2 || ldv_work_2_0 == 3) {
#line 513
    ldv_work_2_0 = 4;
#line 514
    delayed_cache_work_func(ldv_work_struct_2_0);
#line 515
    ldv_work_2_0 = 1;
  } else {

  }
#line 518
  goto ldv_41471;
  case 1: ;
#line 520
  if (ldv_work_2_1 == 2 || ldv_work_2_1 == 3) {
#line 521
    ldv_work_2_1 = 4;
#line 522
    delayed_cache_work_func(ldv_work_struct_2_0);
#line 523
    ldv_work_2_1 = 1;
  } else {

  }
#line 526
  goto ldv_41471;
  case 2: ;
#line 528
  if (ldv_work_2_2 == 2 || ldv_work_2_2 == 3) {
#line 529
    ldv_work_2_2 = 4;
#line 530
    delayed_cache_work_func(ldv_work_struct_2_0);
#line 531
    ldv_work_2_2 = 1;
  } else {

  }
#line 534
  goto ldv_41471;
  case 3: ;
#line 536
  if (ldv_work_2_3 == 2 || ldv_work_2_3 == 3) {
#line 537
    ldv_work_2_3 = 4;
#line 538
    delayed_cache_work_func(ldv_work_struct_2_0);
#line 539
    ldv_work_2_3 = 1;
  } else {

  }
#line 542
  goto ldv_41471;
  default: 
#line 543
  ldv_stop();
  }
  ldv_41471: ;
#line 545
  return;
}
}
#line 549 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_main_exported_6(void) 
{ 
  char *ldvarg2 ;
  void *tmp ;
  char *ldvarg5 ;
  void *tmp___0 ;
  loff_t *ldvarg0 ;
  void *tmp___1 ;
  loff_t *ldvarg3 ;
  void *tmp___2 ;
  size_t ldvarg4 ;
  size_t ldvarg1 ;
  int tmp___3 ;

  {
#line 550
  tmp = ldv_init_zalloc(1UL);
#line 550
  ldvarg2 = (char *)tmp;
#line 551
  tmp___0 = ldv_init_zalloc(1UL);
#line 551
  ldvarg5 = (char *)tmp___0;
#line 552
  tmp___1 = ldv_init_zalloc(8UL);
#line 552
  ldvarg0 = (loff_t *)tmp___1;
#line 553
  tmp___2 = ldv_init_zalloc(8UL);
#line 553
  ldvarg3 = (loff_t *)tmp___2;
#line 554
  ldv_memset((void *)(& ldvarg4), 0, 8UL);
#line 555
  ldv_memset((void *)(& ldvarg1), 0, 8UL);
#line 557
  tmp___3 = __VERIFIER_nondet_int();
#line 557
  switch (tmp___3) {
  case 0: ;
#line 560
  if (ldv_state_variable_6 == 1) {
#line 562
    size_write(size_fops_group2, (char const   *)ldvarg5, ldvarg4, ldvarg3);
#line 564
    ldv_state_variable_6 = 1;
  } else {

  }
#line 567
  if (ldv_state_variable_6 == 2) {
#line 569
    size_write(size_fops_group2, (char const   *)ldvarg5, ldvarg4, ldvarg3);
#line 571
    ldv_state_variable_6 = 2;
  } else {

  }
#line 574
  goto ldv_41486;
  case 1: ;
#line 577
  if (ldv_state_variable_6 == 2) {
#line 579
    size_read(size_fops_group2, ldvarg2, ldvarg1, ldvarg0);
#line 581
    ldv_state_variable_6 = 2;
  } else {

  }
#line 584
  goto ldv_41486;
  case 2: ;
#line 587
  if (ldv_state_variable_6 == 1) {
#line 589
    ldv_retval_0 = simple_open(size_fops_group1, size_fops_group2);
#line 590
    if (ldv_retval_0 == 0) {
#line 591
      ldv_state_variable_6 = 2;
#line 592
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
#line 596
  goto ldv_41486;
  case 3: ;
#line 599
  if (ldv_state_variable_6 == 2) {
#line 601
    ldv_release_6();
#line 602
    ldv_state_variable_6 = 1;
#line 603
    ref_cnt = ref_cnt - 1;
  } else {

  }
#line 606
  goto ldv_41486;
  default: 
#line 607
  ldv_stop();
  }
  ldv_41486: ;
#line 611
  return;
}
}
#line 616 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_main_exported_5(void) 
{ 
  char *ldvarg30 ;
  void *tmp ;
  char *ldvarg33 ;
  void *tmp___0 ;
  loff_t *ldvarg28 ;
  void *tmp___1 ;
  size_t ldvarg29 ;
  loff_t *ldvarg31 ;
  void *tmp___2 ;
  size_t ldvarg32 ;
  int tmp___3 ;

  {
#line 617
  tmp = ldv_init_zalloc(1UL);
#line 617
  ldvarg30 = (char *)tmp;
#line 618
  tmp___0 = ldv_init_zalloc(1UL);
#line 618
  ldvarg33 = (char *)tmp___0;
#line 619
  tmp___1 = ldv_init_zalloc(8UL);
#line 619
  ldvarg28 = (loff_t *)tmp___1;
#line 621
  tmp___2 = ldv_init_zalloc(8UL);
#line 621
  ldvarg31 = (loff_t *)tmp___2;
#line 620
  ldv_memset((void *)(& ldvarg29), 0, 8UL);
#line 622
  ldv_memset((void *)(& ldvarg32), 0, 8UL);
#line 624
  tmp___3 = __VERIFIER_nondet_int();
#line 624
  switch (tmp___3) {
  case 0: ;
#line 627
  if (ldv_state_variable_5 == 1) {
#line 629
    limit_write(limit_fops_group2, (char const   *)ldvarg33, ldvarg32, ldvarg31);
#line 631
    ldv_state_variable_5 = 1;
  } else {

  }
#line 634
  if (ldv_state_variable_5 == 2) {
#line 636
    limit_write(limit_fops_group2, (char const   *)ldvarg33, ldvarg32, ldvarg31);
#line 638
    ldv_state_variable_5 = 2;
  } else {

  }
#line 641
  goto ldv_41501;
  case 1: ;
#line 644
  if (ldv_state_variable_5 == 2) {
#line 646
    limit_read(limit_fops_group2, ldvarg30, ldvarg29, ldvarg28);
#line 648
    ldv_state_variable_5 = 2;
  } else {

  }
#line 651
  goto ldv_41501;
  case 2: ;
#line 654
  if (ldv_state_variable_5 == 1) {
#line 656
    ldv_retval_2 = simple_open(limit_fops_group1, limit_fops_group2);
#line 657
    if (ldv_retval_2 == 0) {
#line 658
      ldv_state_variable_5 = 2;
#line 659
      ref_cnt = ref_cnt + 1;
    } else {

    }
  } else {

  }
#line 663
  goto ldv_41501;
  case 3: ;
#line 666
  if (ldv_state_variable_5 == 2) {
#line 668
    ldv_release_5();
#line 669
    ldv_state_variable_5 = 1;
#line 670
    ref_cnt = ref_cnt - 1;
  } else {

  }
#line 673
  goto ldv_41501;
  default: 
#line 674
  ldv_stop();
  }
  ldv_41501: ;
#line 678
  return;
}
}
#line 703 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
bool ldv_queue_work_on_91(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 707
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 707
  ldv_func_res = tmp;
#line 709
  activate_work_3(ldv_func_arg3, 2);
#line 711
  return (ldv_func_res);
}
}
#line 714 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
bool ldv_queue_delayed_work_on_92(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 718
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 718
  ldv_func_res = tmp;
#line 720
  activate_work_3(& ldv_func_arg3->work, 2);
#line 722
  return (ldv_func_res);
}
}
#line 725 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
bool ldv_queue_work_on_93(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                          struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 729
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 729
  ldv_func_res = tmp;
#line 731
  activate_work_3(ldv_func_arg3, 2);
#line 733
  return (ldv_func_res);
}
}
#line 736 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_flush_workqueue_94(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 739
  flush_workqueue(ldv_func_arg1);
#line 741
  call_and_disable_all_3(2);
#line 742
  return;
}
}
#line 744 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
bool ldv_queue_delayed_work_on_95(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                  struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 748
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 748
  ldv_func_res = tmp;
#line 750
  activate_work_3(& ldv_func_arg3->work, 2);
#line 752
  return (ldv_func_res);
}
}
#line 755 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
int ldv_mod_timer_96(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___3 ldv_func_res ;
  int tmp ;

  {
#line 759
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
#line 759
  ldv_func_res = tmp;
#line 761
  activate_pending_timer_4(ldv_func_arg1, ldv_func_arg2, 1);
#line 763
  return (ldv_func_res);
}
}
#line 766 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
int ldv_mod_timer_97(struct timer_list *ldv_func_arg1 , unsigned long ldv_func_arg2 ) 
{ 
  ldv_func_ret_type___4 ldv_func_res ;
  int tmp ;

  {
#line 770
  tmp = mod_timer(ldv_func_arg1, ldv_func_arg2);
#line 770
  ldv_func_res = tmp;
#line 772
  activate_pending_timer_4(ldv_func_arg1, ldv_func_arg2, 1);
#line 774
  return (ldv_func_res);
}
}
#line 777 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
bool ldv_cancel_delayed_work_98(struct delayed_work *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___5 ldv_func_res ;
  bool tmp ;

  {
#line 781
  tmp = cancel_delayed_work(ldv_func_arg1);
#line 781
  ldv_func_res = tmp;
#line 783
  disable_work_3(& ldv_func_arg1->work);
#line 785
  return (ldv_func_res);
}
}
#line 788 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_flush_workqueue_99(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 791
  flush_workqueue(ldv_func_arg1);
#line 793
  call_and_disable_all_3(2);
#line 794
  return;
}
}
#line 796 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
void ldv_destroy_workqueue_100(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 799
  destroy_workqueue(ldv_func_arg1);
#line 801
  call_and_disable_all_3(2);
#line 802
  return;
}
}
#line 804 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mr.o.c.prepared"
int ldv_del_timer_sync_101(struct timer_list *ldv_func_arg1 ) 
{ 
  ldv_func_ret_type___6 ldv_func_res ;
  int tmp ;

  {
#line 808
  tmp = del_timer_sync(ldv_func_arg1);
#line 808
  ldv_func_res = tmp;
#line 810
  disable_suitable_timer_4(ldv_func_arg1);
#line 812
  return (ldv_func_res);
}
}
#line 23 "include/linux/err.h"
__inline static void *ERR_PTR(long error ) ;
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_117(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_119(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_118(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_121(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_120(struct workqueue_struct *ldv_func_arg1 ) ;
#line 531 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct ib_ah *create_ib_ah(struct ib_ah_attr *ah_attr , struct mlx5_ib_ah *ah ) ;
#line 35 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.c"
struct ib_ah *create_ib_ah(struct ib_ah_attr *ah_attr , struct mlx5_ib_ah *ah ) 
{ 
  __u32 tmp ;
  __u16 tmp___0 ;

  {
#line 38
  if ((int )ah_attr->ah_flags & 1) {
#line 39
    memcpy((void *)(& ah->av.rgid), (void const   *)(& ah_attr->grh.dgid), 16UL);
#line 40
    tmp = __fswab32((ah_attr->grh.flow_label | (u32 )((int )ah_attr->grh.sgid_index << 20)) | 1073741824U);
#line 40
    ah->av.grh_gid_fl = tmp;
#line 43
    ah->av.hop_limit = ah_attr->grh.hop_limit;
#line 44
    ah->av.tclass = ah_attr->grh.traffic_class;
  } else {

  }
#line 47
  tmp___0 = __fswab16((int )ah_attr->dlid);
#line 47
  ah->av.rlid = tmp___0;
#line 48
  ah->av.fl_mlid = (unsigned int )ah_attr->src_path_bits & 127U;
#line 49
  ah->av.stat_rate_sl = (u8 )((int )((signed char )((int )ah_attr->static_rate << 4)) | ((int )((signed char )ah_attr->sl) & 15));
#line 51
  return (& ah->ibah);
}
}
#line 54 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.c"
struct ib_ah *mlx5_ib_create_ah(struct ib_pd *pd , struct ib_ah_attr *ah_attr ) 
{ 
  struct mlx5_ib_ah *ah ;
  void *tmp ;
  void *tmp___0 ;
  struct ib_ah *tmp___1 ;

  {
#line 58
  tmp = kzalloc(72UL, 32U);
#line 58
  ah = (struct mlx5_ib_ah *)tmp;
#line 59
  if ((unsigned long )ah == (unsigned long )((struct mlx5_ib_ah *)0)) {
#line 60
    tmp___0 = ERR_PTR(-12L);
#line 60
    return ((struct ib_ah *)tmp___0);
  } else {

  }
#line 62
  tmp___1 = create_ib_ah(ah_attr, ah);
#line 62
  return (tmp___1);
}
}
#line 65 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.c"
int mlx5_ib_query_ah(struct ib_ah *ibah , struct ib_ah_attr *ah_attr ) 
{ 
  struct mlx5_ib_ah *ah ;
  struct mlx5_ib_ah *tmp ;
  u32 tmp___0 ;
  __u32 tmp___1 ;
  __u16 tmp___2 ;

  {
#line 67
  tmp = to_mah(ibah);
#line 67
  ah = tmp;
#line 70
  memset((void *)ah_attr, 0, 40UL);
#line 72
  tmp___1 = __fswab32(ah->av.grh_gid_fl);
#line 72
  tmp___0 = tmp___1;
#line 73
  if ((tmp___0 & 1073741824U) != 0U) {
#line 74
    ah_attr->ah_flags = 1U;
#line 75
    ah_attr->grh.sgid_index = (u8 )(tmp___0 >> 20);
#line 76
    ah_attr->grh.flow_label = tmp___0 & 1048575U;
#line 77
    memcpy((void *)(& ah_attr->grh.dgid), (void const   *)(& ah->av.rgid), 16UL);
#line 78
    ah_attr->grh.hop_limit = ah->av.hop_limit;
#line 79
    ah_attr->grh.traffic_class = ah->av.tclass;
  } else {

  }
#line 81
  tmp___2 = __fswab16((int )ah->av.rlid);
#line 81
  ah_attr->dlid = tmp___2;
#line 82
  ah_attr->static_rate = (u8 )((int )ah->av.stat_rate_sl >> 4);
#line 83
  ah_attr->sl = (unsigned int )ah->av.stat_rate_sl & 15U;
#line 85
  return (0);
}
}
#line 88 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.c"
int mlx5_ib_destroy_ah(struct ib_ah *ah ) 
{ 
  struct mlx5_ib_ah *tmp ;

  {
#line 90
  tmp = to_mah(ah);
#line 90
  kfree((void const   *)tmp);
#line 91
  return (0);
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.o.c.prepared"
bool ldv_queue_work_on_117(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.o.c.prepared"
bool ldv_queue_delayed_work_on_118(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.o.c.prepared"
bool ldv_queue_work_on_119(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.o.c.prepared"
void ldv_flush_workqueue_120(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/ah.o.c.prepared"
bool ldv_queue_delayed_work_on_121(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 154 "include/uapi/linux/swab.h"
__inline static __u16 __swab16p(__u16 const   *p ) 
{ 
  __u16 tmp ;

  {
#line 159
  tmp = __fswab16((int )*p);
#line 159
  return (tmp);
}
}
#line 167 "include/uapi/linux/swab.h"
__inline static __u32 __swab32p(__u32 const   *p ) 
{ 
  __u32 tmp ;

  {
#line 172
  tmp = __fswab32(*p);
#line 172
  return (tmp);
}
}
#line 79 "include/uapi/linux/byteorder/little_endian.h"
__inline static __u32 __be32_to_cpup(__be32 const   *p ) 
{ 
  __u32 tmp ;

  {
#line 81
  tmp = __swab32p(p);
#line 81
  return (tmp);
}
}
#line 87 "include/uapi/linux/byteorder/little_endian.h"
__inline static __u16 __be16_to_cpup(__be16 const   *p ) 
{ 
  __u16 tmp ;

  {
#line 89
  tmp = __swab16p(p);
#line 89
  return (tmp);
}
}
#line 433 "include/linux/workqueue.h"
bool ldv_queue_work_on_131(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
#line 437
bool ldv_queue_work_on_133(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
#line 443
bool ldv_queue_delayed_work_on_132(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 447
bool ldv_queue_delayed_work_on_135(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 455
void ldv_flush_workqueue_134(struct workqueue_struct *ldv_func_arg1 ) ;
#line 702 "include/linux/mlx5/driver.h"
extern int mlx5_core_mad_ifc(struct mlx5_core_dev * , void const   * , void * , u16  ,
                             u8  ) ;
#line 528 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
int mlx5_MAD_IFC(struct mlx5_ib_dev *dev , int ignore_mkey , int ignore_bkey , u8 port ,
                 struct ib_wc  const  *in_wc , struct ib_grh  const  *in_grh , void const   *in_mad ,
                 void *response_mad ) ;
#line 601
int mlx5_query_mad_ifc_smp_attr_node_info(struct ib_device *ibdev , struct ib_smp *out_mad ) ;
#line 669 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static void init_query_mad(struct ib_smp *mad ) 
{ 


  {
#line 671
  mad->base_version = 1U;
#line 672
  mad->mgmt_class = 1U;
#line 673
  mad->class_version = 1U;
#line 674
  mad->method = 1U;
#line 675
  return;
}
}
#line 43 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_MAD_IFC(struct mlx5_ib_dev *dev , int ignore_mkey , int ignore_bkey , u8 port ,
                 struct ib_wc  const  *in_wc , struct ib_grh  const  *in_grh , void const   *in_mad ,
                 void *response_mad ) 
{ 
  u8 op_modifier ;
  int tmp ;

  {
#line 47
  op_modifier = 0U;
#line 52
  if (ignore_mkey != 0 || (unsigned long )in_wc == (unsigned long )((struct ib_wc  const  *)0)) {
#line 53
    op_modifier = (u8 )((unsigned int )op_modifier | 1U);
  } else {

  }
#line 54
  if (ignore_bkey != 0 || (unsigned long )in_wc == (unsigned long )((struct ib_wc  const  *)0)) {
#line 55
    op_modifier = (u8 )((unsigned int )op_modifier | 2U);
  } else {

  }
#line 57
  tmp = mlx5_core_mad_ifc(dev->mdev, in_mad, response_mad, (int )op_modifier, (int )port);
#line 57
  return (tmp);
}
}
#line 60 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_ib_process_mad(struct ib_device *ibdev , int mad_flags , u8 port_num , struct ib_wc  const  *in_wc ,
                        struct ib_grh  const  *in_grh , struct ib_mad_hdr  const  *in ,
                        size_t in_mad_size , struct ib_mad_hdr *out , size_t *out_mad_size ,
                        u16 *out_mad_pkey_index ) 
{ 
  u16 slid ;
  int err ;
  struct ib_mad  const  *in_mad ;
  struct ib_mad *out_mad ;
  long tmp ;
  struct mlx5_ib_dev *tmp___0 ;

  {
#line 68
  in_mad = (struct ib_mad  const  *)in;
#line 69
  out_mad = (struct ib_mad *)out;
#line 71
  tmp = ldv__builtin_expect((long )(in_mad_size != 256UL || *out_mad_size != 256UL),
                         0L);
#line 71
  if (tmp != 0L) {
#line 71
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.long 1b - 2b, %c0 - 2b\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"),
                         "i" (72), "i" (12UL));
    ldv_36921: ;
#line 71
    goto ldv_36921;
  } else {

  }
#line 74
  slid = (unsigned long )in_wc != (unsigned long )((struct ib_wc  const  *)0) ? (u16 )in_wc->slid : 65535U;
#line 76
  if ((unsigned int )((unsigned char )in_mad->mad_hdr.method) == 5U && (unsigned int )slid == 0U) {
#line 77
    return (5);
  } else {

  }
#line 79
  if ((unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 1U || (unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 129U) {
#line 81
    if (((unsigned int )((unsigned char )in_mad->mad_hdr.method) != 1U && (unsigned int )((unsigned char )in_mad->mad_hdr.method) != 2U) && (unsigned int )((unsigned char )in_mad->mad_hdr.method) != 7U) {
#line 84
      return (1);
    } else {

    }
#line 88
    if ((unsigned int )((unsigned short )in_mad->mad_hdr.attr_id) == 8192U) {
#line 89
      return (1);
    } else {

    }
  } else
#line 90
  if ((((unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 4U || (unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 9U) || (unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 10U) || (unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 33U) {
#line 94
    if ((unsigned int )((unsigned char )in_mad->mad_hdr.method) != 1U && (unsigned int )((unsigned char )in_mad->mad_hdr.method) != 2U) {
#line 96
      return (1);
    } else {

    }
  } else {
#line 98
    return (1);
  }
#line 101
  tmp___0 = to_mdev(ibdev);
#line 101
  err = mlx5_MAD_IFC(tmp___0, mad_flags & 1, mad_flags & 2, (int )port_num, in_wc,
                     in_grh, (void const   *)in_mad, (void *)out_mad);
#line 105
  if (err != 0) {
#line 106
    return (0);
  } else {

  }
#line 109
  if ((unsigned int )((unsigned char )in_mad->mad_hdr.mgmt_class) == 129U) {
#line 110
    out_mad->mad_hdr.status = (__be16 )((unsigned int )out_mad->mad_hdr.status | 128U);
  } else {

  }
#line 112
  if ((unsigned int )((unsigned char )in_mad->mad_hdr.method) == 7U) {
#line 114
    return (5);
  } else {

  }
#line 116
  return (3);
}
}
#line 119 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_ext_port_caps(struct mlx5_ib_dev *dev , u8 port ) 
{ 
  struct ib_smp *in_mad ;
  struct ib_smp *out_mad ;
  int err ;
  u16 packet_error ;
  void *tmp ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  __u16 tmp___2 ;

  {
#line 121
  in_mad = (struct ib_smp *)0;
#line 122
  out_mad = (struct ib_smp *)0;
#line 123
  err = -12;
#line 126
  tmp = kzalloc(256UL, 208U);
#line 126
  in_mad = (struct ib_smp *)tmp;
#line 127
  tmp___0 = kmalloc(256UL, 208U);
#line 127
  out_mad = (struct ib_smp *)tmp___0;
#line 128
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0) || (unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 129
    goto out;
  } else {

  }
#line 131
  init_query_mad(in_mad);
#line 132
  in_mad->attr_id = 37119U;
#line 133
  tmp___1 = __fswab32((__u32 )port);
#line 133
  in_mad->attr_mod = tmp___1;
#line 135
  err = mlx5_MAD_IFC(dev, 1, 1, 1, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 137
  tmp___2 = __fswab16((int )out_mad->status);
#line 137
  packet_error = tmp___2;
#line 139
  (dev->mdev)->port_caps[(int )port + -1].ext_port_cap = (u8 )(err == 0 && (unsigned int )packet_error == 0U);
  out: 
#line 143
  kfree((void const   *)in_mad);
#line 144
  kfree((void const   *)out_mad);
#line 145
  return (err);
}
}
#line 148 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_smp_attr_node_info(struct ib_device *ibdev , struct ib_smp *out_mad ) 
{ 
  struct ib_smp *in_mad ;
  int err ;
  void *tmp ;
  struct mlx5_ib_dev *tmp___0 ;

  {
#line 151
  in_mad = (struct ib_smp *)0;
#line 152
  err = -12;
#line 154
  tmp = kzalloc(256UL, 208U);
#line 154
  in_mad = (struct ib_smp *)tmp;
#line 155
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0)) {
#line 156
    return (-12);
  } else {

  }
#line 158
  init_query_mad(in_mad);
#line 159
  in_mad->attr_id = 4352U;
#line 161
  tmp___0 = to_mdev(ibdev);
#line 161
  err = mlx5_MAD_IFC(tmp___0, 1, 1, 1, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 164
  kfree((void const   *)in_mad);
#line 165
  return (err);
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_system_image_guid(struct ib_device *ibdev , __be64 *sys_image_guid ) 
{ 
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;

  {
#line 171
  out_mad = (struct ib_smp *)0;
#line 172
  err = -12;
#line 174
  tmp = kmalloc(256UL, 208U);
#line 174
  out_mad = (struct ib_smp *)tmp;
#line 175
  if ((unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 176
    return (-12);
  } else {

  }
#line 178
  err = mlx5_query_mad_ifc_smp_attr_node_info(ibdev, out_mad);
#line 179
  if (err != 0) {
#line 180
    goto out;
  } else {

  }
#line 182
  memcpy((void *)sys_image_guid, (void const   *)(& out_mad->data) + 4U, 8UL);
  out: 
#line 185
  kfree((void const   *)out_mad);
#line 187
  return (err);
}
}
#line 190 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_max_pkeys(struct ib_device *ibdev , u16 *max_pkeys ) 
{ 
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;

  {
#line 193
  out_mad = (struct ib_smp *)0;
#line 194
  err = -12;
#line 196
  tmp = kmalloc(256UL, 208U);
#line 196
  out_mad = (struct ib_smp *)tmp;
#line 197
  if ((unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 198
    return (-12);
  } else {

  }
#line 200
  err = mlx5_query_mad_ifc_smp_attr_node_info(ibdev, out_mad);
#line 201
  if (err != 0) {
#line 202
    goto out;
  } else {

  }
#line 204
  *max_pkeys = __be16_to_cpup((__be16 const   *)(& out_mad->data) + 28U);
  out: 
#line 207
  kfree((void const   *)out_mad);
#line 209
  return (err);
}
}
#line 212 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_vendor_id(struct ib_device *ibdev , u32 *vendor_id ) 
{ 
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;
  __u32 tmp___0 ;

  {
#line 215
  out_mad = (struct ib_smp *)0;
#line 216
  err = -12;
#line 218
  tmp = kmalloc(256UL, 208U);
#line 218
  out_mad = (struct ib_smp *)tmp;
#line 219
  if ((unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 220
    return (-12);
  } else {

  }
#line 222
  err = mlx5_query_mad_ifc_smp_attr_node_info(ibdev, out_mad);
#line 223
  if (err != 0) {
#line 224
    goto out;
  } else {

  }
#line 226
  tmp___0 = __be32_to_cpup((__be32 const   *)(& out_mad->data) + 36U);
#line 226
  *vendor_id = tmp___0 & 65535U;
  out: 
#line 229
  kfree((void const   *)out_mad);
#line 231
  return (err);
}
}
#line 234 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_node_desc(struct mlx5_ib_dev *dev , char *node_desc ) 
{ 
  struct ib_smp *in_mad ;
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 236
  in_mad = (struct ib_smp *)0;
#line 237
  out_mad = (struct ib_smp *)0;
#line 238
  err = -12;
#line 240
  tmp = kzalloc(256UL, 208U);
#line 240
  in_mad = (struct ib_smp *)tmp;
#line 241
  tmp___0 = kmalloc(256UL, 208U);
#line 241
  out_mad = (struct ib_smp *)tmp___0;
#line 242
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0) || (unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 243
    goto out;
  } else {

  }
#line 245
  init_query_mad(in_mad);
#line 246
  in_mad->attr_id = 4096U;
#line 248
  err = mlx5_MAD_IFC(dev, 1, 1, 1, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 249
  if (err != 0) {
#line 250
    goto out;
  } else {

  }
#line 252
  memcpy((void *)node_desc, (void const   *)(& out_mad->data), 64UL);
  out: 
#line 254
  kfree((void const   *)in_mad);
#line 255
  kfree((void const   *)out_mad);
#line 256
  return (err);
}
}
#line 259 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_node_guid(struct mlx5_ib_dev *dev , __be64 *node_guid ) 
{ 
  struct ib_smp *in_mad ;
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;
  void *tmp___0 ;

  {
#line 261
  in_mad = (struct ib_smp *)0;
#line 262
  out_mad = (struct ib_smp *)0;
#line 263
  err = -12;
#line 265
  tmp = kzalloc(256UL, 208U);
#line 265
  in_mad = (struct ib_smp *)tmp;
#line 266
  tmp___0 = kmalloc(256UL, 208U);
#line 266
  out_mad = (struct ib_smp *)tmp___0;
#line 267
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0) || (unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 268
    goto out;
  } else {

  }
#line 270
  init_query_mad(in_mad);
#line 271
  in_mad->attr_id = 4352U;
#line 273
  err = mlx5_MAD_IFC(dev, 1, 1, 1, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 274
  if (err != 0) {
#line 275
    goto out;
  } else {

  }
#line 277
  memcpy((void *)node_guid, (void const   *)(& out_mad->data) + 12U, 8UL);
  out: 
#line 279
  kfree((void const   *)in_mad);
#line 280
  kfree((void const   *)out_mad);
#line 281
  return (err);
}
}
#line 284 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_pkey(struct ib_device *ibdev , u8 port , u16 index , u16 *pkey ) 
{ 
  struct ib_smp *in_mad ;
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  struct mlx5_ib_dev *tmp___2 ;
  __u16 tmp___3 ;

  {
#line 287
  in_mad = (struct ib_smp *)0;
#line 288
  out_mad = (struct ib_smp *)0;
#line 289
  err = -12;
#line 291
  tmp = kzalloc(256UL, 208U);
#line 291
  in_mad = (struct ib_smp *)tmp;
#line 292
  tmp___0 = kmalloc(256UL, 208U);
#line 292
  out_mad = (struct ib_smp *)tmp___0;
#line 293
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0) || (unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 294
    goto out;
  } else {

  }
#line 296
  init_query_mad(in_mad);
#line 297
  in_mad->attr_id = 5632U;
#line 298
  tmp___1 = __fswab32((unsigned int )index / 32U);
#line 298
  in_mad->attr_mod = tmp___1;
#line 300
  tmp___2 = to_mdev(ibdev);
#line 300
  err = mlx5_MAD_IFC(tmp___2, 1, 1, (int )port, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 302
  if (err != 0) {
#line 303
    goto out;
  } else {

  }
#line 305
  tmp___3 = __fswab16((int )*((__be16 *)(& out_mad->data) + ((unsigned long )index & 31UL)));
#line 305
  *pkey = tmp___3;
  out: 
#line 308
  kfree((void const   *)in_mad);
#line 309
  kfree((void const   *)out_mad);
#line 310
  return (err);
}
}
#line 313 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_gids(struct ib_device *ibdev , u8 port , int index , union ib_gid *gid ) 
{ 
  struct ib_smp *in_mad ;
  struct ib_smp *out_mad ;
  int err ;
  void *tmp ;
  void *tmp___0 ;
  __u32 tmp___1 ;
  struct mlx5_ib_dev *tmp___2 ;
  __u32 tmp___3 ;
  struct mlx5_ib_dev *tmp___4 ;

  {
#line 316
  in_mad = (struct ib_smp *)0;
#line 317
  out_mad = (struct ib_smp *)0;
#line 318
  err = -12;
#line 320
  tmp = kzalloc(256UL, 208U);
#line 320
  in_mad = (struct ib_smp *)tmp;
#line 321
  tmp___0 = kmalloc(256UL, 208U);
#line 321
  out_mad = (struct ib_smp *)tmp___0;
#line 322
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0) || (unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 323
    goto out;
  } else {

  }
#line 325
  init_query_mad(in_mad);
#line 326
  in_mad->attr_id = 5376U;
#line 327
  tmp___1 = __fswab32((__u32 )port);
#line 327
  in_mad->attr_mod = tmp___1;
#line 329
  tmp___2 = to_mdev(ibdev);
#line 329
  err = mlx5_MAD_IFC(tmp___2, 1, 1, (int )port, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 331
  if (err != 0) {
#line 332
    goto out;
  } else {

  }
#line 334
  memcpy((void *)(& gid->raw), (void const   *)(& out_mad->data) + 8U, 8UL);
#line 336
  init_query_mad(in_mad);
#line 337
  in_mad->attr_id = 5120U;
#line 338
  tmp___3 = __fswab32((__u32 )(index / 8));
#line 338
  in_mad->attr_mod = tmp___3;
#line 340
  tmp___4 = to_mdev(ibdev);
#line 340
  err = mlx5_MAD_IFC(tmp___4, 1, 1, (int )port, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 342
  if (err != 0) {
#line 343
    goto out;
  } else {

  }
#line 345
  memcpy((void *)(& gid->raw) + 8U, (void const   *)(& out_mad->data) + (unsigned long )((index % 8) * 8),
           8UL);
  out: 
#line 348
  kfree((void const   *)in_mad);
#line 349
  kfree((void const   *)out_mad);
#line 350
  return (err);
}
}
#line 353 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.c"
int mlx5_query_mad_ifc_port(struct ib_device *ibdev , u8 port , struct ib_port_attr *props ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_core_dev *mdev ;
  struct ib_smp *in_mad ;
  struct ib_smp *out_mad ;
  int ext_active_speed ;
  int err ;
  struct task_struct *tmp___0 ;
  __u32 tmp___1 ;
  void *tmp___2 ;
  void *tmp___3 ;
  __u32 tmp___4 ;
  struct task_struct *tmp___5 ;
  __u32 tmp___6 ;
  __u16 tmp___7 ;
  __u16 tmp___8 ;
  __u32 tmp___9 ;

  {
#line 356
  tmp = to_mdev(ibdev);
#line 356
  dev = tmp;
#line 357
  mdev = dev->mdev;
#line 358
  in_mad = (struct ib_smp *)0;
#line 359
  out_mad = (struct ib_smp *)0;
#line 361
  err = -12;
#line 363
  if ((unsigned int )port == 0U) {
#line 364
    tmp___0 = get_current();
#line 364
    printk("\f%s:%s:%d:(pid %d): invalid port number %d\n", (char *)(& dev->ib_dev.name),
           "mlx5_query_mad_ifc_port", 364, tmp___0->pid, (int )port);
#line 365
    return (-22);
  } else {
#line 363
    tmp___1 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 13UL));
#line 363
    if ((unsigned int )port > (tmp___1 & 255U)) {
#line 364
      tmp___0 = get_current();
#line 364
      printk("\f%s:%s:%d:(pid %d): invalid port number %d\n", (char *)(& dev->ib_dev.name),
             "mlx5_query_mad_ifc_port", 364, tmp___0->pid, (int )port);
#line 365
      return (-22);
    } else {

    }
  }
#line 368
  tmp___2 = kzalloc(256UL, 208U);
#line 368
  in_mad = (struct ib_smp *)tmp___2;
#line 369
  tmp___3 = kmalloc(256UL, 208U);
#line 369
  out_mad = (struct ib_smp *)tmp___3;
#line 370
  if ((unsigned long )in_mad == (unsigned long )((struct ib_smp *)0) || (unsigned long )out_mad == (unsigned long )((struct ib_smp *)0)) {
#line 371
    goto out;
  } else {

  }
#line 373
  memset((void *)props, 0, 48UL);
#line 375
  init_query_mad(in_mad);
#line 376
  in_mad->attr_id = 5376U;
#line 377
  tmp___4 = __fswab32((__u32 )port);
#line 377
  in_mad->attr_mod = tmp___4;
#line 379
  err = mlx5_MAD_IFC(dev, 1, 1, (int )port, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                     (void const   *)in_mad, (void *)out_mad);
#line 380
  if (err != 0) {
#line 381
    tmp___5 = get_current();
#line 381
    printk("\f%s:%s:%d:(pid %d): err %d\n", (char *)(& dev->ib_dev.name), "mlx5_query_mad_ifc_port",
           381, tmp___5->pid, err);
#line 382
    goto out;
  } else {

  }
#line 385
  props->lid = __be16_to_cpup((__be16 const   *)(& out_mad->data) + 16U);
#line 386
  props->lmc = (unsigned int )out_mad->data[34] & 7U;
#line 387
  props->sm_lid = __be16_to_cpup((__be16 const   *)(& out_mad->data) + 18U);
#line 388
  props->sm_sl = (unsigned int )out_mad->data[36] & 15U;
#line 389
  props->state = (enum ib_port_state )((int )out_mad->data[32] & 15);
#line 390
  props->phys_state = (u8 )((int )out_mad->data[33] >> 4);
#line 391
  props->port_cap_flags = __be32_to_cpup((__be32 const   *)(& out_mad->data) + 20U);
#line 392
  props->gid_tbl_len = (int )out_mad->data[50];
#line 393
  tmp___6 = __fswab32(*((__be32 *)(& mdev->hca_caps_cur) + 14UL));
#line 393
  props->max_msg_sz = (u32 )(1 << ((int )(tmp___6 >> 24) & 31));
#line 394
  props->pkey_tbl_len = (u16 )mdev->port_caps[(int )port + -1].pkey_table_len;
#line 395
  tmp___7 = __be16_to_cpup((__be16 const   *)(& out_mad->data) + 46U);
#line 395
  props->bad_pkey_cntr = (u32 )tmp___7;
#line 396
  tmp___8 = __be16_to_cpup((__be16 const   *)(& out_mad->data) + 48U);
#line 396
  props->qkey_viol_cntr = (u32 )tmp___8;
#line 397
  props->active_width = (unsigned int )out_mad->data[31] & 15U;
#line 398
  props->active_speed = (u8 )((int )out_mad->data[35] >> 4);
#line 399
  props->max_mtu = (enum ib_mtu )((int )out_mad->data[41] & 15);
#line 400
  props->active_mtu = (enum ib_mtu )((int )out_mad->data[36] >> 4);
#line 401
  props->subnet_timeout = (unsigned int )out_mad->data[51] & 31U;
#line 402
  props->max_vl_num = (u8 )((int )out_mad->data[37] >> 4);
#line 403
  props->init_type_reply = (u8 )((int )out_mad->data[41] >> 4);
#line 406
  if ((props->port_cap_flags & 16384U) != 0U) {
#line 407
    ext_active_speed = (int )out_mad->data[62] >> 4;
#line 409
    switch (ext_active_speed) {
    case 1: 
#line 411
    props->active_speed = 16U;
#line 412
    goto ldv_37008;
    case 2: 
#line 414
    props->active_speed = 32U;
#line 415
    goto ldv_37008;
    }
    ldv_37008: ;
  } else {

  }
#line 420
  if ((unsigned int )props->active_speed == 4U) {
#line 421
    if ((int )mdev->port_caps[(int )port + -1].ext_port_cap & 1) {
#line 423
      init_query_mad(in_mad);
#line 424
      in_mad->attr_id = 37119U;
#line 425
      tmp___9 = __fswab32((__u32 )port);
#line 425
      in_mad->attr_mod = tmp___9;
#line 427
      err = mlx5_MAD_IFC(dev, 1, 1, (int )port, (struct ib_wc  const  *)0, (struct ib_grh  const  *)0,
                         (void const   *)in_mad, (void *)out_mad);
#line 429
      if (err != 0) {
#line 430
        goto out;
      } else {

      }
#line 433
      if ((int )out_mad->data[15] & 1) {
#line 434
        props->active_speed = 8U;
      } else {

      }
    } else {

    }
  } else {

  }
  out: 
#line 439
  kfree((void const   *)in_mad);
#line 440
  kfree((void const   *)out_mad);
#line 442
  return (err);
}
}
#line 127 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.o.c.prepared"
bool ldv_queue_work_on_131(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 131
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 131
  ldv_func_res = tmp;
#line 133
  activate_work_3(ldv_func_arg3, 2);
#line 135
  return (ldv_func_res);
}
}
#line 138 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.o.c.prepared"
bool ldv_queue_delayed_work_on_132(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 142
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 142
  ldv_func_res = tmp;
#line 144
  activate_work_3(& ldv_func_arg3->work, 2);
#line 146
  return (ldv_func_res);
}
}
#line 149 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.o.c.prepared"
bool ldv_queue_work_on_133(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 153
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 153
  ldv_func_res = tmp;
#line 155
  activate_work_3(ldv_func_arg3, 2);
#line 157
  return (ldv_func_res);
}
}
#line 160 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.o.c.prepared"
void ldv_flush_workqueue_134(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 163
  flush_workqueue(ldv_func_arg1);
#line 165
  call_and_disable_all_3(2);
#line 166
  return;
}
}
#line 168 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/mad.o.c.prepared"
bool ldv_queue_delayed_work_on_135(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 172
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 172
  ldv_func_res = tmp;
#line 174
  activate_work_3(& ldv_func_arg3->work, 2);
#line 176
  return (ldv_func_res);
}
}
#line 1 "<compiler builtins>"
__inline static long ldv__builtin_expect(long exp , long c ) ;
#line 333 "include/linux/lockdep.h"
extern void lock_acquire(struct lockdep_map * , unsigned int  , int  , int  , int  ,
                         struct lockdep_map * , unsigned long  ) ;
#line 337
extern void lock_release(struct lockdep_map * , int  , unsigned long  ) ;
#line 95 "include/linux/completion.h"
extern unsigned long wait_for_completion_timeout(struct completion * , unsigned long  ) ;
#line 447 "include/linux/rcupdate.h"
__inline static void rcu_lock_acquire(struct lockdep_map *map ) 
{ 


  {
#line 449
  lock_acquire(map, 0U, 0, 2, 0, (struct lockdep_map *)0, 0UL);
#line 450
  return;
}
}
#line 452 "include/linux/rcupdate.h"
__inline static void rcu_lock_release(struct lockdep_map *map ) 
{ 


  {
#line 454
  lock_release(map, 1, 0UL);
#line 455
  return;
}
}
#line 424 "include/linux/workqueue.h"
void ldv_destroy_workqueue_151(struct workqueue_struct *ldv_func_arg1 ) ;
#line 437
bool ldv_queue_work_on_145(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
#line 441
bool ldv_queue_work_on_147(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) ;
#line 447
bool ldv_queue_delayed_work_on_146(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 451
bool ldv_queue_delayed_work_on_149(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) ;
#line 459
void ldv_flush_workqueue_148(struct workqueue_struct *ldv_func_arg1 ) ;
#line 463
void ldv_flush_workqueue_150(struct workqueue_struct *ldv_func_arg1 ) ;
#line 469 "include/linux/workqueue.h"
__inline static bool queue_work___0(struct workqueue_struct *wq , struct work_struct *work ) 
{ 
  bool tmp ;

  {
#line 472
  tmp = ldv_queue_work_on_145(8192, wq, work);
#line 472
  return (tmp);
}
}
#line 67 "include/linux/srcu.h"
extern int __init_srcu_struct(struct srcu_struct * , char const   * , struct lock_class_key * ) ;
#line 131
extern void cleanup_srcu_struct(struct srcu_struct * ) ;
#line 132
extern int __srcu_read_lock(struct srcu_struct * ) ;
#line 133
extern void __srcu_read_unlock(struct srcu_struct * , int  ) ;
#line 216 "include/linux/srcu.h"
__inline static int srcu_read_lock(struct srcu_struct *sp ) 
{ 
  int retval ;
  int tmp ;

  {
#line 218
  tmp = __srcu_read_lock(sp);
#line 218
  retval = tmp;
#line 220
  rcu_lock_acquire(& sp->dep_map);
#line 221
  return (retval);
}
}
#line 231 "include/linux/srcu.h"
__inline static void srcu_read_unlock(struct srcu_struct *sp , int idx ) 
{ 


  {
#line 234
  rcu_lock_release(& sp->dep_map);
#line 235
  __srcu_read_unlock(sp, idx);
#line 236
  return;
}
}
#line 352 "include/linux/gfp.h"
extern unsigned long __get_free_pages(gfp_t  , unsigned int  ) ;
#line 86 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void call_and_disable_work_3(struct work_struct *work ) ;
#line 92
void invoke_work_3(void) ;
#line 103 "include/rdma/ib_umem_odp.h"
extern int ib_umem_odp_map_dma_pages(struct ib_umem * , u64  , u64  , u64  , unsigned long  ) ;
#line 106
extern void ib_umem_odp_unmap_dma_pages(struct ib_umem * , u64  , u64  ) ;
#line 125 "include/rdma/ib_umem_odp.h"
__inline static int ib_umem_mmu_notifier_retry(struct ib_umem *item , unsigned long mmu_seq ) 
{ 
  long tmp ;

  {
#line 138
  if (! (item->odp_data)->mn_counters_active) {
#line 139
    return (1);
  } else {

  }
#line 141
  tmp = ldv__builtin_expect((item->odp_data)->notifiers_count != 0, 0L);
#line 141
  if (tmp != 0L) {
#line 142
    return (1);
  } else {

  }
#line 143
  if ((unsigned long )(item->odp_data)->notifiers_seq != mmu_seq) {
#line 144
    return (1);
  } else {

  }
#line 145
  return (0);
}
}
#line 639 "include/linux/mlx5/qp.h"
extern int mlx5_core_page_fault_resume(struct mlx5_core_dev * , u32  , u8  , int  ) ;
#line 165 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
__inline static enum mlx5_ib_pagefault_context mlx5_ib_get_pagefault_context(struct mlx5_pagefault *pagefault ) 
{ 


  {
#line 167
  return ((enum mlx5_ib_pagefault_context )((unsigned int )pagefault->flags & 3U));
}
}
#line 638 "/work/ldvuser/mutilin/launch/inst/current/envs/linux-4.2-rc1.tar.xz/linux-4.2-rc1/drivers/infiniband/hw/mlx5/mlx5_ib.h"
struct workqueue_struct *mlx5_ib_page_fault_wq  ;
#line 641
void mlx5_ib_mr_pfault_handler(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ) ;
#line 46 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_invalidate_range(struct ib_umem *umem , unsigned long start , unsigned long end ) 
{ 
  struct mlx5_ib_mr *mr ;
  u64 umr_block_mask ;
  u64 idx ;
  u64 blk_start_idx ;
  int in_block ;
  u64 addr ;
  u64 __max1 ;
  unsigned long tmp ;
  u64 __max2 ;
  u64 __min1 ;
  unsigned long tmp___0 ;
  u64 __min2 ;
  unsigned long tmp___1 ;
  u64 umr_offset ;

  {
#line 50
  umr_block_mask = 7ULL;
#line 51
  idx = 0ULL;
#line 51
  blk_start_idx = 0ULL;
#line 52
  in_block = 0;
#line 55
  if ((unsigned long )umem == (unsigned long )((struct ib_umem *)0) || (unsigned long )umem->odp_data == (unsigned long )((struct ib_umem_odp *)0)) {
#line 56
    printk("\vinvalidation called on NULL umem or non-ODP umem\n");
#line 57
    return;
  } else {

  }
#line 60
  mr = (struct mlx5_ib_mr *)(umem->odp_data)->private;
#line 62
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0) || (unsigned long )mr->ibmr.pd == (unsigned long )((struct ib_pd *)0)) {
#line 63
    return;
  } else {

  }
#line 65
  tmp = ib_umem_start(umem);
#line 65
  __max1 = (u64 )tmp;
#line 65
  __max2 = (u64 )start;
#line 65
  start = (unsigned long )(__max1 > __max2 ? __max1 : __max2);
#line 66
  tmp___0 = ib_umem_end(umem);
#line 66
  __min1 = (u64 )tmp___0;
#line 66
  __min2 = (u64 )end;
#line 66
  end = (unsigned long )(__min1 < __min2 ? __min1 : __min2);
#line 75
  addr = (u64 )start;
#line 75
  goto ldv_37031;
  ldv_37030: 
#line 76
  tmp___1 = ib_umem_start(umem);
#line 76
  idx = (addr - (unsigned long long )tmp___1) / 4096ULL;
#line 83
  if ((*((umem->odp_data)->dma_list + idx) & 3ULL) != 0ULL) {
#line 85
    if (in_block == 0) {
#line 86
      blk_start_idx = idx;
#line 87
      in_block = 1;
    } else {

    }
  } else {
#line 90
    umr_offset = idx & umr_block_mask;
#line 92
    if (in_block != 0 && umr_offset == 0ULL) {
#line 93
      mlx5_ib_update_mtt(mr, blk_start_idx, (int )((unsigned int )idx - (unsigned int )blk_start_idx),
                         1);
#line 95
      in_block = 0;
    } else {

    }
  }
#line 75
  addr = (unsigned long long )umem->page_size + addr;
  ldv_37031: ;
#line 75
  if (addr < (unsigned long long )end) {
#line 77
    goto ldv_37030;
  } else {

  }

#line 99
  if (in_block != 0) {
#line 100
    mlx5_ib_update_mtt(mr, blk_start_idx, (int )(((unsigned int )idx - (unsigned int )blk_start_idx) + 1U),
                       1);
  } else {

  }
#line 109
  ib_umem_odp_unmap_dma_pages(umem, (u64 )start, (u64 )end);
#line 110
  return;
}
}
#line 112 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_internal_fill_odp_caps(struct mlx5_ib_dev *dev ) 
{ 
  struct ib_odp_caps *caps ;
  __u32 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  __u32 tmp___2 ;
  __u32 tmp___3 ;
  __u32 tmp___4 ;

  {
#line 114
  caps = & dev->odp_caps;
#line 116
  memset((void *)caps, 0, 24UL);
#line 118
  tmp = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 17UL));
#line 118
  if ((tmp & 16777216U) == 0U) {
#line 119
    return;
  } else {

  }
#line 121
  caps->general_caps = 1ULL;
#line 123
  tmp___0 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 8U));
#line 123
  if ((int )tmp___0 < 0) {
#line 124
    caps->per_transport_caps.ud_odp_caps = caps->per_transport_caps.ud_odp_caps | 1U;
  } else {

  }
#line 126
  tmp___1 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 6U));
#line 126
  if ((int )tmp___1 < 0) {
#line 127
    caps->per_transport_caps.rc_odp_caps = caps->per_transport_caps.rc_odp_caps | 1U;
  } else {

  }
#line 129
  tmp___2 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 6U));
#line 129
  if ((tmp___2 & 1073741824U) != 0U) {
#line 130
    caps->per_transport_caps.rc_odp_caps = caps->per_transport_caps.rc_odp_caps | 2U;
  } else {

  }
#line 132
  tmp___3 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 6U));
#line 132
  if ((tmp___3 & 536870912U) != 0U) {
#line 133
    caps->per_transport_caps.rc_odp_caps = caps->per_transport_caps.rc_odp_caps | 4U;
  } else {

  }
#line 135
  tmp___4 = __fswab32(*((__be32 *)(& (dev->mdev)->hca_caps_cur) + 6U));
#line 135
  if ((tmp___4 & 268435456U) != 0U) {
#line 136
    caps->per_transport_caps.rc_odp_caps = caps->per_transport_caps.rc_odp_caps | 8U;
  } else {

  }
#line 138
  return;
}
}
#line 141 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static struct mlx5_ib_mr *mlx5_ib_odp_find_mr_lkey(struct mlx5_ib_dev *dev , u32 key ) 
{ 
  u32 base_key ;
  u32 tmp ;
  struct mlx5_core_mr *mmr ;
  struct mlx5_core_mr *tmp___0 ;
  struct mlx5_ib_mr *mr ;
  struct mlx5_core_mr  const  *__mptr ;
  struct mlx5_core_mr  const  *__mptr___0 ;

  {
#line 144
  tmp = mlx5_base_mkey(key);
#line 144
  base_key = tmp;
#line 145
  tmp___0 = __mlx5_mr_lookup(dev->mdev, base_key);
#line 145
  mmr = tmp___0;
#line 146
  __mptr = (struct mlx5_core_mr  const  *)mmr;
#line 146
  mr = (struct mlx5_ib_mr *)__mptr + 0xffffffffffffffd8UL;
#line 148
  if (((unsigned long )mmr == (unsigned long )((struct mlx5_core_mr *)0) || mmr->key != key) || mr->live == 0) {
#line 149
    return ((struct mlx5_ib_mr *)0);
  } else {

  }
#line 151
  __mptr___0 = (struct mlx5_core_mr  const  *)mmr;
#line 151
  return ((struct mlx5_ib_mr *)__mptr___0 + 0xffffffffffffffd8UL);
}
}
#line 154 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static void mlx5_ib_page_fault_resume(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ,
                                      int error ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int ret ;
  int tmp___0 ;

  {
#line 157
  tmp = to_mdev((qp->ibqp.pd)->device);
#line 157
  dev = tmp;
#line 158
  tmp___0 = mlx5_core_page_fault_resume(dev->mdev, (u32 )qp->mqp.qpn, (int )((u8 )pfault->mpfault.flags),
                                        error);
#line 158
  ret = tmp___0;
#line 161
  if (ret != 0) {
#line 162
    printk("\vFailed to resolve the page fault on QP 0x%x\n", qp->mqp.qpn);
  } else {

  }
#line 163
  return;
}
}
#line 178 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static int pagefault_single_data_segment(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ,
                                         u32 key , u64 io_virt , size_t bcnt , u32 *bytes_mapped ) 
{ 
  struct mlx5_ib_dev *mib_dev ;
  struct mlx5_ib_dev *tmp ;
  int srcu_key ;
  unsigned int current_seq ;
  u64 start_idx ;
  int npages ;
  int ret ;
  struct mlx5_ib_mr *mr ;
  u64 access_mask ;
  struct _ddebug descriptor ;
  long tmp___0 ;
  int __var ;
  int tmp___1 ;
  u32 new_mappings ;
  u32 __min1 ;
  u32 __min2 ;
  struct ib_umem_odp *odp_data ;
  unsigned long timeout ;
  unsigned long tmp___2 ;
  unsigned long tmp___3 ;

  {
#line 183
  tmp = to_mdev((qp->ibqp.pd)->device);
#line 183
  mib_dev = tmp;
#line 187
  npages = 0;
#line 187
  ret = 0;
#line 189
  access_mask = 1ULL;
#line 191
  srcu_key = srcu_read_lock(& mib_dev->mr_srcu);
#line 192
  mr = mlx5_ib_odp_find_mr_lkey(mib_dev, key);
#line 198
  if ((unsigned long )mr == (unsigned long )((struct mlx5_ib_mr *)0) || (unsigned long )mr->ibmr.pd == (unsigned long )((struct ib_pd *)0)) {
#line 199
    printk("\vFailed to find relevant mr for lkey=0x%06x, probably the MR was destroyed\n",
           key);
#line 201
    ret = -14;
#line 202
    goto srcu_unlock;
  } else {

  }
#line 204
  if ((unsigned long )(mr->umem)->odp_data == (unsigned long )((struct ib_umem_odp *)0)) {
#line 205
    descriptor.modname = "mlx5_ib";
#line 205
    descriptor.function = "pagefault_single_data_segment";
#line 205
    descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c";
#line 205
    descriptor.format = "skipping non ODP MR (lkey=0x%06x) in page fault handler.\n";
#line 205
    descriptor.lineno = 206U;
#line 205
    descriptor.flags = 0U;
#line 205
    tmp___0 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 205
    if (tmp___0 != 0L) {
#line 205
      __dynamic_pr_debug(& descriptor, "skipping non ODP MR (lkey=0x%06x) in page fault handler.\n",
                         key);
    } else {

    }
#line 207
    if ((unsigned long )bytes_mapped != (unsigned long )((u32 *)0U)) {
#line 208
      *bytes_mapped = *bytes_mapped + ((u32 )bcnt - pfault->mpfault.bytes_committed);
    } else {

    }
#line 210
    goto srcu_unlock;
  } else {

  }
#line 212
  if ((unsigned long )mr->ibmr.pd != (unsigned long )qp->ibqp.pd) {
#line 213
    printk("\vPage-fault with different PDs for QP and MR.\n");
#line 214
    ret = -14;
#line 215
    goto srcu_unlock;
  } else {

  }
#line 218
  __var = 0;
#line 218
  current_seq = (unsigned int )*((int volatile   *)(& ((mr->umem)->odp_data)->notifiers_seq));
#line 223
  __asm__  volatile   ("": : : "memory");
#line 230
  io_virt = (u64 )pfault->mpfault.bytes_committed + io_virt;
#line 231
  bcnt = bcnt - (size_t )pfault->mpfault.bytes_committed;
#line 233
  start_idx = (io_virt - (mr->mmr.iova & 0xfffffffffffff000ULL)) >> 12;
#line 235
  if ((mr->umem)->writable != 0) {
#line 236
    access_mask = access_mask | 2ULL;
  } else {

  }
#line 237
  npages = ib_umem_odp_map_dma_pages(mr->umem, io_virt, (u64 )bcnt, access_mask, (unsigned long )current_seq);
#line 239
  if (npages < 0) {
#line 240
    ret = npages;
#line 241
    goto srcu_unlock;
  } else {

  }
#line 244
  if (npages > 0) {
#line 245
    mutex_lock_nested(& ((mr->umem)->odp_data)->umem_mutex, 0U);
#line 246
    tmp___1 = ib_umem_mmu_notifier_retry(mr->umem, (unsigned long )current_seq);
#line 246
    if (tmp___1 == 0) {
#line 252
      ret = mlx5_ib_update_mtt(mr, start_idx, npages, 0);
    } else {
#line 254
      ret = -11;
    }
#line 256
    mutex_unlock(& ((mr->umem)->odp_data)->umem_mutex);
#line 257
    if (ret < 0) {
#line 258
      if (ret != -11) {
#line 259
        printk("\vFailed to update mkey page tables\n");
      } else {

      }
#line 260
      goto srcu_unlock;
    } else {

    }
#line 263
    if ((unsigned long )bytes_mapped != (unsigned long )((u32 *)0U)) {
#line 264
      new_mappings = (u32 )((unsigned long )npages) * 4096U - ((u32 )io_virt & 4095U);
#line 266
      __min1 = new_mappings;
#line 266
      __min2 = (u32 )bcnt;
#line 266
      *bytes_mapped = *bytes_mapped + (__min1 < __min2 ? __min1 : __min2);
    } else {

    }
  } else {

  }
  srcu_unlock: ;
#line 271
  if (ret == -11) {
#line 272
    if (((mr->umem)->odp_data)->dying == 0) {
#line 273
      odp_data = (mr->umem)->odp_data;
#line 274
      tmp___2 = msecs_to_jiffies(1000U);
#line 274
      timeout = tmp___2;
#line 277
      tmp___3 = wait_for_completion_timeout(& odp_data->notifier_completion, timeout);
#line 277
      if (tmp___3 == 0UL) {
#line 280
        printk("\ftimeout waiting for mmu notifier completion\n");
      } else {

      }
    } else {
#line 284
      ret = -14;
    }
  } else {

  }
#line 287
  srcu_read_unlock(& mib_dev->mr_srcu, srcu_key);
#line 288
  pfault->mpfault.bytes_committed = 0U;
#line 289
  return (ret != 0 ? ret : npages);
}
}
#line 310 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static int pagefault_data_segments(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ,
                                   void *wqe , void *wqe_end , u32 *bytes_mapped ,
                                   u32 *total_wqe_bytes , int receive_queue ) 
{ 
  int ret ;
  int npages ;
  u64 io_virt ;
  u32 key ;
  u32 byte_count ;
  size_t bcnt ;
  int inline_segment ;
  struct mlx5_wqe_data_seg *dseg ;
  __u64 tmp ;
  __u32 tmp___0 ;
  __u32 tmp___1 ;
  size_t __min1 ;
  size_t __min2 ;
  size_t __min1___0 ;
  size_t __min2___0 ;

  {
#line 315
  ret = 0;
#line 315
  npages = 0;
#line 323
  if (receive_queue != 0 && (unsigned long )qp->ibqp.srq != (unsigned long )((struct ib_srq *)0)) {
#line 324
    wqe = wqe + 16UL;
  } else {

  }
#line 326
  if ((unsigned long )bytes_mapped != (unsigned long )((u32 *)0U)) {
#line 327
    *bytes_mapped = 0U;
  } else {

  }
#line 328
  if ((unsigned long )total_wqe_bytes != (unsigned long )((u32 *)0U)) {
#line 329
    *total_wqe_bytes = 0U;
  } else {

  }
#line 331
  goto ldv_37106;
  ldv_37107: 
#line 332
  dseg = (struct mlx5_wqe_data_seg *)wqe;
#line 334
  tmp = __fswab64(dseg->addr);
#line 334
  io_virt = tmp;
#line 335
  tmp___0 = __fswab32(dseg->lkey);
#line 335
  key = tmp___0;
#line 336
  tmp___1 = __fswab32(dseg->byte_count);
#line 336
  byte_count = tmp___1;
#line 337
  inline_segment = (int )byte_count < 0;
#line 338
  bcnt = (size_t )byte_count & 2147483647UL;
#line 340
  if (inline_segment != 0) {
#line 341
    bcnt = bcnt & 1023UL;
#line 342
    wqe = wqe + ((bcnt + 19UL) & 0xfffffffffffffff0UL);
  } else {
#line 345
    wqe = wqe + 16UL;
  }
#line 349
  if (((receive_queue != 0 && bcnt == 0UL) && key == 256U) && io_virt == 0ULL) {
#line 351
    goto ldv_37099;
  } else {

  }
#line 353
  if (inline_segment == 0 && (unsigned long )total_wqe_bytes != (unsigned long )((u32 *)0U)) {
#line 354
    __min1 = bcnt;
#line 354
    __min2 = (size_t )pfault->mpfault.bytes_committed;
#line 354
    *total_wqe_bytes = *total_wqe_bytes + ((u32 )bcnt - (u32 )(__min1 < __min2 ? __min1 : __min2));
  } else {

  }
#line 359
  if (bcnt == 0UL) {
#line 360
    bcnt = 2147483648UL;
  } else {

  }
#line 362
  if (inline_segment != 0 || (size_t )pfault->mpfault.bytes_committed >= bcnt) {
#line 364
    __min1___0 = bcnt;
#line 364
    __min2___0 = (size_t )pfault->mpfault.bytes_committed;
#line 364
    pfault->mpfault.bytes_committed = pfault->mpfault.bytes_committed - (u32 )(__min1___0 < __min2___0 ? __min1___0 : __min2___0);
#line 366
    goto ldv_37106;
  } else {

  }
#line 369
  ret = pagefault_single_data_segment(qp, pfault, key, io_virt, bcnt, bytes_mapped);
#line 371
  if (ret < 0) {
#line 372
    goto ldv_37099;
  } else {

  }
#line 373
  npages = npages + ret;
  ldv_37106: ;
#line 331
  if ((unsigned long )wqe < (unsigned long )wqe_end) {
#line 333
    goto ldv_37107;
  } else {

  }
  ldv_37099: ;
#line 376
  return (ret < 0 ? ret : npages);
}
}
#line 383 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static int mlx5_ib_mr_initiator_pfault_handler(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ,
                                               void **wqe , void **wqe_end , int wqe_length ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_wqe_ctrl_seg *ctrl ;
  u16 wqe_index ;
  unsigned int ds ;
  unsigned int opcode ;
  __u32 tmp___0 ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;
  __u32 tmp___3 ;
  struct task_struct *tmp___4 ;

  {
#line 387
  tmp = to_mdev((qp->ibqp.pd)->device);
#line 387
  dev = tmp;
#line 388
  ctrl = (struct mlx5_wqe_ctrl_seg *)*wqe;
#line 389
  wqe_index = pfault->mpfault.__annonCompField70.wqe.wqe_index;
#line 395
  tmp___0 = __fswab32(ctrl->qpn_ds);
#line 395
  ds = tmp___0 & 63U;
#line 396
  if (ds * 16U > (unsigned int )wqe_length) {
#line 397
    tmp___1 = get_current();
#line 397
    printk("\v%s:%s:%d:(pid %d): Unable to read the complete WQE. ds = 0x%x, ret = 0x%x\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_mr_initiator_pfault_handler", 398,
           tmp___1->pid, ds, wqe_length);
#line 399
    return (-14);
  } else {

  }
#line 402
  if (ds == 0U) {
#line 403
    tmp___2 = get_current();
#line 403
    printk("\v%s:%s:%d:(pid %d): Got WQE with zero DS. wqe_index=%x, qpn=%x\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_mr_initiator_pfault_handler", 404, tmp___2->pid, (int )wqe_index,
           qp->mqp.qpn);
#line 405
    return (-14);
  } else {

  }
#line 429
  *wqe_end = *wqe + (unsigned long )(ds * 16U);
#line 430
  *wqe = *wqe + 16UL;
#line 432
  tmp___3 = __fswab32(ctrl->opmod_idx_opcode);
#line 432
  opcode = tmp___3 & 255U;
#line 434
  switch ((unsigned int )qp->ibqp.qp_type) {
  case 2U: ;
#line 436
  switch (opcode) {
  case 10U: ;
  case 11U: ;
  case 1U: ;
#line 440
  if ((dev->odp_caps.per_transport_caps.rc_odp_caps & 1U) == 0U) {
#line 442
    goto invalid_transport_or_opcode;
  } else {

  }
#line 443
  goto ldv_37126;
  case 8U: ;
  case 9U: ;
#line 446
  if ((dev->odp_caps.per_transport_caps.rc_odp_caps & 4U) == 0U) {
#line 448
    goto invalid_transport_or_opcode;
  } else {

  }
#line 449
  *wqe = *wqe + 16UL;
#line 450
  goto ldv_37126;
  case 16U: ;
#line 452
  if ((dev->odp_caps.per_transport_caps.rc_odp_caps & 8U) == 0U) {
#line 454
    goto invalid_transport_or_opcode;
  } else {

  }
#line 455
  *wqe = *wqe + 16UL;
#line 456
  goto ldv_37126;
  default: ;
#line 458
  goto invalid_transport_or_opcode;
  }
  ldv_37126: ;
#line 460
  goto ldv_37131;
  case 4U: ;
#line 462
  switch (opcode) {
  case 10U: ;
  case 11U: ;
#line 465
  if ((dev->odp_caps.per_transport_caps.ud_odp_caps & 1U) == 0U) {
#line 467
    goto invalid_transport_or_opcode;
  } else {

  }
#line 468
  *wqe = *wqe + 48UL;
#line 469
  goto ldv_37135;
  default: ;
#line 471
  goto invalid_transport_or_opcode;
  }
  ldv_37135: ;
#line 473
  goto ldv_37131;
  default: ;
  invalid_transport_or_opcode: 
#line 476
  tmp___4 = get_current();
#line 476
  printk("\v%s:%s:%d:(pid %d): ODP fault on QP of an unsupported opcode or transport. transport: 0x%x opcode: 0x%x.\n",
         (char *)(& dev->ib_dev.name), "mlx5_ib_mr_initiator_pfault_handler", 477,
         tmp___4->pid, (unsigned int )qp->ibqp.qp_type, opcode);
#line 478
  return (-14);
  }
  ldv_37131: ;
#line 481
  return (0);
}
}
#line 488 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static int mlx5_ib_mr_responder_pfault_handler(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ,
                                               void **wqe , void **wqe_end , int wqe_length ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  struct mlx5_ib_wq *wq ;
  int wqe_size ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;
  struct task_struct *tmp___3 ;

  {
#line 492
  tmp = to_mdev((qp->ibqp.pd)->device);
#line 492
  dev = tmp;
#line 493
  wq = & qp->rq;
#line 494
  wqe_size = 1 << wq->wqe_shift;
#line 496
  if ((unsigned long )qp->ibqp.srq != (unsigned long )((struct ib_srq *)0)) {
#line 497
    tmp___0 = get_current();
#line 497
    printk("\v%s:%s:%d:(pid %d): ODP fault on SRQ is not supported\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_mr_responder_pfault_handler", 497, tmp___0->pid);
#line 498
    return (-14);
  } else {

  }
#line 501
  if (qp->wq_sig != 0) {
#line 502
    tmp___1 = get_current();
#line 502
    printk("\v%s:%s:%d:(pid %d): ODP fault with WQE signatures is not supported\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_mr_responder_pfault_handler", 502,
           tmp___1->pid);
#line 503
    return (-14);
  } else {

  }
#line 506
  if (wqe_size > wqe_length) {
#line 507
    tmp___2 = get_current();
#line 507
    printk("\v%s:%s:%d:(pid %d): Couldn\'t read all of the receive WQE\'s content\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_mr_responder_pfault_handler", 507,
           tmp___2->pid);
#line 508
    return (-14);
  } else {

  }
#line 511
  switch ((unsigned int )qp->ibqp.qp_type) {
  case 2U: ;
#line 513
  if ((dev->odp_caps.per_transport_caps.rc_odp_caps & 2U) == 0U) {
#line 515
    goto invalid_transport_or_opcode;
  } else {

  }
#line 516
  goto ldv_37151;
  default: ;
  invalid_transport_or_opcode: 
#line 519
  tmp___3 = get_current();
#line 519
  printk("\v%s:%s:%d:(pid %d): ODP fault on QP of an unsupported transport. transport: 0x%x\n",
         (char *)(& dev->ib_dev.name), "mlx5_ib_mr_responder_pfault_handler", 520,
         tmp___3->pid, (unsigned int )qp->ibqp.qp_type);
#line 521
  return (-14);
  }
  ldv_37151: 
#line 524
  *wqe_end = *wqe + (unsigned long )wqe_size;
#line 526
  return (0);
}
}
#line 529 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static void mlx5_ib_mr_wqe_pfault_handler(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ) 
{ 
  struct mlx5_ib_dev *dev ;
  struct mlx5_ib_dev *tmp ;
  int ret ;
  void *wqe ;
  void *wqe_end ;
  u32 bytes_mapped ;
  u32 total_wqe_bytes ;
  char *buffer ;
  int resume_with_error ;
  u16 wqe_index ;
  int requestor ;
  unsigned long tmp___0 ;
  struct task_struct *tmp___1 ;
  struct task_struct *tmp___2 ;
  struct task_struct *tmp___3 ;
  struct task_struct *tmp___4 ;
  struct _ddebug descriptor ;
  struct task_struct *tmp___5 ;
  long tmp___6 ;

  {
#line 532
  tmp = to_mdev((qp->ibqp.pd)->device);
#line 532
  dev = tmp;
#line 536
  buffer = (char *)0;
#line 537
  resume_with_error = 0;
#line 538
  wqe_index = pfault->mpfault.__annonCompField70.wqe.wqe_index;
#line 539
  requestor = (int )pfault->mpfault.flags & 1;
#line 541
  tmp___0 = __get_free_pages(208U, 0U);
#line 541
  buffer = (char *)tmp___0;
#line 542
  if ((unsigned long )buffer == (unsigned long )((char *)0)) {
#line 543
    tmp___1 = get_current();
#line 543
    printk("\v%s:%s:%d:(pid %d): Error allocating memory for IO page fault handling.\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_mr_wqe_pfault_handler", 543, tmp___1->pid);
#line 544
    resume_with_error = 1;
#line 545
    goto resolve_page_fault;
  } else {

  }
#line 548
  ret = mlx5_ib_read_user_wqe(qp, requestor, (int )wqe_index, (void *)buffer, 4096U);
#line 550
  if (ret < 0) {
#line 551
    tmp___2 = get_current();
#line 551
    printk("\v%s:%s:%d:(pid %d): Failed reading a WQE following page fault, error=%x, wqe_index=%x, qpn=%x\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_mr_wqe_pfault_handler", 552, tmp___2->pid,
           - ret, (int )wqe_index, qp->mqp.qpn);
#line 553
    resume_with_error = 1;
#line 554
    goto resolve_page_fault;
  } else {

  }
#line 557
  wqe = (void *)buffer;
#line 558
  if (requestor != 0) {
#line 559
    ret = mlx5_ib_mr_initiator_pfault_handler(qp, pfault, & wqe, & wqe_end, ret);
  } else {
#line 562
    ret = mlx5_ib_mr_responder_pfault_handler(qp, pfault, & wqe, & wqe_end, ret);
  }
#line 564
  if (ret < 0) {
#line 565
    resume_with_error = 1;
#line 566
    goto resolve_page_fault;
  } else {

  }
#line 569
  if ((unsigned long )wqe >= (unsigned long )wqe_end) {
#line 570
    tmp___3 = get_current();
#line 570
    printk("\v%s:%s:%d:(pid %d): ODP fault on invalid WQE.\n", (char *)(& dev->ib_dev.name),
           "mlx5_ib_mr_wqe_pfault_handler", 570, tmp___3->pid);
#line 571
    resume_with_error = 1;
#line 572
    goto resolve_page_fault;
  } else {

  }
#line 575
  ret = pagefault_data_segments(qp, pfault, wqe, wqe_end, & bytes_mapped, & total_wqe_bytes,
                                requestor == 0);
#line 577
  if (ret == -11) {
#line 578
    goto resolve_page_fault;
  } else
#line 579
  if (ret < 0 || total_wqe_bytes > bytes_mapped) {
#line 580
    tmp___4 = get_current();
#line 580
    printk("\v%s:%s:%d:(pid %d): Error getting user pages for page fault. Error: 0x%x\n",
           (char *)(& dev->ib_dev.name), "mlx5_ib_mr_wqe_pfault_handler", 581, tmp___4->pid,
           - ret);
#line 582
    resume_with_error = 1;
#line 583
    goto resolve_page_fault;
  } else {

  }
  resolve_page_fault: 
#line 587
  mlx5_ib_page_fault_resume(qp, pfault, resume_with_error);
#line 588
  descriptor.modname = "mlx5_ib";
#line 588
  descriptor.function = "mlx5_ib_mr_wqe_pfault_handler";
#line 588
  descriptor.filename = "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c";
#line 588
  descriptor.format = "%s:%s:%d:(pid %d): PAGE FAULT completed. QP 0x%x resume_with_error=%d, flags: 0x%x\n";
#line 588
  descriptor.lineno = 589U;
#line 588
  descriptor.flags = 0U;
#line 588
  tmp___6 = ldv__builtin_expect((long )descriptor.flags & 1L, 0L);
#line 588
  if (tmp___6 != 0L) {
#line 588
    tmp___5 = get_current();
#line 588
    __dynamic_pr_debug(& descriptor, "%s:%s:%d:(pid %d): PAGE FAULT completed. QP 0x%x resume_with_error=%d, flags: 0x%x\n",
                       (char *)(& dev->ib_dev.name), "mlx5_ib_mr_wqe_pfault_handler",
                       589, tmp___5->pid, qp->mqp.qpn, resume_with_error, (unsigned int )pfault->mpfault.flags);
  } else {

  }
#line 591
  free_pages((unsigned long )buffer, 0U);
#line 592
  return;
}
}
#line 594 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static int pages_in_range(u64 address , u32 length ) 
{ 


  {
#line 596
  return ((int )((((((u64 )length + address) + 4095ULL) & 0xfffffffffffff000ULL) - (address & 0xfffffffffffff000ULL)) >> 12));
}
}
#line 600 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static void mlx5_ib_mr_rdma_pfault_handler(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ) 
{ 
  struct mlx5_pagefault *mpfault ;
  u64 address ;
  u32 length ;
  u32 prefetch_len ;
  int prefetch_activated ;
  u32 rkey ;
  int ret ;
  struct mlx5_ib_pfault dummy_pfault ;
  u32 _min1 ;
  u32 _min2 ;
  unsigned int _min1___0 ;
  u32 _min2___0 ;
  int tmp ;

  {
#line 603
  mpfault = & pfault->mpfault;
#line 606
  prefetch_len = mpfault->bytes_committed;
#line 607
  prefetch_activated = 0;
#line 608
  rkey = mpfault->__annonCompField70.rdma.r_key;
#line 617
  dummy_pfault.work.data.counter = 0L;
#line 617
  dummy_pfault.work.entry.next = 0;
#line 617
  dummy_pfault.work.entry.prev = 0;
#line 617
  dummy_pfault.work.func = 0;
#line 617
  dummy_pfault.work.lockdep_map.key = 0;
#line 617
  dummy_pfault.work.lockdep_map.class_cache[0] = 0;
#line 617
  dummy_pfault.work.lockdep_map.class_cache[1] = 0;
#line 617
  dummy_pfault.work.lockdep_map.name = 0;
#line 617
  dummy_pfault.work.lockdep_map.cpu = 0;
#line 617
  dummy_pfault.work.lockdep_map.ip = 0UL;
#line 617
  dummy_pfault.mpfault.bytes_committed = 0U;
#line 617
  dummy_pfault.mpfault.event_subtype = (unsigned char)0;
#line 617
  dummy_pfault.mpfault.flags = 0;
#line 617
  dummy_pfault.mpfault.__annonCompField70.rdma.r_key = 0U;
#line 617
  dummy_pfault.mpfault.__annonCompField70.rdma.packet_size = 0U;
#line 617
  dummy_pfault.mpfault.__annonCompField70.rdma.rdma_op_len = 0U;
#line 617
  dummy_pfault.mpfault.__annonCompField70.rdma.rdma_va = 0ULL;
#line 619
  dummy_pfault.mpfault.bytes_committed = 0U;
#line 621
  mpfault->__annonCompField70.rdma.rdma_va = mpfault->__annonCompField70.rdma.rdma_va + (u64 )mpfault->bytes_committed;
#line 622
  _min1 = mpfault->bytes_committed;
#line 622
  _min2 = mpfault->__annonCompField70.rdma.rdma_op_len;
#line 622
  mpfault->__annonCompField70.rdma.rdma_op_len = mpfault->__annonCompField70.rdma.rdma_op_len - (_min1 < _min2 ? _min1 : _min2);
#line 624
  mpfault->bytes_committed = 0U;
#line 626
  address = mpfault->__annonCompField70.rdma.rdma_va;
#line 627
  length = mpfault->__annonCompField70.rdma.rdma_op_len;
#line 632
  if (length == 0U) {
#line 633
    prefetch_activated = 1;
#line 634
    length = mpfault->__annonCompField70.rdma.packet_size;
#line 635
    _min1___0 = 4194304U;
#line 635
    _min2___0 = prefetch_len;
#line 635
    prefetch_len = _min1___0 < _min2___0 ? _min1___0 : _min2___0;
  } else {

  }
#line 638
  ret = pagefault_single_data_segment(qp, pfault, rkey, address, (size_t )length,
                                      (u32 *)0U);
#line 640
  if (ret == -11) {
#line 642
    prefetch_activated = 0;
  } else
#line 643
  if (ret < 0) {
#line 644
    mlx5_ib_page_fault_resume(qp, pfault, 1);
#line 645
    return;
  } else {
#line 643
    tmp = pages_in_range(address, length);
#line 643
    if (tmp > ret) {
#line 644
      mlx5_ib_page_fault_resume(qp, pfault, 1);
#line 645
      return;
    } else {

    }
  }
#line 648
  mlx5_ib_page_fault_resume(qp, pfault, 0);
#line 655
  if (prefetch_activated != 0) {
#line 656
    ret = pagefault_single_data_segment(qp, & dummy_pfault, rkey, address, (size_t )prefetch_len,
                                        (u32 *)0U);
#line 660
    if (ret < 0) {
#line 661
      printk("\fPrefetch failed (ret = %d, prefetch_activated = %d) for QPN %d, address: 0x%.16llx, length = 0x%.16x\n",
             ret, prefetch_activated, qp->ibqp.qp_num, address, prefetch_len);
    } else {

    }
  } else {

  }
#line 663
  return;
}
}
#line 668 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_mr_pfault_handler(struct mlx5_ib_qp *qp , struct mlx5_ib_pfault *pfault ) 
{ 
  u8 event_subtype ;

  {
#line 671
  event_subtype = pfault->mpfault.event_subtype;
#line 673
  switch ((int )event_subtype) {
  case 0: 
#line 675
  mlx5_ib_mr_wqe_pfault_handler(qp, pfault);
#line 676
  goto ldv_37198;
  case 1: 
#line 678
  mlx5_ib_mr_rdma_pfault_handler(qp, pfault);
#line 679
  goto ldv_37198;
  default: 
#line 681
  printk("\fInvalid page fault event subtype: 0x%x\n", (int )event_subtype);
#line 683
  mlx5_ib_page_fault_resume(qp, pfault, 1);
#line 684
  goto ldv_37198;
  }
  ldv_37198: ;
#line 687
  return;
}
}
#line 688 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static void mlx5_ib_qp_pfault_action(struct work_struct *work ) 
{ 
  struct mlx5_ib_pfault *pfault ;
  struct work_struct  const  *__mptr ;
  enum mlx5_ib_pagefault_context context ;
  enum mlx5_ib_pagefault_context tmp ;
  struct mlx5_ib_qp *qp ;
  struct mlx5_ib_pfault  const  *__mptr___0 ;

  {
#line 690
  __mptr = (struct work_struct  const  *)work;
#line 690
  pfault = (struct mlx5_ib_pfault *)__mptr;
#line 693
  tmp = mlx5_ib_get_pagefault_context(& pfault->mpfault);
#line 693
  context = tmp;
#line 695
  __mptr___0 = (struct mlx5_ib_pfault  const  *)pfault;
#line 695
  qp = (struct mlx5_ib_qp *)__mptr___0 + - ((unsigned long )context * 120UL + 968UL);
#line 697
  mlx5_ib_mr_pfault_handler(qp, pfault);
#line 698
  return;
}
}
#line 700 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_qp_disable_pagefaults(struct mlx5_ib_qp *qp ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 704
  tmp = spinlock_check(& qp->disable_page_faults_lock);
#line 704
  flags = _raw_spin_lock_irqsave(tmp);
#line 705
  qp->disable_page_faults = 1;
#line 706
  spin_unlock_irqrestore(& qp->disable_page_faults_lock, flags);
#line 713
  ldv_flush_workqueue_150(mlx5_ib_page_fault_wq);
#line 714
  return;
}
}
#line 716 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_qp_enable_pagefaults(struct mlx5_ib_qp *qp ) 
{ 
  unsigned long flags ;
  raw_spinlock_t *tmp ;

  {
#line 720
  tmp = spinlock_check(& qp->disable_page_faults_lock);
#line 720
  flags = _raw_spin_lock_irqsave(tmp);
#line 721
  qp->disable_page_faults = 0;
#line 722
  spin_unlock_irqrestore(& qp->disable_page_faults_lock, flags);
#line 723
  return;
}
}
#line 725 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
static void mlx5_ib_pfault_handler(struct mlx5_core_qp *qp , struct mlx5_pagefault *pfault ) 
{ 
  struct mlx5_ib_qp *mibqp ;
  struct mlx5_ib_qp *tmp ;
  enum mlx5_ib_pagefault_context context ;
  enum mlx5_ib_pagefault_context tmp___0 ;
  struct mlx5_ib_pfault *qp_pfault ;

  {
#line 735
  tmp = to_mibqp(qp);
#line 735
  mibqp = tmp;
#line 736
  tmp___0 = mlx5_ib_get_pagefault_context(pfault);
#line 736
  context = tmp___0;
#line 738
  qp_pfault = (struct mlx5_ib_pfault *)(& mibqp->pagefaults) + (unsigned long )context;
#line 740
  qp_pfault->mpfault = *pfault;
#line 743
  spin_lock(& mibqp->disable_page_faults_lock);
#line 744
  if (mibqp->disable_page_faults == 0) {
#line 745
    queue_work___0(mlx5_ib_page_fault_wq, & qp_pfault->work);
  } else {

  }
#line 746
  spin_unlock(& mibqp->disable_page_faults_lock);
#line 747
  return;
}
}
#line 749 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_odp_create_qp(struct mlx5_ib_qp *qp ) 
{ 
  int i ;
  struct lock_class_key __key ;
  struct lock_class_key __key___0 ;
  atomic_long_t __constr_expr_0 ;

  {
#line 753
  qp->disable_page_faults = 1;
#line 754
  spinlock_check(& qp->disable_page_faults_lock);
#line 754
  __raw_spin_lock_init(& qp->disable_page_faults_lock.__annonCompField18.rlock, "&(&qp->disable_page_faults_lock)->rlock",
                       & __key);
#line 756
  qp->mqp.pfault_handler = & mlx5_ib_pfault_handler;
#line 758
  i = 0;
#line 758
  goto ldv_37240;
  ldv_37239: 
#line 759
  __init_work(& qp->pagefaults[i].work, 0);
#line 759
  __constr_expr_0.counter = 137438953408L;
#line 759
  qp->pagefaults[i].work.data = __constr_expr_0;
#line 759
  lockdep_init_map(& qp->pagefaults[i].work.lockdep_map, "(&qp->pagefaults[i].work)",
                   & __key___0, 0);
#line 759
  INIT_LIST_HEAD(& qp->pagefaults[i].work.entry);
#line 759
  qp->pagefaults[i].work.func = & mlx5_ib_qp_pfault_action;
#line 758
  i = i + 1;
  ldv_37240: ;
#line 758
  if (i <= 3) {
#line 760
    goto ldv_37239;
  } else {

  }

#line 765
  return;
}
}
#line 762 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
int mlx5_ib_odp_init_one(struct mlx5_ib_dev *ibdev ) 
{ 
  int ret ;
  struct lock_class_key __srcu_key ;
  int tmp ;

  {
#line 766
  tmp = __init_srcu_struct(& ibdev->mr_srcu, "&ibdev->mr_srcu", & __srcu_key);
#line 766
  ret = tmp;
#line 767
  if (ret != 0) {
#line 768
    return (ret);
  } else {

  }
#line 770
  return (0);
}
}
#line 773 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_odp_remove_one(struct mlx5_ib_dev *ibdev ) 
{ 


  {
#line 775
  cleanup_srcu_struct(& ibdev->mr_srcu);
#line 776
  return;
}
}
#line 778 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
int mlx5_ib_odp_init(void) 
{ 
  struct lock_class_key __key ;
  char const   *__lock_name ;
  struct workqueue_struct *tmp ;

  {
#line 781
  __lock_name = "\"%s\"\"mlx5_ib_page_faults\"";
#line 781
  tmp = __alloc_workqueue_key("%s", 131082U, 1, & __key, __lock_name, (char *)"mlx5_ib_page_faults");
#line 781
  mlx5_ib_page_fault_wq = tmp;
#line 782
  if ((unsigned long )mlx5_ib_page_fault_wq == (unsigned long )((struct workqueue_struct *)0)) {
#line 783
    return (-12);
  } else {

  }
#line 785
  return (0);
}
}
#line 788 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.c"
void mlx5_ib_odp_cleanup(void) 
{ 


  {
#line 790
  ldv_destroy_workqueue_151(mlx5_ib_page_fault_wq);
#line 791
  return;
}
}
#line 104 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void work_init_3(void) 
{ 


  {
#line 105
  ldv_work_3_0 = 0;
#line 106
  ldv_work_3_1 = 0;
#line 107
  ldv_work_3_2 = 0;
#line 108
  ldv_work_3_3 = 0;
#line 109
  return;
}
}
#line 112 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void activate_work_3(struct work_struct *work , int state ) 
{ 


  {
#line 113
  if (ldv_work_3_0 == 0) {
#line 114
    ldv_work_struct_3_0 = work;
#line 115
    ldv_work_3_0 = state;
#line 116
    return;
  } else {

  }
#line 119
  if (ldv_work_3_1 == 0) {
#line 120
    ldv_work_struct_3_1 = work;
#line 121
    ldv_work_3_1 = state;
#line 122
    return;
  } else {

  }
#line 125
  if (ldv_work_3_2 == 0) {
#line 126
    ldv_work_struct_3_2 = work;
#line 127
    ldv_work_3_2 = state;
#line 128
    return;
  } else {

  }
#line 131
  if (ldv_work_3_3 == 0) {
#line 132
    ldv_work_struct_3_3 = work;
#line 133
    ldv_work_3_3 = state;
#line 134
    return;
  } else {

  }
#line 136
  return;
}
}
#line 139 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void call_and_disable_work_3(struct work_struct *work ) 
{ 


  {
#line 142
  if ((ldv_work_3_0 == 2 || ldv_work_3_0 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_0) {
#line 144
    mlx5_ib_qp_pfault_action(work);
#line 145
    ldv_work_3_0 = 1;
#line 146
    return;
  } else {

  }
#line 148
  if ((ldv_work_3_1 == 2 || ldv_work_3_1 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_1) {
#line 150
    mlx5_ib_qp_pfault_action(work);
#line 151
    ldv_work_3_1 = 1;
#line 152
    return;
  } else {

  }
#line 154
  if ((ldv_work_3_2 == 2 || ldv_work_3_2 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_2) {
#line 156
    mlx5_ib_qp_pfault_action(work);
#line 157
    ldv_work_3_2 = 1;
#line 158
    return;
  } else {

  }
#line 160
  if ((ldv_work_3_3 == 2 || ldv_work_3_3 == 3) && (unsigned long )work == (unsigned long )ldv_work_struct_3_3) {
#line 162
    mlx5_ib_qp_pfault_action(work);
#line 163
    ldv_work_3_3 = 1;
#line 164
    return;
  } else {

  }
#line 166
  return;
}
}
#line 169 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void disable_work_3(struct work_struct *work ) 
{ 


  {
#line 171
  if ((ldv_work_3_0 == 3 || ldv_work_3_0 == 2) && (unsigned long )ldv_work_struct_3_0 == (unsigned long )work) {
#line 173
    ldv_work_3_0 = 1;
  } else {

  }
#line 175
  if ((ldv_work_3_1 == 3 || ldv_work_3_1 == 2) && (unsigned long )ldv_work_struct_3_1 == (unsigned long )work) {
#line 177
    ldv_work_3_1 = 1;
  } else {

  }
#line 179
  if ((ldv_work_3_2 == 3 || ldv_work_3_2 == 2) && (unsigned long )ldv_work_struct_3_2 == (unsigned long )work) {
#line 181
    ldv_work_3_2 = 1;
  } else {

  }
#line 183
  if ((ldv_work_3_3 == 3 || ldv_work_3_3 == 2) && (unsigned long )ldv_work_struct_3_3 == (unsigned long )work) {
#line 185
    ldv_work_3_3 = 1;
  } else {

  }
#line 186
  return;
}
}
#line 190 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void invoke_work_3(void) 
{ 
  int tmp ;

  {
#line 192
  tmp = __VERIFIER_nondet_int();
#line 192
  switch (tmp) {
  case 0: ;
#line 194
  if (ldv_work_3_0 == 2 || ldv_work_3_0 == 3) {
#line 195
    ldv_work_3_0 = 4;
#line 196
    mlx5_ib_qp_pfault_action(ldv_work_struct_3_0);
#line 197
    ldv_work_3_0 = 1;
  } else {

  }
#line 200
  goto ldv_37281;
  case 1: ;
#line 202
  if (ldv_work_3_1 == 2 || ldv_work_3_1 == 3) {
#line 203
    ldv_work_3_1 = 4;
#line 204
    mlx5_ib_qp_pfault_action(ldv_work_struct_3_0);
#line 205
    ldv_work_3_1 = 1;
  } else {

  }
#line 208
  goto ldv_37281;
  case 2: ;
#line 210
  if (ldv_work_3_2 == 2 || ldv_work_3_2 == 3) {
#line 211
    ldv_work_3_2 = 4;
#line 212
    mlx5_ib_qp_pfault_action(ldv_work_struct_3_0);
#line 213
    ldv_work_3_2 = 1;
  } else {

  }
#line 216
  goto ldv_37281;
  case 3: ;
#line 218
  if (ldv_work_3_3 == 2 || ldv_work_3_3 == 3) {
#line 219
    ldv_work_3_3 = 4;
#line 220
    mlx5_ib_qp_pfault_action(ldv_work_struct_3_0);
#line 221
    ldv_work_3_3 = 1;
  } else {

  }
#line 224
  goto ldv_37281;
  default: 
#line 225
  ldv_stop();
  }
  ldv_37281: ;
#line 227
  return;
}
}
#line 231 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void call_and_disable_all_3(int state ) 
{ 


  {
#line 233
  if (ldv_work_3_0 == state) {
#line 234
    call_and_disable_work_3(ldv_work_struct_3_0);
  } else {

  }
#line 235
  if (ldv_work_3_1 == state) {
#line 236
    call_and_disable_work_3(ldv_work_struct_3_1);
  } else {

  }
#line 237
  if (ldv_work_3_2 == state) {
#line 238
    call_and_disable_work_3(ldv_work_struct_3_2);
  } else {

  }
#line 239
  if (ldv_work_3_3 == state) {
#line 240
    call_and_disable_work_3(ldv_work_struct_3_3);
  } else {

  }
#line 241
  return;
}
}
#line 267 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
bool ldv_queue_work_on_145(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type ldv_func_res ;
  bool tmp ;

  {
#line 271
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 271
  ldv_func_res = tmp;
#line 273
  activate_work_3(ldv_func_arg3, 2);
#line 275
  return (ldv_func_res);
}
}
#line 278 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
bool ldv_queue_delayed_work_on_146(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___0 ldv_func_res ;
  bool tmp ;

  {
#line 282
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 282
  ldv_func_res = tmp;
#line 284
  activate_work_3(& ldv_func_arg3->work, 2);
#line 286
  return (ldv_func_res);
}
}
#line 289 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
bool ldv_queue_work_on_147(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                           struct work_struct *ldv_func_arg3 ) 
{ 
  ldv_func_ret_type___1 ldv_func_res ;
  bool tmp ;

  {
#line 293
  tmp = queue_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 293
  ldv_func_res = tmp;
#line 295
  activate_work_3(ldv_func_arg3, 2);
#line 297
  return (ldv_func_res);
}
}
#line 300 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void ldv_flush_workqueue_148(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 303
  flush_workqueue(ldv_func_arg1);
#line 305
  call_and_disable_all_3(2);
#line 306
  return;
}
}
#line 308 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
bool ldv_queue_delayed_work_on_149(int ldv_func_arg1 , struct workqueue_struct *ldv_func_arg2 ,
                                   struct delayed_work *ldv_func_arg3 , unsigned long ldv_func_arg4 ) 
{ 
  ldv_func_ret_type___2 ldv_func_res ;
  bool tmp ;

  {
#line 312
  tmp = queue_delayed_work_on(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3, ldv_func_arg4);
#line 312
  ldv_func_res = tmp;
#line 314
  activate_work_3(& ldv_func_arg3->work, 2);
#line 316
  return (ldv_func_res);
}
}
#line 319 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void ldv_flush_workqueue_150(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 322
  flush_workqueue(ldv_func_arg1);
#line 324
  call_and_disable_all_3(2);
#line 325
  return;
}
}
#line 327 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/dscv/ri/08_1a/drivers/infiniband/hw/mlx5/odp.o.c.prepared"
void ldv_destroy_workqueue_151(struct workqueue_struct *ldv_func_arg1 ) 
{ 


  {
#line 330
  destroy_workqueue(ldv_func_arg1);
#line 332
  call_and_disable_all_3(2);
#line 333
  return;
}
}
#line 8 "/home/ldvuser/ldv/inst/kernel-rules/verifier/sv-comp.h"
extern void *memset(void * , int  , size_t  ) ;
#line 12 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
__inline static void ldv_error(void) 
{ 


  {
  ERROR: ;
#line 14
  __VERIFIER_error();
}
}
#line 7 "/home/ldvuser/ldv/inst/kernel-rules/kernel-model/ERR.inc"
bool ldv_is_err(void const   *ptr ) 
{ 


  {
#line 10
  return ((unsigned long )ptr > 2012UL);
}
}
#line 14 "/home/ldvuser/ldv/inst/kernel-rules/kernel-model/ERR.inc"
void *ldv_err_ptr(long error ) 
{ 


  {
#line 17
  return ((void *)(2012L - error));
}
}
#line 21 "/home/ldvuser/ldv/inst/kernel-rules/kernel-model/ERR.inc"
long ldv_ptr_err(void const   *ptr ) 
{ 


  {
#line 24
  return ((long )(2012UL - (unsigned long )ptr));
}
}
#line 28 "/home/ldvuser/ldv/inst/kernel-rules/kernel-model/ERR.inc"
bool ldv_is_err_or_null(void const   *ptr ) 
{ 
  bool tmp ;
  int tmp___0 ;

  {
#line 31
  if ((unsigned long )ptr == (unsigned long )((void const   *)0)) {
#line 31
    tmp___0 = 1;
  } else {
#line 31
    tmp = ldv_is_err(ptr);
#line 31
    if ((int )tmp) {
#line 31
      tmp___0 = 1;
    } else {
#line 31
      tmp___0 = 0;
    }
  }
#line 31
  return ((bool )tmp___0);
}
}
#line 7 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
int ldv_module_refcounter  =    1;
#line 10 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
void ldv_module_get(struct module *module ) 
{ 


  {
#line 13
  if ((unsigned long )module != (unsigned long )((struct module *)0)) {
#line 15
    ldv_module_refcounter = ldv_module_refcounter + 1;
  } else {

  }
#line 16
  return;
}
}
#line 20 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
int ldv_try_module_get(struct module *module ) 
{ 
  int module_get_succeeded ;

  {
#line 25
  if ((unsigned long )module != (unsigned long )((struct module *)0)) {
#line 28
    module_get_succeeded = ldv_undef_int();
#line 30
    if (module_get_succeeded == 1) {
#line 32
      ldv_module_refcounter = ldv_module_refcounter + 1;
#line 34
      return (1);
    } else {
#line 39
      return (0);
    }
  } else {

  }
#line 41
  return (0);
}
}
#line 45 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
void ldv_module_put(struct module *module ) 
{ 


  {
#line 48
  if ((unsigned long )module != (unsigned long )((struct module *)0)) {
#line 50
    if (ldv_module_refcounter <= 1) {
#line 50
      ldv_error();
    } else {

    }
#line 52
    ldv_module_refcounter = ldv_module_refcounter - 1;
  } else {

  }
#line 54
  return;
}
}
#line 57 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
void ldv_module_put_and_exit(void) 
{ 


  {
#line 59
  ldv_module_put((struct module *)1);
  LDV_STOP: ;
#line 61
  goto LDV_STOP;
}
}
#line 65 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
unsigned int ldv_module_refcount(void) 
{ 


  {
#line 68
  return ((unsigned int )(ldv_module_refcounter + -1));
}
}
#line 72 "/work/ldvuser/mutilin/launch/work/current--X--drivers/--X--defaultlinux-4.2-rc1.tar.xz--X--08_1a--X--cpachecker/linux-4.2-rc1.tar.xz/csd_deg_dscv/4906/dscv_tempdir/rule-instrumentor/08_1a/common-model/ldv_common_model.c"
void ldv_check_final_state(void) 
{ 


  {
#line 75
  if (ldv_module_refcounter != 1) {
#line 75
    ldv_error();
  } else {

  }
#line 79
  return;
}
}
